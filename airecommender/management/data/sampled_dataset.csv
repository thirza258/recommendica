title,category,summary,authors
Learning Chordal Markov Networks by Constraint Satisfaction,Artificial Intelligence,"We investigate the problem of learning the structure of a Markov network from
data. It is shown that the structure of such networks can be described in terms
of constraints which enables the use of existing solver technology with
optimization capabilities to compute optimal networks starting from initial
scores computed from the data. To achieve efficient encodings, we develop a
novel characterization of Markov network structure using a balancing condition
on the separators between cliques forming the network. The resulting
translations into propositional satisfiability and its extensions such as
maximum satisfiability, satisfiability modulo theories, and answer set
programming, enable us to prove optimal certain network structures which have
been previously found by stochastic search.","['Jukka Corander', 'Tomi Janhunen', 'Jussi Rintanen', 'Henrik Nyman', 'Johan Pensar']"
3D Semantic Trajectory Reconstruction from 3D Pixel Continuum,Computer Vision and Pattern Recognition,"This paper presents a method to reconstruct dense semantic trajectory stream
of human interactions in 3D from synchronized multiple videos. The interactions
inherently introduce self-occlusion and illumination/appearance/shape changes,
resulting in highly fragmented trajectory reconstruction with noisy and coarse
semantic labels. Our conjecture is that among many views, there exists a set of
views that can confidently recognize the visual semantic label of a 3D
trajectory. We introduce a new representation called 3D semantic map---a
probability distribution over the semantic labels per trajectory. We construct
the 3D semantic map by reasoning about visibility and 2D recognition confidence
based on view-pooling, i.e., finding the view that best represents the
semantics of the trajectory. Using the 3D semantic map, we precisely infer all
trajectory labels jointly by considering the affinity between long range
trajectories via estimating their local rigid transformations. This inference
quantitatively outperforms the baseline approaches in terms of predictive
validity, representation robustness, and affinity effectiveness. We demonstrate
that our algorithm can robustly compute the semantic labels of a large scale
trajectory set involving real-world human interactions with object, scenes, and
people.","['Jae Shin Yoon', 'Ziwei Li', 'Hyun Soo Park']"
Enhanced version of AdaBoostM1 with J48 Tree learning method,Machine Learning (Statistics),"Machine Learning focuses on the construction and study of systems that can
learn from data. This is connected with the classification problem, which
usually is what Machine Learning algorithms are designed to solve. When a
machine learning method is used by people with no special expertise in machine
learning, it is important that the method be robust in classification, in the
sense that reasonable performance is obtained with minimal tuning of the
problem at hand. Algorithms are evaluated based on how robust they can classify
the given data. In this paper, we propose a quantifiable measure of robustness,
and describe a particular learning method that is robust according to this
measure in the context of classification problem. We proposed Adaptive Boosting
(AdaBoostM1) with J48(C4.5 tree) as a base learner with tuning weight threshold
(P) and number of iterations (I) for boosting algorithm. To benchmark the
performance, we used the baseline classifier, AdaBoostM1 with Decision Stump as
base learner without tuning parameters. By tuning parameters and using J48 as
base learner, we are able to reduce the overall average error rate ratio
(errorC/errorNB) from 2.4 to 0.9 for development sets of data and 2.1 to 1.2
for evaluation sets of data.","['Kyongche Kang', 'Jack Michalak']"
Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning,Computation and Language (Natural Language Processing),"Prompt tuning, in which a base pretrained model is adapted to each task via
conditioning on learned prompt vectors, has emerged as a promising approach for
efficiently adapting large language models to multiple downstream tasks.
However, existing methods typically learn soft prompt vectors from scratch, and
it has not been clear how to exploit the rich cross-task knowledge with prompt
vectors in a multitask learning setting. We propose multitask prompt tuning
(MPT), which first learns a single transferable prompt by distilling knowledge
from multiple task-specific source prompts. We then learn multiplicative low
rank updates to this shared prompt to efficiently adapt it to each downstream
target task. Extensive experiments on 23 NLP datasets demonstrate that our
proposed approach outperforms the state-of-the-art methods, including the full
finetuning baseline in some cases, despite only tuning 0.035% as many
task-specific parameters.","['Zhen Wang', 'Rameswar Panda', 'Leonid Karlinsky', 'Rogerio Feris', 'Huan Sun', 'Yoon Kim']"
Reinforcement Learning using Guided Observability,Machine Learning,"Due to recent breakthroughs, reinforcement learning (RL) has demonstrated
impressive performance in challenging sequential decision-making problems.
However, an open question is how to make RL cope with partial observability
which is prevalent in many real-world problems. Contrary to contemporary RL
approaches, which focus mostly on improved memory representations or strong
assumptions about the type of partial observability, we propose a simple but
efficient approach that can be applied together with a wide variety of RL
methods. Our main insight is that smoothly transitioning from full
observability to partial observability during the training process yields a
high performance policy. The approach, called partially observable guided
reinforcement learning (PO-GRL), allows to utilize full state information
during policy optimization without compromising the optimality of the final
policy. A comprehensive evaluation in discrete partially observableMarkov
decision process (POMDP) benchmark problems and continuous partially observable
MuJoCo and OpenAI gym tasks shows that PO-GRL improves performance. Finally, we
demonstrate PO-GRL in the ball-in-the-cup task on a real Barrett WAM robot
under partial observability.","['Stephan Weigand', 'Pascal Klink', 'Jan Peters', 'Joni Pajarinen']"
"Restoration of Non-rigidly Distorted Underwater Images using a
  Combination of Compressive Sensing and Local Polynomial Image Representations",Computer Vision and Pattern Recognition,"Images of static scenes submerged beneath a wavy water surface exhibit severe
non-rigid distortions. The physics of water flow suggests that water surfaces
possess spatio-temporal smoothness and temporal periodicity. Hence they possess
a sparse representation in the 3D discrete Fourier (DFT) basis. Motivated by
this, we pose the task of restoration of such video sequences as a compressed
sensing (CS) problem. We begin by tracking a few salient feature points across
the frames of a video sequence of the submerged scene. Using these point
trajectories, we show that the motion fields at all other (non-tracked) points
can be effectively estimated using a typical CS solver. This by itself is a
novel contribution in the field of non-rigid motion estimation. We show that
this method outperforms state of the art algorithms for underwater image
restoration. We further consider a simple optical flow algorithm based on local
polynomial expansion of the image frames (PEOF). Surprisingly, we demonstrate
that PEOF is more efficient and often outperforms all the state of the art
methods in terms of numerical measures. Finally, we demonstrate that a
two-stage approach consisting of the CS step followed by PEOF much more
accurately preserves the image structure and improves the (visual as well as
numerical) video quality as compared to just the PEOF stage.","['Jerin Geo James', 'Pranay Agrawal', 'Ajit Rajwade']"
Customer 360-degree Insights in Predicting Chronic Diabetes,Machine Learning,"Chronic diseases such as diabetes are quite prevalent in the world and are
responsible for a significant number of deaths per year. In addition,
treatments for such chronic diseases account for a high healthcare cost.
However, research has shown that diabetes can be proactively managed and
prevented while lowering these healthcare costs. We have mined a sample of ten
million customers' 360-degree data representing the state of Texas, USA, with
attributes current as of late 2018. The sample received from a market research
data vendor has over 1000 customer attributes consisting of demography,
lifestyle, and in some cases self-reported chronic conditions. In this study,
we have developed a classification model to predict chronic diabetes with an
accuracy of 80%. We demonstrate a use case where a large volume of 360-degree
customer data can be useful to predict and hence proactively prevent chronic
diseases such as diabetes.","['Asish Satpathy', 'Satyajit Behari']"
Generative Adversarial Symmetry Discovery,Machine Learning,"Despite the success of equivariant neural networks in scientific
applications, they require knowing the symmetry group a priori. However, it may
be difficult to know which symmetry to use as an inductive bias in practice.
Enforcing the wrong symmetry could even hurt the performance. In this paper, we
propose a framework, LieGAN, to automatically discover equivariances from a
dataset using a paradigm akin to generative adversarial training. Specifically,
a generator learns a group of transformations applied to the data, which
preserve the original distribution and fool the discriminator. LieGAN
represents symmetry as interpretable Lie algebra basis and can discover various
symmetries such as the rotation group $\mathrm{SO}(n)$, restricted Lorentz
group $\mathrm{SO}(1,3)^+$ in trajectory prediction and top-quark tagging
tasks. The learned symmetry can also be readily used in several existing
equivariant neural networks to improve accuracy and generalization in
prediction.","['Jianke Yang', 'Robin Walters', 'Nima Dehmamy', 'Rose Yu']"
Intra-Camera Supervised Person Re-Identification,Computer Vision and Pattern Recognition,"Existing person re-identification (re-id) methods mostly exploit a large set
of cross-camera identity labelled training data. This requires a tedious data
collection and annotation process, leading to poor scalability in practical
re-id applications. On the other hand unsupervised re-id methods do not need
identity label information, but they usually suffer from much inferior and
insufficient model performance. To overcome these fundamental limitations, we
propose a novel person re-identification paradigm based on an idea of
independent per-camera identity annotation. This eliminates the most
time-consuming and tedious inter-camera identity labelling process,
significantly reducing the amount of human annotation efforts. Consequently, it
gives rise to a more scalable and more feasible setting, which we call
Intra-Camera Supervised (ICS) person re-id, for which we formulate a Multi-tAsk
mulTi-labEl (MATE) deep learning method. Specifically, MATE is designed for
self-discovering the cross-camera identity correspondence in a per-camera
multi-task inference framework. Extensive experiments demonstrate the
cost-effectiveness superiority of our method over the alternative approaches on
three large person re-id datasets. For example, MATE yields 88.7% rank-1 score
on Market-1501 in the proposed ICS person re-id setting, significantly
outperforming unsupervised learning models and closely approaching conventional
fully supervised learning competitors.","['Xiangping Zhu', 'Xiatian Zhu', 'Minxian Li', 'Pietro Morerio', 'Vittorio Murino', 'Shaogang Gong']"
Improving Learning from Demonstrations by Learning from Experience,Artificial Intelligence,"How to make imitation learning more general when demonstrations are
relatively limited has been a persistent problem in reinforcement learning
(RL). Poor demonstrations lead to narrow and biased date distribution,
non-Markovian human expert demonstration makes it difficult for the agent to
learn, and over-reliance on sub-optimal trajectories can make it hard for the
agent to improve its performance. To solve these problems we propose a new
algorithm named TD3fG that can smoothly transition from learning from experts
to learning from experience. Our algorithm achieves good performance in the
MUJOCO environment with limited and sub-optimal demonstrations. We use behavior
cloning to train the network as a reference action generator and utilize it in
terms of both loss function and exploration noise. This innovation can help
agents extract a priori knowledge from demonstrations while reducing the
detrimental effects of the poor Markovian properties of the demonstrations. It
has a better performance compared to the BC+ fine-tuning and DDPGfD approach,
especially when the demonstrations are relatively limited. We call our method
TD3fG meaning TD3 from a generator.","['Haofeng Liu', 'Yiwen Chen', 'Jiayi Tan', 'Marcelo H Ang Jr']"
Mirror Natural Evolution Strategies,Machine Learning,"The zeroth-order optimization has been widely used in machine learning
applications. However, the theoretical study of the zeroth-order optimization
focus on the algorithms which approximate (first-order) gradients using
(zeroth-order) function value difference at a random direction. The theory of
algorithms which approximate the gradient and Hessian information by
zeroth-order queries is much less studied. In this paper, we focus on the
theory of zeroth-order optimization which utilizes both the first-order and
second-order information approximated by the zeroth-order queries. We first
propose a novel reparameterized objective function with parameters $(\mu,
\Sigma)$. This reparameterized objective function achieves its optimum at the
minimizer and the Hessian inverse of the original objective function
respectively, but with small perturbations. Accordingly, we propose a new
algorithm to minimize our proposed reparameterized objective, which we call
\texttt{MiNES} (mirror descent natural evolution strategy). We show that the
estimated covariance matrix of \texttt{MiNES} converges to the inverse of
Hessian matrix of the objective function with a convergence rate
$\widetilde{\mathcal{O}}(1/k)$, where $k$ is the iteration number and
$\widetilde{\mathcal{O}}(\cdot)$ hides the constant and $\log$ terms. We also
provide the explicit convergence rate of \texttt{MiNES} and how the covariance
matrix promotes the convergence rate.",['Haishan Ye']
Extensions and Limitations of the Neural GPU,Neural and Evolutionary Computing,"The Neural GPU is a recent model that can learn algorithms such as
multi-digit binary addition and binary multiplication in a way that generalizes
to inputs of arbitrary length. We show that there are two simple ways of
improving the performance of the Neural GPU: by carefully designing a
curriculum, and by increasing model size. The latter requires a memory
efficient implementation, as a naive implementation of the Neural GPU is memory
intensive. We find that these techniques increase the set of algorithmic
problems that can be solved by the Neural GPU: we have been able to learn to
perform all the arithmetic operations (and generalize to arbitrarily long
numbers) when the arguments are given in the decimal representation (which,
surprisingly, has not been possible before). We have also been able to train
the Neural GPU to evaluate long arithmetic expressions with multiple operands
that require respecting the precedence order of the operands, although these
have succeeded only in their binary representation, and not with perfect
accuracy.
  In addition, we gain insight into the Neural GPU by investigating its failure
modes. We find that Neural GPUs that correctly generalize to arbitrarily long
numbers still fail to compute the correct answer on highly-symmetric, atypical
inputs: for example, a Neural GPU that achieves near-perfect generalization on
decimal multiplication of up to 100-digit long numbers can fail on
$000000\dots002 \times 000000\dots002$ while succeeding at $2 \times 2$. These
failure modes are reminiscent of adversarial examples.","['Eric Price', 'Wojciech Zaremba', 'Ilya Sutskever']"
"Deep Reinforcement Learning for Orienteering Problems Based on
  Decomposition",Neural and Evolutionary Computing,"This paper presents a new method for solving an orienteering problem (OP) by
breaking it down into two parts: a knapsack problem (KP) and a traveling
salesman problem (TSP). A KP solver is responsible for picking nodes, while a
TSP solver is responsible for designing the proper path and assisting the KP
solver in judging constraint violations. To address constraints, we propose a
dual-population coevolutionary algorithm (DPCA) as the KP solver, which
simultaneously maintains both feasible and infeasible populations. A dynamic
pointer network (DYPN) is introduced as the TSP solver, which takes city
locations as inputs and immediately outputs a permutation of nodes. The model,
which is trained by reinforcement learning, can capture both the structural and
dynamic patterns of the given problem. The model can generalize to other
instances with different scales and distributions. Experimental results show
that the proposed algorithm can outperform conventional approaches in terms of
training, inference, and generalization ability.","['Wei Liu', 'Tao Zhang', 'Rui Wang', 'Kaiwen Li', 'Wenhua Li', 'Kang Yang']"
"Language Generation with Recurrent Generative Adversarial Networks
  without Pre-training",Computation and Language (Natural Language Processing),"Generative Adversarial Networks (GANs) have shown great promise recently in
image generation. Training GANs for language generation has proven to be more
difficult, because of the non-differentiable nature of generating text with
recurrent neural networks. Consequently, past work has either resorted to
pre-training with maximum-likelihood or used convolutional networks for
generation. In this work, we show that recurrent neural networks can be trained
to generate text with GANs from scratch using curriculum learning, by slowly
teaching the model to generate sequences of increasing and variable length. We
empirically show that our approach vastly improves the quality of generated
sequences compared to a convolutional baseline.","['Ofir Press', 'Amir Bar', 'Ben Bogin', 'Jonathan Berant', 'Lior Wolf']"
"Learning Hierarchical Object Maps Of Non-Stationary Environments with
  mobile robots",Machine Learning,"Building models, or maps, of robot environments is a highly active research
area; however, most existing techniques construct unstructured maps and assume
static environments. In this paper, we present an algorithm for learning object
models of non-stationary objects found in office-type environments. Our
algorithm exploits the fact that many objects found in office environments look
alike (e.g., chairs, recycling bins). It does so through a two-level
hierarchical representation, which links individual objects with generic shape
templates of object classes. We derive an approximate EM algorithm for learning
shape parameters at both levels of the hierarchy, using local occupancy grid
maps for representing shape. Additionally, we develop a Bayesian model
selection algorithm that enables the robot to estimate the total number of
objects and object templates in the environment. Experimental results using a
real robot equipped with a laser range finder indicate that our approach
performs well at learning object-based maps of simple office environments. The
approach outperforms a previously developed non-hierarchical algorithm that
models objects but lacks class templates.","['Dragomir Anguelov', 'Rahul Biswas', 'Daphne Koller', 'Benson Limketkai', 'Sebastian Thrun']"
"An Enhanced Harmony Search Method for Bangla Handwritten Character
  Recognition Using Region Sampling",Computer Vision and Pattern Recognition,"Identification of minimum number of local regions of a handwritten character
image, containing well-defined discriminating features which are sufficient for
a minimal but complete description of the character is a challenging task. A
new region selection technique based on the idea of an enhanced Harmony Search
methodology has been proposed here. The powerful framework of Harmony Search
has been utilized to search the region space and detect only the most
informative regions for correctly recognizing the handwritten character. The
proposed method has been tested on handwritten samples of Bangla Basic,
Compound and mixed (Basic and Compound characters) characters separately with
SVM based classifier using a longest run based feature-set obtained from the
image subregions formed by a CG based quad-tree partitioning approach. Applying
this methodology on the above mentioned three types of datasets, respectively
43.75%, 12.5% and 37.5% gains have been achieved in terms of region reduction
and 2.3%, 0.6% and 1.2% gains have been achieved in terms of recognition
accuracy. The results show a sizeable reduction in the minimal number of
descriptive regions as well a significant increase in recognition accuracy for
all the datasets using the proposed technique. Thus the time and cost related
to feature extraction is decreased without dampening the corresponding
recognition accuracy.","['Ritesh Sarkhel', 'Amit K Saha', 'Nibaran Das']"
Tuned Compositional Feature Replays for Efficient Stream Learning,Computer Vision and Pattern Recognition,"Our brains extract durable, generalizable knowledge from transient
experiences of the world. Artificial neural networks come nowhere close to this
ability. When tasked with learning to classify objects by training on
non-repeating video frames in temporal order (online stream learning), models
that learn well from shuffled datasets catastrophically forget old knowledge
upon learning new stimuli. We propose a new continual learning algorithm,
Compositional Replay Using Memory Blocks (CRUMB), which mitigates forgetting by
replaying feature maps reconstructed by combining generic parts. CRUMB
concatenates trainable and re-usable ""memory block"" vectors to compositionally
reconstruct feature map tensors in convolutional neural networks. Storing the
indices of memory blocks used to reconstruct new stimuli enables memories of
the stimuli to be replayed during later tasks. This reconstruction mechanism
also primes the neural network to minimize catastrophic forgetting by biasing
it towards attending to information about object shapes more than information
about image textures, and stabilizes the network during stream learning by
providing a shared feature-level basis for all training examples. These
properties allow CRUMB to outperform an otherwise identical algorithm that
stores and replays raw images, while occupying only 3.6% as much memory. We
stress-tested CRUMB alongside 13 competing methods on 7 challenging datasets.
To address the limited number of existing online stream learning datasets, we
introduce 2 new benchmarks by adapting existing datasets for stream learning.
With only 3.7-4.1% as much memory and 15-43% as much runtime, CRUMB mitigates
catastrophic forgetting more effectively than the state-of-the-art. Our code is
available at https://github.com/MorganBDT/crumb.git.","['Morgan B. Talbot', 'Rushikesh Zawar', 'Rohil Badkundri', 'Mengmi Zhang', 'Gabriel Kreiman']"
"Stratified Labeling for Surface Consistent Parallax Correction and
  Occlusion Completion",Computer Vision and Pattern Recognition,"The light field faithfully records the spatial and angular configurations of
the scene, which facilitates a wide range of imaging possibilities. In this
work, we propose an LF synthesis algorithm which renders high quality novel LF
views far outside the range of angular baselines of the given references. A
stratified synthesis strategy is adopted which parses the scene content based
on stratified disparity layers and across a varying range of spatial
granularities. Such a stratified methodology proves to help preserve scene
structures over large perspective shifts, and it provides informative clues for
inferring the textures of occluded regions. A generative-adversarial network
model is further adopted for parallax correction and occlusion completion
conditioned on the stratified synthesis features. Experiments show that our
proposed model can provide more reliable novel view synthesis quality at large
baseline extension ratios. Over 3dB quality improvement has been achieved
against state-of-the-art LF view synthesis algorithms.","['Jie Chen', 'Lap-Pui Chau', 'Junhui Hou']"
Video Generation with Consistency Tuning,Computer Vision and Pattern Recognition,"Currently, various studies have been exploring generation of long videos.
However, the generated frames in these videos often exhibit jitter and noise.
Therefore, in order to generate the videos without these noise, we propose a
novel framework composed of four modules: separate tuning module, average
fusion module, combined tuning module, and inter-frame consistency module. By
applying our newly proposed modules subsequently, the consistency of the
background and foreground in each video frames is optimized. Besides, the
experimental results demonstrate that videos generated by our method exhibit a
high quality in comparison of the state-of-the-art methods.","['Chaoyi Wang', 'Yaozhe Song', 'Yafeng Zhang', 'Jun Pei', 'Lijie Xia', 'Jianpo Liu']"
"A Comprehensive Comparison of Machine Learning Based Methods Used in
  Bengali Question Classification",Computation and Language (Natural Language Processing),"QA classification system maps questions asked by humans to an appropriate
answer category. A sound question classification (QC) system model is the
pre-requisite of a sound QA system. This work demonstrates phases of assembling
a QA type classification model. We present a comprehensive comparison
(performance and computational complexity) among some machine learning based
approaches used in QC for Bengali language.","['Afra Anika', 'Md. Hasibur Rahman', 'Salekul Islam', 'Abu Shafin Mohammad Mahdee Jameel', 'Chowdhury Rafeed Rahman']"
Border-Peeling Clustering,Computer Vision and Pattern Recognition,"In this paper, we present a novel non-parametric clustering technique. Our
technique is based on the notion that each latent cluster is comprised of
layers that surround its core, where the external layers, or border points,
implicitly separate the clusters. Unlike previous techniques, such as DBSCAN,
where the cores of the clusters are defined directly by their densities, here
the latent cores are revealed by a progressive peeling of the border points.
Analyzing the density of the local neighborhoods allows identifying the border
points and associating them with points of inner layers. We show that the
peeling process adapts to the local densities and characteristics to
successfully separate adjacent clusters (of possibly different densities). We
extensively tested our technique on large sets of labeled data, including
high-dimensional datasets of deep features that were trained by a convolutional
neural network. We show that our technique is competitive to other
state-of-the-art non-parametric methods using a fixed set of parameters
throughout the experiments.","['Hadar Averbuch-Elor', 'Nadav Bar', 'Daniel Cohen-Or']"
Neural Architecture Codesign for Fast Bragg Peak Analysis,Machine Learning,"We develop an automated pipeline to streamline neural architecture codesign
for fast, real-time Bragg peak analysis in high-energy diffraction microscopy.
Traditional approaches, notably pseudo-Voigt fitting, demand significant
computational resources, prompting interest in deep learning models for more
efficient solutions. Our method employs neural architecture search and AutoML
to enhance these models, including hardware costs, leading to the discovery of
more hardware-efficient neural architectures. Our results match the
performance, while achieving a 13$\times$ reduction in bit operations compared
to the previous state-of-the-art. We show further speedup through model
compression techniques such as quantization-aware-training and neural network
pruning. Additionally, our hierarchical search space provides greater
flexibility in optimization, which can easily extend to other tasks and
domains.","['Luke McDermott', 'Jason Weitz', 'Dmitri Demler', 'Daniel Cummings', 'Nhan Tran', 'Javier Duarte']"
"Federated Learning Algorithms for Generalized Mixed-effects Model (GLMM)
  on Horizontally Partitioned Data from Distributed Sources",Machine Learning (Statistics),"Objectives: This paper develops two algorithms to achieve federated
generalized linear mixed effect models (GLMM), and compares the developed
model's outcomes with each other, as well as that from the standard R package
(`lme4').
  Methods: The log-likelihood function of GLMM is approximated by two numerical
methods (Laplace approximation and Gaussian Hermite approximation), which
supports federated decomposition of GLMM to bring computation to data.
  Results: Our developed method can handle GLMM to accommodate hierarchical
data with multiple non-independent levels of observations in a federated
setting. The experiment results demonstrate comparable (Laplace) and superior
(Gaussian-Hermite) performances with simulated and real-world data.
  Conclusion: We developed and compared federated GLMMs with different
approximations, which can support researchers in analyzing biomedical data to
accommodate mixed effects and address non-independence due to hierarchical
structures (i.e., institutes, region, country, etc.).","['Wentao Li', 'Jiayi Tong', 'Md. Monowar Anjum', 'Noman Mohammed', 'Yong Chen', 'Xiaoqian Jiang']"
"Tuning a Multiple Classifier System for Side Effect Discovery using
  Genetic Algorithms",Machine Learning,"In previous work, a novel supervised framework implementing a binary
classifier was presented that obtained excellent results for side effect
discovery. Interestingly, unique side effects were identified when different
binary classifiers were used within the framework, prompting the investigation
of applying a multiple classifier system. In this paper we investigate tuning a
side effect multiple classifying system using genetic algorithms. The results
of this research show that the novel framework implementing a multiple
classifying system trained using genetic algorithms can obtain a higher partial
area under the receiver operating characteristic curve than implementing a
single classifier. Furthermore, the framework is able to detect side effects
efficiently and obtains a low false positive rate.","['Jenna M. Reps', 'Uwe Aickelin', 'Jonathan M. Garibaldi']"
Memory-Augmented Relation Network for Few-Shot Learning,Computer Vision and Pattern Recognition,"Metric-based few-shot learning methods concentrate on learning transferable
feature embedding that generalizes well from seen categories to unseen
categories under the supervision of limited number of labelled instances.
However, most of them treat each individual instance in the working context
separately without considering its relationships with the others. In this work,
we investigate a new metric-learning method, Memory-Augmented Relation Network
(MRN), to explicitly exploit these relationships. In particular, for an
instance, we choose the samples that are visually similar from the working
context, and perform weighted information propagation to attentively aggregate
helpful information from the chosen ones to enhance its representation. In MRN,
we also formulate the distance metric as a learnable relation module which
learns to compare for similarity measurement, and augment the working context
with memory slots, both contributing to its generality. We empirically
demonstrate that MRN yields significant improvement over its ancestor and
achieves competitive or even better performance when compared with other
few-shot learning approaches on the two major benchmark datasets, i.e.
miniImagenet and tieredImagenet.","['Jun He', 'Richang Hong', 'Xueliang Liu', 'Mingliang Xu', 'Zhengjun Zha', 'Meng Wang']"
Detect All Abuse! Toward Universal Abusive Language Detection Models,Computation and Language (Natural Language Processing),"Online abusive language detection (ALD) has become a societal issue of
increasing importance in recent years. Several previous works in online ALD
focused on solving a single abusive language problem in a single domain, like
Twitter, and have not been successfully transferable to the general ALD task or
domain. In this paper, we introduce a new generic ALD framework, MACAS, which
is capable of addressing several types of ALD tasks across different domains.
Our generic framework covers multi-aspect abusive language embeddings that
represent the target and content aspects of abusive language and applies a
textual graph embedding that analyses the user's linguistic behaviour. Then, we
propose and use the cross-attention gate flow mechanism to embrace multiple
aspects of abusive language. Quantitative and qualitative evaluation results
show that our ALD algorithm rivals or exceeds the six state-of-the-art ALD
algorithms across seven ALD datasets covering multiple aspects of abusive
language and different online community domains.","['Kunze Wang', 'Dong Lu', 'Soyeon Caren Han', 'Siqu Long', 'Josiah Poon']"
"Uncertainty Decomposition in Bayesian Neural Networks with Latent
  Variables",Machine Learning (Statistics),"Bayesian neural networks (BNNs) with latent variables are probabilistic
models which can automatically identify complex stochastic patterns in the
data. We describe and study in these models a decomposition of predictive
uncertainty into its epistemic and aleatoric components. First, we show how
such a decomposition arises naturally in a Bayesian active learning scenario by
following an information theoretic approach. Second, we use a similar
decomposition to develop a novel risk sensitive objective for safe
reinforcement learning (RL). This objective minimizes the effect of model bias
in environments whose stochastic dynamics are described by BNNs with latent
variables. Our experiments illustrate the usefulness of the resulting
decomposition in active learning and safe RL settings.","['Stefan Depeweg', 'José Miguel Hernández-Lobato', 'Finale Doshi-Velez', 'Steffen Udluft']"
Order Embeddings from Merged Ontologies using Sketching,Computation and Language (Natural Language Processing),"We give a simple, low resource method to produce order embeddings from
ontologies. Such embeddings map words to vectors so that order relations on the
words, such as hypernymy/hyponymy, are represented in a direct way. Our method
uses sketching techniques, in particular countsketch, for dimensionality
reduction. We also study methods to merge ontologies, in particular those in
medical domains, so that order relations are preserved. We give computational
results for medical ontologies and for wordnet, showing that our merging
techniques are effective and our embedding yields an accurate representation in
both generic and specialised domains.","['Kenneth L. Clarkson', 'Sanjana Sahayaraj']"
"Kernel Density Feature Points Estimator for Content-Based Image
  Retrieval",Computer Vision and Pattern Recognition,"Research is taking place to find effective algorithms for content-based image
representation and description. There is a substantial amount of algorithms
available that use visual features (color, shape, texture). Shape feature has
attracted much attention from researchers that there are many shape
representation and description algorithms in literature. These shape image
representation and description algorithms are usually not application
independent or robust, making them undesirable for generic shape description.
This paper presents an object shape representation using Kernel Density Feature
Points Estimator (KDFPE). In this method, the density of feature points within
defined rings around the centroid of the image is obtained. The KDFPE is then
applied to the vector of the image. KDFPE is invariant to translation, scale
and rotation. This method of image representation shows improved retrieval rate
when compared to Density Histogram Feature Points (DHFP) method. Analytic
analysis is done to justify our method, which was compared with the DHFP to
prove its robustness.","['Tranos Zuva', 'Oludayo O. Olugbara', 'Sunday O. Ojo', 'Seleman M. Ngwira']"
Contextual Feature Selection with Conditional Stochastic Gates,Machine Learning,"Feature selection is a crucial tool in machine learning and is widely applied
across various scientific disciplines. Traditional supervised methods generally
identify a universal set of informative features for the entire population.
However, feature relevance often varies with context, while the context itself
may not directly affect the outcome variable. Here, we propose a novel
architecture for contextual feature selection where the subset of selected
features is conditioned on the value of context variables. Our new approach,
Conditional Stochastic Gates (c-STG), models the importance of features using
conditional Bernoulli variables whose parameters are predicted based on
contextual variables. We introduce a hypernetwork that maps context variables
to feature selection parameters to learn the context-dependent gates along with
a prediction model. We further present a theoretical analysis of our model,
indicating that it can improve performance and flexibility over
population-level methods in complex feature selection settings. Finally, we
conduct an extensive benchmark using simulated and real-world datasets across
multiple domains demonstrating that c-STG can lead to improved feature
selection capabilities while enhancing prediction accuracy and
interpretability.","['Ram Dyuthi Sristi', 'Ofir Lindenbaum', 'Shira Lifshitz', 'Maria Lavzin', 'Jackie Schiller', 'Gal Mishne', 'Hadas Benisty']"
Improving and Benchmarking Offline Reinforcement Learning Algorithms,Machine Learning,"Recently, Offline Reinforcement Learning (RL) has achieved remarkable
progress with the emergence of various algorithms and datasets. However, these
methods usually focus on algorithmic advancements, ignoring that many low-level
implementation choices considerably influence or even drive the final
performance. As a result, it becomes hard to attribute the progress in Offline
RL as these choices are not sufficiently discussed and aligned in the
literature. In addition, papers focusing on a dataset (e.g., D4RL) often ignore
algorithms proposed on another dataset (e.g., RL Unplugged), causing isolation
among the algorithms, which might slow down the overall progress. Therefore,
this work aims to bridge the gaps caused by low-level choices and datasets. To
this end, we empirically investigate 20 implementation choices using three
representative algorithms (i.e., CQL, CRR, and IQL) and present a guidebook for
choosing implementations. Following the guidebook, we find two variants CRR+
and CQL+ , achieving new state-of-the-art on D4RL. Moreover, we benchmark eight
popular offline RL algorithms across datasets under unified training and
evaluation framework. The findings are inspiring: the success of a learning
paradigm severely depends on the data distribution, and some previous
conclusions are biased by the dataset used. Our code is available at
https://github.com/sail-sg/offbench.","['Bingyi Kang', 'Xiao Ma', 'Yirui Wang', 'Yang Yue', 'Shuicheng Yan']"
"Lightweight Image Super-Resolution with Adaptive Weighted Learning
  Network",Computer Vision and Pattern Recognition,"Deep learning has been successfully applied to the single-image
super-resolution (SISR) task with great performance in recent years. However,
most convolutional neural network based SR models require heavy computation,
which limit their real-world applications. In this work, a lightweight SR
network, named Adaptive Weighted Super-Resolution Network (AWSRN), is proposed
for SISR to address this issue. A novel local fusion block (LFB) is designed in
AWSRN for efficient residual learning, which consists of stacked adaptive
weighted residual units (AWRU) and a local residual fusion unit (LRFU).
Moreover, an adaptive weighted multi-scale (AWMS) module is proposed to make
full use of features in reconstruction layer. AWMS consists of several
different scale convolutions, and the redundancy scale branch can be removed
according to the contribution of adaptive weights in AWMS for lightweight
network. The experimental results on the commonly used datasets show that the
proposed lightweight AWSRN achieves superior performance on x2, x3, x4, and x8
scale factors to state-of-the-art methods with similar parameters and
computational overhead. Code is avaliable at:
https://github.com/ChaofWang/AWSRN","['Chaofeng Wang', 'Zheng Li', 'Jun Shi']"
Automatic Handgun Detection Alarm in Videos Using Deep Learning,Computer Vision and Pattern Recognition,"Current surveillance and control systems still require human supervision and
intervention. This work presents a novel automatic handgun detection system in
videos appropriate for both, surveillance and control purposes. We reformulate
this detection problem into the problem of minimizing false positives and solve
it by building the key training data-set guided by the results of a deep
Convolutional Neural Networks (CNN) classifier, then assessing the best
classification model under two approaches, the sliding window approach and
region proposal approach. The most promising results are obtained by Faster
R-CNN based model trained on our new database. The best detector show a high
potential even in low quality youtube videos and provides satisfactory results
as automatic alarm system. Among 30 scenes, it successfully activates the alarm
after five successive true positives in less than 0.2 seconds, in 27 scenes. We
also define a new metric, Alarm Activation per Interval (AApI), to assess the
performance of a detection model as an automatic detection system in videos.","['Roberto Olmos', 'Siham Tabik', 'Francisco Herrera']"
"Discrimination of Radiologists Utilizing Eye-Tracking Technology and
  Machine Learning: A Case Study",Computer Vision and Pattern Recognition,"Perception-related errors comprise most diagnostic mistakes in radiology. To
mitigate this problem, radiologists employ personalized and high-dimensional
visual search strategies, otherwise known as search patterns. Qualitative
descriptions of these search patterns, which involve the physician verbalizing
or annotating the order he/she analyzes the image, can be unreliable due to
discrepancies in what is reported versus the actual visual patterns. This
discrepancy can interfere with quality improvement interventions and negatively
impact patient care. This study presents a novel discretized feature encoding
based on spatiotemporal binning of fixation data for efficient geometric
alignment and temporal ordering of eye movement when reading chest X-rays. The
encoded features of the eye-fixation data are employed by machine learning
classifiers to discriminate between faculty and trainee radiologists. We
include a clinical trial case study utilizing the Area Under the Curve (AUC),
Accuracy, F1, Sensitivity, and Specificity metrics for class separability to
evaluate the discriminability between the two subjects in regard to their level
of experience. We then compare the classification performance to
state-of-the-art methodologies. A repeatability experiment using a separate
dataset, experimental protocol, and eye tracker was also performed using eight
subjects to evaluate the robustness of the proposed approach. The numerical
results from both experiments demonstrate that classifiers employing the
proposed feature encoding methods outperform the current state-of-the-art in
differentiating between radiologists in terms of experience level. This
signifies the potential impact of the proposed method for identifying
radiologists' level of expertise and those who would benefit from additional
training.","['Stanford Martinez', 'Carolina Ramirez-Tamayo', 'Syed Hasib Akhter Faruqui', 'Kal L. Clark', 'Adel Alaeddini', 'Nicholas Czarnek', 'Aarushi Aggarwal', 'Sahra Emamzadeh', 'Jeffrey R. Mock', 'Edward J. Golob']"
"Mutual Information-Based Unsupervised Feature Transformation for
  Heterogeneous Feature Subset Selection",Machine Learning (Statistics),"Conventional mutual information (MI) based feature selection (FS) methods are
unable to handle heterogeneous feature subset selection properly because of
data format differences or estimation methods of MI between feature subset and
class label. A way to solve this problem is feature transformation (FT). In
this study, a novel unsupervised feature transformation (UFT) which can
transform non-numerical features into numerical features is developed and
tested. The UFT process is MI-based and independent of class label. MI-based FS
algorithms, such as Parzen window feature selector (PWFS), minimum redundancy
maximum relevance feature selection (mRMR), and normalized MI feature selection
(NMIFS), can all adopt UFT for pre-processing of non-numerical features. Unlike
traditional FT methods, the proposed UFT is unbiased while PWFS is utilized to
its full advantage. Simulations and analyses of large-scale datasets showed
that feature subset selected by the integrated method, UFT-PWFS, outperformed
other FT-FS integrated methods in classification accuracy.","['Min Wei', 'Tommy W. S. Chow', 'Rosa H. M. Chan']"
FoxNet: A Multi-face Alignment Method,Computer Vision and Pattern Recognition,"Multi-face alignment aims to identify geometry structures of multiple faces
in an image, and its performance is essential for the many practical tasks,
such as face recognition, face tracking, and face animation. In this work, we
present a fast bottom-up multi-face alignment approach, which can
simultaneously localize multi-person facial landmarks with high precision.In
more detail, our bottom-up architecture maps the landmarks to the
high-dimensional space with which landmarks of all faces are represented. By
clustering the features belonging to the same face, our approach can align the
multi-person facial landmarks synchronously.Extensive experiments show that our
method can achieve high performance in the multi-face landmark alignment task
while our model is extremely fast. Moreover, we propose a new multi-face
dataset to compare the speed and precision of bottom-up face alignment method
with top-down methods. Our dataset is publicly available at
https://github.com/AISAResearch/FoxNet","['Yuxiang Wu', 'Zehua Cheng', 'Bin Huang', 'Yiming Chen', 'Xinghui Zhu', 'Weiyang Wang']"
Learning Multi-Layered GBDT Via Back Propagation,Machine Learning,"Deep neural networks are able to learn multi-layered representation via back
propagation (BP). Although the gradient boosting decision tree (GBDT) is
effective for modeling tabular data, it is non-differentiable with respect to
its input, thus suffering from learning multi-layered representation. In this
paper, we propose a framework of learning multi-layered GBDT via BP. We
approximate the gradient of GBDT based on linear regression. Specifically, we
use linear regression to replace the constant value at each leaf ignoring the
contribution of individual samples to the tree structure. In this way, we
estimate the gradient for intermediate representations, which facilitates BP
for multi-layered GBDT. Experiments show the effectiveness of the proposed
method in terms of performance and representation ability. To the best of our
knowledge, this is the first work of optimizing multi-layered GBDT via BP. This
work provides a new possibility of exploring deep tree based learning and
combining GBDT with neural networks.",['Zhendong Zhang']
"Saturn Platform: Foundation Model Operations and Generative AI for
  Financial Services",Artificial Intelligence,"Saturn is an innovative platform that assists Foundation Model (FM) building
and its integration with IT operations (Ops). It is custom-made to meet the
requirements of data scientists, enabling them to effectively create and
implement FMs while enhancing collaboration within their technical domain. By
offering a wide range of tools and features, Saturn streamlines and automates
different stages of FM development, making it an invaluable asset for data
science teams. This white paper introduces prospective applications of
generative AI models derived from FMs in the financial sector.","['Antonio J. G. Busson', 'Rennan Gaio', 'Rafael H. Rocha', 'Francisco Evangelista', 'Bruno Rizzi', 'Luan Carvalho', 'Rafael Miceli', 'Marcos Rabaioli', 'David Favaro']"
Automatic Full Compilation of Julia Programs and ML Models to Cloud TPUs,Programming Languages,"Google's Cloud TPUs are a promising new hardware architecture for machine
learning workloads. They have powered many of Google's milestone machine
learning achievements in recent years. Google has now made TPUs available for
general use on their cloud platform and as of very recently has opened them up
further to allow use by non-TensorFlow frontends. We describe a method and
implementation for offloading suitable sections of Julia programs to TPUs via
this new API and the Google XLA compiler. Our method is able to completely fuse
the forward pass of a VGG19 model expressed as a Julia program into a single
TPU executable to be offloaded to the device. Our method composes well with
existing compiler-based automatic differentiation techniques on Julia code, and
we are thus able to also automatically obtain the VGG19 backwards pass and
similarly offload it to the TPU. Targeting TPUs using our compiler, we are able
to evaluate the VGG19 forward pass on a batch of 100 images in 0.23s which
compares favorably to the 52.4s required for the original model on the CPU. Our
implementation is less than 1000 lines of Julia, with no TPU specific changes
made to the core Julia compiler or any other Julia packages.","['Keno Fischer', 'Elliot Saba']"
"Machine Learning and Visualization in Clinical Decision Support: Current
  State and Future Directions",Machine Learning,"Deep learning, an area of machine learning, is set to revolutionize patient
care. But it is not yet part of standard of care, especially when it comes to
individual patient care. In fact, it is unclear to what extent data-driven
techniques are being used to support clinical decision making (CDS).
Heretofore, there has not been a review of ways in which research in machine
learning and other types of data-driven techniques can contribute effectively
to clinical care and the types of support they can bring to clinicians. In this
paper, we consider ways in which two data driven domains - machine learning and
data visualizations - can contribute to the next generation of clinical
decision support systems. We review the literature regarding the ways heuristic
knowledge, machine learning, and visualization are - and can be - applied to
three types of CDS. There has been substantial research into the use of
predictive modeling for alerts, however current CDS systems are not utilizing
these methods. Approaches that leverage interactive visualizations and
machine-learning inferences to organize and review patient data are gaining
popularity but are still at the prototype stage and are not yet in use. CDS
systems that could benefit from prescriptive machine learning (e.g., treatment
recommendations for specific patients) have not yet been developed. We discuss
potential reasons for the lack of deployment of data-driven methods in CDS and
directions for future research.","['Gal Levy-Fix', 'Gilad J. Kuperman', 'Noémie Elhadad']"
"Neural Architecture Evolution in Deep Reinforcement Learning for
  Continuous Control",Machine Learning,"Current Deep Reinforcement Learning algorithms still heavily rely on
handcrafted neural network architectures. We propose a novel approach to
automatically find strong topologies for continuous control tasks while only
adding a minor overhead in terms of interactions in the environment. To achieve
this, we combine Neuroevolution techniques with off-policy training and propose
a novel architecture mutation operator. Experiments on five continuous control
benchmarks show that the proposed Actor-Critic Neuroevolution algorithm often
outperforms the strong Actor-Critic baseline and is capable of automatically
finding topologies in a sample-efficient manner which would otherwise have to
be found by expensive architecture search.","['Jörg K. H. Franke', 'Gregor Köhler', 'Noor Awad', 'Frank Hutter']"
JacobiNeRF: NeRF Shaping with Mutual Information Gradients,Computer Vision and Pattern Recognition,"We propose a method that trains a neural radiance field (NeRF) to encode not
only the appearance of the scene but also semantic correlations between scene
points, regions, or entities -- aiming to capture their mutual co-variation
patterns. In contrast to the traditional first-order photometric reconstruction
objective, our method explicitly regularizes the learning dynamics to align the
Jacobians of highly-correlated entities, which proves to maximize the mutual
information between them under random scene perturbations. By paying attention
to this second-order information, we can shape a NeRF to express semantically
meaningful synergies when the network weights are changed by a delta along the
gradient of a single entity, region, or even a point. To demonstrate the merit
of this mutual information modeling, we leverage the coordinated behavior of
scene entities that emerges from our shaping to perform label propagation for
semantic and instance segmentation. Our experiments show that a JacobiNeRF is
more efficient in propagating annotations among 2D pixels and 3D points
compared to NeRFs without mutual information shaping, especially in extremely
sparse label regimes -- thus reducing annotation burden. The same machinery can
further be used for entity selection or scene modifications.","['Xiaomeng Xu', 'Yanchao Yang', 'Kaichun Mo', 'Boxiao Pan', 'Li Yi', 'Leonidas Guibas']"
bigMap: Big Data Mapping with Parallelized t-SNE,Machine Learning,"We introduce an improved unsupervised clustering protocol specially suited
for large-scale structured data. The protocol follows three steps: a
dimensionality reduction of the data, a density estimation over the low
dimensional representation of the data, and a final segmentation of the density
landscape. For the dimensionality reduction step we introduce a parallelized
implementation of the well-known t-Stochastic Neighbouring Embedding (t-SNE)
algorithm that significantly alleviates some inherent limitations, while
improving its suitability for large datasets. We also introduce a new adaptive
Kernel Density Estimation particularly coupled with the t-SNE framework in
order to get accurate density estimates out of the embedded data, and a variant
of the rainfalling watershed algorithm to identify clusters within the density
landscape. The whole mapping protocol is wrapped in the bigMap R package,
together with visualization and analysis tools to ease the qualitative and
quantitative assessment of the clustering.","['Joan Garriga', 'Frederic Bartumeus']"
On the Robustness of Decision Tree Learning under Label Noise,Machine Learning,"In most practical problems of classifier learning, the training data suffers
from the label noise. Hence, it is important to understand how robust is a
learning algorithm to such label noise. This paper presents some theoretical
analysis to show that many popular decision tree algorithms are robust to
symmetric label noise under large sample size. We also present some sample
complexity results which provide some bounds on the sample size for the
robustness to hold with a high probability. Through extensive simulations we
illustrate this robustness.","['Aritra Ghosh', 'Naresh Manwani', 'P. S. Sastry']"
Improving Tagging Performance by Using Voting Taggers,Computation and Language (Natural Language Processing),"We present a bootstrapping method to develop an annotated corpus, which is
specially useful for languages with few available resources. The method is
being applied to develop a corpus of Spanish of over 5Mw. The method consists
on taking advantage of the collaboration of two different POS taggers. The
cases in which both taggers agree present a higher accuracy and are used to
retrain the taggers.","['L. Marquez', 'L. Padro', 'H. Rodriguez']"
"Flow to Control: Offline Reinforcement Learning with Lossless Primitive
  Discovery",Machine Learning,"Offline reinforcement learning (RL) enables the agent to effectively learn
from logged data, which significantly extends the applicability of RL
algorithms in real-world scenarios where exploration can be expensive or
unsafe. Previous works have shown that extracting primitive skills from the
recurring and temporally extended structures in the logged data yields better
learning. However, these methods suffer greatly when the primitives have
limited representation ability to recover the original policy space, especially
in offline settings. In this paper, we give a quantitative characterization of
the performance of offline hierarchical learning and highlight the importance
of learning lossless primitives. To this end, we propose to use a
\emph{flow}-based structure as the representation for low-level policies. This
allows us to represent the behaviors in the dataset faithfully while keeping
the expression ability to recover the whole policy space. We show that such
lossless primitives can drastically improve the performance of hierarchical
policies. The experimental results and extensive ablation studies on the
standard D4RL benchmark show that our method has a good representation ability
for policies and achieves superior performance in most tasks.","['Yiqin Yang', 'Hao Hu', 'Wenzhe Li', 'Siyuan Li', 'Jun Yang', 'Qianchuan Zhao', 'Chongjie Zhang']"
Combining Models of Approximation with Partial Learning,Machine Learning,"In Gold's framework of inductive inference, the model of partial learning
requires the learner to output exactly one correct index for the target object
and only the target object infinitely often. Since infinitely many of the
learner's hypotheses may be incorrect, it is not obvious whether a partial
learner can be modifed to ""approximate"" the target object.
  Fulk and Jain (Approximate inference and scientific method. Information and
Computation 114(2):179--191, 1994) introduced a model of approximate learning
of recursive functions. The present work extends their research and solves an
open problem of Fulk and Jain by showing that there is a learner which
approximates and partially identifies every recursive function by outputting a
sequence of hypotheses which, in addition, are also almost all finite variants
of the target function.
  The subsequent study is dedicated to the question how these findings
generalise to the learning of r.e. languages from positive data. Here three
variants of approximate learning will be introduced and investigated with
respect to the question whether they can be combined with partial learning.
Following the line of Fulk and Jain's research, further investigations provide
conditions under which partial language learners can eventually output only
finite variants of the target language. The combinabilities of other partial
learning criteria will also be briefly studied.","['Ziyuan Gao', 'Frank Stephan', 'Sandra Zilles']"
ML-powered KQI estimation for XR services. A case study on 360-Video,Networking and Internet Architecture,"The arise of cutting-edge technologies and services such as XR promise to
change the concepts of how day-to-day things are done. At the same time, the
appearance of modern and decentralized architectures approaches has given birth
to a new generation of mobile networks such as 5G, as well as outlining the
roadmap for B5G and posterior. These networks are expected to be the enablers
for bringing to life the Metaverse and other futuristic approaches. In this
sense, this work presents an ML-based (Machine Learning) framework that allows
the estimation of service Key Quality Indicators (KQIs). For this, only
information reachable to operators is required, such as statistics and
configuration parameters from these networks. This strategy prevents operators
from avoiding intrusion into the user data and guaranteeing privacy. To test
this proposal, 360-Video has been selected as a use case of Virtual Reality
(VR), from which specific KQIs are estimated such as video resolution, frame
rate, initial startup time, throughput, and latency, among others. To select
the best model for each KQI, a search grid with a cross-validation strategy has
been used to determine the best hyperparameter tuning. To boost the creation of
each KQI model, feature engineering techniques together with cross-validation
strategies have been used. The performance is assessed using MAE (Mean Average
Error) and the prediction time. The outcomes point out that KNR (K-Near
Neighbors) and RF (Random Forest) are the best algorithms in combination with
Feature Selection techniques. Likewise, this work will help as a baseline for
E2E-Quality-of-Experience-based network management working in conjunction with
network slicing, virtualization, and MEC, among other enabler technologies.","['O. S. Peñaherrera-Pulla', 'Carlos Baena', 'Sergio Fortes', 'Raquel Barco']"
"Placeto: Learning Generalizable Device Placement Algorithms for
  Distributed Machine Learning",Machine Learning,"We present Placeto, a reinforcement learning (RL) approach to efficiently
find device placements for distributed neural network training. Unlike prior
approaches that only find a device placement for a specific computation graph,
Placeto can learn generalizable device placement policies that can be applied
to any graph. We propose two key ideas in our approach: (1) we represent the
policy as performing iterative placement improvements, rather than outputting a
placement in one shot; (2) we use graph embeddings to capture relevant
information about the structure of the computation graph, without relying on
node labels for indexing. These ideas allow Placeto to train efficiently and
generalize to unseen graphs. Our experiments show that Placeto requires up to
6.1x fewer training steps to find placements that are on par with or better
than the best placements found by prior approaches. Moreover, Placeto is able
to learn a generalizable placement policy for any given family of graphs, which
can then be used without any retraining to predict optimized placements for
unseen graphs from the same family. This eliminates the large overhead incurred
by prior RL approaches whose lack of generalizability necessitates re-training
from scratch every time a new graph is to be placed.","['Ravichandra Addanki', 'Shaileshh Bojja Venkatakrishnan', 'Shreyan Gupta', 'Hongzi Mao', 'Mohammad Alizadeh']"
"Outlier Detection as Instance Selection Method for Feature Selection in
  Time Series Classification",Machine Learning,"In order to allow machine learning algorithms to extract knowledge from raw
data, these data must first be cleaned, transformed, and put into
machine-appropriate form. These often very time-consuming phase is referred to
as preprocessing. An important step in the preprocessing phase is feature
selection, which aims at better performance of prediction models by reducing
the amount of features of a data set. Within these datasets, instances of
different events are often imbalanced, which means that certain normal events
are over-represented while other rare events are very limited. Typically, these
rare events are of special interest since they have more discriminative power
than normal events. The aim of this work was to filter instances provided to
feature selection methods for these rare instances, and thus positively
influence the feature selection process. In the course of this work, we were
able to show that this filtering has a positive effect on the performance of
classification models and that outlier detection methods are suitable for this
filtering. For some data sets, the resulting increase in performance was only a
few percent, but for other datasets, we were able to achieve increases in
performance of up to 16 percent. This work should lead to the improvement of
the predictive models and the better interpretability of feature selection in
the course of the preprocessing phase. In the spirit of open science and to
increase transparency within our research field, we have made all our source
code and the results of our experiments available in a publicly available
repository.",['David Cemernek']
"Controllable and Diverse Data Augmentation with Large Language Model for
  Low-Resource Open-Domain Dialogue Generation",Computation and Language (Natural Language Processing),"Data augmentation (DA) is crucial to mitigate model training instability and
over-fitting problems in low-resource open-domain dialogue generation. However,
traditional DA methods often neglect semantic data diversity, restricting the
overall quality. Recently, large language models (LLM) have been used for DA to
generate diversified dialogues. However, they have limited controllability and
tend to generate dialogues with a distribution shift compared to the seed
dialogues. To maximize the augmentation diversity and address the
controllability problem, we propose \textbf{S}ummary-based \textbf{D}ialogue
\textbf{A}ugmentation with LLM (SDA). Our approach enhances the controllability
of LLM by using dialogue summaries as a planning tool. Based on summaries, SDA
can generate high-quality and diverse dialogue data even with a small seed
dataset. To evaluate the efficacy of data augmentation methods for open-domain
dialogue, we designed a clustering-based metric to characterize the semantic
diversity of the augmented dialogue data. The experimental results show that
SDA can augment high-quality and semantically diverse dialogues given a small
seed dataset and an LLM, and the augmented data can boost the performance of
open-domain dialogue models.","['Zhenhua Liu', 'Tong Zhu', 'Jianxiang Xiang', 'Wenliang Chen']"
"Paired Open-Ended Trailblazer (POET): Endlessly Generating Increasingly
  Complex and Diverse Learning Environments and Their Solutions",Neural and Evolutionary Computing,"While the history of machine learning so far largely encompasses a series of
problems posed by researchers and algorithms that learn their solutions, an
important question is whether the problems themselves can be generated by the
algorithm at the same time as they are being solved. Such a process would in
effect build its own diverse and expanding curricula, and the solutions to
problems at various stages would become stepping stones towards solving even
more challenging problems later in the process. The Paired Open-Ended
Trailblazer (POET) algorithm introduced in this paper does just that: it pairs
the generation of environmental challenges and the optimization of agents to
solve those challenges. It simultaneously explores many different paths through
the space of possible problems and solutions and, critically, allows these
stepping-stone solutions to transfer between problems if better, catalyzing
innovation. The term open-ended signifies the intriguing potential for
algorithms like POET to continue to create novel and increasingly complex
capabilities without bound. Our results show that POET produces a diverse range
of sophisticated behaviors that solve a wide range of environmental challenges,
many of which cannot be solved by direct optimization alone, or even through a
direct-path curriculum-building control algorithm introduced to highlight the
critical role of open-endedness in solving ambitious challenges. The ability to
transfer solutions from one environment to another proves essential to
unlocking the full potential of the system as a whole, demonstrating the
unpredictable nature of fortuitous stepping stones. We hope that POET will
inspire a new push towards open-ended discovery across many domains, where
algorithms like POET can blaze a trail through their interesting possible
manifestations and solutions.","['Rui Wang', 'Joel Lehman', 'Jeff Clune', 'Kenneth O. Stanley']"
client2vec: Towards Systematic Baselines for Banking Applications,Machine Learning (Statistics),"The workflow of data scientists normally involves potentially inefficient
processes such as data mining, feature engineering and model selection. Recent
research has focused on automating this workflow, partly or in its entirety, to
improve productivity. We choose the former approach and in this paper share our
experience in designing the client2vec: an internal library to rapidly build
baselines for banking applications. Client2vec uses marginalized stacked
denoising autoencoders on current account transactions data to create vector
embeddings which represent the behaviors of our clients. These representations
can then be used in, and optimized against, a variety of tasks such as client
segmentation, profiling and targeting. Here we detail how we selected the
algorithmic machinery of client2vec and the data it works on and present
experimental results on several business cases.","['Leonardo Baldassini', 'Jose Antonio Rodríguez Serrano']"
Visualizing and Understanding the Effectiveness of BERT,Computation and Language (Natural Language Processing),"Language model pre-training, such as BERT, has achieved remarkable results in
many NLP tasks. However, it is unclear why the pre-training-then-fine-tuning
paradigm can improve performance and generalization capability across different
tasks. In this paper, we propose to visualize loss landscapes and optimization
trajectories of fine-tuning BERT on specific datasets. First, we find that
pre-training reaches a good initial point across downstream tasks, which leads
to wider optima and easier optimization compared with training from scratch. We
also demonstrate that the fine-tuning procedure is robust to overfitting, even
though BERT is highly over-parameterized for downstream tasks. Second, the
visualization results indicate that fine-tuning BERT tends to generalize better
because of the flat and wide optima, and the consistency between the training
loss surface and the generalization error surface. Third, the lower layers of
BERT are more invariant during fine-tuning, which suggests that the layers that
are close to input learn more transferable representations of language.","['Yaru Hao', 'Li Dong', 'Furu Wei', 'Ke Xu']"
"Cross-lingual Word Segmentation and Morpheme Segmentation as Sequence
  Labelling",Computation and Language (Natural Language Processing),"This paper presents our segmentation system developed for the MLP 2017 shared
tasks on cross-lingual word segmentation and morpheme segmentation. We model
both word and morpheme segmentation as character-level sequence labelling
tasks. The prevalent bidirectional recurrent neural network with conditional
random fields as the output interface is adapted as the baseline system, which
is further improved via ensemble decoding. Our universal system is applied to
and extensively evaluated on all the official data sets without any
language-specific adjustment. The official evaluation results indicate that the
proposed model achieves outstanding accuracies both for word and morpheme
segmentation on all the languages in various types when compared to the other
participating systems.",['Yan Shao']
Theory and Algorithms for Shapelet-based Multiple-Instance Learning,Machine Learning,"We propose a new formulation of Multiple-Instance Learning (MIL), in which a
unit of data consists of a set of instances called a bag. The goal is to find a
good classifier of bags based on the similarity with a ""shapelet"" (or pattern),
where the similarity of a bag with a shapelet is the maximum similarity of
instances in the bag. In previous work, some of the training instances are
chosen as shapelets with no theoretical justification. In our formulation, we
use all possible, and thus infinitely many shapelets, resulting in a richer
class of classifiers. We show that the formulation is tractable, that is, it
can be reduced through Linear Programming Boosting (LPBoost) to Difference of
Convex (DC) programs of finite (actually polynomial) size. Our theoretical
result also gives justification to the heuristics of some of the previous work.
The time complexity of the proposed algorithm highly depends on the size of the
set of all instances in the training sample. To apply to the data containing a
large number of instances, we also propose a heuristic option of the algorithm
without the loss of the theoretical guarantee. Our empirical study demonstrates
that our algorithm uniformly works for Shapelet Learning tasks on time-series
classification and various MIL tasks with comparable accuracy to the existing
methods. Moreover, we show that the proposed heuristics allow us to achieve the
result with reasonable computational time.","['Daiki Suehiro', 'Kohei Hatano', 'Eiji Takimoto', 'Shuji Yamamoto', 'Kenichi Bannai', 'Akiko Takeda']"
S2vNTM: Semi-supervised vMF Neural Topic Modeling,Computation and Language (Natural Language Processing),"Language model based methods are powerful techniques for text classification.
However, the models have several shortcomings. (1) It is difficult to integrate
human knowledge such as keywords. (2) It needs a lot of resources to train the
models. (3) It relied on large text data to pretrain. In this paper, we propose
Semi-Supervised vMF Neural Topic Modeling (S2vNTM) to overcome these
difficulties. S2vNTM takes a few seed keywords as input for topics. S2vNTM
leverages the pattern of keywords to identify potential topics, as well as
optimize the quality of topics' keywords sets. Across a variety of datasets,
S2vNTM outperforms existing semi-supervised topic modeling methods in
classification accuracy with limited keywords provided. S2vNTM is at least
twice as fast as baselines.","['Weijie Xu', 'Jay Desai', 'Srinivasan Sengamedu', 'Xiaoyu Jiang', 'Francis Iannacci']"
"Development and Validation of the Provider Documentation Summarization
  Quality Instrument for Large Language Models",Artificial Intelligence,"As Large Language Models (LLMs) are integrated into electronic health record
(EHR) workflows, validated instruments are essential to evaluate their
performance before implementation. Existing instruments for provider
documentation quality are often unsuitable for the complexities of
LLM-generated text and lack validation on real-world data. The Provider
Documentation Summarization Quality Instrument (PDSQI-9) was developed to
evaluate LLM-generated clinical summaries. Multi-document summaries were
generated from real-world EHR data across multiple specialties using several
LLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson
correlation for substantive validity, factor analysis and Cronbach's alpha for
structural validity, inter-rater reliability (ICC and Krippendorff's alpha) for
generalizability, a semi-Delphi process for content validity, and comparisons
of high-versus low-quality summaries for discriminant validity. Seven physician
raters evaluated 779 summaries and answered 8,329 questions, achieving over 80%
power for inter-rater reliability. The PDSQI-9 demonstrated strong internal
consistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and high
inter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting
structural validity and generalizability. Factor analysis identified a 4-factor
model explaining 58% of the variance, representing organization, clarity,
accuracy, and utility. Substantive validity was supported by correlations
between note length and scores for Succinct (rho = -0.200, p = 0.029) and
Organized ($\rho = -0.190$, $p = 0.037$). Discriminant validity distinguished
high- from low-quality summaries ($p < 0.001$). The PDSQI-9 demonstrates robust
construct validity, supporting its use in clinical practice to evaluate
LLM-generated summaries and facilitate safer integration of LLMs into
healthcare workflows.","['Emma Croxford', 'Yanjun Gao', 'Nicholas Pellegrino', 'Karen K. Wong', 'Graham Wills', 'Elliot First', 'Miranda Schnier', 'Kyle Burton', 'Cris G. Ebby', 'Jillian Gorskic', 'Matthew Kalscheur', 'Samy Khalil', 'Marie Pisani', 'Tyler Rubeor', 'Peter Stetson', 'Frank Liao', 'Cherodeep Goswami', 'Brian Patterson', 'Majid Afshar']"
Learning 3D Object Categories by Looking Around Them,Computer Vision and Pattern Recognition,"Traditional approaches for learning 3D object categories use either synthetic
data or manual supervision. In this paper, we propose a method which does not
require manual annotations and is instead cued by observing objects from a
moving vantage point. Our system builds on two innovations: a Siamese viewpoint
factorization network that robustly aligns different videos together without
explicitly comparing 3D shapes; and a 3D shape completion network that can
extract the full shape of an object from partial observations. We also
demonstrate the benefits of configuring networks to perform probabilistic
predictions as well as of geometry-aware data augmentation schemes. We obtain
state-of-the-art results on publicly-available benchmarks.","['David Novotny', 'Diane Larlus', 'Andrea Vedaldi']"
"Enhancing Multiview Synergy: Robust Learning by Exploiting the Wave Loss
  Function with Consensus and Complementarity Principles",Machine Learning,"Multiview learning (MvL) is an advancing domain in machine learning,
leveraging multiple data perspectives to enhance model performance through
view-consistency and view-discrepancy. Despite numerous successful
multiview-based SVM models, existing frameworks predominantly focus on the
consensus principle, often overlooking the complementarity principle.
Furthermore, they exhibit limited robustness against noisy, error-prone, and
view-inconsistent samples, prevalent in multiview datasets. To tackle the
aforementioned limitations, this paper introduces Wave-MvSVM, a novel multiview
support vector machine framework leveraging the wave loss (W-loss) function,
specifically designed to harness both consensus and complementarity principles.
Unlike traditional approaches that often overlook the complementary information
among different views, the proposed Wave-MvSVM ensures a more comprehensive and
resilient learning process by integrating both principles effectively. The
W-loss function, characterized by its smoothness, asymmetry, and bounded
nature, is particularly effective in mitigating the adverse effects of noisy
and outlier data, thereby enhancing model stability. Theoretically, the W-loss
function also exhibits a crucial classification-calibrated property, further
boosting its effectiveness. Wave-MvSVM employs a between-view co-regularization
term to enforce view consistency and utilizes an adaptive combination weight
strategy to maximize the discriminative power of each view. The optimization
problem is efficiently solved using a combination of GD and the ADMM, ensuring
reliable convergence to optimal solutions. Theoretical analyses, grounded in
Rademacher complexity, validate the generalization capabilities of the
Wave-MvSVM model. Extensive empirical evaluations across diverse datasets
demonstrate the superior performance of Wave-MvSVM in comparison to existing
benchmark models.","['A. Quadir', 'Mushir Akhtar', 'M. Tanveer']"
Deep Edge-Aware Saliency Detection,Computer Vision and Pattern Recognition,"There has been profound progress in visual saliency thanks to the deep
learning architectures, however, there still exist three major challenges that
hinder the detection performance for scenes with complex compositions, multiple
salient objects, and salient objects of diverse scales. In particular, output
maps of the existing methods remain low in spatial resolution causing blurred
edges due to the stride and pooling operations, networks often neglect
descriptive statistical and handcrafted priors that have potential to
complement saliency detection results, and deep features at different layers
stay mainly desolate waiting to be effectively fused to handle multi-scale
salient objects. In this paper, we tackle these issues by a new fully
convolutional neural network that jointly learns salient edges and saliency
labels in an end-to-end fashion. Our framework first employs convolutional
layers that reformulate the detection task as a dense labeling problem, then
integrates handcrafted saliency features in a hierarchical manner into lower
and higher levels of the deep network to leverage available information for
multi-scale response, and finally refines the saliency map through dilated
convolutions by imposing context. In this way, the salient edge priors are
efficiently incorporated and the output resolution is significantly improved
while keeping the memory requirements low, leading to cleaner and sharper
object boundaries. Extensive experimental analyses on ten benchmarks
demonstrate that our framework achieves consistently superior performance and
attains robustness for complex scenes in comparison to the very recent
state-of-the-art approaches.","['Jing Zhang', 'Yuchao Dai', 'Fatih Porikli', 'Mingyi He']"
"Classification of COVID-19 in chest X-ray images using DeTraC deep
  convolutional neural network",Image and Video Processing,"Chest X-ray is the first imaging technique that plays an important role in
the diagnosis of COVID-19 disease. Due to the high availability of large-scale
annotated image datasets, great success has been achieved using convolutional
neural networks (CNNs) for image recognition and classification. However, due
to the limited availability of annotated medical images, the classification of
medical images remains the biggest challenge in medical diagnosis. Thanks to
transfer learning, an effective mechanism that can provide a promising solution
by transferring knowledge from generic object recognition tasks to
domain-specific tasks. In this paper, we validate and adapt our previously
developed CNN, called Decompose, Transfer, and Compose (DeTraC), for the
classification of COVID-19 chest X-ray images. DeTraC can deal with any
irregularities in the image dataset by investigating its class boundaries using
a class decomposition mechanism. The experimental results showed the capability
of DeTraC in the detection of COVID-19 cases from a comprehensive image dataset
collected from several hospitals around the world. High accuracy of 95.12%
(with a sensitivity of 97.91%, a specificity of 91.87%, and a precision of
93.36%) was achieved by DeTraC in the detection of COVID-19 X-ray images from
normal, and severe acute respiratory syndrome cases.","['Asmaa Abbas', 'Mohammed M. Abdelsamea', 'Mohamed Medhat Gaber']"
Towards Efficient Training with Negative Samples in Visual Tracking,Computer Vision and Pattern Recognition,"Current state-of-the-art (SOTA) methods in visual object tracking often
require extensive computational resources and vast amounts of training data,
leading to a risk of overfitting. This study introduces a more efficient
training strategy to mitigate overfitting and reduce computational
requirements. We balance the training process with a mix of negative and
positive samples from the outset, named as Joint learning with Negative samples
(JN). Negative samples refer to scenarios where the object from the template is
not present in the search region, which helps to prevent the model from simply
memorizing the target, and instead encourages it to use the template for object
location. To handle the negative samples effectively, we adopt a
distribution-based head, which modeling the bounding box as distribution of
distances to express uncertainty about the target's location in the presence of
negative samples, offering an efficient way to manage the mixed sample
training. Furthermore, our approach introduces a target-indicating token. It
encapsulates the target's precise location within the template image. This
method provides exact boundary details with negligible computational cost but
improving performance. Our model, JN-256, exhibits superior performance on
challenging benchmarks, achieving 75.8% AO on GOT-10k and 84.1% AUC on
TrackingNet. Notably, JN-256 outperforms previous SOTA trackers that utilize
larger models and higher input resolutions, even though it is trained with only
half the number of data sampled used in those works.","['Qingmao Wei', 'Bi Zeng', 'Guotian Zeng']"
"How to keep text private? A systematic review of deep learning methods
  for privacy-preserving natural language processing",Computation and Language (Natural Language Processing),"Deep learning (DL) models for natural language processing (NLP) tasks often
handle private data, demanding protection against breaches and disclosures.
Data protection laws, such as the European Union's General Data Protection
Regulation (GDPR), thereby enforce the need for privacy. Although many
privacy-preserving NLP methods have been proposed in recent years, no
categories to organize them have been introduced yet, making it hard to follow
the progress of the literature. To close this gap, this article systematically
reviews over sixty DL methods for privacy-preserving NLP published between 2016
and 2020, covering theoretical foundations, privacy-enhancing technologies, and
analysis of their suitability for real-world scenarios. First, we introduce a
novel taxonomy for classifying the existing methods into three categories: data
safeguarding methods, trusted methods, and verification methods. Second, we
present an extensive summary of privacy threats, datasets for applications, and
metrics for privacy evaluation. Third, throughout the review, we describe
privacy issues in the NLP pipeline in a holistic view. Further, we discuss open
challenges in privacy-preserving NLP regarding data traceability, computation
overhead, dataset size, the prevalence of human biases in embeddings, and the
privacy-utility tradeoff. Finally, this review presents future research
directions to guide successive research and development of privacy-preserving
NLP models.","['Samuel Sousa', 'Roman Kern']"
"Constrained Decoding for Computationally Efficient Named Entity
  Recognition Taggers",Computation and Language (Natural Language Processing),"Current state-of-the-art models for named entity recognition (NER) are neural
models with a conditional random field (CRF) as the final layer. Entities are
represented as per-token labels with a special structure in order to decode
them into spans. Current work eschews prior knowledge of how the span encoding
scheme works and relies on the CRF learning which transitions are illegal and
which are not to facilitate global coherence. We find that by constraining the
output to suppress illegal transitions we can train a tagger with a
cross-entropy loss twice as fast as a CRF with differences in F1 that are
statistically insignificant, effectively eliminating the need for a CRF. We
analyze the dynamics of tag co-occurrence to explain when these constraints are
most effective and provide open source implementations of our tagger in both
PyTorch and TensorFlow.","['Brian Lester', 'Daniel Pressel', 'Amy Hemmeter', 'Sagnik Ray Choudhury', 'Srinivas Bangalore']"
"Procedural Content Generation in Games: A Survey with Insights on
  Emerging LLM Integration",Artificial Intelligence,"Procedural Content Generation (PCG) is defined as the automatic creation of
game content using algorithms. PCG has a long history in both the game industry
and the academic world. It can increase player engagement and ease the work of
game designers. While recent advances in deep learning approaches in PCG have
enabled researchers and practitioners to create more sophisticated content, it
is the arrival of Large Language Models (LLMs) that truly disrupted the
trajectory of PCG advancement.
  This survey explores the differences between various algorithms used for PCG,
including search-based methods, machine learning-based methods, other
frequently used methods (e.g., noise functions), and the newcomer, LLMs. We
also provide a detailed discussion on combined methods. Furthermore, we compare
these methods based on the type of content they generate and the publication
dates of their respective papers. Finally, we identify gaps in the existing
academic work and suggest possible directions for future research.","['Mahdi Farrokhi Maleki', 'Richard Zhao']"
"S$^2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor
  Critic",Machine Learning,"Learning expressive stochastic policies instead of deterministic ones has
been proposed to achieve better stability, sample complexity, and robustness.
Notably, in Maximum Entropy Reinforcement Learning (MaxEnt RL), the policy is
modeled as an expressive Energy-Based Model (EBM) over the Q-values. However,
this formulation requires the estimation of the entropy of such EBMs, which is
an open problem. To address this, previous MaxEnt RL methods either implicitly
estimate the entropy, resulting in high computational complexity and variance
(SQL), or follow a variational inference procedure that fits simplified actor
distributions (e.g., Gaussian) for tractability (SAC). We propose Stein Soft
Actor-Critic (S$^2$AC), a MaxEnt RL algorithm that learns expressive policies
without compromising efficiency. Specifically, S$^2$AC uses parameterized Stein
Variational Gradient Descent (SVGD) as the underlying policy. We derive a
closed-form expression of the entropy of such policies. Our formula is
computationally efficient and only depends on first-order derivatives and
vector products. Empirical results show that S$^2$AC yields more optimal
solutions to the MaxEnt objective than SQL and SAC in the multi-goal
environment, and outperforms SAC and SQL on the MuJoCo benchmark. Our code is
available at:
https://github.com/SafaMessaoud/S2AC-Energy-Based-RL-with-Stein-Soft-Actor-Critic","['Safa Messaoud', 'Billel Mokeddem', 'Zhenghai Xue', 'Linsey Pang', 'Bo An', 'Haipeng Chen', 'Sanjay Chawla']"
Using Description Logics for Recognising Textual Entailment,Computation and Language (Natural Language Processing),"The aim of this paper is to show how we can handle the Recognising Textual
Entailment (RTE) task by using Description Logics (DLs). To do this, we propose
a representation of natural language semantics in DLs inspired by existing
representations in first-order logic. But our most significant contribution is
the definition of two novel inference tasks: A-Box saturation and subgraph
detection which are crucial for our approach to RTE.",['Paul Bedaride']
"Autonomous Navigation of Tractor-Trailer Vehicles through Roundabout
  Intersections",Robotics,"In recent years, significant advancements have been made in the field of
autonomous driving with the aim of increasing safety and efficiency. However,
research that focuses on tractor-trailer vehicles is relatively sparse. Due to
the physical characteristics and articulated joints, such vehicles require
tailored models. While turning, the back wheels of the trailer turn at a
tighter radius and the truck often has to deviate from the centre of the lane
to accommodate this. Due to the lack of publicly available models, this work
develops truck and trailer models using the high-fidelity simulation software
CARLA, together with several roundabout scenarios, to establish a baseline
dataset for benchmarks. Using a twin-q soft actor-critic algorithm, we train a
quasi-end-to-end autonomous driving model which is able to achieve a 73%
success rate on different roundabouts.","['Daniel Attard', 'Josef Bajada']"
"A Group-Equivariant Autoencoder for Identifying Spontaneously Broken
  Symmetries",Statistical Mechanics,"We introduce the group-equivariant autoencoder (GE-autoencoder) -- a deep
neural network (DNN) method that locates phase boundaries by determining which
symmetries of the Hamiltonian have spontaneously broken at each temperature. We
use group theory to deduce which symmetries of the system remain intact in all
phases, and then use this information to constrain the parameters of the
GE-autoencoder such that the encoder learns an order parameter invariant to
these ``never-broken'' symmetries. This procedure produces a dramatic reduction
in the number of free parameters such that the GE-autoencoder size is
independent of the system size. We include symmetry regularization terms in the
loss function of the GE-autoencoder so that the learned order parameter is also
equivariant to the remaining symmetries of the system. By examining the group
representation by which the learned order parameter transforms, we are then
able to extract information about the associated spontaneous symmetry breaking.
We test the GE-autoencoder on the 2D classical ferromagnetic and
antiferromagnetic Ising models, finding that the GE-autoencoder (1) accurately
determines which symmetries have spontaneously broken at each temperature; (2)
estimates the critical temperature in the thermodynamic limit with greater
accuracy, robustness, and time-efficiency than a symmetry-agnostic baseline
autoencoder; and (3) detects the presence of an external symmetry-breaking
magnetic field with greater sensitivity than the baseline method. Finally, we
describe various key implementation details, including a new method for
extracting the critical temperature estimate from trained autoencoders and
calculations of the DNN initialization and learning rate settings required for
fair model comparisons.","['Devanshu Agrawal', 'Adrian Del Maestro', 'Steven Johnston', 'James Ostrowski']"
"FedHe: Heterogeneous Models and Communication-Efficient Federated
  Learning",Machine Learning,"Federated learning (FL) is able to manage edge devices to cooperatively train
a model while maintaining the training data local and private. One common
assumption in FL is that all edge devices share the same machine learning model
in training, for example, identical neural network architecture. However, the
computation and store capability of different devices may not be the same.
Moreover, reducing communication overheads can improve the training efficiency
though it is still a challenging problem in FL. In this paper, we propose a
novel FL method, called FedHe, inspired by knowledge distillation, which can
train heterogeneous models and support asynchronous training processes with
significantly reduced communication overheads. Our analysis and experimental
results demonstrate that the performance of our proposed method is better than
the state-of-the-art algorithms in terms of communication overheads and model
accuracy.","['Chan Yun Hin', 'Ngai Edith']"
Asynchronous Multi Agent Active Search,Machine Learning,"Active search refers to the problem of efficiently locating targets in an
unknown environment by actively making data-collection decisions, and has many
applications including detecting gas leaks, radiation sources or human
survivors of disasters using aerial and/or ground robots (agents). Existing
active search methods are in general only amenable to a single agent, or if
they extend to multi agent they require a central control system to coordinate
the actions of all agents. However, such control systems are often impractical
in robotics applications. In this paper, we propose two distinct active search
algorithms called SPATS (Sparse Parallel Asynchronous Thompson Sampling) and
LATSI (LAplace Thompson Sampling with Information gain) that allow for multiple
agents to independently make data-collection decisions without a central
coordinator. Throughout we consider that targets are sparsely located around
the environment in keeping with compressive sensing assumptions and its
applicability in real world scenarios. Additionally, while most common search
algorithms assume that agents can sense the entire environment (e.g.
compressive sensing) or sense point-wise (e.g. Bayesian Optimization) at all
times, we make a realistic assumption that each agent can only sense a
contiguous region of space at a time. We provide simulation results as well as
theoretical analysis to demonstrate the efficacy of our proposed algorithms.","['Ramina Ghods', 'Arundhati Banerjee', 'Jeff Schneider']"
Caveat Lector: Large Language Models in Legal Practice,Computation and Language (Natural Language Processing),"The current fascination with large language models, or LLMs, derives from the
fact that many users lack the expertise to evaluate the quality of the
generated text. LLMs may therefore appear more capable than they actually are.
The dangerous combination of fluency and superficial plausibility leads to the
temptation to trust the generated text and creates the risk of overreliance.
Who would not trust perfect legalese? Relying recent findings in both technical
and legal scholarship, this Article counterbalances the overly optimistic
predictions as to the role of LLMs in legal practice. Integrating LLMs into
legal workstreams without a better comprehension of their limitations, will
create inefficiencies if not outright risks. Notwithstanding their
unprecedented ability to generate text, LLMs do not understand text. Without
the ability to understand meaning, LLMs will remain unable to use language, to
acquire knowledge and to perform complex reasoning tasks. Trained to model
language on the basis of stochastic word predictions, LLMs cannot distinguish
fact from fiction. Their knowledge of the law is limited to word strings
memorized in their parameters. It is also incomplete and largely incorrect.
LLMs operate at the level of word distributions, not at the level of verified
facts. The resulting propensity to hallucinate, to produce statements that are
incorrect but appear helpful and relevant, is alarming in high-risk areas like
legal services. At present, lawyers should beware of relying on text generated
by LLMs.",['Eliza Mik']
"Improving the Robustness of Object Detection and Classification AI
  models against Adversarial Patch Attacks",Computer Vision and Pattern Recognition,"Adversarial patch attacks, crafted to compromise the integrity of Deep Neural
Networks (DNNs), significantly impact Artificial Intelligence (AI) systems
designed for object detection and classification tasks. The primary purpose of
this work is to defend models against real-world physical attacks that target
object detection and classification. We analyze attack techniques and propose a
robust defense approach. We successfully reduce model confidence by over 20%
using adversarial patch attacks that exploit object shape, texture and
position. Leveraging the inpainting pre-processing technique, we effectively
restore the original confidence levels, demonstrating the importance of robust
defenses in mitigating these threats. Following fine-tuning of an AI model for
traffic sign classification, we subjected it to a simulated pixelized
patch-based physical adversarial attack, resulting in misclassifications. Our
inpainting defense approach significantly enhances model resilience, achieving
high accuracy and reliable localization despite the adversarial attacks. This
contribution advances the resilience and reliability of object detection and
classification networks against adversarial challenges, providing a robust
foundation for critical applications.","['Roie Kazoom', 'Raz Birman', 'Ofer Hadar']"
"Prediction of Time and Distance of Trips Using Explainable
  Attention-based LSTMs",Machine Learning,"In this paper, we propose machine learning solutions to predict the time of
future trips and the possible distance the vehicle will travel. For this
prediction task, we develop and investigate four methods. In the first method,
we use long short-term memory (LSTM)-based structures specifically designed to
handle multi-dimensional historical data of trip time and distances
simultaneously. Using it, we predict the future trip time and forecast the
distance a vehicle will travel by concatenating the outputs of LSTM networks
through fully connected layers. The second method uses attention-based LSTM
networks (At-LSTM) to perform the same tasks. The third method utilizes two
LSTM networks in parallel, one for forecasting the time of the trip and the
other for predicting the distance. The output of each LSTM is then concatenated
through fully connected layers. Finally, the last model is based on two
parallel At-LSTMs, where similarly, each At-LSTM predicts time and distance
separately through fully connected layers. Among the proposed methods, the most
advanced one, i.e., parallel At-LSTM, predicts the next trip's distance and
time with 3.99% error margin where it is 23.89% better than LSTM, the first
method. We also propose TimeSHAP as an explainability method for understanding
how the networks perform learning and model the sequence of information.","['Ebrahim Balouji', 'Jonas Sjöblom', 'Nikolce Murgovski', 'Morteza Haghir Chehreghani']"
"An Agent Based Architecture (Using Planning) for Dynamic and Semantic
  Web Services Composition in an EBXML Context",Artificial Intelligence,"The process-based semantic composition of Web Services is gaining a
considerable momentum as an approach for the effective integration of
distributed, heterogeneous, and autonomous applications. To compose Web
Services semantically, we need an ontology. There are several ways of inserting
semantics in Web Services. One of them consists of using description languages
like OWL-S. In this paper, we introduce our work which consists in the
proposition of a new model and the use of semantic matching technology for
semantic and dynamic composition of ebXML business processes.","['Hioual Ouassila', 'Boufaida Zizette']"
The Convex Information Bottleneck Lagrangian,Machine Learning (Statistics),"The information bottleneck (IB) problem tackles the issue of obtaining
relevant compressed representations $T$ of some random variable $X$ for the
task of predicting $Y$. It is defined as a constrained optimization problem
which maximizes the information the representation has about the task,
$I(T;Y)$, while ensuring that a certain level of compression $r$ is achieved
(i.e., $ I(X;T) \leq r$). For practical reasons, the problem is usually solved
by maximizing the IB Lagrangian (i.e., $\mathcal{L}_{\text{IB}}(T;\beta) =
I(T;Y) - \beta I(X;T)$) for many values of $\beta \in [0,1]$. Then, the curve
of maximal $I(T;Y)$ for a given $I(X;T)$ is drawn and a representation with the
desired predictability and compression is selected. It is known when $Y$ is a
deterministic function of $X$, the IB curve cannot be explored and another
Lagrangian has been proposed to tackle this problem: the squared IB Lagrangian:
$\mathcal{L}_{\text{sq-IB}}(T;\beta_{\text{sq}})=I(T;Y)-\beta_{\text{sq}}I(X;T)^2$.
In this paper, we (i) present a general family of Lagrangians which allow for
the exploration of the IB curve in all scenarios; (ii) provide the exact
one-to-one mapping between the Lagrange multiplier and the desired compression
rate $r$ for known IB curve shapes; and (iii) show we can approximately obtain
a specific compression level with the convex IB Lagrangian for both known and
unknown IB curve shapes. This eliminates the burden of solving the optimization
problem for many values of the Lagrange multiplier. That is, we prove that we
can solve the original constrained problem with a single optimization.","['Borja Rodríguez-Gálvez', 'Ragnar Thobaben', 'Mikael Skoglund']"
Deep Reinforcement Learning in Parameterized Action Space,Artificial Intelligence,"Recent work has shown that deep neural networks are capable of approximating
both value functions and policies in reinforcement learning domains featuring
continuous state and action spaces. However, to the best of our knowledge no
previous work has succeeded at using deep neural networks in structured
(parameterized) continuous action spaces. To fill this gap, this paper focuses
on learning within the domain of simulated RoboCup soccer, which features a
small set of discrete action types, each of which is parameterized with
continuous variables. The best learned agent can score goals more reliably than
the 2012 RoboCup champion agent. As such, this paper represents a successful
extension of deep reinforcement learning to the class of parameterized action
space MDPs.","['Matthew Hausknecht', 'Peter Stone']"
An Interpretability Illusion for BERT,Computation and Language (Natural Language Processing),"We describe an ""interpretability illusion"" that arises when analyzing the
BERT model. Activations of individual neurons in the network may spuriously
appear to encode a single, simple concept, when in fact they are encoding
something far more complex. The same effect holds for linear combinations of
activations. We trace the source of this illusion to geometric properties of
BERT's embedding space as well as the fact that common text corpora represent
only narrow slices of possible English sentences. We provide a taxonomy of
model-learned concepts and discuss methodological implications for
interpretability research, especially the importance of testing hypotheses on
multiple data sets.","['Tolga Bolukbasi', 'Adam Pearce', 'Ann Yuan', 'Andy Coenen', 'Emily Reif', 'Fernanda Viégas', 'Martin Wattenberg']"
Fast TreeSHAP: Accelerating SHAP Value Computation for Trees,Machine Learning,"SHAP (SHapley Additive exPlanation) values are one of the leading tools for
interpreting machine learning models, with strong theoretical guarantees
(consistency, local accuracy) and a wide availability of implementations and
use cases. Even though computing SHAP values takes exponential time in general,
TreeSHAP takes polynomial time on tree-based models. While the speedup is
significant, TreeSHAP can still dominate the computation time of industry-level
machine learning solutions on datasets with millions or more entries, causing
delays in post-hoc model diagnosis and interpretation service. In this paper we
present two new algorithms, Fast TreeSHAP v1 and v2, designed to improve the
computational efficiency of TreeSHAP for large datasets. We empirically find
that Fast TreeSHAP v1 is 1.5x faster than TreeSHAP while keeping the memory
cost unchanged. Similarly, Fast TreeSHAP v2 is 2.5x faster than TreeSHAP, at
the cost of a slightly higher memory usage, thanks to the pre-computation of
expensive TreeSHAP steps. We also show that Fast TreeSHAP v2 is well-suited for
multi-time model interpretations, resulting in as high as 3x faster explanation
of newly incoming samples.",['Jilei Yang']
Generalization Error of GAN from the Discriminator's Perspective,Machine Learning,"The generative adversarial network (GAN) is a well-known model for learning
high-dimensional distributions, but the mechanism for its generalization
ability is not understood. In particular, GAN is vulnerable to the memorization
phenomenon, the eventual convergence to the empirical distribution. We consider
a simplified GAN model with the generator replaced by a density, and analyze
how the discriminator contributes to generalization. We show that with early
stopping, the generalization error measured by Wasserstein metric escapes from
the curse of dimensionality, despite that in the long term, memorization is
inevitable. In addition, we present a hardness of learning result for WGAN.","['Hongkang Yang', 'Weinan E']"
"Concentrate Attention: Towards Domain-Generalizable Prompt Optimization
  for Language Models",Computation and Language (Natural Language Processing),"Recent advances in prompt optimization have notably enhanced the performance
of pre-trained language models (PLMs) on downstream tasks. However, the
potential of optimized prompts on domain generalization has been
under-explored. To explore the nature of prompt generalization on unknown
domains, we conduct pilot experiments and find that (i) Prompts gaining more
attention weight from PLMs' deep layers are more generalizable and (ii) Prompts
with more stable attention distributions in PLMs' deep layers are more
generalizable. Thus, we offer a fresh objective towards domain-generalizable
prompts optimization named ""Concentration"", which represents the ""lookback""
attention from the current decoding token to the prompt tokens, to increase the
attention strength on prompts and reduce the fluctuation of attention
distribution. We adapt this new objective to popular soft prompt and hard
prompt optimization methods, respectively. Extensive experiments demonstrate
that our idea improves comparison prompt optimization methods by 1.42% for soft
prompt generalization and 2.16% for hard prompt generalization in accuracy on
the multi-source domain generalization setting, while maintaining satisfying
in-domain performance. The promising results validate the effectiveness of our
proposed prompt optimization objective and provide key insights into
domain-generalizable prompts.","['Chengzhengxu Li', 'Xiaoming Liu', 'Zhaohan Zhang', 'Yichen Wang', 'Chen Liu', 'Yu Lan', 'Chao Shen']"
"Learning Gaussian Graphical Models with Ordered Weighted L1
  Regularization",Machine Learning (Statistics),"We address the task of identifying densely connected subsets of multivariate
Gaussian random variables within a graphical model framework. We propose two
novel estimators based on the Ordered Weighted $\ell_1$ (OWL) norm: 1) The
Graphical OWL (GOWL) is a penalized likelihood method that applies the OWL norm
to the lower triangle components of the precision matrix. 2) The
column-by-column Graphical OWL (ccGOWL) estimates the precision matrix by
performing OWL regularized linear regressions. Both methods can simultaneously
identify highly correlated groups of variables and control the sparsity in the
resulting precision matrix. We formulate GOWL such that it solves a composite
optimization problem and establish that the estimator has a unique global
solution. In addition, we prove sufficient grouping conditions for each column
of the ccGOWL precision matrix estimate. We propose proximal descent algorithms
to find the optimum for both estimators. For synthetic data where group
structure is present, the ccGOWL estimator requires significantly reduced
computation and achieves similar or greater accuracy than state-of-the-art
estimators. Timing comparisons are presented and demonstrates the superior
computational efficiency of the ccGOWL. We illustrate the grouping performance
of the ccGOWL method on a cancer gene expression data set and an equities data
set.","['Cody Mazza-Anthony', 'Bogdan Mazoure', 'Mark Coates']"
"Beyond Unconstrained Features: Neural Collapse for Shallow Neural
  Networks with General Data",Machine Learning (Statistics),"Neural collapse (NC) is a phenomenon that emerges at the terminal phase of
the training (TPT) of deep neural networks (DNNs). The features of the data in
the same class collapse to their respective sample means and the sample means
exhibit a simplex equiangular tight frame (ETF). In the past few years, there
has been a surge of works that focus on explaining why the NC occurs and how it
affects generalization. Since the DNNs are notoriously difficult to analyze,
most works mainly focus on the unconstrained feature model (UFM). While the UFM
explains the NC to some extent, it fails to provide a complete picture of how
the network architecture and the dataset affect NC. In this work, we focus on
shallow ReLU neural networks and try to understand how the width, depth, data
dimension, and statistical property of the training dataset influence the
neural collapse. We provide a complete characterization of when the NC occurs
for two or three-layer neural networks. For two-layer ReLU neural networks, a
sufficient condition on when the global minimizer of the regularized empirical
risk function exhibits the NC configuration depends on the data dimension,
sample size, and the signal-to-noise ratio in the data instead of the network
width. For three-layer neural networks, we show that the NC occurs as long as
the first layer is sufficiently wide. Regarding the connection between NC and
generalization, we show the generalization heavily depends on the SNR
(signal-to-noise ratio) in the data: even if the NC occurs, the generalization
can still be bad provided that the SNR in the data is too low. Our results
significantly extend the state-of-the-art theoretical analysis of the N C under
the UFM by characterizing the emergence of the N C under shallow nonlinear
networks and showing how it depends on data properties and network
architecture.","['Wanli Hong', 'Shuyang Ling']"
"The Complexity of Bayesian Networks Specified by Propositional and
  Relational Languages",Artificial Intelligence,"We examine the complexity of inference in Bayesian networks specified by
logical languages. We consider representations that range from fragments of
propositional logic to function-free first-order logic with equality; in doing
so we cover a variety of plate models and of probabilistic relational models.
We study the complexity of inferences when network, query and domain are the
input (the inferential and the combined complexity), when the network is fixed
and query and domain are the input (the query/data complexity), and when the
network and query are fixed and the domain is the input (the domain
complexity). We draw connections with probabilistic databases and liftability
results, and obtain complexity classes that range from polynomial to
exponential levels.","['Fabio Gagliardi Cozman', 'Denis Deratani Mauá']"
Introducing Fuzzy Layers for Deep Learning,Computer Vision and Pattern Recognition,"Many state-of-the-art technologies developed in recent years have been
influenced by machine learning to some extent. Most popular at the time of this
writing are artificial intelligence methodologies that fall under the umbrella
of deep learning. Deep learning has been shown across many applications to be
extremely powerful and capable of handling problems that possess great
complexity and difficulty. In this work, we introduce a new layer to deep
learning: the fuzzy layer. Traditionally, the network architecture of neural
networks is composed of an input layer, some combination of hidden layers, and
an output layer. We propose the introduction of fuzzy layers into the deep
learning architecture to exploit the powerful aggregation properties expressed
through fuzzy methodologies, such as the Choquet and Sugueno fuzzy integrals.
To date, fuzzy approaches taken to deep learning have been through the
application of various fusion strategies at the decision level to aggregate
outputs from state-of-the-art pre-trained models, e.g., AlexNet, VGG16,
GoogLeNet, Inception-v3, ResNet-18, etc. While these strategies have been shown
to improve accuracy performance for image classification tasks, none have
explored the use of fuzzified intermediate, or hidden, layers. Herein, we
present a new deep learning strategy that incorporates fuzzy strategies into
the deep learning architecture focused on the application of semantic
segmentation using per-pixel classification. Experiments are conducted on a
benchmark data set as well as a data set collected via an unmanned aerial
system at a U.S. Army test site for the task of automatic road segmentation,
and preliminary results are promising.","['Stanton R. Price', 'Steven R. Price', 'Derek T. Anderson']"
"Are Current Task-oriented Dialogue Systems Able to Satisfy Impolite
  Users?",Computation and Language (Natural Language Processing),"Task-oriented dialogue (TOD) systems have assisted users on many tasks,
including ticket booking and service inquiries. While existing TOD systems have
shown promising performance in serving customer needs, these systems mostly
assume that users would interact with the dialogue agent politely. This
assumption is unrealistic as impatient or frustrated customers may also
interact with TOD systems impolitely. This paper aims to address this research
gap by investigating impolite users' effects on TOD systems. Specifically, we
constructed an impolite dialogue corpus and conducted extensive experiments to
evaluate the state-of-the-art TOD systems on our impolite dialogue corpus. Our
experimental results show that existing TOD systems are unable to handle
impolite user utterances. We also present a data augmentation method to improve
TOD performance in impolite dialogues. Nevertheless, handling impolite
dialogues remains a very challenging research task. We hope by releasing the
impolite dialogue corpus and establishing the benchmark evaluations, more
researchers are encouraged to investigate this new challenging research task.","['Zhiqiang Hu', 'Roy Kaa-Wei Lee', 'Nancy F. Chen']"
Feature Descriptors for Tracking by Detection: a Benchmark,Computer Vision and Pattern Recognition,"In this paper, we provide an extensive evaluation of the performance of local
descriptors for tracking applications. Many different descriptors have been
proposed in the literature for a wide range of application in computer vision
such as object recognition and 3D reconstruction. More recently, due to fast
key-point detectors, local image features can be used in online tracking
frameworks. However, while much effort has been spent on evaluating their
performance in terms of distinctiveness and robustness to image
transformations, very little has been done in the contest of tracking. Our
evaluation is performed in terms of distinctiveness, tracking precision and
tracking speed. Our results show that binary descriptors like ORB or BRISK have
comparable results to SIFT or AKAZE due to a higher number of key-points.","['Alessandro Pieropan', 'Mårten Björkman', 'Niklas Bergström', 'Danica Kragic']"
"From driving automation systems to autonomous vehicles: clarifying the
  terminology",Artificial Intelligence,"The terminological landscape is rather cluttered when referring to autonomous
driving or vehicles. A plethora of terms are used interchangeably, leading to
misuse and confusion. With its technological, social and legal progress, it is
increasingly imperative to establish a clear terminology that allows each
concept to be placed in its corresponding place.",['David Fernández Llorca']
Contrastive Representation Learning for Gaze Estimation,Computer Vision and Pattern Recognition,"Self-supervised learning (SSL) has become prevalent for learning
representations in computer vision. Notably, SSL exploits contrastive learning
to encourage visual representations to be invariant under various image
transformations. The task of gaze estimation, on the other hand, demands not
just invariance to various appearances but also equivariance to the geometric
transformations. In this work, we propose a simple contrastive representation
learning framework for gaze estimation, named Gaze Contrastive Learning
(GazeCLR). GazeCLR exploits multi-view data to promote equivariance and relies
on selected data augmentation techniques that do not alter gaze directions for
invariance learning. Our experiments demonstrate the effectiveness of GazeCLR
for several settings of the gaze estimation task. Particularly, our results
show that GazeCLR improves the performance of cross-domain gaze estimation and
yields as high as 17.2% relative improvement. Moreover, the GazeCLR framework
is competitive with state-of-the-art representation learning methods for
few-shot evaluation. The code and pre-trained models are available at
https://github.com/jswati31/gazeclr.","['Swati Jindal', 'Roberto Manduchi']"
"Project proposal: A modular reinforcement learning based automated
  theorem prover",Artificial Intelligence,"We propose to build a reinforcement learning prover of independent
components: a deductive system (an environment), the proof state representation
(how an agent sees the environment), and an agent training algorithm. To that
purpose, we contribute an additional Vampire-based environment to
$\texttt{gym-saturation}$ package of OpenAI Gym environments for saturation
provers. We demonstrate a prototype of using $\texttt{gym-saturation}$ together
with a popular reinforcement learning framework (Ray $\texttt{RLlib}$).
Finally, we discuss our plans for completing this work in progress to a
competitive automated theorem prover.",['Boris Shminke']
Boosting Neural Machine Translation,Computation and Language (Natural Language Processing),"Training efficiency is one of the main problems for Neural Machine
Translation (NMT). Deep networks need for very large data as well as many
training iterations to achieve state-of-the-art performance. This results in
very high computation cost, slowing down research and industrialisation. In
this paper, we propose to alleviate this problem with several training methods
based on data boosting and bootstrap with no modifications to the neural
network. It imitates the learning process of humans, which typically spend more
time when learning ""difficult"" concepts than easier ones. We experiment on an
English-French translation task showing accuracy improvements of up to 1.63
BLEU while saving 20% of training time.","['Dakun Zhang', 'Jungi Kim', 'Josep Crego', 'Jean Senellart']"
Knowledge-Guided Deep Fractal Neural Networks for Human Pose Estimation,Computer Vision and Pattern Recognition,"Human pose estimation using deep neural networks aims to map input images
with large variations into multiple body keypoints which must satisfy a set of
geometric constraints and inter-dependency imposed by the human body model.
This is a very challenging nonlinear manifold learning process in a very high
dimensional feature space. We believe that the deep neural network, which is
inherently an algebraic computation system, is not the most effecient way to
capture highly sophisticated human knowledge, for example those highly coupled
geometric characteristics and interdependence between keypoints in human poses.
In this work, we propose to explore how external knowledge can be effectively
represented and injected into the deep neural networks to guide its training
process using learned projections that impose proper prior. Specifically, we
use the stacked hourglass design and inception-resnet module to construct a
fractal network to regress human pose images into heatmaps with no explicit
graphical modeling. We encode external knowledge with visual features which are
able to characterize the constraints of human body models and evaluate the
fitness of intermediate network output. We then inject these external features
into the neural network using a projection matrix learned using an auxiliary
cost function. The effectiveness of the proposed inception-resnet module and
the benefit in guided learning with knowledge projection is evaluated on two
widely used benchmarks. Our approach achieves state-of-the-art performance on
both datasets.","['Guanghan Ning', 'Zhi Zhang', 'Zhihai He']"
"Robust Multi-view Registration of Point Sets with Laplacian Mixture
  Model",Computer Vision and Pattern Recognition,"Point set registration is an essential step in many computer vision
applications, such as 3D reconstruction and SLAM. Although there exist many
registration algorithms for different purposes, however, this topic is still
challenging due to the increasing complexity of various real-world scenarios,
such as heavy noise and outlier contamination. In this paper, we propose a
novel probabilistic generative method to simultaneously align multiple point
sets based on the heavy-tailed Laplacian distribution. The proposed method
assumes each data point is generated by a Laplacian Mixture Model (LMM), where
its centers are determined by the corresponding points in other point sets.
Different from the previous Gaussian Mixture Model (GMM) based method, which
minimizes the quadratic distance between points and centers of Gaussian
probability density, LMM minimizes the sparsity-induced L1 distance, thereby it
is more robust against noise and outliers. We adopt Expectation-Maximization
(EM) framework to solve LMM parameters and rigid transformations. We
approximate the L1 optimization as a linear programming problem by exponential
mapping in Lie algebra, which can be effectively solved through the interior
point method. To improve efficiency, we also solve the L1 optimization by
Alternating Direction Multiplier Method (ADMM). We demonstrate the advantages
of our method by comparing it with representative state-of-the-art approaches
on benchmark challenging data sets, in terms of robustness and accuracy.","['Jin Zhang', 'Mingyang Zhao', 'Xin Jiang', 'Dong-Ming Yan']"
"Common-Description Learning: A Framework for Learning Algorithms and
  Generating Subproblems from Few Examples",Artificial Intelligence,"Current learning algorithms face many difficulties in learning simple
patterns and using them to learn more complex ones. They also require more
examples than humans do to learn the same pattern, assuming no prior knowledge.
In this paper, a new learning framework is introduced that is called
common-description learning (CDL). This framework has been tested on 32 small
multi-task datasets, and the results show that it was able to learn complex
algorithms from a few number of examples. The final model is perfectly
interpretable and its depth depends on the question. What is meant by depth
here is that whenever needed, the model learns to break down the problem into
simpler subproblems and solves them using previously learned models. Finally,
we explain the capabilities of our framework in discovering complex relations
in data and how it can help in improving language understanding in machines.",['Basem G. El-Barashy']
"Multi-dimensional Gated Recurrent Units for Automated Anatomical
  Landmark Localization",Computer Vision and Pattern Recognition,"We present an automated method for localizing an anatomical landmark in
three-dimensional medical images. The method combines two recurrent neural
networks in a coarse-to-fine approach: The first network determines a candidate
neighborhood by analyzing the complete given image volume. The second network
localizes the actual landmark precisely and accurately in the candidate
neighborhood. Both networks take advantage of multi-dimensional gated recurrent
units in their main layers, which allow for high model complexity with a
comparatively small set of parameters. We localize the medullopontine sulcus in
3D magnetic resonance images of the head and neck. We show that the proposed
approach outperforms similar localization techniques both in terms of mean
distance in millimeters and voxels w.r.t. manual labelings of the data. With a
mean localization error of 1.7 mm, the proposed approach performs on par with
neurological experts, as we demonstrate in an interrater comparison.","['Simon Andermatt', 'Simon Pezold', 'Michael Amann', 'Philippe C. Cattin']"
Black Box Adversarial Prompting for Foundation Models,Machine Learning,"Prompting interfaces allow users to quickly adjust the output of generative
models in both vision and language. However, small changes and design choices
in the prompt can lead to significant differences in the output. In this work,
we develop a black-box framework for generating adversarial prompts for
unstructured image and text generation. These prompts, which can be standalone
or prepended to benign prompts, induce specific behaviors into the generative
process, such as generating images of a particular object or generating high
perplexity text.","['Natalie Maus', 'Patrick Chao', 'Eric Wong', 'Jacob Gardner']"
Online Learning Using Only Peer Prediction,Machine Learning,"This paper considers a variant of the classical online learning problem with
expert predictions. Our model's differences and challenges are due to lacking
any direct feedback on the loss each expert incurs at each time step $t$. We
propose an approach that uses peer prediction and identify conditions where it
succeeds. Our techniques revolve around a carefully designed peer score
function $s()$ that scores experts' predictions based on the peer consensus. We
show a sufficient condition, that we call \emph{peer calibration}, under which
standard online learning algorithms using loss feedback computed by the
carefully crafted $s()$ have bounded regret with respect to the unrevealed
ground truth values. We then demonstrate how suitable $s()$ functions can be
derived for different assumptions and models.","['Yang Liu', 'David P. Helmbold']"
Learning to Train a Binary Neural Network,Machine Learning,"Convolutional neural networks have achieved astonishing results in different
application areas. Various methods which allow us to use these models on mobile
and embedded devices have been proposed. Especially binary neural networks seem
to be a promising approach for these devices with low computational power.
However, understanding binary neural networks and training accurate models for
practical applications remains a challenge. In our work, we focus on increasing
our understanding of the training process and making it accessible to everyone.
We publish our code and models based on BMXNet for everyone to use. Within this
framework, we systematically evaluated different network architectures and
hyperparameters to provide useful insights on how to train a binary neural
network. Further, we present how we improved accuracy by increasing the number
of connections in the network.","['Joseph Bethge', 'Haojin Yang', 'Christian Bartz', 'Christoph Meinel']"
Adaptive Gradient Method with Resilience and Momentum,Machine Learning,"Several variants of stochastic gradient descent (SGD) have been proposed to
improve the learning effectiveness and efficiency when training deep neural
networks, among which some recent influential attempts would like to adaptively
control the parameter-wise learning rate (e.g., Adam and RMSProp). Although
they show a large improvement in convergence speed, most adaptive learning rate
methods suffer from compromised generalization compared with SGD. In this
paper, we proposed an Adaptive Gradient Method with Resilience and Momentum
(AdaRem), motivated by the observation that the oscillations of network
parameters slow the training, and give a theoretical proof of convergence. For
each parameter, AdaRem adjusts the parameter-wise learning rate according to
whether the direction of one parameter changes in the past is aligned with the
direction of the current gradient, and thus encourages long-term consistent
parameter updating with much fewer oscillations. Comprehensive experiments have
been conducted to verify the effectiveness of AdaRem when training various
models on a large-scale image recognition dataset, e.g., ImageNet, which also
demonstrate that our method outperforms previous adaptive learning rate-based
algorithms in terms of the training speed and the test error, respectively.","['Jie Liu', 'Chen Lin', 'Chuming Li', 'Lu Sheng', 'Ming Sun', 'Junjie Yan', 'Wanli Ouyang']"
"T5 for Hate Speech, Augmented Data and Ensemble",Computation and Language (Natural Language Processing),"We conduct relatively extensive investigations of automatic hate speech (HS)
detection using different state-of-the-art (SoTA) baselines over 11 subtasks of
6 different datasets. Our motivation is to determine which of the recent SoTA
models is best for automatic hate speech detection and what advantage methods
like data augmentation and ensemble may have on the best model, if any. We
carry out 6 cross-task investigations. We achieve new SoTA on two subtasks -
macro F1 scores of 91.73% and 53.21% for subtasks A and B of the HASOC 2020
dataset, where previous SoTA are 51.52% and 26.52%, respectively. We achieve
near-SoTA on two others - macro F1 scores of 81.66% for subtask A of the OLID
2019 dataset and 82.54% for subtask A of the HASOC 2021 dataset, where SoTA are
82.9% and 83.05%, respectively. We perform error analysis and use two
explainable artificial intelligence (XAI) algorithms (IG and SHAP) to reveal
how two of the models (Bi-LSTM and T5) make the predictions they do by using
examples. Other contributions of this work are 1) the introduction of a simple,
novel mechanism for correcting out-of-class (OOC) predictions in T5, 2) a
detailed description of the data augmentation methods, 3) the revelation of the
poor data annotations in the HASOC 2021 dataset by using several examples and
XAI (buttressing the need for better quality control), and 4) the public
release of our model checkpoints and codes to foster transparency.","['Tosin Adewumi', 'Sana Sabah Sabry', 'Nosheen Abid', 'Foteini Liwicki', 'Marcus Liwicki']"
"A Hybrid System for Systematic Generalization in Simple Arithmetic
  Problems",Neural and Evolutionary Computing,"Solving symbolic reasoning problems that require compositionality and
systematicity is considered one of the key ingredients of human intelligence.
However, symbolic reasoning is still a great challenge for deep learning
models, which often cannot generalize the reasoning pattern to
out-of-distribution test cases. In this work, we propose a hybrid system
capable of solving arithmetic problems that require compositional and
systematic reasoning over sequences of symbols. The model acquires such a skill
by learning appropriate substitution rules, which are applied iteratively to
the input string until the expression is completely resolved. We show that the
proposed system can accurately solve nested arithmetical expressions even when
trained only on a subset including the simplest cases, significantly
outperforming both a sequence-to-sequence model trained end-to-end and a
state-of-the-art large language model.","['Flavio Petruzzellis', 'Alberto Testolin', 'Alessandro Sperduti']"
"MiddleGAN: Generate Domain Agnostic Samples for Unsupervised Domain
  Adaptation",Computer Vision and Pattern Recognition,"In recent years, machine learning has achieved impressive results across
different application areas. However, machine learning algorithms do not
necessarily perform well on a new domain with a different distribution than its
training set. Domain Adaptation (DA) is used to mitigate this problem. One
approach of existing DA algorithms is to find domain invariant features whose
distributions in the source domain are the same as their distribution in the
target domain. In this paper, we propose to let the classifier that performs
the final classification task on the target domain learn implicitly the
invariant features to perform classification. It is achieved via feeding the
classifier during training generated fake samples that are similar to samples
from both the source and target domains. We call these generated samples
domain-agnostic samples. To accomplish this we propose a novel variation of
generative adversarial networks (GAN), called the MiddleGAN, that generates
fake samples that are similar to samples from both the source and target
domains, using two discriminators and one generator. We extend the theory of
GAN to show that there exist optimal solutions for the parameters of the two
discriminators and one generator in MiddleGAN, and empirically show that the
samples generated by the MiddleGAN are similar to both samples from the source
domain and samples from the target domain. We conducted extensive evaluations
using 24 benchmarks; on the 24 benchmarks, we compare MiddleGAN against various
state-of-the-art algorithms and outperform the state-of-the-art by up to 20.1\%
on certain benchmarks.","['Ye Gao', 'Zhendong Chu', 'Hongning Wang', 'John Stankovic']"
"Generalization ability and Vulnerabilities to adversarial perturbations:
  Two sides of the same coin",Machine Learning,"Deep neural networks (DNNs), the agents of deep learning (DL), require a
massive number of parallel/sequential operations, which makes it difficult to
comprehend them and impedes proper diagnosis. Without better knowledge of DNNs'
internal process, deploying DNNs in high-stakes domains may lead to
catastrophic failures. Therefore, to build more reliable DNNs/DL, it is
imperative that we gain insights into their underlying decision-making process.
Here, we use the self-organizing map (SOM) to analyze DL models' internal codes
associated with DNNs' decision-making. Our analyses suggest that shallow layers
close to the input layer map onto homogeneous codes and that deep layers close
to the output layer transform these homogeneous codes in shallow layers to
diverse codes. We also found evidence indicating that homogeneous codes may
underlie DNNs' vulnerabilities to adversarial perturbations.","['Jung Hoon Lee', 'Sujith Vijayan']"
The Computational Limits of Deep Learning,Machine Learning,"Deep learning's recent history has been one of achievement: from triumphing
over humans in the game of Go to world-leading performance in image
classification, voice recognition, translation, and other tasks. But this
progress has come with a voracious appetite for computing power. This article
catalogs the extent of this dependency, showing that progress across a wide
variety of applications is strongly reliant on increases in computing power.
Extrapolating forward this reliance reveals that progress along current lines
is rapidly becoming economically, technically, and environmentally
unsustainable. Thus, continued progress in these applications will require
dramatically more computationally-efficient methods, which will either have to
come from changes to deep learning or from moving to other machine learning
methods.","['Neil C. Thompson', 'Kristjan Greenewald', 'Keeheon Lee', 'Gabriel F. Manso']"
Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach,Optimization and Control,"Mean-field Langevin dynamics (MLFD) is a class of interacting particle
methods that tackle convex optimization over probability measures on a
manifold, which are scalable, versatile, and enjoy computational guarantees.
However, some important problems -- such as risk minimization for infinite
width two-layer neural networks, or sparse deconvolution -- are originally
defined over the set of signed, rather than probability, measures. In this
paper, we investigate how to extend the MFLD framework to convex optimization
problems over signed measures. Among two known reductions from signed to
probability measures -- the lifting and the bilevel approaches -- we show that
the bilevel reduction leads to stronger guarantees and faster rates (at the
price of a higher per-iteration complexity). In particular, we investigate the
convergence rate of MFLD applied to the bilevel reduction in the low-noise
regime and obtain two results. First, this dynamics is amenable to an annealing
schedule, adapted from Suzuki et al. (2023), that results in improved
convergence rates to a fixed multiplicative accuracy. Second, we investigate
the problem of learning a single neuron with the bilevel approach and obtain
local exponential convergence rates that depend polynomially on the dimension
and noise level (to compare with the exponential dependence that would result
from prior analyses).","['Guillaume Wang', 'Alireza Mousavi-Hosseini', 'Lénaïc Chizat']"
Gaussian Process Networks,Artificial Intelligence,"In this paper we address the problem of learning the structure of a Bayesian
network in domains with continuous variables. This task requires a procedure
for comparing different candidate structures. In the Bayesian framework, this
is done by evaluating the {em marginal likelihood/} of the data given a
candidate structure. This term can be computed in closed-form for standard
parametric families (e.g., Gaussians), and can be approximated, at some
computational cost, for some semi-parametric families (e.g., mixtures of
Gaussians).
  We present a new family of continuous variable probabilistic networks that
are based on {em Gaussian Process/} priors. These priors are semi-parametric in
nature and can learn almost arbitrary noisy functional relations. Using these
priors, we can directly compute marginal likelihoods for structure learning.
The resulting method can discover a wide range of functional dependencies in
multivariate data. We develop the Bayesian score of Gaussian Process Networks
and describe how to learn them from data. We present empirical results on
artificial data as well as on real-life domains with non-linear dependencies.","['Nir Friedman', 'Iftach Nachman']"
"Tinkering Under the Hood: Interactive Zero-Shot Learning with Net
  Surgery",Computer Vision and Pattern Recognition,"We consider the task of visual net surgery, in which a CNN can be
reconfigured without extra data to recognize novel concepts that may be omitted
from the training set. While most prior work make use of linguistic cues for
such ""zero-shot"" learning, we do so by using a pictorial language
representation of the training set, implicitly learned by a CNN, to generalize
to new classes. To this end, we introduce a set of visualization techniques
that better reveal the activation patterns and relations between groups of CNN
filters. We next demonstrate that knowledge of pictorial languages can be used
to rewire certain CNN neurons into a part model, which we call a pictorial
language classifier. We demonstrate the robustness of simple PLCs by applying
them in a weakly supervised manner: labeling unlabeled concepts for visual
classes present in the training data. Specifically we show that a PLC built on
top of a CNN trained for ImageNet classification can localize humans in Graz-02
and determine the pose of birds in PASCAL-VOC without extra labeled data or
additional training. We then apply PLCs in an interactive zero-shot manner,
demonstrating that pictorial languages are expressive enough to detect a set of
visual classes in MS-COCO that never appear in the ImageNet training set.","['Vivek Krishnan', 'Deva Ramanan']"
Pyramidal Fisher Motion for Multiview Gait Recognition,Computer Vision and Pattern Recognition,"The goal of this paper is to identify individuals by analyzing their gait.
Instead of using binary silhouettes as input data (as done in many previous
works) we propose and evaluate the use of motion descriptors based on densely
sampled short-term trajectories. We take advantage of state-of-the-art people
detectors to define custom spatial configurations of the descriptors around the
target person. Thus, obtaining a pyramidal representation of the gait motion.
The local motion features (described by the Divergence-Curl-Shear descriptor)
extracted on the different spatial areas of the person are combined into a
single high-level gait descriptor by using the Fisher Vector encoding. The
proposed approach, coined Pyramidal Fisher Motion, is experimentally validated
on the recent `AVA Multiview Gait' dataset. The results show that this new
approach achieves promising results in the problem of gait recognition.","['F. M. Castro', 'M. J. Marin-Jimenez', 'R. Medina-Carnicer']"
Knot Selection in Sparse Gaussian Processes,Machine Learning (Statistics),"Knot-based, sparse Gaussian processes have enjoyed considerable success as
scalable approximations to full Gaussian processes. Problems can occur,
however, when knot selection is done by optimizing the marginal likelihood. For
example, the marginal likelihood surface is highly multimodal, which can cause
suboptimal knot placement where some knots serve practically no function. This
is especially a problem when many more knots are used than are necessary,
resulting in extra computational cost for little to no gains in accuracy.
  We propose a one-at-a-time knot selection algorithm to select both the number
and placement of knots. Our algorithm uses Bayesian optimization to efficiently
propose knots that are likely to be good and largely avoids the pathologies
encountered when using the marginal likelihood as the objective function. We
provide empirical results showing improved accuracy and speed over the current
standard approaches.","['Nathaniel Garton', 'Jarad Niemi', 'Alicia Carriquiry']"
Imitation of Manipulation Skills Using Multiple Geometries,Robotics,"Daily manipulation tasks are characterized by geometric primitives related to
actions and object shapes. Such geometric descriptors are poorly represented by
only using Cartesian coordinate systems. In this paper, we propose a learning
approach to extract the optimal representation from a dictionary of coordinate
systems to encode an observed movement/behavior. This is achieved by using an
extension of Gaussian distributions on Riemannian manifolds, which is used to
analyse a set of user demonstrations statistically, by considering multiple
geometries as candidate representations of the task. We formulate the
reproduction problem as a general optimal control problem based on an iterative
linear quadratic regulator (iLQR), where the Gaussian distribution in the
extracted coordinate systems are used to define the cost function. We apply our
approach to object grasping and box opening tasks in simulation and on a 7-axis
Franka Emika robot. The results show that the robot can exploit several
geometries to execute the manipulation task and generalize it to new
situations, by maintaining the invariant characteristics of the task in the
coordinate system(s) of interest.","['Boyang Ti', 'Yongsheng Gao', 'Jie Zhao', 'Sylvain Calinon']"
Optimizing Performance of Recurrent Neural Networks on GPUs,Machine Learning,"As recurrent neural networks become larger and deeper, training times for
single networks are rising into weeks or even months. As such there is a
significant incentive to improve the performance and scalability of these
networks. While GPUs have become the hardware of choice for training and
deploying recurrent models, the implementations employed often make use of only
basic optimizations for these architectures. In this article we demonstrate
that by exposing parallelism between operations within the network, an order of
magnitude speedup across a range of network sizes can be achieved over a naive
implementation. We describe three stages of optimization that have been
incorporated into the fifth release of NVIDIA's cuDNN: firstly optimizing a
single cell, secondly a single layer, and thirdly the entire network.","['Jeremy Appleyard', 'Tomas Kocisky', 'Phil Blunsom']"
"Investigating the use of ChatGPT for the scheduling of construction
  projects",Human-Computer Interaction,"Large language models such as ChatGPT have the potential to revolutionize the
construction industry by automating repetitive and time-consuming tasks. This
paper presents a study in which ChatGPT was used to generate a construction
schedule for a simple construction project. The output from ChatGPT was
evaluated by a pool of participants that provided feedback regarding their
overall interaction experience and the quality of the output. The results show
that ChatGPT can generate a coherent schedule that follows a logical approach
to fulfill the requirements of the scope indicated. The participants had an
overall positive interaction experience and indicated the great potential of
such a tool to automate many preliminary and time-consuming tasks. However, the
technology still has limitations, and further development is needed before it
can be widely adopted in the industry. Overall, this study highlights the
potential of using large language models in the construction industry and the
need for further research.","['Samuel A. Prieto', 'Eyob T. Mengiste', 'Borja García de Soto']"
"Symbolic Regression for Space Applications: Differentiable Cartesian
  Genetic Programming Powered by Multi-objective Memetic Algorithms",Artificial Intelligence,"Interpretable regression models are important for many application domains,
as they allow experts to understand relations between variables from sparse
data. Symbolic regression addresses this issue by searching the space of all
possible free form equations that can be constructed from elementary algebraic
functions. While explicit mathematical functions can be rediscovered this way,
the determination of unknown numerical constants during search has been an
often neglected issue. We propose a new multi-objective memetic algorithm that
exploits a differentiable Cartesian Genetic Programming encoding to learn
constants during evolutionary loops. We show that this approach is competitive
or outperforms machine learned black box regression models or hand-engineered
fits for two applications from space: the Mars express thermal power estimation
and the determination of the age of stars by gyrochronology.","['Marcus Märtens', 'Dario Izzo']"
"Dialogue Term Extraction using Transfer Learning and Topological Data
  Analysis",Computation and Language (Natural Language Processing),"Goal oriented dialogue systems were originally designed as a natural language
interface to a fixed data-set of entities that users might inquire about,
further described by domain, slots, and values. As we move towards adaptable
dialogue systems where knowledge about domains, slots, and values may change,
there is an increasing need to automatically extract these terms from raw
dialogues or related non-dialogue data on a large scale. In this paper, we take
an important step in this direction by exploring different features that can
enable systems to discover realizations of domains, slots, and values in
dialogues in a purely data-driven fashion. The features that we examine stem
from word embeddings, language modelling features, as well as topological
features of the word embedding space. To examine the utility of each feature
set, we train a seed model based on the widely used MultiWOZ data-set. Then, we
apply this model to a different corpus, the Schema-Guided Dialogue data-set.
Our method outperforms the previously proposed approach that relies solely on
word embeddings. We also demonstrate that each of the features is responsible
for discovering different kinds of content. We believe our results warrant
further research towards ontology induction, and continued harnessing of
topological data analysis for dialogue and natural language processing
research.","['Renato Vukovic', 'Michael Heck', 'Benjamin Matthias Ruppik', 'Carel van Niekerk', 'Marcus Zibrowius', 'Milica Gašić']"
"Multi-Domain Adversarial Feature Generalization for Person
  Re-Identification",Computer Vision and Pattern Recognition,"With the assistance of sophisticated training methods applied to single
labeled datasets, the performance of fully-supervised person re-identification
(Person Re-ID) has been improved significantly in recent years. However, these
models trained on a single dataset usually suffer from considerable performance
degradation when applied to videos of a different camera network. To make
Person Re-ID systems more practical and scalable, several cross-dataset domain
adaptation methods have been proposed, which achieve high performance without
the labeled data from the target domain. However, these approaches still
require the unlabeled data of the target domain during the training process,
making them impractical. A practical Person Re-ID system pre-trained on other
datasets should start running immediately after deployment on a new site
without having to wait until sufficient images or videos are collected and the
pre-trained model is tuned. To serve this purpose, in this paper, we
reformulate person re-identification as a multi-dataset domain generalization
problem. We propose a multi-dataset feature generalization network (MMFA-AAE),
which is capable of learning a universal domain-invariant feature
representation from multiple labeled datasets and generalizing it to `unseen'
camera systems. The network is based on an adversarial auto-encoder to learn a
generalized domain-invariant latent feature representation with the Maximum
Mean Discrepancy (MMD) measure to align the distributions across multiple
domains. Extensive experiments demonstrate the effectiveness of the proposed
method. Our MMFA-AAE approach not only outperforms most of the domain
generalization Person Re-ID methods, but also surpasses many state-of-the-art
supervised methods and unsupervised domain adaptation methods by a large
margin.","['Shan Lin', 'Chang-Tsun Li', 'Alex C. Kot']"
"Recognizing and Splitting Conditional Sentences for Automation of
  Business Processes Management",Computation and Language (Natural Language Processing),"Business Process Management (BPM) is the discipline which is responsible for
management of discovering, analyzing, redesigning, monitoring, and controlling
business processes. One of the most crucial tasks of BPM is discovering and
modelling business processes from text documents. In this paper, we present our
system that resolves an end-to-end problem consisting of 1) recognizing
conditional sentences from technical documents, 2) finding boundaries to
extract conditional and resultant clauses from each conditional sentence, and
3) categorizing resultant clause as Action or Consequence which later helps to
generate new steps in our business process model automatically. We created a
new dataset and three models solve this problem. Our best model achieved very
promising results of 83.82, 87.84, and 85.75 for Precision, Recall, and F1,
respectively, for extracting Condition, Action, and Consequence clauses using
Exact Match metric.","['Ngoc Phuoc An Vo', 'Irene Manotas', 'Octavian Popescu', 'Algimantas Cerniauskas', 'Vadim Sheinin']"
"Linear Matrix Factorization Embeddings for Single-objective Optimization
  Landscapes",Neural and Evolutionary Computing,"Automated per-instance algorithm selection and configuration have shown
promising performances for a number of classic optimization problems, including
satisfiability, AI planning, and TSP. The techniques often rely on a set of
features that measure some characteristics of the problem instance at hand. In
the context of black-box optimization, these features have to be derived from a
set of $(x,f(x))$ samples. A number of different features have been proposed in
the literature, measuring, for example, the modality, the separability, or the
ruggedness of the instance at hand. Several of the commonly used features,
however, are highly correlated. While state-of-the-art machine learning
techniques can routinely filter such correlations, they hinder explainability
of the derived algorithm design techniques.
  We therefore propose in this work to pre-process the measured (raw) landscape
features through representation learning. More precisely, we show that a linear
dimensionality reduction via matrix factorization significantly contributes
towards a better detection of correlation between different problem instances
-- a key prerequisite for successful automated algorithm design.","['Tome Eftimov', 'Gorjan Popovski', 'Quentin Renau', 'Peter Korosec', 'Carola Doerr']"
"The Better Angels of Machine Personality: How Personality Relates to LLM
  Safety",Computation and Language (Natural Language Processing),"Personality psychologists have analyzed the relationship between personality
and safety behaviors in human society. Although Large Language Models (LLMs)
demonstrate personality traits, the relationship between personality traits and
safety abilities in LLMs still remains a mystery. In this paper, we discover
that LLMs' personality traits are closely related to their safety abilities,
i.e., toxicity, privacy, and fairness, based on the reliable MBTI-M scale.
Meanwhile, the safety alignment generally increases various LLMs' Extraversion,
Sensing, and Judging traits. According to such findings, we can edit LLMs'
personality traits and improve their safety performance, e.g., inducing
personality from ISTJ to ISTP resulted in a relative improvement of
approximately 43% and 10% in privacy and fairness performance, respectively.
Additionally, we find that LLMs with different personality traits are
differentially susceptible to jailbreak. This study pioneers the investigation
of LLM safety from a personality perspective, providing new insights into LLM
safety enhancement.","['Jie Zhang', 'Dongrui Liu', 'Chen Qian', 'Ziyue Gan', 'Yong Liu', 'Yu Qiao', 'Jing Shao']"
"Textbook Question Answering with Multi-modal Context Graph Understanding
  and Self-supervised Open-set Comprehension",Computation and Language (Natural Language Processing),"In this work, we introduce a novel algorithm for solving the textbook
question answering (TQA) task which describes more realistic QA problems
compared to other recent tasks. We mainly focus on two related issues with
analysis of the TQA dataset. First, solving the TQA problems requires to
comprehend multi-modal contexts in complicated input data. To tackle this issue
of extracting knowledge features from long text lessons and merging them with
visual features, we establish a context graph from texts and images, and
propose a new module f-GCN based on graph convolutional networks (GCN). Second,
scientific terms are not spread over the chapters and subjects are split in the
TQA dataset. To overcome this so called ""out-of-domain"" issue, before learning
QA problems, we introduce a novel self-supervised open-set learning process
without any annotations. The experimental results show that our model
significantly outperforms prior state-of-the-art methods. Moreover, ablation
studies validate that both methods of incorporating f-GCN for extracting
knowledge from multi-modal contexts and our newly proposed self-supervised
learning process are effective for TQA problems.","['Daesik Kim', 'Seonhoon Kim', 'Nojun Kwak']"
Estimating Model Performance Under Covariate Shift Without Labels,Machine Learning,"Machine learning models often experience performance degradation
post-deployment due to shifts in data distribution. It is challenging to assess
model's performance accurately when labels are missing or delayed. Existing
proxy methods, such as drift detection, fail to measure the effects of these
shifts adequately. To address this, we introduce a new method, Probabilistic
Adaptive Performance Estimation (PAPE), for evaluating classification models on
unlabeled data that accurately quantifies the impact of covariate shift on
model performance. It is model and data-type agnostic and works for various
performance metrics. Crucially, PAPE operates independently of the original
model, relying only on its predictions and probability estimates, and does not
need any assumptions about the nature of the covariate shift, learning directly
from data instead. We tested PAPE on tabular data using over 900 dataset-model
combinations created from US census data, assessing its performance against
multiple benchmarks. Overall, PAPE provided more accurate performance estimates
than other evaluated methodologies.","['Jakub Białek', 'Wojtek Kuberski', 'Nikolaos Perrakis', 'Albert Bifet']"
Learning ReLU Networks via Alternating Minimization,Machine Learning,"We propose and analyze a new family of algorithms for training neural
networks with ReLU activations. Our algorithms are based on the technique of
alternating minimization: estimating the activation patterns of each ReLU for
all given samples, interleaved with weight updates via a least-squares step.
The main focus of our paper are 1-hidden layer networks with $k$ hidden neurons
and ReLU activation. We show that under standard distributional assumptions on
the $d-$dimensional input data, our algorithm provably recovers the true
`ground truth' parameters in a linearly convergent fashion. This holds as long
as the weights are sufficiently well initialized; furthermore, our method
requires only $n=\widetilde{O}(dk^2)$ samples. We also analyze the special case
of 1-hidden layer networks with skipped connections, commonly used in
ResNet-type architectures, and propose a novel initialization strategy for the
same. For ReLU based ResNet type networks, we provide the first linear
convergence guarantee with an end-to-end algorithm. We also extend this
framework to deeper networks and empirically demonstrate its convergence to a
global minimum.","['Gauri Jagatap', 'Chinmay Hegde']"
"Multi-View Fuzzy Clustering with Minimax Optimization for Effective
  Clustering of Data from Multiple Sources",Artificial Intelligence,"Multi-view data clustering refers to categorizing a data set by making good
use of related information from multiple representations of the data. It
becomes important nowadays because more and more data can be collected in a
variety of ways, in different settings and from different sources, so each data
set can be represented by different sets of features to form different views of
it. Many approaches have been proposed to improve clustering performance by
exploring and integrating heterogeneous information underlying different views.
In this paper, we propose a new multi-view fuzzy clustering approach called
MinimaxFCM by using minimax optimization based on well-known Fuzzy c means. In
MinimaxFCM the consensus clustering results are generated based on minimax
optimization in which the maximum disagreements of different weighted views are
minimized. Moreover, the weight of each view can be learned automatically in
the clustering process. In addition, there is only one parameter to be set
besides the fuzzifier. The detailed problem formulation, updating rules
derivation, and the in-depth analysis of the proposed MinimaxFCM are provided
here. Experimental studies on nine multi-view data sets including real world
image and document data sets have been conducted. We observed that MinimaxFCM
outperforms related multi-view clustering approaches in terms of clustering
accuracy, demonstrating the great potential of MinimaxFCM for multi-view data
analysis.","['Yangtao Wang', 'Lihui Chen']"
Neural reality of argument structure constructions,Computation and Language (Natural Language Processing),"In lexicalist linguistic theories, argument structure is assumed to be
predictable from the meaning of verbs. As a result, the verb is the primary
determinant of the meaning of a clause. In contrast, construction grammarians
propose that argument structure is encoded in constructions (or form-meaning
pairs) that are distinct from verbs. Decades of psycholinguistic research have
produced substantial empirical evidence in favor of the construction view. Here
we adapt several psycholinguistic studies to probe for the existence of
argument structure constructions (ASCs) in Transformer-based language models
(LMs). First, using a sentence sorting experiment, we find that sentences
sharing the same construction are closer in embedding space than sentences
sharing the same verb. Furthermore, LMs increasingly prefer grouping by
construction with more input data, mirroring the behaviour of non-native
language learners. Second, in a ""Jabberwocky"" priming-based experiment, we find
that LMs associate ASCs with meaning, even in semantically nonsensical
sentences. Our work offers the first evidence for ASCs in LMs and highlights
the potential to devise novel probing methods grounded in psycholinguistic
research.","['Bai Li', 'Zining Zhu', 'Guillaume Thomas', 'Frank Rudzicz', 'Yang Xu']"
Language Tags Matter for Zero-Shot Neural Machine Translation,Computation and Language (Natural Language Processing),"Multilingual Neural Machine Translation (MNMT) has aroused widespread
interest due to its efficiency. An exciting advantage of MNMT models is that
they could also translate between unsupervised (zero-shot) language directions.
Language tag (LT) strategies are often adopted to indicate the translation
directions in MNMT. In this paper, we demonstrate that the LTs are not only
indicators for translation directions but also crucial to zero-shot translation
qualities. Unfortunately, previous work tends to ignore the importance of LT
strategies. We demonstrate that a proper LT strategy could enhance the
consistency of semantic representations and alleviate the off-target issue in
zero-shot directions. Experimental results show that by ignoring the source
language tag (SLT) and adding the target language tag (TLT) to the encoder, the
zero-shot translations could achieve a +8 BLEU score difference over other LT
strategies in IWSLT17, Europarl, TED talks translation tasks.","['Liwei Wu', 'Shanbo Cheng', 'Mingxuan Wang', 'Lei Li']"
"Balancing the Style-Content Trade-Off in Sentiment Transfer Using
  Polarity-Aware Denoising",Computation and Language (Natural Language Processing),"Text sentiment transfer aims to flip the sentiment polarity of a sentence
(positive to negative or vice versa) while preserving its sentiment-independent
content. Although current models show good results at changing the sentiment,
content preservation in transferred sentences is insufficient. In this paper,
we present a sentiment transfer model based on polarity-aware denoising, which
accurately controls the sentiment attributes in generated text, preserving the
content to a great extent and helping to balance the style-content trade-off.
Our proposed model is structured around two key stages in the sentiment
transfer process: better representation learning using a shared encoder and
sentiment-controlled generation using separate sentiment-specific decoders.
Empirical results show that our methods outperforms state-of-the-art baselines
in terms of content preservation while staying competitive in terms of style
transfer accuracy and fluency.","['Sourabrata Mukherjee', 'Zdeněk Kasner', 'Ondřej Dušek']"
The 'Letter' Distribution in the Chinese Language,Computation and Language (Natural Language Processing),"Corpus-based statistical analysis plays a significant role in linguistic
research, and ample evidence has shown that different languages exhibit some
common laws. Studies have found that letters in some alphabetic writing
languages have strikingly similar statistical usage frequency distributions.
Does this hold for Chinese, which employs ideogram writing? We obtained letter
frequency data of some alphabetic writing languages and found the common law of
the letter distributions. In addition, we collected Chinese literature corpora
for different historical periods from the Tang Dynasty to the present, and we
dismantled the Chinese written language into three kinds of basic particles:
characters, strokes and constructive parts. The results of the statistical
analysis showed that, in different historical periods, the intensity of the use
of basic particles in Chinese writing varied, but the form of the distribution
was consistent. In particular, the distributions of the Chinese constructive
parts are certainly consistent with those alphabetic writing languages. This
study provides new evidence of the consistency of human languages.","['Qinghua Chen', 'Yan Wang', 'Mengmeng Wang', 'Xiaomeng Li']"
Synthesis of Near-regular Natural Textures,Computer Vision and Pattern Recognition,"Texture synthesis is widely used in the field of computer graphics, vision,
and image processing. In the present paper, a texture synthesis algorithm is
proposed for near-regular natural textures with the help of a representative
periodic pattern extracted from the input textures using distance matching
function. Local texture statistics is then analyzed against global texture
statistics for non-overlapping windows of size same as periodic pattern size
and a representative periodic pattern is extracted from the image and used for
texture synthesis, while preserving the global regularity and visual
appearance. Validation of the algorithm based on experiments with synthetic
textures whose periodic pattern sizes are known and containing camouflages /
defects proves the strength of the algorithm for texture synthesis and its
application in detection of camouflages / defects in textures.",['V. Asha']
Stance and Sentiment in Tweets,Computation and Language (Natural Language Processing),"We can often detect from a person's utterances whether he/she is in favor of
or against a given target entity -- their stance towards the target. However, a
person may express the same stance towards a target by using negative or
positive language. Here for the first time we present a dataset of
tweet--target pairs annotated for both stance and sentiment. The targets may or
may not be referred to in the tweets, and they may or may not be the target of
opinion in the tweets. Partitions of this dataset were used as training and
test sets in a SemEval-2016 shared task competition. We propose a simple stance
detection system that outperforms submissions from all 19 teams that
participated in the shared task. Additionally, access to both stance and
sentiment annotations allows us to explore several research questions. We show
that while knowing the sentiment expressed by a tweet is beneficial for stance
classification, it alone is not sufficient. Finally, we use additional
unlabeled data through distant supervision techniques and word embeddings to
further improve stance classification.","['Saif M. Mohammad', 'Parinaz Sobhani', 'Svetlana Kiritchenko']"
"SADA: A General Framework to Support Robust Causation Discovery with
  Theoretical Guarantee",Artificial Intelligence,"Causation discovery without manipulation is considered a crucial problem to a
variety of applications. The state-of-the-art solutions are applicable only
when large numbers of samples are available or the problem domain is
sufficiently small. Motivated by the observations of the local sparsity
properties on causal structures, we propose a general Split-and-Merge
framework, named SADA, to enhance the scalability of a wide class of causation
discovery algorithms. In SADA, the variables are partitioned into subsets, by
finding causal cut on the sparse causal structure over the variables. By
running mainstream causation discovery algorithms as basic causal solvers on
the subproblems, complete causal structure can be reconstructed by combining
the partial results. SADA benefits from the recursive division technique, since
each small subproblem generates more accurate result under the same number of
samples. We theoretically prove that SADA always reduces the scales of problems
without sacrifice on accuracy, under the condition of local causal sparsity and
reliable conditional independence tests. We also present sufficient condition
to accuracy enhancement by SADA, even when the conditional independence tests
are vulnerable. Extensive experiments on both simulated and real-world datasets
verify the improvements on scalability and accuracy by applying SADA together
with existing causation discovery algorithms.","['Ruichu Cai', 'Zhenjie Zhang', 'Zhifeng Hao']"
"Mining Permission Request Patterns from Android and Facebook
  Applications (extended author version)",Cryptography and Security,"Android and Facebook provide third-party applications with access to users'
private data and the ability to perform potentially sensitive operations (e.g.,
post to a user's wall or place phone calls). As a security measure, these
platforms restrict applications' privileges with permission systems: users must
approve the permissions requested by applications before the applications can
make privacy- or security-relevant API calls. However, recent studies have
shown that users often do not understand permission requests and lack a notion
of typicality of requests. As a first step towards simplifying permission
systems, we cluster a corpus of 188,389 Android applications and 27,029
Facebook applications to find patterns in permission requests. Using a method
for Boolean matrix factorization for finding overlapping clusters, we find that
Facebook permission requests follow a clear structure that exhibits high
stability when fitted with only five clusters, whereas Android applications
demonstrate more complex permission requests. We also find that low-reputation
applications often deviate from the permission request patterns that we
identified for high-reputation applications suggesting that permission request
patterns are indicative for user satisfaction or application quality.","['Mario Frank', 'Ben Dong', 'Adrienne Porter Felt', 'Dawn Song']"
Graph Sparsification for GCN Towards Optimal Crop Yield Predictions,Machine Learning,"In agronomics, predicting crop yield at a per field/county granularity is
important for farmers to minimize uncertainty and plan seeding for the next
crop cycle. While state-of-the-art prediction techniques employ graph
convolutional nets (GCN) to predict future crop yields given relevant features
and crop yields of previous years, a dense underlying graph kernel requires
long training and execution time. In this paper, we propose a graph
sparsification method based on the Fiedler number to remove edges from a
complete graph kernel, in order to lower the complexity of GCN
training/execution. Specifically, we first show that greedily removing an edge
at a time that induces the minimal change in the second eigenvalue leads to a
sparse graph with good GCN performance. We then propose a fast method to choose
an edge for removal per iteration based on an eigenvalue perturbation theorem.
Experiments show that our Fiedler-based method produces a sparse graph with
good GCN performance compared to other graph sparsification schemes in crop
yield prediction.","['Saghar Bagheri', 'Gene Cheung', 'Tim Eadie']"
Improved Adversarial Robustness via Logit Regularization Methods,Machine Learning,"While great progress has been made at making neural networks effective across
a wide range of visual tasks, most models are surprisingly vulnerable. This
frailness takes the form of small, carefully chosen perturbations of their
input, known as adversarial examples, which represent a security threat for
learned vision models in the wild -- a threat which should be responsibly
defended against in safety-critical applications of computer vision. In this
paper, we advocate for and experimentally investigate the use of a family of
logit regularization techniques as an adversarial defense, which can be used in
conjunction with other methods for creating adversarial robustness at little to
no marginal cost. We also demonstrate that much of the effectiveness of one
recent adversarial defense mechanism can in fact be attributed to logit
regularization, and show how to improve its defense against both white-box and
black-box attacks, in the process creating a stronger black-box attack against
PGD-based models. We validate our methods on three datasets and include results
on both gradient-free attacks and strong gradient-based iterative attacks with
as many as 1,000 steps.","['Cecilia Summers', 'Michael J. Dinneen']"
"A Rotated Hyperbolic Wrapped Normal Distribution for Hierarchical
  Representation Learning",Machine Learning,"We present a rotated hyperbolic wrapped normal distribution (RoWN), a simple
yet effective alteration of a hyperbolic wrapped normal distribution (HWN). The
HWN expands the domain of probabilistic modeling from Euclidean to hyperbolic
space, where a tree can be embedded with arbitrary low distortion in theory. In
this work, we analyze the geometric properties of the diagonal HWN, a standard
choice of distribution in probabilistic modeling. The analysis shows that the
distribution is inappropriate to represent the data points at the same
hierarchy level through their angular distance with the same norm in the
Poincar\'e disk model. We then empirically verify the presence of limitations
of HWN, and show how RoWN, the proposed distribution, can alleviate the
limitations on various hierarchical datasets, including noisy synthetic binary
tree, WordNet, and Atari 2600 Breakout. The code is available at
https://github.com/ml-postech/RoWN.","['Seunghyuk Cho', 'Juyong Lee', 'Jaesik Park', 'Dongwoo Kim']"
"Action is the primary key: a categorical framework for episode
  description and logical reasoning",Artificial Intelligence,"This research presents a computational framework for describing and
recognizing episodes and for logical reasoning. This framework, named
cognitive-logs, consists of a set of relational and graph databases.
Cognitive-logs record knowledge, particularly in episodes that consist of
""actions"" represented by verbs in natural languages and ""participants"" who
perform the actions. These objects are connected by arrows (morphisms) that
link each action to its participant and link cause to effect. Operations based
on category theory enable comparisons between episodes and deductive
inferences, including abstractions of stories. One of the goals of this study
is to develop a database-driven artificial intelligence. This artificial
intelligence thinks like a human but possesses the accuracy and rigour of a
machine. The vast capacities of databases (up to petabyte scales in current
technologies) enable the artificial intelligence to store a greater volume of
knowledge than neural-network based artificial intelligences. Cognitive-logs
serve as a model of human cognition and designed with references to cognitive
linguistics. Cognitive-logs also have the potential to model various human mind
activities.",['Yoshiki Fukada']
On the Convergence of Adam and Beyond,Machine Learning,"Several recently proposed stochastic optimization methods that have been
successfully used in training deep networks such as RMSProp, Adam, Adadelta,
Nadam are based on using gradient updates scaled by square roots of exponential
moving averages of squared past gradients. In many applications, e.g. learning
with large output spaces, it has been empirically observed that these
algorithms fail to converge to an optimal solution (or a critical point in
nonconvex settings). We show that one cause for such failures is the
exponential moving average used in the algorithms. We provide an explicit
example of a simple convex optimization setting where Adam does not converge to
the optimal solution, and describe the precise problems with the previous
analysis of Adam algorithm. Our analysis suggests that the convergence issues
can be fixed by endowing such algorithms with `long-term memory' of past
gradients, and propose new variants of the Adam algorithm which not only fix
the convergence issues but often also lead to improved empirical performance.","['Sashank J. Reddi', 'Satyen Kale', 'Sanjiv Kumar']"
Learning Structured Inference Neural Networks with Label Relations,Computer Vision and Pattern Recognition,"Images of scenes have various objects as well as abundant attributes, and
diverse levels of visual categorization are possible. A natural image could be
assigned with fine-grained labels that describe major components,
coarse-grained labels that depict high level abstraction or a set of labels
that reveal attributes. Such categorization at different concept layers can be
modeled with label graphs encoding label information. In this paper, we exploit
this rich information with a state-of-art deep learning framework, and propose
a generic structured model that leverages diverse label relations to improve
image classification performance. Our approach employs a novel stacked label
prediction neural network, capturing both inter-level and intra-level label
semantics. We evaluate our method on benchmark image datasets, and empirical
results illustrate the efficacy of our model.","['Hexiang Hu', 'Guang-Tong Zhou', 'Zhiwei Deng', 'Zicheng Liao', 'Greg Mori']"
Calibration tests beyond classification,Machine Learning (Statistics),"Most supervised machine learning tasks are subject to irreducible prediction
errors. Probabilistic predictive models address this limitation by providing
probability distributions that represent a belief over plausible targets,
rather than point estimates. Such models can be a valuable tool in
decision-making under uncertainty, provided that the model output is meaningful
and interpretable. Calibrated models guarantee that the probabilistic
predictions are neither over- nor under-confident. In the machine learning
literature, different measures and statistical tests have been proposed and
studied for evaluating the calibration of classification models. For regression
problems, however, research has been focused on a weaker condition of
calibration based on predicted quantiles for real-valued targets. In this
paper, we propose the first framework that unifies calibration evaluation and
tests for general probabilistic predictive models. It applies to any such
model, including classification and regression models of arbitrary dimension.
Furthermore, the framework generalizes existing measures and provides a more
intuitive reformulation of a recently proposed framework for calibration in
multi-class classification. In particular, we reformulate and generalize the
kernel calibration error, its estimators, and hypothesis tests using
scalar-valued kernels, and evaluate the calibration of real-valued regression
problems.","['David Widmann', 'Fredrik Lindsten', 'Dave Zachariah']"
Feature Extraction for Novelty Detection in Network Traffic,Networking and Internet Architecture,"Data representation plays a critical role in the performance of novelty
detection (or ``anomaly detection'') methods in machine learning. The data
representation of network traffic often determines the effectiveness of these
models as much as the model itself. The wide range of novel events that network
operators need to detect (e.g., attacks, malware, new applications, changes in
traffic demands) introduces the possibility for a broad range of possible
models and data representations. In each scenario, practitioners must spend
significant effort extracting and engineering features that are most predictive
for that situation or application. While anomaly detection is well-studied in
computer networking, much existing work develops specific models that presume a
particular representation -- often IPFIX/NetFlow. Yet, other representations
may result in higher model accuracy, and the rise of programmable networks now
makes it more practical to explore a broader range of representations. To
facilitate such exploration, we develop a systematic framework, open-source
toolkit, and public Python library that makes it both possible and easy to
extract and generate features from network traffic and perform and end-to-end
evaluation of these representations across most prevalent modern novelty
detection models. We first develop and publicly release an open-source tool, an
accompanying Python library (NetML), and end-to-end pipeline for novelty
detection in network traffic. Second, we apply this tool to five different
novelty detection problems in networking, across a range of scenarios from
attack detection to novel device detection. Our findings general insights and
guidelines concerning which features appear to be more appropriate for
particular situations.","['Kun Yang', 'Samory Kpotufe', 'Nick Feamster']"
K-Prototype Segmentation Analysis on Large-scale Ridesourcing Trip Data,Computers and Society,"Shared mobility-on-demand services are expanding rapidly in cities around the
world. As a prominent example, app-based ridesourcing is becoming an integral
part of many urban transportation ecosystems. Despite the centrality, limited
public availability of detailed temporal and spatial data on ridesourcing trips
has limited research on how new services interact with traditional mobility
options and how they impact travel in cities. Improving data-sharing agreements
are opening unprecedented opportunities for research in this area. This study
examines emerging patterns of mobility using recently released City of Chicago
public ridesourcing data. The detailed spatio-temporal ridesourcing data are
matched with weather, transit, and taxi data to gain a deeper understanding of
ridesourcings role in Chicagos mobility system. The goal is to investigate the
systematic variations in patronage of ride-hailing. K-prototypes is utilized to
detect user segments owing to its ability to accept mixed variable data types.
An extension of the K-means algorithm, its output is a classification of the
data into several clusters called prototypes. Six ridesourcing prototypes are
identified and discussed based on significant differences in relation to
adverse weather conditions, competition with alternative modes, location and
timing of use, and tendency for ridesplitting. The paper discusses implications
of the identified clusters related to affordability, equity and competition
with transit.","['J Soria', 'Y Chen', 'A Stathopoulos']"
Quasi-Monte Carlo Graph Random Features,Machine Learning (Statistics),"We present a novel mechanism to improve the accuracy of the
recently-introduced class of graph random features (GRFs). Our method induces
negative correlations between the lengths of the algorithm's random walks by
imposing antithetic termination: a procedure to sample more diverse random
walks which may be of independent interest. It has a trivial drop-in
implementation. We derive strong theoretical guarantees on the properties of
these quasi-Monte Carlo GRFs (q-GRFs), proving that they yield lower-variance
estimators of the 2-regularised Laplacian kernel under mild conditions.
Remarkably, our results hold for any graph topology. We demonstrate empirical
accuracy improvements on a variety of tasks including a new practical
application: time-efficient approximation of the graph diffusion process. To
our knowledge, q-GRFs constitute the first rigorously studied quasi-Monte Carlo
scheme for kernels defined on combinatorial objects, inviting new research on
correlations between graph random walks.","['Isaac Reid', 'Krzysztof Choromanski', 'Adrian Weller']"
On the Limits of Learning to Actively Learn Semantic Representations,Computation and Language (Natural Language Processing),"One of the goals of natural language understanding is to develop models that
map sentences into meaning representations. However, training such models
requires expensive annotation of complex structures, which hinders their
adoption. Learning to actively-learn (LTAL) is a recent paradigm for reducing
the amount of labeled data by learning a policy that selects which samples
should be labeled. In this work, we examine LTAL for learning semantic
representations, such as QA-SRL. We show that even an oracle policy that is
allowed to pick examples that maximize performance on the test set (and
constitutes an upper bound on the potential of LTAL), does not substantially
improve performance compared to a random policy. We investigate factors that
could explain this finding and show that a distinguishing characteristic of
successful applications of LTAL is the interaction between optimization and the
oracle policy selection process. In successful applications of LTAL, the
examples selected by the oracle policy do not substantially depend on the
optimization procedure, while in our setup the stochastic nature of
optimization strongly affects the examples selected by the oracle. We conclude
that the current applicability of LTAL for improving data efficiency in
learning semantic meaning representations is limited.","['Omri Koshorek', 'Gabriel Stanovsky', 'Yichu Zhou', 'Vivek Srikumar', 'Jonathan Berant']"
"Multi-Objective Deep Reinforcement Learning for Optimisation in
  Autonomous Systems",Artificial Intelligence,"Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as
it enables learning at runtime without the need for a model of the environment
or predefined actions. However, most applications of RL in AS, such as those
based on Q-learning, can only optimize one objective, making it necessary in
multi-objective systems to combine multiple objectives in a single objective
function with predefined weights. A number of Multi-Objective Reinforcement
Learning (MORL) techniques exist but they have mostly been applied in RL
benchmarks rather than real-world AS systems. In this work, we use a MORL
technique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers
exemplar, a self-adaptive server, to find the optimal configuration for runtime
performance optimization. We compare DWN to two single-objective optimization
implementations: {\epsilon}-greedy algorithm and Deep Q-Networks. Our initial
evaluation shows that DWN optimizes multiple objectives simultaneously with
similar results than DQN and {\epsilon}-greedy approaches, having a better
performance for some metrics, and avoids issues associated with combining
multiple objectives into a single utility function.","['Juan C. Rosero', 'Ivana Dusparic', 'Nicolás Cardozo']"
Dual Recurrent Attention Units for Visual Question Answering,Artificial Intelligence,"Visual Question Answering (VQA) requires AI models to comprehend data in two
domains, vision and text. Current state-of-the-art models use learned attention
mechanisms to extract relevant information from the input domains to answer a
certain question. Thus, robust attention mechanisms are essential for powerful
VQA models. In this paper, we propose a recurrent attention mechanism and show
its benefits compared to the traditional convolutional approach. We perform two
ablation studies to evaluate recurrent attention. First, we introduce a
baseline VQA model with visual attention and test the performance difference
between convolutional and recurrent attention on the VQA 2.0 dataset. Secondly,
we design an architecture for VQA which utilizes dual (textual and visual)
Recurrent Attention Units (RAUs). Using this model, we show the effect of all
possible combinations of recurrent and convolutional dual attention. Our single
model outperforms the first place winner on the VQA 2016 challenge and to the
best of our knowledge, it is the second best performing single model on the VQA
1.0 dataset. Furthermore, our model noticeably improves upon the winner of the
VQA 2017 challenge. Moreover, we experiment replacing attention mechanisms in
state-of-the-art models with our RAUs and show increased performance.","['Ahmed Osman', 'Wojciech Samek']"
RoPINN: Region Optimized Physics-Informed Neural Networks,Machine Learning,"Physics-informed neural networks (PINNs) have been widely applied to solve
partial differential equations (PDEs) by enforcing outputs and gradients of
deep models to satisfy target equations. Due to the limitation of numerical
computation, PINNs are conventionally optimized on finite selected points.
However, since PDEs are usually defined on continuous domains, solely
optimizing models on scattered points may be insufficient to obtain an accurate
solution for the whole domain. To mitigate this inherent deficiency of the
default scatter-point optimization, this paper proposes and theoretically
studies a new training paradigm as region optimization. Concretely, we propose
to extend the optimization process of PINNs from isolated points to their
continuous neighborhood regions, which can theoretically decrease the
generalization error, especially for hidden high-order constraints of PDEs. A
practical training algorithm, Region Optimized PINN (RoPINN), is seamlessly
derived from this new paradigm, which is implemented by a straightforward but
effective Monte Carlo sampling method. By calibrating the sampling process into
trust regions, RoPINN finely balances optimization and generalization error.
Experimentally, RoPINN consistently boosts the performance of diverse PINNs on
a wide range of PDEs without extra backpropagation or gradient calculation.
Code is available at this repository: https://github.com/thuml/RoPINN.","['Haixu Wu', 'Huakun Luo', 'Yuezhou Ma', 'Jianmin Wang', 'Mingsheng Long']"
"Delta: A Cloud-assisted Data Enrichment Framework for On-Device
  Continual Learning",Machine Learning,"In modern mobile applications, users frequently encounter various new
contexts, necessitating on-device continual learning (CL) to ensure consistent
model performance. While existing research predominantly focused on developing
lightweight CL frameworks, we identify that data scarcity is a critical
bottleneck for on-device CL. In this work, we explore the potential of
leveraging abundant cloud-side data to enrich scarce on-device data, and
propose a private, efficient and effective data enrichment framework Delta.
Specifically, Delta first introduces a directory dataset to decompose the data
enrichment problem into device-side and cloud-side sub-problems without sharing
sensitive data. Next, Delta proposes a soft data matching strategy to
effectively solve the device-side sub-problem with sparse user data, and an
optimal data sampling scheme for cloud server to retrieve the most suitable
dataset for enrichment with low computational complexity. Further, Delta
refines the data sampling scheme by jointly considering the impact of enriched
data on both new and past contexts, mitigating the catastrophic forgetting
issue from a new aspect. Comprehensive experiments across four typical mobile
computing tasks with varied data modalities demonstrate that Delta could
enhance the overall model accuracy by an average of 15.1%, 12.4%, 1.1% and 5.6%
for visual, IMU, audio and textual tasks compared with few-shot CL, and
consistently reduce the communication costs by over 90% compared to federated
CL.","['Chen Gong', 'Zhenzhe Zheng', 'Fan Wu', 'Xiaofeng Jia', 'Guihai Chen']"
"A Feature Clustering Approach Based on Histogram of Oriented Optical
  Flow and Superpixels",Computer Vision and Pattern Recognition,"Visual feature clustering is one of the cost-effective approaches to segment
objects in videos. However, the assumptions made for developing the existing
algorithms prevent them from being used in situations like segmenting an
unknown number of static and moving objects under heavy camera movements. This
paper addresses the problem by introducing a clustering approach based on
superpixels and short-term Histogram of Oriented Optical Flow (HOOF). Salient
Dither Pattern Feature (SDPF) is used as the visual feature to track the flow
and Simple Linear Iterative Clustering (SLIC) is used for obtaining the
superpixels. This new clustering approach is based on merging superpixels by
comparing short term local HOOF and a color cue to form high-level semantic
segments. The new approach was compared with one of the latest feature
clustering approaches based on K-Means in eight-dimensional space and the
results revealed that the new approach is better by means of consistency,
completeness, and spatial accuracy. Further, the new approach completely solved
the problem of not knowing the number of objects in a scene.","['A. M. R. R. Bandara', 'L. Ranathunga', 'N. A. Abdullah']"
"mlOSP: Towards a Unified Implementation of Regression Monte Carlo
  Algorithms",Computational Finance,"We introduce mlOSP, a computational template for Machine Learning for Optimal
Stopping Problems. The template is implemented in the R statistical environment
and publicly available via a GitHub repository. mlOSP presents a unified
numerical implementation of Regression Monte Carlo (RMC) approaches to optimal
stopping, providing a state-of-the-art, open-source, reproducible and
transparent platform. Highlighting its modular nature, we present multiple
novel variants of RMC algorithms, especially in terms of constructing
simulation designs for training the regressors, as well as in terms of machine
learning regression modules. Furthermore, mlOSP nests most of the existing RMC
schemes, allowing for a consistent and verifiable benchmarking of extant
algorithms. The article contains extensive R code snippets and figures, and
serves as a vignette to the underlying software package.",['Mike Ludkovski']
"Point-Teaching: Weakly Semi-Supervised Object Detection with Point
  Annotations",Computer Vision and Pattern Recognition,"Point annotations are considerably more time-efficient than bounding box
annotations. However, how to use cheap point annotations to boost the
performance of semi-supervised object detection remains largely unsolved. In
this work, we present Point-Teaching, a weakly semi-supervised object detection
framework to fully exploit the point annotations. Specifically, we propose a
Hungarian-based point matching method to generate pseudo labels for point
annotated images. We further propose multiple instance learning (MIL)
approaches at the level of images and points to supervise the object detector
with point annotations. Finally, we propose a simple-yet-effective data
augmentation, termed point-guided copy-paste, to reduce the impact of the
unmatched points. Experiments demonstrate the effectiveness of our method on a
few datasets and various data regimes.","['Yongtao Ge', 'Qiang Zhou', 'Xinlong Wang', 'Zhibin Wang', 'Hao Li', 'Chunhua Shen']"
"Combining Federated and Active Learning for Communication-efficient
  Distributed Failure Prediction in Aeronautics",Artificial Intelligence,"Machine Learning has proven useful in the recent years as a way to achieve
failure prediction for industrial systems. However, the high computational
resources necessary to run learning algorithms are an obstacle to its
widespread application. The sub-field of Distributed Learning offers a solution
to this problem by enabling the use of remote resources but at the expense of
introducing communication costs in the application that are not always
acceptable. In this paper, we propose a distributed learning approach able to
optimize the use of computational and communication resources to achieve
excellent learning model performances through a centralized architecture. To
achieve this, we present a new centralized distributed learning algorithm that
relies on the learning paradigms of Active Learning and Federated Learning to
offer a communication-efficient method that offers guarantees of model
precision on both the clients and the central server. We evaluate this method
on a public benchmark and show that its performances in terms of precision are
very close to state-of-the-art performance level of non-distributed learning
despite additional constraints.","['Nicolas Aussel', 'Sophie Chabridon', 'Yohan Petetin']"
Emergence of Compositional Language with Deep Generational Transmission,Machine Learning,"Recent work has studied the emergence of language among deep reinforcement
learning agents that must collaborate to solve a task. Of particular interest
are the factors that cause language to be compositional -- i.e., express
meaning by combining words which themselves have meaning. Evolutionary
linguists have found that in addition to structural priors like those already
studied in deep learning, the dynamics of transmitting language from generation
to generation contribute significantly to the emergence of compositionality. In
this paper, we introduce these cultural evolutionary dynamics into language
emergence by periodically replacing agents in a population to create a
knowledge gap, implicitly inducing cultural transmission of language. We show
that this implicit cultural transmission encourages the resulting languages to
exhibit better compositional generalization.","['Michael Cogswell', 'Jiasen Lu', 'Stefan Lee', 'Devi Parikh', 'Dhruv Batra']"
"Improving Empathetic Dialogue Generation by Dynamically Infusing
  Commonsense Knowledge",Computation and Language (Natural Language Processing),"In empathetic conversations, individuals express their empathy towards
others. Previous work has mainly focused on generating empathetic responses by
utilizing the speaker's emotion. Besides, external commonsense knowledge has
been applied to enhance the system's understandings of the speaker's situation.
However, given an event, commonsense knowledge base contains various relations,
potentially leading to confusion for the dialogue system. Consequently,
inconsistencies arise among the emotion, generated response and speaker's
contextual information. To this end, we propose a novel approach for empathetic
response generation, which incorporates an adaptive module for commonsense
knowledge selection to ensure consistency between the generated empathetic
responses and the speaker's situation. This selected knowledge is used to
refine the commonsense cognition and empathy expression for generated
responses. Experimental results show that our approach significantly
outperforms baseline models in both automatic and human evaluations, exhibiting
the generation of more coherent and empathetic responses. Moreover, case
studies highlight the interpretability of knowledge selection in the responses
and the effectiveness of adaptive module in our model. Code:
https://github.com/Hanscal/DCKS.","['Hua Cai', 'Xuli Shen', 'Qing Xu', 'Weilin Shen', 'Xiaomei Wang', 'Weifeng Ge', 'Xiaoqing Zheng', 'Xiangyang Xue']"
"A Recurrent Neural Model with Attention for the Recognition of Chinese
  Implicit Discourse Relations",Computation and Language (Natural Language Processing),"We introduce an attention-based Bi-LSTM for Chinese implicit discourse
relations and demonstrate that modeling argument pairs as a joint sequence can
outperform word order-agnostic approaches. Our model benefits from a partial
sampling scheme and is conceptually simple, yet achieves state-of-the-art
performance on the Chinese Discourse Treebank. We also visualize its attention
activity to illustrate the model's ability to selectively focus on the relevant
parts of an input sequence.","['Samuel Rönnqvist', 'Niko Schenk', 'Christian Chiarcos']"
Modeling Future Cost for Neural Machine Translation,Computation and Language (Natural Language Processing),"Existing neural machine translation (NMT) systems utilize
sequence-to-sequence neural networks to generate target translation word by
word, and then make the generated word at each time-step and the counterpart in
the references as consistent as possible. However, the trained translation
model tends to focus on ensuring the accuracy of the generated target word at
the current time-step and does not consider its future cost which means the
expected cost of generating the subsequent target translation (i.e., the next
target word). To respond to this issue, we propose a simple and effective
method to model the future cost of each target word for NMT systems. In detail,
a time-dependent future cost is estimated based on the current generated target
word and its contextual information to boost the training of the NMT model.
Furthermore, the learned future context representation at the current time-step
is used to help the generation of the next target word in the decoding.
Experimental results on three widely-used translation datasets, including the
WMT14 German-to-English, WMT14 English-to-French, and WMT17 Chinese-to-English,
show that the proposed approach achieves significant improvements over strong
Transformer-based NMT baseline.","['Chaoqun Duan', 'Kehai Chen', 'Rui Wang', 'Masao Utiyama', 'Eiichiro Sumita', 'Conghui Zhu', 'Tiejun Zhao']"
"Can Model Uncertainty Function as a Proxy for Multiple-Choice Question
  Item Difficulty?",Computation and Language (Natural Language Processing),"Estimating the difficulty of multiple-choice questions would be great help
for educators who must spend substantial time creating and piloting stimuli for
their tests, and for learners who want to practice. Supervised approaches to
difficulty estimation have yielded to date mixed results. In this contribution
we leverage an aspect of generative large models which might be seen as a
weakness when answering questions, namely their uncertainty, and exploit it
towards exploring correlations between two different metrics of uncertainty,
and the actual student response distribution. While we observe some present but
weak correlations, we also discover that the models' behaviour is different in
the case of correct vs wrong answers, and that correlations differ
substantially according to the different question types which are included in
our fine-grained, previously unused dataset of 451 questions from a
Biopsychology course. In discussing our findings, we also suggest potential
avenues to further leverage model uncertainty as an additional proxy for item
difficulty.","['Leonidas Zotos', 'Hedderik van Rijn', 'Malvina Nissim']"
"Orthogonal Language and Task Adapters in Zero-Shot Cross-Lingual
  Transfer",Computation and Language (Natural Language Processing),"Adapter modules, additional trainable parameters that enable efficient
fine-tuning of pretrained transformers, have recently been used for language
specialization of multilingual transformers, improving downstream zero-shot
cross-lingual transfer. In this work, we propose orthogonal language and task
adapters (dubbed orthoadapters) for cross-lingual transfer. They are trained to
encode language- and task-specific information that is complementary (i.e.,
orthogonal) to the knowledge already stored in the pretrained transformer's
parameters. Our zero-shot cross-lingual transfer experiments, involving three
tasks (POS-tagging, NER, NLI) and a set of 10 diverse languages, 1) point to
the usefulness of orthoadapters in cross-lingual transfer, especially for the
most complex NLI task, but also 2) indicate that the optimal adapter
configuration highly depends on the task and the target language. We hope that
our work will motivate a wider investigation of usefulness of orthogonality
constraints in language- and task-specific fine-tuning of pretrained
transformers.","['Marko Vidoni', 'Ivan Vulić', 'Goran Glavaš']"
Group Sparse Regularization for Deep Neural Networks,Machine Learning (Statistics),"In this paper, we consider the joint task of simultaneously optimizing (i)
the weights of a deep neural network, (ii) the number of neurons for each
hidden layer, and (iii) the subset of active input features (i.e., feature
selection). While these problems are generally dealt with separately, we
present a simple regularized formulation allowing to solve all three of them in
parallel, using standard optimization routines. Specifically, we extend the
group Lasso penalty (originated in the linear regression literature) in order
to impose group-level sparsity on the network's connections, where each group
is defined as the set of outgoing weights from a unit. Depending on the
specific case, the weights can be related to an input variable, to a hidden
neuron, or to a bias unit, thus performing simultaneously all the
aforementioned tasks in order to obtain a compact network. We perform an
extensive experimental evaluation, by comparing with classical weight decay and
Lasso penalties. We show that a sparse version of the group Lasso penalty is
able to achieve competitive performances, while at the same time resulting in
extremely compact networks with a smaller number of input features. We evaluate
both on a toy dataset for handwritten digit recognition, and on multiple
realistic large-scale classification problems.","['Simone Scardapane', 'Danilo Comminiello', 'Amir Hussain', 'Aurelio Uncini']"
Evaluating the Usefulness of Sentiment Information for Focused Crawlers,Information Retrieval,"Despite the prevalence of sentiment-related content on the Web, there has
been limited work on focused crawlers capable of effectively collecting such
content. In this study, we evaluated the efficacy of using sentiment-related
information for enhanced focused crawling of opinion-rich web content regarding
a particular topic. We also assessed the impact of using sentiment-labeled web
graphs to further improve collection accuracy. Experimental results on a large
test bed encompassing over half a million web pages revealed that focused
crawlers utilizing sentiment information as well as sentiment-labeled web
graphs are capable of gathering more holistic collections of opinion-related
content regarding a particular topic. The results have important implications
for business and marketing intelligence gathering efforts in the Web 2.0 era.","['Tianjun Fu', 'Ahmed Abbasi', 'Daniel Zeng', 'Hsinchun Chen']"
Improving Hyper-Relational Knowledge Graph Completion,Machine Learning,"Different from traditional knowledge graphs (KGs) where facts are represented
as entity-relation-entity triplets, hyper-relational KGs (HKGs) allow triplets
to be associated with additional relation-entity pairs (a.k.a qualifiers) to
convey more complex information. How to effectively and efficiently model the
triplet-qualifier relationship for prediction tasks such as HKG completion is
an open challenge for research. This paper proposes to improve the
best-performing method in HKG completion, namely STARE, by introducing two
novel revisions: (1) Replacing the computation-heavy graph neural network
module with light-weight entity/relation embedding processing techniques for
efficiency improvement without sacrificing effectiveness; (2) Adding a
qualifier-oriented auxiliary training task for boosting the prediction power of
our approach on HKG completion. The proposed approach consistently outperforms
STARE in our experiments on three benchmark datasets, with significantly
improved computational efficiency.","['Donghan Yu', 'Yiming Yang']"
"Ridgeless Interpolation with Shallow ReLU Networks in $1D$ is Nearest
  Neighbor Curvature Extrapolation and Provably Generalizes on Lipschitz
  Functions",Machine Learning (Statistics),"We prove a precise geometric description of all one layer ReLU networks
$z(x;\theta)$ with a single linear unit and input/output dimensions equal to
one that interpolate a given dataset $\mathcal D=\{(x_i,f(x_i))\}$ and, among
all such interpolants, minimize the $\ell_2$-norm of the neuron weights. Such
networks can intuitively be thought of as those that minimize the mean-squared
error over $\mathcal D$ plus an infinitesimal weight decay penalty. We
therefore refer to them as ridgeless ReLU interpolants. Our description proves
that, to extrapolate values $z(x;\theta)$ for inputs $x\in (x_i,x_{i+1})$ lying
between two consecutive datapoints, a ridgeless ReLU interpolant simply
compares the signs of the discrete estimates for the curvature of $f$ at $x_i$
and $x_{i+1}$ derived from the dataset $\mathcal D$. If the curvature estimates
at $x_i$ and $x_{i+1}$ have different signs, then $z(x;\theta)$ must be linear
on $(x_i,x_{i+1})$. If in contrast the curvature estimates at $x_i$ and
$x_{i+1}$ are both positive (resp. negative), then $z(x;\theta)$ is convex
(resp. concave) on $(x_i,x_{i+1})$. Our results show that ridgeless ReLU
interpolants achieve the best possible generalization for learning $1d$
Lipschitz functions, up to universal constants.",['Boris Hanin']
Abiotic Stress Prediction from RGB-T Images of Banana Plantlets,Computer Vision and Pattern Recognition,"Prediction of stress conditions is important for monitoring plant growth
stages, disease detection, and assessment of crop yields. Multi-modal data,
acquired from a variety of sensors, offers diverse perspectives and is expected
to benefit the prediction process. We present several methods and strategies
for abiotic stress prediction in banana plantlets, on a dataset acquired during
a two and a half weeks period, of plantlets subject to four separate water and
fertilizer treatments. The dataset consists of RGB and thermal images, taken
once daily of each plant. Results are encouraging, in the sense that neural
networks exhibit high prediction rates (over $90\%$ amongst four classes), in
cases where there are hardly any noticeable features distinguishing the
treatments, much higher than field experts can supply.","['Sagi Levanon', 'Oshry Markovich', 'Itamar Gozlan', 'Ortal Bakhshian', 'Alon Zvirin', 'Yaron Honen', 'Ron Kimmel']"
From Stochastic Mixability to Fast Rates,Machine Learning,"Empirical risk minimization (ERM) is a fundamental learning rule for
statistical learning problems where the data is generated according to some
unknown distribution $\mathsf{P}$ and returns a hypothesis $f$ chosen from a
fixed class $\mathcal{F}$ with small loss $\ell$. In the parametric setting,
depending upon $(\ell, \mathcal{F},\mathsf{P})$ ERM can have slow
$(1/\sqrt{n})$ or fast $(1/n)$ rates of convergence of the excess risk as a
function of the sample size $n$. There exist several results that give
sufficient conditions for fast rates in terms of joint properties of $\ell$,
$\mathcal{F}$, and $\mathsf{P}$, such as the margin condition and the Bernstein
condition. In the non-statistical prediction with expert advice setting, there
is an analogous slow and fast rate phenomenon, and it is entirely characterized
in terms of the mixability of the loss $\ell$ (there being no role there for
$\mathcal{F}$ or $\mathsf{P}$). The notion of stochastic mixability builds a
bridge between these two models of learning, reducing to classical mixability
in a special case. The present paper presents a direct proof of fast rates for
ERM in terms of stochastic mixability of $(\ell,\mathcal{F}, \mathsf{P})$, and
in so doing provides new insight into the fast-rates phenomenon. The proof
exploits an old result of Kemperman on the solution to the general moment
problem. We also show a partial converse that suggests a characterization of
fast rates for ERM in terms of stochastic mixability is possible.","['Nishant A. Mehta', 'Robert C. Williamson']"
"Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria
  Shaping Modern Artificial Neural Network Architectures",Neural and Evolutionary Computing,"This study examined the viability of enhancing the prediction accuracy of
artificial neural networks (ANNs) in image classification tasks by developing
ANNs with evolution patterns similar to those of biological neural networks.
ResNet is a widely used family of neural networks with both deep and wide
variants; therefore, it was selected as the base model for our investigation.
The aim of this study is to improve the image classification performance of
ANNs via a novel approach inspired by the biological nervous system
architecture of planarians, which comprises a brain and two nerve cords. We
believe that the unique neural architecture of planarians offers valuable
insights into the performance enhancement of ANNs. The proposed planarian
neural architecture-based neural network was evaluated on the CIFAR-10 and
CIFAR-100 datasets. Our results indicate that the proposed method exhibits
higher prediction accuracy than the baseline neural network models in image
classification tasks. These findings demonstrate the significant potential of
biologically inspired neural network architectures in improving the performance
of ANNs in a wide range of applications.","['Ziyuan Huang', 'Mark Newman', 'Maria Vaida', 'Srikar Bellur', 'Roozbeh Sadeghian', 'Andrew Siu', 'Hui Wang', 'Kevin Huggins']"
Learning to Infer User Hidden States for Online Sequential Advertising,Artificial Intelligence,"To drive purchase in online advertising, it is of the advertiser's great
interest to optimize the sequential advertising strategy whose performance and
interpretability are both important. The lack of interpretability in existing
deep reinforcement learning methods makes it not easy to understand, diagnose
and further optimize the strategy. In this paper, we propose our Deep Intents
Sequential Advertising (DISA) method to address these issues. The key part of
interpretability is to understand a consumer's purchase intent which is,
however, unobservable (called hidden states). In this paper, we model this
intention as a latent variable and formulate the problem as a Partially
Observable Markov Decision Process (POMDP) where the underlying intents are
inferred based on the observable behaviors. Large-scale industrial offline and
online experiments demonstrate our method's superior performance over several
baselines. The inferred hidden states are analyzed, and the results prove the
rationality of our inference.","['Zhaoqing Peng', 'Junqi Jin', 'Lan Luo', 'Yaodong Yang', 'Rui Luo', 'Jun Wang', 'Weinan Zhang', 'Haiyang Xu', 'Miao Xu', 'Chuan Yu', 'Tiejian Luo', 'Han Li', 'Jian Xu', 'Kun Gai']"
Machine Learning in Quantitative PET Imaging,Image and Video Processing,"This paper reviewed the machine learning-based studies for quantitative
positron emission tomography (PET). Specifically, we summarized the recent
developments of machine learning-based methods in PET attenuation correction
and low-count PET reconstruction by listing and comparing the proposed methods,
study designs and reported performances of the current published studies with
brief discussion on representative studies. The contributions and challenges
among the reviewed studies were summarized and highlighted in the discussion
part followed by.","['Tonghe Wang', 'Yang Lei', 'Yabo Fu', 'Walter J. Curran', 'Tian Liu', 'Xiaofeng Yang']"
"A Coupled Random Projection Approach to Large-Scale Canonical Polyadic
  Decomposition",Machine Learning,"We propose a novel algorithm for the computation of canonical polyadic
decomposition (CPD) of large-scale tensors. The proposed algorithm generalizes
the random projection (RAP) technique, which is often used to compute
large-scale decompositions, from one single projection to multiple but coupled
random projections (CoRAP). The proposed CoRAP technique yields a set of
tensors that together admits a coupled CPD (C-CPD) and a C-CPD algorithm is
then used to jointly decompose these tensors. The results of C-CPD are finally
fused to obtain factor matrices of the original large-scale data tensor. As
more data samples are jointly exploited via C-CPD, the proposed CoRAP based CPD
is more accurate than RAP based CPD. Experiments are provided to illustrate the
performance of the proposed approach.","['Lu-Ming Wang', 'Ya-Nan Wang', 'Xiao-Feng Gong', 'Qiu-Hua Lin', 'Fei Xiang']"
"Defending against Machine Learning based Inference Attacks via
  Adversarial Examples: Opportunities and Challenges",Cryptography and Security,"As machine learning (ML) becomes more and more powerful and easily
accessible, attackers increasingly leverage ML to perform automated large-scale
inference attacks in various domains. In such an ML-equipped inference attack,
an attacker has access to some data (called public data) of an individual, a
software, or a system; and the attacker uses an ML classifier to automatically
infer their private data. Inference attacks pose severe privacy and security
threats to individuals and systems. Inference attacks are successful because
private data are statistically correlated with public data, and ML classifiers
can capture such statistical correlations. In this chapter, we discuss the
opportunities and challenges of defending against ML-equipped inference attacks
via adversarial examples. Our key observation is that attackers rely on ML
classifiers in inference attacks. The adversarial machine learning community
has demonstrated that ML classifiers have various vulnerabilities. Therefore,
we can turn the vulnerabilities of ML into defenses against inference attacks.
For example, ML classifiers are vulnerable to adversarial examples, which add
carefully crafted noise to normal examples such that an ML classifier makes
predictions for the examples as we desire. To defend against inference attacks,
we can add carefully crafted noise into the public data to turn them into
adversarial examples, such that attackers' classifiers make incorrect
predictions for the private data. However, existing methods to construct
adversarial examples are insufficient because they did not consider the unique
challenges and requirements for the crafted noise at defending against
inference attacks. In this chapter, we take defending against inference attacks
in online social networks as an example to illustrate the opportunities and
challenges.","['Jinyuan Jia', 'Neil Zhenqiang Gong']"
Generative weather for improved crop model simulations,Machine Learning,"Accurate and precise crop yield prediction is invaluable for decision making
at both farm levels and regional levels. To make yield prediction, crop models
are widely used for their capability to simulate hypothetical scenarios. While
accuracy and precision of yield prediction critically depend on weather inputs
to simulations, surprisingly little attention has been paid to preparing
weather inputs. We propose a new method to construct generative models for
long-term weather forecasts and ultimately improve crop yield prediction. We
demonstrate use of the method in two representative scenarios -- single-year
production of wheat, barley and canola and three-year production using
rotations of these crops. Results show significant improvement from the
conventional method, measured in terms of mean and standard deviation of
prediction errors. Our method outperformed the conventional method in every one
of 18 metrics for the first scenario and in 29 out of 36 metrics for the second
scenario. For individual crop modellers to start applying the method to their
problems, technical details are carefully explained, and all the code, trained
PyTorch models, APSIM simulation files and result data are made available.",['Yuji Saikai']
Fixed-Target Runtime Analysis,Neural and Evolutionary Computing,"Runtime analysis aims at contributing to our understanding of evolutionary
algorithms through mathematical analyses of their runtimes. In the context of
discrete optimization problems, runtime analysis classically studies the time
needed to find an optimal solution. However, both from a practical and from a
theoretical viewpoint, more fine-grained performance measures are needed to
gain a more detailed understanding of the main working principles and their
resulting performance implications. Two complementary approaches have been
suggested: fixed-budget analyses and fixed-target analyses.
  In this work, we conduct an in-depth study on the advantages and the
limitations of fixed-target analyses. We show that, different from fixed-budget
analyses, many classical methods from the runtime analysis of discrete
evolutionary algorithms yield fixed-target results without greater effort. We
use this to conduct a number of new fixed-target analyses. However, we also
point out examples where an extension of existing runtime results to
fixed-target results is highly non-trivial.","['Maxim Buzdalov', 'Benjamin Doerr', 'Carola Doerr', 'Dmitry Vinokurov']"
"Multimodal Co-learning: Challenges, Applications with Datasets, Recent
  Advances and Future Directions",Machine Learning,"Multimodal deep learning systems which employ multiple modalities like text,
image, audio, video, etc., are showing better performance in comparison with
individual modalities (i.e., unimodal) systems. Multimodal machine learning
involves multiple aspects: representation, translation, alignment, fusion, and
co-learning. In the current state of multimodal machine learning, the
assumptions are that all modalities are present, aligned, and noiseless during
training and testing time. However, in real-world tasks, typically, it is
observed that one or more modalities are missing, noisy, lacking annotated
data, have unreliable labels, and are scarce in training or testing and or
both. This challenge is addressed by a learning paradigm called multimodal
co-learning. The modeling of a (resource-poor) modality is aided by exploiting
knowledge from another (resource-rich) modality using transfer of knowledge
between modalities, including their representations and predictive models.
Co-learning being an emerging area, there are no dedicated reviews explicitly
focusing on all challenges addressed by co-learning. To that end, in this work,
we provide a comprehensive survey on the emerging area of multimodal
co-learning that has not been explored in its entirety yet. We review
implementations that overcome one or more co-learning challenges without
explicitly considering them as co-learning challenges. We present the
comprehensive taxonomy of multimodal co-learning based on the challenges
addressed by co-learning and associated implementations. The various techniques
employed to include the latest ones are reviewed along with some of the
applications and datasets. Our final goal is to discuss challenges and
perspectives along with the important ideas and directions for future work that
we hope to be beneficial for the entire research community focusing on this
exciting domain.","['Anil Rahate', 'Rahee Walambe', 'Sheela Ramanna', 'Ketan Kotecha']"
"Trying AGAIN instead of Trying Longer: Prior Learning for Automatic
  Curriculum Learning",Machine Learning,"A major challenge in the Deep RL (DRL) community is to train agents able to
generalize over unseen situations, which is often approached by training them
on a diversity of tasks (or environments). A powerful method to foster
diversity is to procedurally generate tasks by sampling their parameters from a
multi-dimensional distribution, enabling in particular to propose a different
task for each training episode. In practice, to get the high diversity of
training tasks necessary for generalization, one has to use complex procedural
generation systems. With such generators, it is hard to get prior knowledge on
the subset of tasks that are actually learnable at all (many generated tasks
may be unlearnable), what is their relative difficulty and what is the most
efficient task distribution ordering for training. A typical solution in such
cases is to rely on some form of Automated Curriculum Learning (ACL) to adapt
the sampling distribution. One limit of current approaches is their need to
explore the task space to detect progress niches over time, which leads to a
loss of time. Additionally, we hypothesize that the induced noise in the
training data may impair the performances of brittle DRL learners. We address
this problem by proposing a two stage ACL approach where 1) a teacher algorithm
first learns to train a DRL agent with a high-exploration curriculum, and then
2) distills learned priors from the first run to generate an ""expert
curriculum"" to re-train the same agent from scratch. Besides demonstrating 50%
improvements on average over the current state of the art, the objective of
this work is to give a first example of a new research direction oriented
towards refining ACL techniques over multiple learners, which we call Classroom
Teaching.","['Rémy Portelas', 'Katja Hofmann', 'Pierre-Yves Oudeyer']"
"Data-Informed Global Sparseness in Attention Mechanisms for Deep Neural
  Networks",Computation and Language (Natural Language Processing),"Attention mechanisms play a crucial role in the neural revolution of Natural
Language Processing (NLP). With the growth of attention-based models, several
pruning techniques have been developed to identify and exploit sparseness,
making these models more efficient. Most efforts focus on hard-coding attention
patterns or pruning attention weights based on training data. We propose
Attention Pruning (AP), a framework that observes attention patterns in a fixed
dataset and generates a global sparseness mask. AP saves 90% of attention
computation for language modeling and about 50% for machine translation and
GLUE tasks, maintaining result quality. Our method reveals important
distinctions between self- and cross-attention patterns, guiding future NLP
research. Our framework can reduce both latency and memory requirements for any
attention-based model, aiding in the development of improved models for
existing or new NLP applications. We have demonstrated this with encoder and
autoregressive transformer models using Triton GPU kernels and make our code
publicly available at https://github.com/irugina/AP.","['Ileana Rugina', 'Rumen Dangovski', 'Li Jing', 'Preslav Nakov', 'Marin Soljačić']"
"Projective Methods for Mitigating Gender Bias in Pre-trained Language
  Models",Computation and Language (Natural Language Processing),"Mitigation of gender bias in NLP has a long history tied to debiasing static
word embeddings. More recently, attention has shifted to debiasing pre-trained
language models. We study to what extent the simplest projective debiasing
methods, developed for word embeddings, can help when applied to BERT's
internal representations. Projective methods are fast to implement, use a small
number of saved parameters, and make no updates to the existing model
parameters. We evaluate the efficacy of the methods in reducing both intrinsic
bias, as measured by BERT's next sentence prediction task, and in mitigating
observed bias in a downstream setting when fine-tuned. To this end, we also
provide a critical analysis of a popular gender-bias assessment test for
quantifying intrinsic bias, resulting in an enhanced test set and new bias
measures. We find that projective methods can be effective at both intrinsic
bias and downstream bias mitigation, but that the two outcomes are not
necessarily correlated. This finding serves as a warning that intrinsic bias
test sets, based either on language modeling tasks or next sentence prediction,
should not be the only benchmark in developing a debiased language model.","['Hillary Dawkins', 'Isar Nejadgholi', 'Daniel Gillis', 'Judi McCuaig']"
Adapted tree boosting for Transfer Learning,Machine Learning,"Secure online transaction is an essential task for e-commerce platforms.
Alipay, one of the world's leading cashless payment platform, provides the
payment service to both merchants and individual customers. The fraud detection
models are built to protect the customers, but stronger demands are raised by
the new scenes, which are lacking in training data and labels. The proposed
model makes a difference by utilizing the data under similar old scenes and the
data under a new scene is treated as the target domain to be promoted. Inspired
by this real case in Alipay, we view the problem as a transfer learning problem
and design a set of revise strategies to transfer the source domain models to
the target domain under the framework of gradient boosting tree models. This
work provides an option for the cold-starting and data-sharing problems.","['Wenjing Fang', 'Chaochao Chen', 'Bowen Song', 'Li Wang', 'Jun Zhou', 'Kenny Q. Zhu']"
"Pac-Bayesian Supervised Classification: The Thermodynamics of
  Statistical Learning",Machine Learning (Statistics),"This monograph deals with adaptive supervised classification, using tools
borrowed from statistical mechanics and information theory, stemming from the
PACBayesian approach pioneered by David McAllester and applied to a conception
of statistical learning theory forged by Vladimir Vapnik. Using convex analysis
on the set of posterior probability measures, we show how to get local measures
of the complexity of the classification model involving the relative entropy of
posterior distributions with respect to Gibbs posterior measures. We then
discuss relative bounds, comparing the generalization error of two
classification rules, showing how the margin assumption of Mammen and Tsybakov
can be replaced with some empirical measure of the covariance structure of the
classification model.We show how to associate to any posterior distribution an
effective temperature relating it to the Gibbs prior distribution with the same
level of expected error rate, and how to estimate this effective temperature
from data, resulting in an estimator whose expected error rate converges
according to the best possible power of the sample size adaptively under any
margin and parametric complexity assumptions. We describe and study an
alternative selection scheme based on relative bounds between estimators, and
present a two step localization technique which can handle the selection of a
parametric model from a family of those. We show how to extend systematically
all the results obtained in the inductive setting to transductive learning, and
use this to improve Vapnik's generalization bounds, extending them to the case
when the sample is made of independent non-identically distributed pairs of
patterns and labels. Finally we review briefly the construction of Support
Vector Machines and show how to derive generalization bounds for them,
measuring the complexity either through the number of support vectors or
through the value of the transductive or inductive margin.",['Olivier Catoni']
Layer-Neighbor Sampling -- Defusing Neighborhood Explosion in GNNs,Machine Learning,"Graph Neural Networks (GNNs) have received significant attention recently,
but training them at a large scale remains a challenge. Mini-batch training
coupled with sampling is used to alleviate this challenge. However, existing
approaches either suffer from the neighborhood explosion phenomenon or have
poor performance. To address these issues, we propose a new sampling algorithm
called LAyer-neighBOR sampling (LABOR). It is designed to be a direct
replacement for Neighbor Sampling (NS) with the same fanout hyperparameter
while sampling up to 7 times fewer vertices, without sacrificing quality. By
design, the variance of the estimator of each vertex matches NS from the point
of view of a single vertex. Moreover, under the same vertex sampling budget
constraints, LABOR converges faster than existing layer sampling approaches and
can use up to 112 times larger batch sizes compared to NS.","['Muhammed Fatih Balın', 'Ümit V. Çatalyürek']"
"OPFData: Large-scale datasets for AC optimal power flow with topological
  perturbations",Machine Learning,"Solving the AC optimal power flow problem (AC-OPF) is critical to the
efficient and safe planning and operation of power grids. Small efficiency
improvements in this domain have the potential to lead to billions of dollars
of cost savings, and significant reductions in emissions from fossil fuel
generators. Recent work on data-driven solution methods for AC-OPF shows the
potential for large speed improvements compared to traditional solvers;
however, no large-scale open datasets for this problem exist. We present the
largest readily-available collection of solved AC-OPF problems to date. This
collection is orders of magnitude larger than existing readily-available
datasets, allowing training of high-capacity data-driven models. Uniquely, it
includes topological perturbations - a critical requirement for usage in
realistic power grid operations. We hope this resource will spur the community
to scale research to larger grid sizes with variable topology.","['Sean Lovett', 'Miha Zgubic', 'Sofia Liguori', 'Sephora Madjiheurem', 'Hamish Tomlinson', 'Sophie Elster', 'Chris Apps', 'Sims Witherspoon', 'Luis Piloto']"
"Densely Connected $G$-invariant Deep Neural Networks with Signed
  Permutation Representations",Machine Learning,"We introduce and investigate, for finite groups $G$, $G$-invariant deep
neural network ($G$-DNN) architectures with ReLU activation that are densely
connected-- i.e., include all possible skip connections. In contrast to other
$G$-invariant architectures in the literature, the preactivations of
the$G$-DNNs presented here are able to transform by \emph{signed} permutation
representations (signed perm-reps) of $G$. Moreover, the individual layers of
the $G$-DNNs are not required to be $G$-equivariant; instead, the
preactivations are constrained to be $G$-equivariant functions of the network
input in a way that couples weights across all layers. The result is a richer
family of $G$-invariant architectures never seen previously. We derive an
efficient implementation of $G$-DNNs after a reparameterization of weights, as
well as necessary and sufficient conditions for an architecture to be
``admissible''-- i.e., nondegenerate and inequivalent to smaller architectures.
We include code that allows a user to build a $G$-DNN interactively
layer-by-layer, with the final architecture guaranteed to be admissible. We
show that there are far more admissible $G$-DNN architectures than those
accessible with the ``concatenated ReLU'' activation function from the
literature. Finally, we apply $G$-DNNs to two example problems -- (1)
multiplication in $\{-1, 1\}$ (with theoretical guarantees) and (2) 3D object
classification -- % finding that the inclusion of signed perm-reps
significantly boosts predictive performance compared to baselines with only
ordinary (i.e., unsigned) perm-reps.","['Devanshu Agrawal', 'James Ostrowski']"
The 2021 Image Similarity Dataset and Challenge,Computer Vision and Pattern Recognition,"This paper introduces a new benchmark for large-scale image similarity
detection. This benchmark is used for the Image Similarity Challenge at
NeurIPS'21 (ISC2021). The goal is to determine whether a query image is a
modified copy of any image in a reference corpus of size 1~million. The
benchmark features a variety of image transformations such as automated
transformations, hand-crafted image edits and machine-learning based
manipulations. This mimics real-life cases appearing in social media, for
example for integrity-related problems dealing with misinformation and
objectionable content. The strength of the image manipulations, and therefore
the difficulty of the benchmark, is calibrated according to the performance of
a set of baseline approaches. Both the query and reference set contain a
majority of ""distractor"" images that do not match, which corresponds to a
real-life needle-in-haystack setting, and the evaluation metric reflects that.
We expect the DISC21 benchmark to promote image copy detection as an important
and challenging computer vision task and refresh the state of the art. Code and
data are available at https://github.com/facebookresearch/isc2021","['Matthijs Douze', 'Giorgos Tolias', 'Ed Pizzi', 'Zoë Papakipos', 'Lowik Chanussot', 'Filip Radenovic', 'Tomas Jenicek', 'Maxim Maximov', 'Laura Leal-Taixé', 'Ismail Elezi', 'Ondřej Chum', 'Cristian Canton Ferrer']"
"Forecaster: A Graph Transformer for Forecasting Spatial and
  Time-Dependent Data",Machine Learning,"Spatial and time-dependent data is of interest in many applications. This
task is difficult due to its complex spatial dependency, long-range temporal
dependency, data non-stationarity, and data heterogeneity. To address these
challenges, we propose Forecaster, a graph Transformer architecture.
Specifically, we start by learning the structure of the graph that
parsimoniously represents the spatial dependency between the data at different
locations. Based on the topology of the graph, we sparsify the Transformer to
account for the strength of spatial dependency, long-range temporal dependency,
data non-stationarity, and data heterogeneity. We evaluate Forecaster in the
problem of forecasting taxi ride-hailing demand and show that our proposed
architecture significantly outperforms the state-of-the-art baselines.","['Yang Li', 'José M. F. Moura']"
"Utility-based Perturbed Gradient Descent: An Optimizer for Continual
  Learning",Machine Learning,"Modern representation learning methods often struggle to adapt quickly under
non-stationarity because they suffer from catastrophic forgetting and decaying
plasticity. Such problems prevent learners from fast adaptation since they may
forget useful features or have difficulty learning new ones. Hence, these
methods are rendered ineffective for continual learning. This paper proposes
Utility-based Perturbed Gradient Descent (UPGD), an online learning algorithm
well-suited for continual learning agents. UPGD protects useful weights or
features from forgetting and perturbs less useful ones based on their
utilities. Our empirical results show that UPGD helps reduce forgetting and
maintain plasticity, enabling modern representation learning methods to work
effectively in continual learning.","['Mohamed Elsayed', 'A. Rupam Mahmood']"
"Kernel Inversed Pyramidal Resizing Network for Efficient Pavement
  Distress Recognition",Computer Vision and Pattern Recognition,"Pavement Distress Recognition (PDR) is an important step in pavement
inspection and can be powered by image-based automation to expedite the process
and reduce labor costs. Pavement images are often in high-resolution with a low
ratio of distressed to non-distressed areas. Advanced approaches leverage these
properties via dividing images into patches and explore discriminative features
in the scale space. However, these approaches usually suffer from information
loss during image resizing and low efficiency due to complex learning
frameworks. In this paper, we propose a novel and efficient method for PDR. A
light network named the Kernel Inversed Pyramidal Resizing Network (KIPRN) is
introduced for image resizing, and can be flexibly plugged into the image
classification network as a pre-network to exploit resolution and scale
information. In KIPRN, pyramidal convolution and kernel inversed convolution
are specifically designed to mine discriminative information across different
feature granularities and scales. The mined information is passed along to the
resized images to yield an informative image pyramid to assist the image
classification network for PDR. We applied our method to three well-known
Convolutional Neural Networks (CNNs), and conducted an evaluation on a
large-scale pavement image dataset named CQU-BPDD. Extensive results
demonstrate that KIPRN can generally improve the pavement distress recognition
of these CNN models and show that the simple combination of KIPRN and
EfficientNet-B3 significantly outperforms the state-of-the-art patch-based
method in both performance and efficiency.","['Rong Qin', 'Luwen Huangfu', 'Devon Hood', 'James Ma', 'Sheng Huang']"
"A probabilistic framework for analysing the compositionality of
  conceptual combinations",Computation and Language (Natural Language Processing),"Conceptual combination performs a fundamental role in creating the broad
range of compound phrases utilized in everyday language. This article provides
a novel probabilistic framework for assessing whether the semantics of
conceptual combinations are compositional, and so can be considered as a
function of the semantics of the constituent concepts, or not. While the
systematicity and productivity of language provide a strong argument in favor
of assuming compositionality, this very assumption is still regularly
questioned in both cognitive science and philosophy. Additionally, the
principle of semantic compositionality is underspecified, which means that
notions of both ""strong"" and ""weak"" compositionality appear in the literature.
Rather than adjudicating between different grades of compositionality, the
framework presented here contributes formal methods for determining a clear
dividing line between compositional and non-compositional semantics. In
addition, we suggest that the distinction between these is contextually
sensitive. Utilizing formal frameworks developed for analyzing composite
systems in quantum theory, we present two methods that allow the semantics of
conceptual combinations to be classified as ""compositional"" or
""non-compositional"". Compositionality is first formalised by factorising the
joint probability distribution modeling the combination, where the terms in the
factorisation correspond to individual concepts. This leads to the necessary
and sufficient condition for the joint probability distribution to exist. A
failure to meet this condition implies that the underlying concepts cannot be
modeled in a single probability space when considering their combination, and
the combination is thus deemed ""non-compositional"". The formal analysis methods
are demonstrated by applying them to an empirical study of twenty-four
non-lexicalised conceptual combinations.","['Peter D. Bruza', 'Kirsty Kitto', 'Brentyn J. Ramm', 'Laurianne Sitbon']"
Symlink: A New Dataset for Scientific Symbol-Description Linking,Computation and Language (Natural Language Processing),"Mathematical symbols and descriptions appear in various forms across document
section boundaries without explicit markup. In this paper, we present a new
large-scale dataset that emphasizes extracting symbols and descriptions in
scientific documents. Symlink annotates scientific papers of 5 different
domains (i.e., computer science, biology, physics, mathematics, and economics).
Our experiments on Symlink demonstrate the challenges of the symbol-description
linking task for existing models and call for further research effort in this
area. We will publicly release Symlink to facilitate future research.","['Viet Dac Lai', 'Amir Pouran Ben Veyseh', 'Franck Dernoncourt', 'Thien Huu Nguyen']"
"Image segmentation by optimal and hierarchical piecewise constant
  approximations",Computer Vision and Pattern Recognition,"Piecewise constant image approximations of sequential number of segments or
clusters of disconnected pixels are treated. The method of majorizing of
optimal approximation sequence by hierarchical sequence of image approximations
is proposed. A generalization for multidimensional case of color and
multispectral images is foreseen.",['M. Kharinov']
A pseudo-likelihood approach to community detection in weighted networks,Methodology (Statistics),"Community structure is common in many real networks, with nodes clustered in
groups sharing the same connections patterns. While many community detection
methods have been developed for networks with binary edges, few of them are
applicable to networks with weighted edges, which are common in practice. We
propose a pseudo-likelihood community estimation algorithm derived under the
weighted stochastic block model for networks with normally distributed edge
weights, extending the pseudo-likelihood algorithm for binary networks, which
offers some of the best combinations of accuracy and computational efficiency.
We prove that the estimates obtained by the proposed method are consistent
under the assumption of homogeneous networks, a weighted analogue of the
planted partition model, and show that they work well in practice for both
homogeneous and heterogeneous networks. We illustrate the method on simulated
networks and on a fMRI dataset, where edge weights represent connectivity
between brain regions and are expected to be close to normal in distribution by
construction.","['Andressa Cerqueira', 'Elizaveta Levina']"
"Pre-training of Context-aware Item Representation for Next Basket
  Recommendation",Information Retrieval,"Next basket recommendation, which aims to predict the next a few items that a
user most probably purchases given his historical transactions, plays a vital
role in market basket analysis. From the viewpoint of item, an item could be
purchased by different users together with different items, for different
reasons. Therefore, an ideal recommender system should represent an item
considering its transaction contexts. Existing state-of-the-art deep learning
methods usually adopt the static item representations, which are invariant
among all of the transactions and thus cannot achieve the full potentials of
deep learning. Inspired by the pre-trained representations of BERT in natural
language processing, we propose to conduct context-aware item representation
for next basket recommendation, called Item Encoder Representations from
Transformers (IERT). In the offline phase, IERT pre-trains deep item
representations conditioning on their transaction contexts. In the online
recommendation phase, the pre-trained model is further fine-tuned with an
additional output layer. The output contextualized item embeddings are used to
capture users' sequential behaviors and general tastes to conduct
recommendation. Experimental results on the Ta-Feng data set show that IERT
outperforms the state-of-the-art baseline methods, which demonstrated the
effectiveness of IERT in next basket representation.","['Jingxuan Yang', 'Jun Xu', 'Jianzhuo Tong', 'Sheng Gao', 'Jun Guo', 'Jirong Wen']"
"Unsupervised Image Transformation Learning via Generative Adversarial
  Networks",Computer Vision and Pattern Recognition,"In this work, we study the image transformation problem, which targets at
learning the underlying transformations (e.g., the transition of seasons) from
a collection of unlabeled images. However, there could be countless of
transformations in the real world, making such a task incredibly challenging,
especially under the unsupervised setting. To tackle this obstacle, we propose
a novel learning framework built on generative adversarial networks (GANs),
where the discriminator and the generator share a transformation space. After
the model gets fully optimized, any two points within the shared space are
expected to define a valid transformation. In this way, at the inference stage,
we manage to adequately extract the variation factor between a customizable
image pair by projecting both images onto the transformation space. The
resulting transformation vector can further guide the image synthesis,
facilitating image editing with continuous semantic change (e.g., altering
summer to winter with fall as the intermediate step). Noticeably, the learned
transformation space supports not only transferring image styles (e.g.,
changing day to night), but also manipulating image contents (e.g., adding
clouds in the sky). In addition, we make in-depth analysis on the properties of
the transformation space to help understand how various transformations are
organized. Project page is at https://genforce.github.io/trgan/.","['Kaiwen Zha', 'Yujun Shen', 'Bolei Zhou']"
Integrating selectional preferences in WordNet,Computation and Language (Natural Language Processing),"Selectional preference learning methods have usually focused on word-to-class
relations, e.g., a verb selects as its subject a given nominal class. This
paper extends previous statistical models to class-to-class preferences, and
presents a model that learns selectional preferences for classes of verbs,
together with an algorithm to integrate the learned preferences in WordNet. The
theoretical motivation is twofold: different senses of a verb may have
different preferences, and classes of verbs may share preferences. On the
practical side, class-to-class selectional preferences can be learned from
untagged corpora (the same as word-to-class), they provide selectional
preferences for less frequent word senses via inheritance, and more important,
they allow for easy integration in WordNet. The model is trained on
subject-verb and object-verb relationships extracted from a small corpus
disambiguated with WordNet senses. Examples are provided illustrating that the
theoretical motivations are well founded, and showing that the approach is
feasible. Experimental results on a word sense disambiguation task are also
provided.","['Eneko Agirre', 'David Martinez']"
Joint reconstruction-segmentation on graphs,Computer Vision and Pattern Recognition,"Practical image segmentation tasks concern images which must be reconstructed
from noisy, distorted, and/or incomplete observations. A recent approach for
solving such tasks is to perform this reconstruction jointly with the
segmentation, using each to guide the other. However, this work has so far
employed relatively simple segmentation methods, such as the Chan--Vese
algorithm. In this paper, we present a method for joint
reconstruction-segmentation using graph-based segmentation methods, which have
been seeing increasing recent interest. Complications arise due to the large
size of the matrices involved, and we show how these complications can be
managed. We then analyse the convergence properties of our scheme. Finally, we
apply this scheme to distorted versions of ``two cows'' images familiar from
previous graph-based segmentation literature, first to a highly noised version
and second to a blurred version, achieving highly accurate segmentations in
both cases. We compare these results to those obtained by sequential
reconstruction-segmentation approaches, finding that our method competes with,
or even outperforms, those approaches in terms of reconstruction and
segmentation accuracy.","['Jeremy Budd', 'Yves van Gennip', 'Jonas Latz', 'Simone Parisotto', 'Carola-Bibiane Schönlieb']"
"Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image
  Denoising",Computer Vision and Pattern Recognition,"Discriminative model learning for image denoising has been recently
attracting considerable attentions due to its favorable denoising performance.
In this paper, we take one step forward by investigating the construction of
feed-forward denoising convolutional neural networks (DnCNNs) to embrace the
progress in very deep architecture, learning algorithm, and regularization
method into image denoising. Specifically, residual learning and batch
normalization are utilized to speed up the training process as well as boost
the denoising performance. Different from the existing discriminative denoising
models which usually train a specific model for additive white Gaussian noise
(AWGN) at a certain noise level, our DnCNN model is able to handle Gaussian
denoising with unknown noise level (i.e., blind Gaussian denoising). With the
residual learning strategy, DnCNN implicitly removes the latent clean image in
the hidden layers. This property motivates us to train a single DnCNN model to
tackle with several general image denoising tasks such as Gaussian denoising,
single image super-resolution and JPEG image deblocking. Our extensive
experiments demonstrate that our DnCNN model can not only exhibit high
effectiveness in several general image denoising tasks, but also be efficiently
implemented by benefiting from GPU computing.","['Kai Zhang', 'Wangmeng Zuo', 'Yunjin Chen', 'Deyu Meng', 'Lei Zhang']"
"Active Surrogate Estimators: An Active Learning Approach to
  Label-Efficient Model Evaluation",Machine Learning,"We propose Active Surrogate Estimators (ASEs), a new method for
label-efficient model evaluation. Evaluating model performance is a challenging
and important problem when labels are expensive. ASEs address this active
testing problem using a surrogate-based estimation approach that interpolates
the errors of points with unknown labels, rather than forming a Monte Carlo
estimator. ASEs actively learn the underlying surrogate, and we propose a novel
acquisition strategy, XWED, that tailors this learning to the final estimation
task. We find that ASEs offer greater label-efficiency than the current
state-of-the-art when applied to challenging model evaluation problems for deep
neural networks.","['Jannik Kossen', 'Sebastian Farquhar', 'Yarin Gal', 'Tom Rainforth']"
Randomized Algorithms for the Loop Cutset Problem,Artificial Intelligence,"We show how to find a minimum weight loop cutset in a Bayesian network with
high probability. Finding such a loop cutset is the first step in the method of
conditioning for inference. Our randomized algorithm for finding a loop cutset
outputs a minimum loop cutset after O(c 6^k kn) steps with probability at least
1 - (1 - 1/(6^k))^c6^k, where c > 1 is a constant specified by the user, k is
the minimal size of a minimum weight loop cutset, and n is the number of
vertices. We also show empirically that a variant of this algorithm often finds
a loop cutset that is closer to the minimum weight loop cutset than the ones
found by the best deterministic algorithms known.","['R. Bar-Yehuda', 'A. Becker', 'D. Geiger']"
Counterexample-Driven Synthesis for Probabilistic Program Sketches,Software Engineering,"Probabilistic programs are key to deal with uncertainty in e.g. controller
synthesis. They are typically small but intricate. Their development is complex
and error prone requiring quantitative reasoning over a myriad of alternative
designs. To mitigate this complexity, we adopt counterexample-guided inductive
synthesis (CEGIS) to automatically synthesise finite-state probabilistic
programs. Our approach leverages efficient model checking, modern SMT solving,
and counterexample generation at program level. Experiments on practically
relevant case studies show that design spaces with millions of candidate
designs can be fully explored using a few thousand verification queries.","['Milan Češka', 'Christian Hensel', 'Sebastian Junges', 'Joost-Pieter Katoen']"
Deep learning improved by biological activation functions,Neural and Evolutionary Computing,"`Biologically inspired' activation functions, such as the logistic sigmoid,
have been instrumental in the historical advancement of machine learning.
However in the field of deep learning, they have been largely displaced by
rectified linear units (ReLU) or similar functions, such as its exponential
linear unit (ELU) variant, to mitigate the effects of vanishing gradients
associated with error back-propagation. The logistic sigmoid however does not
represent the true input-output relation in neuronal cells under physiological
conditions. Here, bionodal root unit (BRU) activation functions are introduced,
exhibiting input-output non-linearities that are substantially more
biologically plausible since their functional form is based on known
biophysical properties of neuronal cells.
  In order to evaluate the learning performance of BRU activations, deep
networks are constructed with identical architectures except differing in their
transfer functions (ReLU, ELU, and BRU). Multilayer perceptrons, stacked
auto-encoders, and convolutional networks are used to test supervised and
unsupervised learning based on the MNIST and CIFAR-10/100 datasets. Comparisons
of learning performance, quantified using loss and error measurements,
demonstrate that bionodal networks both train faster than their ReLU and ELU
counterparts and result in the best generalised models even in the absence of
formal regularisation. These results therefore suggest that revisiting the
detailed properties of biological neurones and their circuitry might prove
invaluable in the field of deep learning for the future.",['Gardave S Bhumbra']
Local Context Normalization: Revisiting Local Normalization,Computer Vision and Pattern Recognition,"Normalization layers have been shown to improve convergence in deep neural
networks, and even add useful inductive biases. In many vision applications the
local spatial context of the features is important, but most common
normalization schemes including Group Normalization (GN), Instance
Normalization (IN), and Layer Normalization (LN) normalize over the entire
spatial dimension of a feature. This can wash out important signals and degrade
performance. For example, in applications that use satellite imagery, input
images can be arbitrarily large; consequently, it is nonsensical to normalize
over the entire area. Positional Normalization (PN), on the other hand, only
normalizes over a single spatial position at a time. A natural compromise is to
normalize features by local context, while also taking into account group level
information. In this paper, we propose Local Context Normalization (LCN): a
normalization layer where every feature is normalized based on a window around
it and the filters in its group. We propose an algorithmic solution to make LCN
efficient for arbitrary window sizes, even if every point in the image has a
unique window. LCN outperforms its Batch Normalization (BN), GN, IN, and LN
counterparts for object detection, semantic segmentation, and instance
segmentation applications in several benchmark datasets, while keeping
performance independent of the batch size and facilitating transfer learning.","['Anthony Ortiz', 'Caleb Robinson', 'Dan Morris', 'Olac Fuentes', 'Christopher Kiekintveld', 'Md Mahmudulla Hassan', 'Nebojsa Jojic']"
Character-level Intra Attention Network for Natural Language Inference,Computation and Language (Natural Language Processing),"Natural language inference (NLI) is a central problem in language
understanding. End-to-end artificial neural networks have reached
state-of-the-art performance in NLI field recently.
  In this paper, we propose Character-level Intra Attention Network (CIAN) for
the NLI task. In our model, we use the character-level convolutional network to
replace the standard word embedding layer, and we use the intra attention to
capture the intra-sentence semantics. The proposed CIAN model provides improved
results based on a newly published MNLI corpus.","['Han Yang', 'Marta R. Costa-jussà', 'José A. R. Fonollosa']"
Overcoming Digital Gravity when using AI in Public Health Decisions,Artificial Intelligence,"In popular usage, Data Gravity refers to the ability of a body of data to
attract applications, services and other data. In this work we introduce a
broader concept, ""Digital Gravity"" which includes not just data, but other
elements of the AI/ML workflow. This concept is born out of our recent
experiences in developing and deploying an AI-based decision support platform
intended for use in a public health context. In addition to data, examples of
additional considerations are compute (infrastructure and software), DevSecOps
(personnel and practices), algorithms/programs, control planes, middleware
(considered separately from programs), and even companies/service providers. We
discuss the impact of Digital Gravity on the pathway to adoption and suggest
preliminary approaches to conceptualize and mitigate the friction caused by it.","['Sekou L Remy', 'Aisha Walcott-Bryant', 'Nelson K Bore', 'Charles M Wachira', 'Julian Kuenhert']"
Asymptotic Generalization Bound of Fisher's Linear Discriminant Analysis,Machine Learning (Statistics),"Fisher's linear discriminant analysis (FLDA) is an important dimension
reduction method in statistical pattern recognition. It has been shown that
FLDA is asymptotically Bayes optimal under the homoscedastic Gaussian
assumption. However, this classical result has the following two major
limitations: 1) it holds only for a fixed dimensionality $D$, and thus does not
apply when $D$ and the training sample size $N$ are proportionally large; 2) it
does not provide a quantitative description on how the generalization ability
of FLDA is affected by $D$ and $N$. In this paper, we present an asymptotic
generalization analysis of FLDA based on random matrix theory, in a setting
where both $D$ and $N$ increase and $D/N\longrightarrow\gamma\in[0,1)$. The
obtained lower bound of the generalization discrimination power overcomes both
limitations of the classical result, i.e., it is applicable when $D$ and $N$
are proportionally large and provides a quantitative description of the
generalization ability of FLDA in terms of the ratio $\gamma=D/N$ and the
population discrimination power. Besides, the discrimination power bound also
leads to an upper bound on the generalization error of binary-classification
with FLDA.","['Wei Bian', 'Dacheng Tao']"
"MarkerPose: Robust Real-time Planar Target Tracking for Accurate Stereo
  Pose Estimation",Computer Vision and Pattern Recognition,"Despite the attention marker-less pose estimation has attracted in recent
years, marker-based approaches still provide unbeatable accuracy under
controlled environmental conditions. Thus, they are used in many fields such as
robotics or biomedical applications but are primarily implemented through
classical approaches, which require lots of heuristics and parameter tuning for
reliable performance under different environments. In this work, we propose
MarkerPose, a robust, real-time pose estimation system based on a planar target
of three circles and a stereo vision system. MarkerPose is meant for
high-accuracy pose estimation applications. Our method consists of two deep
neural networks for marker point detection. A SuperPoint-like network for
pixel-level accuracy keypoint localization and classification, and we introduce
EllipSegNet, a lightweight ellipse segmentation network for sub-pixel-level
accuracy keypoint detection. The marker's pose is estimated through stereo
triangulation. The target point detection is robust to low lighting and motion
blur conditions. We compared MarkerPose with a detection method based on
classical computer vision techniques using a robotic arm for validation. The
results show our method provides better accuracy than the classical technique.
Finally, we demonstrate the suitability of MarkerPose in a 3D freehand
ultrasound system, which is an application where highly accurate pose
estimation is required. Code is available in Python and C++ at
https://github.com/jhacsonmeza/MarkerPose.","['Jhacson Meza', 'Lenny A. Romero', 'Andres G. Marrugo']"
"A Robust Unsupervised Ensemble of Feature-Based Explanations using
  Restricted Boltzmann Machines",Machine Learning,"Understanding the results of deep neural networks is an essential step
towards wider acceptance of deep learning algorithms. Many approaches address
the issue of interpreting artificial neural networks, but often provide
divergent explanations. Moreover, different hyperparameters of an explanatory
method can lead to conflicting interpretations. In this paper, we propose a
technique for aggregating the feature attributions of different explanatory
algorithms using Restricted Boltzmann Machines (RBMs) to achieve a more
reliable and robust interpretation of deep neural networks. Several challenging
experiments on real-world datasets show that the proposed RBM method
outperforms popular feature attribution methods and basic ensemble techniques.","['Vadim Borisov', 'Johannes Meier', 'Johan van den Heuvel', 'Hamed Jalali', 'Gjergji Kasneci']"
Assessment of Neural Networks for Stream-Water-Temperature Prediction,Machine Learning,"Climate change results in altered air and water temperatures. Increases
affect physicochemical properties, such as oxygen concentration, and can shift
species distribution and survival, with consequences for ecosystem functioning
and services. These ecosystem services have integral value for humankind and
are forecasted to alter under climate warming. A mechanistic understanding of
the drivers and magnitude of expected changes is essential in identifying
system resilience and mitigation measures. In this work, we present a selection
of state-of-the-art Neural Networks (NN) for the prediction of water
temperatures in six streams in Germany. We show that the use of methods that
compare observed and predicted values, exemplified with the Root Mean Square
Error (RMSE), is not sufficient for their assessment. Hence we introduce
additional analysis methods for our models to complement the state-of-the-art
metrics. These analyses evaluate the NN's robustness, possible maximal and
minimal values, and the impact of single input parameters on the output. We
thus contribute to understanding the processes within the NN and help
applicants choose architectures and input parameters for reliable water
temperature prediction models.","['Stefanie Mohr', 'Konstantina Drainas', 'Juergen Geist']"
"Information Perspective to Probabilistic Modeling: Boltzmann Machines
  versus Born Machines","Data Analysis, Statistics and Probability","We compare and contrast the statistical physics and quantum physics inspired
approaches for unsupervised generative modeling of classical data. The two
approaches represent probabilities of observed data using energy-based models
and quantum states respectively.Classical and quantum information patterns of
the target datasets therefore provide principled guidelines for structural
design and learning in these two approaches. Taking the restricted Boltzmann
machines (RBM) as an example, we analyze the information theoretical bounds of
the two approaches. We verify our reasonings by comparing the performance of
RBMs of various architectures on the standard MNIST datasets.","['Song Cheng', 'Jing Chen', 'Lei Wang']"
Attention vs non-attention for a Shapley-based explanation method,Computation and Language (Natural Language Processing),"The field of explainable AI has recently seen an explosion in the number of
explanation methods for highly non-linear deep neural networks. The extent to
which such methods -- that are often proposed and tested in the domain of
computer vision -- are appropriate to address the explainability challenges in
NLP is yet relatively unexplored. In this work, we consider Contextual
Decomposition (CD) -- a Shapley-based input feature attribution method that has
been shown to work well for recurrent NLP models -- and we test the extent to
which it is useful for models that contain attention operations. To this end,
we extend CD to cover the operations necessary for attention-based models. We
then compare how long distance subject-verb relationships are processed by
models with and without attention, considering a number of different syntactic
structures in two different languages: English and Dutch. Our experiments
confirm that CD can successfully be applied for attention-based models as well,
providing an alternative Shapley-based attribution method for modern neural
networks. In particular, using CD, we show that the English and Dutch models
demonstrate similar processing behaviour, but that under the hood there are
consistent differences between our attention and non-attention models.","['Tom Kersten', 'Hugh Mee Wong', 'Jaap Jumelet', 'Dieuwke Hupkes']"
"On Solving a Stochastic Shortest-Path Markov Decision Process as
  Probabilistic Inference",Machine Learning,"Previous work on planning as active inference addresses finite horizon
problems and solutions valid for online planning. We propose solving the
general Stochastic Shortest-Path Markov Decision Process (SSP MDP) as
probabilistic inference. Furthermore, we discuss online and offline methods for
planning under uncertainty. In an SSP MDP, the horizon is indefinite and
unknown a priori. SSP MDPs generalize finite and infinite horizon MDPs and are
widely used in the artificial intelligence community. Additionally, we
highlight some of the differences between solving an MDP using dynamic
programming approaches widely used in the artificial intelligence community and
approaches used in the active inference community.","['Mohamed Baioumy', 'Bruno Lacerda', 'Paul Duckworth', 'Nick Hawes']"
Machine Comprehension Based on Learning to Rank,Computation and Language (Natural Language Processing),"Machine comprehension plays an essential role in NLP and has been widely
explored with dataset like MCTest. However, this dataset is too simple and too
small for learning true reasoning abilities. \cite{hermann2015teaching}
therefore release a large scale news article dataset and propose a deep LSTM
reader system for machine comprehension. However, the training process is
expensive. We therefore try feature-engineered approach with semantics on the
new dataset to see how traditional machine learning technique and semantics can
help with machine comprehension. Meanwhile, our proposed L2R reader system
achieves good performance with efficiency and less training data.","['Tian Tian', 'Yuezhang Li']"
"HumanDiffusion: a Coarse-to-Fine Alignment Diffusion Framework for
  Controllable Text-Driven Person Image Generation",Computer Vision and Pattern Recognition,"Text-driven person image generation is an emerging and challenging task in
cross-modality image generation. Controllable person image generation promotes
a wide range of applications such as digital human interaction and virtual
try-on. However, previous methods mostly employ single-modality information as
the prior condition (e.g. pose-guided person image generation), or utilize the
preset words for text-driven human synthesis. Introducing a sentence composed
of free words with an editable semantic pose map to describe person appearance
is a more user-friendly way. In this paper, we propose HumanDiffusion, a
coarse-to-fine alignment diffusion framework, for text-driven person image
generation. Specifically, two collaborative modules are proposed, the Stylized
Memory Retrieval (SMR) module for fine-grained feature distillation in data
processing and the Multi-scale Cross-modality Alignment (MCA) module for
coarse-to-fine feature alignment in diffusion. These two modules guarantee the
alignment quality of the text and image, from image-level to feature-level,
from low-resolution to high-resolution. As a result, HumanDiffusion realizes
open-vocabulary person image generation with desired semantic poses. Extensive
experiments conducted on DeepFashion demonstrate the superiority of our method
compared with previous approaches. Moreover, better results could be obtained
for complicated person images with various details and uncommon poses.","['Kaiduo Zhang', 'Muyi Sun', 'Jianxin Sun', 'Binghao Zhao', 'Kunbo Zhang', 'Zhenan Sun', 'Tieniu Tan']"
Contextual Emotion Estimation from Image Captions,Computer Vision and Pattern Recognition,"Emotion estimation in images is a challenging task, typically using computer
vision methods to directly estimate people's emotions using face, body pose and
contextual cues. In this paper, we explore whether Large Language Models (LLMs)
can support the contextual emotion estimation task, by first captioning images,
then using an LLM for inference. First, we must understand: how well do LLMs
perceive human emotions? And which parts of the information enable them to
determine emotions? One initial challenge is to construct a caption that
describes a person within a scene with information relevant for emotion
perception. Towards this goal, we propose a set of natural language descriptors
for faces, bodies, interactions, and environments. We use them to manually
generate captions and emotion annotations for a subset of 331 images from the
EMOTIC dataset. These captions offer an interpretable representation for
emotion estimation, towards understanding how elements of a scene affect
emotion perception in LLMs and beyond. Secondly, we test the capability of a
large language model to infer an emotion from the resulting image captions. We
find that GPT-3.5, specifically the text-davinci-003 model, provides
surprisingly reasonable emotion predictions consistent with human annotations,
but accuracy can depend on the emotion concept. Overall, the results suggest
promise in the image captioning and LLM approach.","['Vera Yang', 'Archita Srivastava', 'Yasaman Etesam', 'Chuxuan Zhang', 'Angelica Lim']"
Belief Conditioning Rules (BCRs),Artificial Intelligence,"In this paper we propose a new family of Belief Conditioning Rules (BCRs) for
belief revision. These rules are not directly related with the fusion of
several sources of evidence but with the revision of a belief assignment
available at a given time according to the new truth (i.e. conditioning
constraint) one has about the space of solutions of the problem.","['Florentin Smarandache', 'Jean Dezert']"
FT-SWRL: A Fuzzy-Temporal Extension of Semantic Web Rule Language,Artificial Intelligence,"We present, FT-SWRL, a fuzzy temporal extension to the Semantic Web Rule
Language (SWRL), which combines fuzzy theories based on the valid-time temporal
model to provide a standard approach for modeling imprecise temporal domain
knowledge in OWL ontologies. The proposal introduces a fuzzy temporal model for
the semantic web, which is syntactically defined as a fuzzy temporal SWRL
ontology (SWRL-FTO) with a new set of fuzzy temporal SWRL built-ins for
defining their semantics. The SWRL-FTO hierarchically defines the necessary
linguistic terminologies and variables for the fuzzy temporal model. An example
model demonstrating the usefulness of the fuzzy temporal SWRL built-ins to
model imprecise temporal information is also represented. Fuzzification process
of interval-based temporal logic is further discussed as a reasoning paradigm
for our FT-SWRL rules, with the aim of achieving a complete OWL-based fuzzy
temporal reasoning. Literature review on fuzzy temporal representation
approaches, both within and without the use of ontologies, led to the
conclusion that the FT-SWRL model can authoritatively serve as a formal
specification for handling imprecise temporal expressions on the semantic web.","['Abba Lawan', 'Abdur Rakib']"
XNMR: A tool for knowledge bases exploration,Logic in Computer Science,"XNMR is a system designed to explore the results of combining the
well-founded semantics system XSB with the stable-models evaluator SMODELS. Its
main goal is to work as a tool for fast and interactive exploration of
knowledge bases.","['L. Castro', 'D. Warren']"
"Joint Inference of Reward Machines and Policies for Reinforcement
  Learning",Artificial Intelligence,"Incorporating high-level knowledge is an effective way to expedite
reinforcement learning (RL), especially for complex tasks with sparse rewards.
We investigate an RL problem where the high-level knowledge is in the form of
reward machines, i.e., a type of Mealy machine that encodes the reward
functions. We focus on a setting in which this knowledge is a priori not
available to the learning agent. We develop an iterative algorithm that
performs joint inference of reward machines and policies for RL (more
specifically, q-learning). In each iteration, the algorithm maintains a
hypothesis reward machine and a sample of RL episodes. It derives q-functions
from the current hypothesis reward machine, and performs RL to update the
q-functions. While performing RL, the algorithm updates the sample by adding RL
episodes along which the obtained rewards are inconsistent with the rewards
based on the current hypothesis reward machine. In the next iteration, the
algorithm infers a new hypothesis reward machine from the updated sample. Based
on an equivalence relationship we defined between states of reward machines, we
transfer the q-functions between the hypothesis reward machines in consecutive
iterations. We prove that the proposed algorithm converges almost surely to an
optimal policy in the limit if a minimal reward machine can be inferred and the
maximal length of each RL episode is sufficiently long. The experiments show
that learning high-level knowledge in the form of reward machines can lead to
fast convergence to optimal policies in RL, while standard RL methods such as
q-learning and hierarchical RL methods fail to converge to optimal policies
after a substantial number of training steps in many tasks.","['Zhe Xu', 'Ivan Gavran', 'Yousef Ahmad', 'Rupak Majumdar', 'Daniel Neider', 'Ufuk Topcu', 'Bo Wu']"
"Proceedings of the Second Summer School on Argumentation: Computational
  and Linguistic Perspectives (SSA'16)",Artificial Intelligence,"This volume contains the thesis abstracts presented at the Second Summer
School on Argumentation: Computational and Linguistic Perspectives (SSA'2016)
held on September 8-12 in Potsdam, Germany.","['Sarah A. Gaggl', 'Matthias Thimm']"
"To each route its own ETA: A generative modeling framework for ETA
  prediction",Machine Learning,"Accurate expected time of arrival (ETA) information is crucial in maintaining
the quality of service of public transit. Recent advances in artificial
intelligence (AI) has led to more effective models for ETA estimation that rely
heavily on a large GPS datasets. More importantly, these are mainly cabs based
datasets which may not be fit for bus-based public transport. Consequently, the
latest methods may not be applicable for ETA estimation in cities with the
absence of large training data set. On the other hand, the ETA estimation
problem in many cities needs to be solved in the absence of big datasets that
also contains outliers, anomalies and may be incomplete. This work presents a
simple but robust model for ETA estimation for a bus route that only relies on
the historical data of the particular route. We propose a system that generates
ETA information for a trip and updates it as the trip progresses based on the
real-time information. We train a deep learning based generative model that
learns the probability distribution of ETA data across trips and conditional on
the current trip information updates the ETA information on the go. Our plug
and play model not only captures the non-linearity of the task well but that
any transit agency can use without needing any other external data source. The
experiments run over three routes, data collected in the city of Delhi
illustrates the promise of our approach.","[' Charul', 'Pravesh Biyani']"
"Human-level performance in first-person multiplayer games with
  population-based deep reinforcement learning",Machine Learning,"Recent progress in artificial intelligence through reinforcement learning
(RL) has shown great success on increasingly complex single-agent environments
and two-player turn-based games. However, the real-world contains multiple
agents, each learning and acting independently to cooperate and compete with
other agents, and environments reflecting this degree of complexity remain an
open challenge. In this work, we demonstrate for the first time that an agent
can achieve human-level in a popular 3D multiplayer first-person video game,
Quake III Arena Capture the Flag, using only pixels and game points as input.
These results were achieved by a novel two-tier optimisation process in which a
population of independent RL agents are trained concurrently from thousands of
parallel matches with agents playing in teams together and against each other
on randomly generated environments. Each agent in the population learns its own
internal reward signal to complement the sparse delayed reward from winning,
and selects actions using a novel temporally hierarchical representation that
enables the agent to reason at multiple timescales. During game-play, these
agents display human-like behaviours such as navigating, following, and
defending based on a rich learned representation that is shown to encode
high-level game knowledge. In an extensive tournament-style evaluation the
trained agents exceeded the win-rate of strong human players both as teammates
and opponents, and proved far stronger than existing state-of-the-art agents.
These results demonstrate a significant jump in the capabilities of artificial
agents, bringing us closer to the goal of human-level intelligence.","['Max Jaderberg', 'Wojciech M. Czarnecki', 'Iain Dunning', 'Luke Marris', 'Guy Lever', 'Antonio Garcia Castaneda', 'Charles Beattie', 'Neil C. Rabinowitz', 'Ari S. Morcos', 'Avraham Ruderman', 'Nicolas Sonnerat', 'Tim Green', 'Louise Deason', 'Joel Z. Leibo', 'David Silver', 'Demis Hassabis', 'Koray Kavukcuoglu', 'Thore Graepel']"
Dual Representation Learning for Out-of-Distribution Detection,Machine Learning,"To classify in-distribution samples, deep neural networks explore strongly
label-related information and discard weakly label-related information
according to the information bottleneck. Out-of-distribution samples drawn from
distributions differing from that of in-distribution samples could be assigned
with unexpected high-confidence predictions because they could obtain minimum
strongly label-related information. To distinguish in- and out-of-distribution
samples, Dual Representation Learning (DRL) makes out-of-distribution samples
harder to have high-confidence predictions by exploring both strongly and
weakly label-related information from in-distribution samples. For a pretrained
network exploring strongly label-related information to learn
label-discriminative representations, DRL trains its auxiliary network
exploring the remaining weakly label-related information to learn
distribution-discriminative representations. Specifically, for a
label-discriminative representation, DRL constructs its complementary
distribution-discriminative representation by integrating diverse
representations less similar to the label-discriminative representation.
Accordingly, DRL combines label- and distribution-discriminative
representations to detect out-of-distribution samples. Experiments show that
DRL outperforms the state-of-the-art methods for out-of-distribution detection.","['Zhilin Zhao', 'Longbing Cao']"
Density Uncertainty Layers for Reliable Uncertainty Estimation,Machine Learning,"Assessing the predictive uncertainty of deep neural networks is crucial for
safety-related applications of deep learning. Although Bayesian deep learning
offers a principled framework for estimating model uncertainty, the common
approaches that approximate the parameter posterior often fail to deliver
reliable estimates of predictive uncertainty. In this paper, we propose a novel
criterion for reliable predictive uncertainty: a model's predictive variance
should be grounded in the empirical density of the input. That is, the model
should produce higher uncertainty for inputs that are improbable in the
training data and lower uncertainty for inputs that are more probable. To
operationalize this criterion, we develop the density uncertainty layer, a
stochastic neural network architecture that satisfies the density uncertain
criterion by design. We study density uncertainty layers on the UCI and
CIFAR-10/100 uncertainty benchmarks. Compared to existing approaches, density
uncertainty layers provide more reliable uncertainty estimates and robust
out-of-distribution detection performance.","['Yookoon Park', 'David M. Blei']"
"Online learnability of Statistical Relational Learning in anomaly
  detection",Machine Learning,"Statistical Relational Learning (SRL) methods for anomaly detection are
introduced via a security-related application. Operational requirements for
online learning stability are outlined and compared to mathematical definitions
as applied to the learning process of a representative SRL method - Bayesian
Logic Programs (BLP). Since a formal proof of online stability appears to be
impossible, tentative common sense requirements are formulated and tested by
theoretical and experimental analysis of a simple and analytically tractable
BLP model. It is found that learning algorithms in initial stages of online
learning can lock on unstable false predictors that nevertheless comply with
our tentative stability requirements and thus masquerade as bona fide
solutions. The very expressiveness of SRL seems to cause significant stability
issues in settings with many variables and scarce data. We conclude that
reliable anomaly detection with SRL-methods requires monitoring by an
overarching framework that may involve a comprehensive context knowledge base
or human supervision.","['Magnus Jändel', 'Pontus Svenson', 'Niclas Wadströmer']"
"Surrogate Assisted Strategies (The Parameterisation of an Infectious
  Disease Agent-Based Model)",Machine Learning,"Parameter calibration is a significant challenge in agent-based modelling and
simulation (ABMS). An agent-based model's (ABM) complexity grows as the number
of parameters required to be calibrated increases. This parameter expansion
leads to the ABMS equivalent of the \say{curse of dimensionality}. In
particular, infeasible computational requirements searching an infinite
parameter space. We propose a more comprehensive and adaptive ABMS Framework
that can effectively swap out parameterisation strategies and surrogate models
to parameterise an infectious disease ABM. This framework allows us to evaluate
different strategy-surrogate combinations' performance in accuracy and
efficiency (speedup). We show that we achieve better than parity in accuracy
across the surrogate assisted sampling strategies and the baselines. Also, we
identify that the Metric Stochastic Response Surface strategy combined with the
Support Vector Machine surrogate is the best overall in getting closest to the
true synthetic parameters. Also, we show that DYnamic COOrdindate Search Using
Response Surface Models with XGBoost as a surrogate attains in combination the
highest probability of approximating a cumulative synthetic daily infection
data distribution and achieves the most significant speedup with regards to our
analysis. Lastly, we show in a real-world setting that DYCORS XGBoost and MSRS
SVM can approximate the real world cumulative daily infection distribution with
$97.12$\% and $96.75$\% similarity respectively.","['Rylan Perumal', 'Terence L van Zyl']"
Feasibility-based Fixed Point Networks,Machine Learning,"Inverse problems consist of recovering a signal from a collection of noisy
measurements. These problems can often be cast as feasibility problems;
however, additional regularization is typically necessary to ensure accurate
and stable recovery with respect to data perturbations. Hand-chosen analytic
regularization can yield desirable theoretical guarantees, but such approaches
have limited effectiveness recovering signals due to their inability to
leverage large amounts of available data. To this end, this work fuses
data-driven regularization and convex feasibility in a theoretically sound
manner. This is accomplished using feasibility-based fixed point networks
(F-FPNs). Each F-FPN defines a collection of nonexpansive operators, each of
which is the composition of a projection-based operator and a data-driven
regularization operator. Fixed point iteration is used to compute fixed points
of these operators, and weights of the operators are tuned so that the fixed
points closely represent available data. Numerical examples demonstrate
performance increases by F-FPNs when compared to standard TV-based recovery
methods for CT reconstruction and a comparable neural network based on
algorithm unrolling.","['Howard Heaton', 'Samy Wu Fung', 'Aviv Gibali', 'Wotao Yin']"
Image Set Querying Based Localization,Computer Vision and Pattern Recognition,"Conventional single image based localization methods usually fail to localize
a querying image when there exist large variations between the querying image
and the pre-built scene. To address this, we propose an image-set querying
based localization approach. When the localization by a single image fails to
work, the system will ask the user to capture more auxiliary images. First, a
local 3D model is established for the querying image set. Then, the pose of the
querying image set is estimated by solving a nonlinear optimization problem,
which aims to match the local 3D model against the pre-built scene. Experiments
have shown the effectiveness and feasibility of the proposed approach.","['Lei Deng', 'Siyuan Huang', 'Yueqi Duan', 'Baohua Chen', 'Jie Zhou']"
On Mixup Regularization,Machine Learning,"Mixup is a data augmentation technique that creates new examples as convex
combinations of training points and labels. This simple technique has
empirically shown to improve the accuracy of many state-of-the-art models in
different settings and applications, but the reasons behind this empirical
success remain poorly understood. In this paper we take a substantial step in
explaining the theoretical foundations of Mixup, by clarifying its
regularization effects. We show that Mixup can be interpreted as standard
empirical risk minimization estimator subject to a combination of data
transformation and random perturbation of the transformed data. We gain two
core insights from this new interpretation. First, the data transformation
suggests that, at test time, a model trained with Mixup should also be applied
to transformed data, a one-line change in code that we show empirically to
improve both accuracy and calibration of the prediction. Second, we show how
the random perturbation of the new interpretation of Mixup induces multiple
known regularization schemes, including label smoothing and reduction of the
Lipschitz constant of the estimator. These schemes interact synergistically
with each other, resulting in a self calibrated and effective regularization
effect that prevents overfitting and overconfident predictions. We corroborate
our theoretical analysis with experiments that support our conclusions.","['Luigi Carratino', 'Moustapha Cissé', 'Rodolphe Jenatton', 'Jean-Philippe Vert']"
Residual Overfit Method of Exploration,Machine Learning,"Exploration is a crucial aspect of bandit and reinforcement learning
algorithms. The uncertainty quantification necessary for exploration often
comes from either closed-form expressions based on simple models or resampling
and posterior approximations that are computationally intensive. We propose
instead an approximate exploration methodology based on fitting only two point
estimates, one tuned and one overfit. The approach, which we term the residual
overfit method of exploration (ROME), drives exploration towards actions where
the overfit model exhibits the most overfitting compared to the tuned model.
The intuition is that overfitting occurs the most at actions and contexts with
insufficient data to form accurate predictions of the reward. We justify this
intuition formally from both a frequentist and a Bayesian information theoretic
perspective. The result is a method that generalizes to a wide variety of
models and avoids the computational overhead of resampling or posterior
approximations. We compare ROME against a set of established contextual bandit
methods on three datasets and find it to be one of the best performing.","['James McInerney', 'Nathan Kallus']"
"Diver: Large Language Model Decoding with Span-Level Mutual Information
  Verification",Computation and Language (Natural Language Processing),"Large language models (LLMs) have shown impressive capabilities in adapting
to various tasks when provided with task-specific instructions. However, LLMs
using standard decoding strategies often struggle with deviations from the
inputs. Intuitively, compliant LLM outputs should reflect the information
present in the input, which can be measured by point-wise mutual information
(PMI) scores. Therefore, we propose Diver, a novel approach that enhances LLM
Decoding through span-level PMI verification. During inference, Diver first
identifies divergence steps that may lead to multiple candidate spans.
Subsequently, it calculates the PMI scores by assessing the log-likelihood
gains of the input if the candidate spans are generated. Finally, the optimal
span is selected based on the PMI re-ranked output distributions. We evaluate
our method across various downstream tasks, and empirical results demonstrate
that Diver significantly outperforms existing decoding methods in both
performance and versatility.","['Jinliang Lu', 'Chen Wang', 'Jiajun Zhang']"
Offline Reinforcement Learning With Combinatorial Action Spaces,Machine Learning,"Reinforcement learning problems often involve large action spaces arising
from the simultaneous execution of multiple sub-actions, resulting in
combinatorial action spaces. Learning in combinatorial action spaces is
difficult due to the exponential growth in action space size with the number of
sub-actions and the dependencies among these sub-actions. In offline settings,
this challenge is compounded by limited and suboptimal data. Current methods
for offline learning in combinatorial spaces simplify the problem by assuming
sub-action independence. We propose Branch Value Estimation (BVE), which
effectively captures sub-action dependencies and scales to large combinatorial
spaces by learning to evaluate only a small subset of actions at each timestep.
Our experiments show that BVE outperforms state-of-the-art methods across a
range of action space sizes.","['Matthew Landers', 'Taylor W. Killian', 'Hugo Barnes', 'Thomas Hartvigsen', 'Afsaneh Doryab']"
Deep Deformation Network for Object Landmark Localization,Computer Vision and Pattern Recognition,"We propose a novel cascaded framework, namely deep deformation network (DDN),
for localizing landmarks in non-rigid objects. The hallmarks of DDN are its
incorporation of geometric constraints within a convolutional neural network
(CNN) framework, ease and efficiency of training, as well as generality of
application. A novel shape basis network (SBN) forms the first stage of the
cascade, whereby landmarks are initialized by combining the benefits of CNN
features and a learned shape basis to reduce the complexity of the highly
nonlinear pose manifold. In the second stage, a point transformer network (PTN)
estimates local deformation parameterized as thin-plate spline transformation
for a finer refinement. Our framework does not incorporate either handcrafted
features or part connectivity, which enables an end-to-end shape prediction
pipeline during both training and testing. In contrast to prior cascaded
networks for landmark localization that learn a mapping from feature space to
landmark locations, we demonstrate that the regularization induced through
geometric priors in the DDN makes it easier to train, yet produces superior
results. The efficacy and generality of the architecture is demonstrated
through state-of-the-art performances on several benchmarks for multiple tasks
such as facial landmark localization, human body pose estimation and bird part
localization.","['Xiang Yu', 'Feng Zhou', 'Manmohan Chandraker']"
On Robustness of Neural Semantic Parsers,Computation and Language (Natural Language Processing),"Semantic parsing maps natural language (NL) utterances into logical forms
(LFs), which underpins many advanced NLP problems. Semantic parsers gain
performance boosts with deep neural networks, but inherit vulnerabilities
against adversarial examples. In this paper, we provide the empirical study on
the robustness of semantic parsers in the presence of adversarial attacks.
Formally, adversaries of semantic parsing are considered to be the perturbed
utterance-LF pairs, whose utterances have exactly the same meanings as the
original ones. A scalable methodology is proposed to construct robustness test
sets based on existing benchmark corpora. Our results answered five research
questions in measuring the sate-of-the-art parsers' performance on robustness
test sets, and evaluating the effect of data augmentation.","['Shuo Huang', 'Zhuang Li', 'Lizhen Qu', 'Lei Pan']"
"AXOLOTL'24 Shared Task on Multilingual Explainable Semantic Change
  Modeling",Computation and Language (Natural Language Processing),"This paper describes the organization and findings of AXOLOTL'24, the first
multilingual explainable semantic change modeling shared task. We present new
sense-annotated diachronic semantic change datasets for Finnish and Russian
which were employed in the shared task, along with a surprise test-only German
dataset borrowed from an existing source. The setup of AXOLOTL'24 is new to the
semantic change modeling field, and involves subtasks of identifying unknown
(novel) senses and providing dictionary-like definitions to these senses. The
methods of the winning teams are described and compared, thus paving a path
towards explainability in computational approaches to historical change of
meaning.","['Mariia Fedorova', 'Timothee Mickus', 'Niko Partanen', 'Janine Siewert', 'Elena Spaziani', 'Andrey Kutuzov']"
Fast Adaptation in Generative Models with Generative Matching Networks,Machine Learning (Statistics),"Despite recent advances, the remaining bottlenecks in deep generative models
are necessity of extensive training and difficulties with generalization from
small number of training examples. We develop a new generative model called
Generative Matching Network which is inspired by the recently proposed matching
networks for one-shot learning in discriminative tasks. By conditioning on the
additional input dataset, our model can instantly learn new concepts that were
not available in the training data but conform to a similar generative process.
The proposed framework does not explicitly restrict diversity of the
conditioning data and also does not require an extensive inference procedure
for training or adaptation. Our experiments on the Omniglot dataset demonstrate
that Generative Matching Networks significantly improve predictive performance
on the fly as more additional data is available and outperform existing state
of the art conditional generative models.","['Sergey Bartunov', 'Dmitry P. Vetrov']"
POLE: Polarized Embedding for Signed Networks,Social and Information Networks,"From the 2016 U.S. presidential election to the 2021 Capitol riots to the
spread of misinformation related to COVID-19, many have blamed social media for
today's deeply divided society. Recent advances in machine learning for signed
networks hold the promise to guide small interventions with the goal of
reducing polarization in social media. However, existing models are especially
ineffective in predicting conflicts (or negative links) among users. This is
due to a strong correlation between link signs and the network structure, where
negative links between polarized communities are too sparse to be predicted
even by state-of-the-art approaches. To address this problem, we first design a
partition-agnostic polarization measure for signed graphs based on the signed
random-walk and show that many real-world graphs are highly polarized. Then, we
propose POLE (POLarized Embedding for signed networks), a signed embedding
method for polarized graphs that captures both topological and signed
similarities jointly via signed autocovariance. Through extensive experiments,
we show that POLE significantly outperforms state-of-the-art methods in signed
link prediction, particularly for negative links with gains of up to one order
of magnitude.","['Zexi Huang', 'Arlei Silva', 'Ambuj Singh']"
FlowX: Towards Explainable Graph Neural Networks via Message Flows,Machine Learning,"We investigate the explainability of graph neural networks (GNNs) as a step
toward elucidating their working mechanisms. While most current methods focus
on explaining graph nodes, edges, or features, we argue that, as the inherent
functional mechanism of GNNs, message flows are more natural for performing
explainability. To this end, we propose a novel method here, known as FlowX, to
explain GNNs by identifying important message flows. To quantify the importance
of flows, we propose to follow the philosophy of Shapley values from
cooperative game theory. To tackle the complexity of computing all coalitions'
marginal contributions, we propose a flow sampling scheme to compute Shapley
value approximations as initial assessments of further training. We then
propose an information-controlled learning algorithm to train flow scores
toward diverse explanation targets: necessary or sufficient explanations.
Experimental studies on both synthetic and real-world datasets demonstrate that
our proposed FlowX and its variants lead to improved explainability of GNNs.
The code is available at https://github.com/divelab/DIG.","['Shurui Gui', 'Hao Yuan', 'Jie Wang', 'Qicheng Lao', 'Kang Li', 'Shuiwang Ji']"
Class Teaching for Inverse Reinforcement Learners,Machine Learning,"In this paper we propose the first machine teaching algorithm for multiple
inverse reinforcement learners. Specifically, our contributions are: (i) we
formally introduce the problem of teaching a sequential task to a heterogeneous
group of learners; (ii) we identify conditions under which it is possible to
conduct such teaching using the same demonstration for all learners; and (iii)
we propose and evaluate a simple algorithm that computes a demonstration(s)
ensuring that all agents in a heterogeneous class learn a task description that
is compatible with the target task. Our analysis shows that, contrary to other
teaching problems, teaching a heterogeneous class with a single demonstration
may not be possible as the differences between agents increase. We also
showcase the advantages of our proposed machine teaching approach against
several possible alternatives.","['Manuel Lopes', 'Francisco Melo']"
"On Choosing Training and Testing Data for Supervised Algorithms in
  Ground Penetrating Radar Data for Buried Threat Detection",Computer Vision and Pattern Recognition,"Ground penetrating radar (GPR) is one of the most popular and successful
sensing modalities that has been investigated for landmine and subsurface
threat detection. Many of the detection algorithms applied to this task are
supervised and therefore require labeled examples of target and non-target data
for training. Training data most often consists of 2-dimensional images (or
patches) of GPR data, from which features are extracted, and provided to the
classifier during training and testing. Identifying desirable training and
testing locations to extract patches, which we term ""keypoints"", is well
established in the literature. In contrast however, a large variety of
strategies have been proposed regarding keypoint utilization (e.g., how many of
the identified keypoints should be used at targets, or non-target, locations).
Given the variety keypoint utilization strategies that are available, it is
very unclear (i) which strategies are best, or (ii) whether the choice of
strategy has a large impact on classifier performance. We address these
questions by presenting a taxonomy of existing utilization strategies, and then
evaluating their effectiveness on a large dataset using many different
classifiers and features. We analyze the results and propose a new strategy,
called PatchSelect, which outperforms other strategies across all experiments.","['Daniël Reichman', 'Leslie M. Collins', 'Jordan M. Malof']"
"Anytime Behavior of Inexact TSP Solvers and Perspectives for Automated
  Algorithm Selection",Artificial Intelligence,"The Traveling-Salesperson-Problem (TSP) is arguably one of the best-known
NP-hard combinatorial optimization problems. The two sophisticated heuristic
solvers LKH and EAX and respective (restart) variants manage to calculate
close-to optimal or even optimal solutions, also for large instances with
several thousand nodes in reasonable time. In this work we extend existing
benchmarking studies by addressing anytime behaviour of inexact TSP solvers
based on empirical runtime distributions leading to an increased understanding
of solver behaviour and the respective relation to problem hardness. It turns
out that performance ranking of solvers is highly dependent on the focused
approximation quality. Insights on intersection points of performances offer
huge potential for the construction of hybridized solvers depending on instance
features. Moreover, instance features tailored to anytime performance and
corresponding performance indicators will highly improve automated algorithm
selection models by including comprehensive information on solver quality.","['Jakob Bossek', 'Pascal Kerschke', 'Heike Trautmann']"
Irreflexive and Hierarchical Relations as Translations,Machine Learning,"We consider the problem of embedding entities and relations of knowledge
bases in low-dimensional vector spaces. Unlike most existing approaches, which
are primarily efficient for modeling equivalence relations, our approach is
designed to explicitly model irreflexive relations, such as hierarchies, by
interpreting them as translations operating on the low-dimensional embeddings
of the entities. Preliminary experiments show that, despite its simplicity and
a smaller number of parameters than previous approaches, our approach achieves
state-of-the-art performance according to standard evaluation protocols on data
from WordNet and Freebase.","['Antoine Bordes', 'Nicolas Usunier', 'Alberto Garcia-Duran', 'Jason Weston', 'Oksana Yakhnenko']"
Coresets for Relational Data and The Applications,Machine Learning,"A coreset is a small set that can approximately preserve the structure of the
original input data set. Therefore we can run our algorithm on a coreset so as
to reduce the total computational complexity. Conventional coreset techniques
assume that the input data set is available to process explicitly. However,
this assumption may not hold in real-world scenarios. In this paper, we
consider the problem of coresets construction over relational data. Namely, the
data is decoupled into several relational tables, and it could be very
expensive to directly materialize the data matrix by joining the tables. We
propose a novel approach called ``aggregation tree with pseudo-cube'' that can
build a coreset from bottom to up. Moreover, our approach can neatly circumvent
several troublesome issues of relational learning problems [Khamis et al., PODS
2019]. Under some mild assumptions, we show that our coreset approach can be
applied for the machine learning tasks, such as clustering, logistic regression
and SVM.","['Jiaxiang Chen', 'Qingyuan Yang', 'Ruomin Huang', 'Hu Ding']"
Learning Sparse Dynamical Systems from a Single Sample Trajectory,Systems and Control,"This paper addresses the problem of identifying sparse linear time-invariant
(LTI) systems from a single sample trajectory generated by the system dynamics.
We introduce a Lasso-like estimator for the parameters of the system, taking
into account their sparse nature. Assuming that the system is stable, or that
it is equipped with an initial stabilizing controller, we provide sharp
finite-time guarantees on the accurate recovery of both the sparsity structure
and the parameter values of the system. In particular, we show that the
proposed estimator can correctly identify the sparsity pattern of the system
matrices with high probability, provided that the length of the sample
trajectory exceeds a threshold. Furthermore, we show that this threshold scales
polynomially in the number of nonzero elements in the system matrices, but
logarithmically in the system dimensions --- this improves on existing sample
complexity bounds for the sparse system identification problem. We further
extend these results to obtain sharp bounds on the $\ell_{\infty}$-norm of the
estimation error and show how different properties of the system---such as its
stability level and \textit{mutual incoherency}---affect this bound. Finally,
an extensive case study on power systems is presented to illustrate the
performance of the proposed estimation method.","['Salar Fattahi', 'Nikolai Matni', 'Somayeh Sojoudi']"
"Pre-training Co-evolutionary Protein Representation via A Pairwise
  Masked Language Model",Computation and Language (Natural Language Processing),"Understanding protein sequences is vital and urgent for biology, healthcare,
and medicine. Labeling approaches are expensive yet time-consuming, while the
amount of unlabeled data is increasing quite faster than that of the labeled
data due to low-cost, high-throughput sequencing methods. In order to extract
knowledge from these unlabeled data, representation learning is of significant
value for protein-related tasks and has great potential for helping us learn
more about protein functions and structures. The key problem in the protein
sequence representation learning is to capture the co-evolutionary information
reflected by the inter-residue co-variation in the sequences. Instead of
leveraging multiple sequence alignment as is usually done, we propose a novel
method to capture this information directly by pre-training via a dedicated
language model, i.e., Pairwise Masked Language Model (PMLM). In a conventional
masked language model, the masked tokens are modeled by conditioning on the
unmasked tokens only, but processed independently to each other. However, our
proposed PMLM takes the dependency among masked tokens into consideration,
i.e., the probability of a token pair is not equal to the product of the
probability of the two tokens. By applying this model, the pre-trained encoder
is able to generate a better representation for protein sequences. Our result
shows that the proposed method can effectively capture the inter-residue
correlations and improves the performance of contact prediction by up to 9%
compared to the MLM baseline under the same setting. The proposed model also
significantly outperforms the MSA baseline by more than 7% on the TAPE contact
prediction benchmark when pre-trained on a subset of the sequence database
which the MSA is generated from, revealing the potential of the sequence
pre-training method to surpass MSA based methods in general.","['Liang He', 'Shizhuo Zhang', 'Lijun Wu', 'Huanhuan Xia', 'Fusong Ju', 'He Zhang', 'Siyuan Liu', 'Yingce Xia', 'Jianwei Zhu', 'Pan Deng', 'Bin Shao', 'Tao Qin', 'Tie-Yan Liu']"
Fast sampling and model selection for Bayesian mixture models,Computation (Statistics),"We describe two Monte Carlo algorithms for sampling from the integrated
posterior distributions of a range of Bayesian mixture models. Both algorithms
allow us to directly sample not only the assignment of observations to
components but also the number of components, thereby fitting the model and
performing model selection over the number of components in a single
computation. The first algorithm is a traditional collapsed Gibbs sampler,
albeit with an unusual move-set; the second builds on the first, adding
rejection-free sampling from the prior over component assignments, to create an
algorithm that has excellent mixing time in typical applications and
outperforms current state-of-the-art methods, in some cases by a wide margin.
We demonstrate our methods with a selection of applications to latent class
analysis.",['M. E. J. Newman']
"A Conjugate Property between Loss Functions and Uncertainty Sets in
  Classification Problems",Machine Learning (Statistics),"In binary classification problems, mainly two approaches have been proposed;
one is loss function approach and the other is uncertainty set approach. The
loss function approach is applied to major learning algorithms such as support
vector machine (SVM) and boosting methods. The loss function represents the
penalty of the decision function on the training samples. In the learning
algorithm, the empirical mean of the loss function is minimized to obtain the
classifier. Against a backdrop of the development of mathematical programming,
nowadays learning algorithms based on loss functions are widely applied to
real-world data analysis. In addition, statistical properties of such learning
algorithms are well-understood based on a lots of theoretical works. On the
other hand, the learning method using the so-called uncertainty set is used in
hard-margin SVM, mini-max probability machine (MPM) and maximum margin MPM. In
the learning algorithm, firstly, the uncertainty set is defined for each binary
label based on the training samples. Then, the best separating hyperplane
between the two uncertainty sets is employed as the decision function. This is
regarded as an extension of the maximum-margin approach. The uncertainty set
approach has been studied as an application of robust optimization in the field
of mathematical programming. The statistical properties of learning algorithms
with uncertainty sets have not been intensively studied. In this paper, we
consider the relation between the above two approaches. We point out that the
uncertainty set is described by using the level set of the conjugate of the
loss function. Based on such relation, we study statistical properties of
learning algorithms using uncertainty sets.","['Takafumi Kanamori', 'Akiko Takeda', 'Taiji Suzuki']"
Optimal To-Do List Gamification for Long Term Planning,Artificial Intelligence,"Most people struggle with prioritizing work. While inexact heuristics have
been developed over time, there is still no tractable principled algorithm for
deciding which of the many possible tasks one should tackle in any given day,
month, week, or year. Additionally, some people suffer from cognitive biases
such as the present bias, leading to prioritization of their immediate
experience over long-term consequences which manifests itself as
procrastination and inefficient task prioritization. Our method utilizes
optimal gamification to help people overcome these problems by incentivizing
each task by a number of points that convey how valuable it is in the long-run.
We extend the previous version of our optimal gamification method with added
services for helping people decide which tasks should and should not be done
when there is not enough time to do everything. To improve the efficiency and
scalability of the to-do list solver, we designed a hierarchical procedure that
tackles the problem from the top-level goals to fine-grained tasks. We test the
accuracy of the incentivised to-do list by comparing the performance of the
strategy with the points computed exactly using Value Iteration for a variety
of case studies. These case studies were specifically designed to cover the
corner cases to get an accurate judge of performance. Our method yielded the
same performance as the exact method for all case studies. To demonstrate its
functionality, we released an API that makes it easy to deploy our method in
Web and app services. We assessed the scalability of our method by applying it
to to-do lists with increasingly larger numbers of goals, sub-goals per goal,
hierarchically nested levels of subgoals. We found that the method provided
through our API is able to tackle fairly large to-do lists having a 576 tasks.
This indicates that our method is suitable for real-world applications.","['Saksham Consul', 'Jugoslav Stojcheski', 'Valkyrie Felso', 'Falk Lieder']"
Thompson Sampling for Contextual Bandits with Linear Payoffs,Machine Learning,"Thompson Sampling is one of the oldest heuristics for multi-armed bandit
problems. It is a randomized algorithm based on Bayesian ideas, and has
recently generated significant interest after several studies demonstrated it
to have better empirical performance compared to the state-of-the-art methods.
However, many questions regarding its theoretical performance remained open. In
this paper, we design and analyze a generalization of Thompson Sampling
algorithm for the stochastic contextual multi-armed bandit problem with linear
payoff functions, when the contexts are provided by an adaptive adversary. This
is among the most important and widely studied versions of the contextual
bandits problem. We provide the first theoretical guarantees for the contextual
version of Thompson Sampling. We prove a high probability regret bound of
$\tilde{O}(d^{3/2}\sqrt{T})$ (or $\tilde{O}(d\sqrt{T \log(N)})$), which is the
best regret bound achieved by any computationally efficient algorithm available
for this problem in the current literature, and is within a factor of
$\sqrt{d}$ (or $\sqrt{\log(N)}$) of the information-theoretic lower bound for
this problem.","['Shipra Agrawal', 'Navin Goyal']"
"Challenging Neural Dialogue Models with Natural Data: Memory Networks
  Fail on Incremental Phenomena",Computation and Language (Natural Language Processing),"Natural, spontaneous dialogue proceeds incrementally on a word-by-word basis;
and it contains many sorts of disfluency such as mid-utterance/sentence
hesitations, interruptions, and self-corrections. But training data for machine
learning approaches to dialogue processing is often either cleaned-up or wholly
synthetic in order to avoid such phenomena. The question then arises of how
well systems trained on such clean data generalise to real spontaneous
dialogue, or indeed whether they are trainable at all on naturally occurring
dialogue data. To answer this question, we created a new corpus called bAbI+ by
systematically adding natural spontaneous incremental dialogue phenomena such
as restarts and self-corrections to the Facebook AI Research's bAbI dialogues
dataset. We then explore the performance of a state-of-the-art retrieval model,
MemN2N, on this more natural dataset. Results show that the semantic accuracy
of the MemN2N model drops drastically; and that although it is in principle
able to learn to process the constructions in bAbI+, it needs an impractical
amount of training data to do so. Finally, we go on to show that an
incremental, semantic parser -- DyLan -- shows 100% semantic accuracy on both
bAbI and bAbI+, highlighting the generalisation properties of linguistically
informed dialogue models.","['Igor Shalyminov', 'Arash Eshghi', 'Oliver Lemon']"
"zGAN: An Outlier-focused Generative Adversarial Network For Realistic
  Synthetic Data Generation",Machine Learning,"The phenomenon of ""black swans"" has posed a fundamental challenge to
performance of classical machine learning models. The perceived rise in
frequency of outlier conditions, especially in post-pandemic environment, has
necessitated exploration of synthetic data as a complement to real data in
model training. This article provides a general overview and experimental
investigation of the zGAN model architecture developed for the purpose of
generating synthetic tabular data with outlier characteristics. The model is
put to test in binary classification environments and shows promising results
on realistic synthetic data generation, as well as uplift capabilities
vis-\`a-vis model performance. A distinctive feature of zGAN is its enhanced
correlation capability between features in the generated data, replicating
correlations of features in real training data. Furthermore, crucial is the
ability of zGAN to generate outliers based on covariance of real data or
synthetically generated covariances. This approach to outlier generation
enables modeling of complex economic events and augmentation of outliers for
tasks such as training predictive models and detecting, processing or removing
outliers. Experiments and comparative analyses as part of this study were
conducted on both private (credit risk in financial services) and public
datasets.","['Azizjon Azimi', 'Bonu Boboeva', 'Ilyas Varshavskiy', 'Shuhrat Khalilbekov', 'Akhlitdin Nizamitdinov', 'Najima Noyoftova', 'Sergey Shulgin']"
"Scalable and Certifiable Graph Unlearning: Overcoming the Approximation
  Error Barrier",Machine Learning,"Graph unlearning has emerged as a pivotal research area for ensuring privacy
protection, given the widespread adoption of Graph Neural Networks (GNNs) in
applications involving sensitive user data. Among existing studies, certified
graph unlearning is distinguished by providing robust privacy guarantees.
However, current certified graph unlearning methods are impractical for
large-scale graphs because they necessitate the costly re-computation of graph
propagation for each unlearning request. Although numerous scalable techniques
have been developed to accelerate graph propagation for GNNs, their integration
into certified graph unlearning remains uncertain as these scalable approaches
introduce approximation errors into node embeddings. In contrast, certified
graph unlearning demands bounded model error on exact node embeddings to
maintain its certified guarantee.
  To address this challenge, we present ScaleGUN, the first approach to scale
certified graph unlearning to billion-edge graphs. ScaleGUN integrates the
approximate graph propagation technique into certified graph unlearning,
offering certified guarantees for three unlearning scenarios: node feature,
edge, and node unlearning. Extensive experiments on real-world datasets
demonstrate the efficiency and unlearning efficacy of ScaleGUN. Remarkably,
ScaleGUN accomplishes $(\epsilon,\delta)=(1,10^{-4})$ certified unlearning on
the billion-edge graph ogbn-papers100M in 20 seconds for a 5,000 random edge
removal request -- of which only 5 seconds are required for updating the node
embeddings -- compared to 1.91 hours for retraining and 1.89 hours for
re-propagation. Our code is available at https://github.com/luyi256/ScaleGUN.","['Lu Yi', 'Zhewei Wei']"
"Aya Dataset: An Open-Access Collection for Multilingual Instruction
  Tuning",Computation and Language (Natural Language Processing),"Datasets are foundational to many breakthroughs in modern artificial
intelligence. Many recent achievements in the space of natural language
processing (NLP) can be attributed to the finetuning of pre-trained models on a
diverse set of tasks that enables a large language model (LLM) to respond to
instructions. Instruction fine-tuning (IFT) requires specifically constructed
and annotated datasets. However, existing datasets are almost all in the
English language. In this work, our primary goal is to bridge the language gap
by building a human-curated instruction-following dataset spanning 65
languages. We worked with fluent speakers of languages from around the world to
collect natural instances of instructions and completions. Furthermore, we
create the most extensive multilingual collection to date, comprising 513
million instances through templating and translating existing datasets across
114 languages. In total, we contribute four key resources: we develop and
open-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection,
and the Aya Evaluation Suite. The Aya initiative also serves as a valuable case
study in participatory research, involving collaborators from 119 countries. We
see this as a valuable framework for future research collaborations that aim to
bridge gaps in resources.","['Shivalika Singh', 'Freddie Vargus', 'Daniel Dsouza', 'Börje F. Karlsson', 'Abinaya Mahendiran', 'Wei-Yin Ko', 'Herumb Shandilya', 'Jay Patel', 'Deividas Mataciunas', 'Laura OMahony', 'Mike Zhang', 'Ramith Hettiarachchi', 'Joseph Wilson', 'Marina Machado', 'Luisa Souza Moura', 'Dominik Krzemiński', 'Hakimeh Fadaei', 'Irem Ergün', 'Ifeoma Okoh', 'Aisha Alaagib', 'Oshan Mudannayake', 'Zaid Alyafeai', 'Vu Minh Chien', 'Sebastian Ruder', 'Surya Guthikonda', 'Emad A. Alghamdi', 'Sebastian Gehrmann', 'Niklas Muennighoff', 'Max Bartolo', 'Julia Kreutzer', 'Ahmet Üstün', 'Marzieh Fadaee', 'Sara Hooker']"
SMMix: Self-Motivated Image Mixing for Vision Transformers,Computer Vision and Pattern Recognition,"CutMix is a vital augmentation strategy that determines the performance and
generalization ability of vision transformers (ViTs). However, the
inconsistency between the mixed images and the corresponding labels harms its
efficacy. Existing CutMix variants tackle this problem by generating more
consistent mixed images or more precise mixed labels, but inevitably introduce
heavy training overhead or require extra information, undermining ease of use.
To this end, we propose an novel and effective Self-Motivated image Mixing
method (SMMix), which motivates both image and label enhancement by the model
under training itself. Specifically, we propose a max-min attention region
mixing approach that enriches the attention-focused objects in the mixed
images. Then, we introduce a fine-grained label assignment technique that
co-trains the output tokens of mixed images with fine-grained supervision.
Moreover, we devise a novel feature consistency constraint to align features
from mixed and unmixed images. Due to the subtle designs of the self-motivated
paradigm, our SMMix is significant in its smaller training overhead and better
performance than other CutMix variants. In particular, SMMix improves the
accuracy of DeiT-T/S/B, CaiT-XXS-24/36, and PVT-T/S/M/L by more than +1% on
ImageNet-1k. The generalization capability of our method is also demonstrated
on downstream tasks and out-of-distribution datasets. Our project is
anonymously available at https://github.com/ChenMnZ/SMMix.","['Mengzhao Chen', 'Mingbao Lin', 'ZhiHang Lin', 'Yuxin Zhang', 'Fei Chao', 'Rongrong Ji']"
Knowledge-based Review Generation by Coherence Enhanced Text Planning,Computation and Language (Natural Language Processing),"As a natural language generation task, it is challenging to generate
informative and coherent review text. In order to enhance the informativeness
of the generated text, existing solutions typically learn to copy entities or
triples from knowledge graphs (KGs). However, they lack overall consideration
to select and arrange the incorporated knowledge, which tends to cause text
incoherence.
  To address the above issue, we focus on improving entity-centric coherence of
the generated reviews by leveraging the semantic structure of KGs. In this
paper, we propose a novel Coherence Enhanced Text Planning model (CETP) based
on knowledge graphs (KGs) to improve both global and local coherence for review
generation. The proposed model learns a two-level text plan for generating a
document: (1) the document plan is modeled as a sequence of sentence plans in
order, and (2) the sentence plan is modeled as an entity-based subgraph from
KG. Local coherence can be naturally enforced by KG subgraphs through
intra-sentence correlations between entities. For global coherence, we design a
hierarchical self-attentive architecture with both subgraph- and node-level
attention to enhance the correlations between subgraphs. To our knowledge, we
are the first to utilize a KG-based text planning model to enhance text
coherence for review generation. Extensive experiments on three datasets
confirm the effectiveness of our model on improving the content coherence of
generated texts.","['Junyi Li', 'Wayne Xin Zhao', 'Zhicheng Wei', 'Nicholas Jing Yuan', 'Ji-Rong Wen']"
"The State of SLIVAR: What's next for robots, human-robot interaction,
  and (spoken) dialogue systems?",Computation and Language (Natural Language Processing),"We synthesize the reported results and recommendations of recent workshops
and seminars that convened to discuss open questions within the important
intersection of robotics, human-robot interaction, and spoken dialogue systems
research. The goal of this growing area of research interest is to enable
people to more effectively and naturally communicate with robots. To carry
forward opportunities networking and discussion towards concrete, potentially
fundable projects, we encourage interested parties to consider participating in
future virtual and in-person discussions and workshops.",['Casey Kennington']
Impact Learning: A Learning Method from Features Impact and Competition,Machine Learning,"Machine learning is the study of computer algorithms that can automatically
improve based on data and experience. Machine learning algorithms build a model
from sample data, called training data, to make predictions or judgments
without being explicitly programmed to do so. A variety of wellknown machine
learning algorithms have been developed for use in the field of computer
science to analyze data. This paper introduced a new machine learning algorithm
called impact learning. Impact learning is a supervised learning algorithm that
can be consolidated in both classification and regression problems. It can
furthermore manifest its superiority in analyzing competitive data. This
algorithm is remarkable for learning from the competitive situation and the
competition comes from the effects of autonomous features. It is prepared by
the impacts of the highlights from the intrinsic rate of natural increase
(RNI). We, moreover, manifest the prevalence of the impact learning over the
conventional machine learning algorithm.","['Nusrat Jahan Prottasha', 'Saydul Akbar Murad', 'Abu Jafar Md Muzahid', 'Masud Rana', 'Md Kowsher', 'Apurba Adhikary', 'Sujit Biswas', 'Anupam Kumar Bairagi']"
"Aug-NeRF: Training Stronger Neural Radiance Fields with Triple-Level
  Physically-Grounded Augmentations",Computer Vision and Pattern Recognition,"Neural Radiance Field (NeRF) regresses a neural parameterized scene by
differentially rendering multi-view images with ground-truth supervision.
However, when interpolating novel views, NeRF often yields inconsistent and
visually non-smooth geometric results, which we consider as a generalization
gap between seen and unseen views. Recent advances in convolutional neural
networks have demonstrated the promise of advanced robust data augmentations,
either random or learned, in enhancing both in-distribution and
out-of-distribution generalization. Inspired by that, we propose Augmented NeRF
(Aug-NeRF), which for the first time brings the power of robust data
augmentations into regularizing the NeRF training. Particularly, our proposal
learns to seamlessly blend worst-case perturbations into three distinct levels
of the NeRF pipeline with physical grounds, including (1) the input
coordinates, to simulate imprecise camera parameters at image capture; (2)
intermediate features, to smoothen the intrinsic feature manifold; and (3)
pre-rendering output, to account for the potential degradation factors in the
multi-view image supervision. Extensive results demonstrate that Aug-NeRF
effectively boosts NeRF performance in both novel view synthesis (up to 1.5dB
PSNR gain) and underlying geometry reconstruction. Furthermore, thanks to the
implicit smooth prior injected by the triple-level augmentations, Aug-NeRF can
even recover scenes from heavily corrupted images, a highly challenging setting
untackled before. Our codes are available in
https://github.com/VITA-Group/Aug-NeRF.","['Tianlong Chen', 'Peihao Wang', 'Zhiwen Fan', 'Zhangyang Wang']"
"T-FFTRadNet: Object Detection with Swin Vision Transformers from Raw ADC
  Radar Signals",Computer Vision and Pattern Recognition,"Object detection utilizing Frequency Modulated Continous Wave radar is
becoming increasingly popular in the field of autonomous systems. Radar does
not possess the same drawbacks seen by other emission-based sensors such as
LiDAR, primarily the degradation or loss of return signals due to weather
conditions such as rain or snow. However, radar does possess traits that make
it unsuitable for standard emission-based deep learning representations such as
point clouds. Radar point clouds tend to be sparse and therefore information
extraction is not efficient. To overcome this, more traditional digital signal
processing pipelines were adapted to form inputs residing directly in the
frequency domain via Fast Fourier Transforms. Commonly, three transformations
were used to form Range-Azimuth-Doppler cubes in which deep learning algorithms
could perform object detection. This too has drawbacks, namely the
pre-processing costs associated with performing multiple Fourier Transforms and
normalization. We explore the possibility of operating on raw radar inputs from
analog to digital converters via the utilization of complex transformation
layers. Moreover, we introduce hierarchical Swin Vision transformers to the
field of radar object detection and show their capability to operate on inputs
varying in pre-processing, along with different radar configurations, i.e.
relatively low and high numbers of transmitters and receivers, while obtaining
on par or better results than the state-of-the-art.","['James Giroux', 'Martin Bouchard', 'Robert Laganiere']"
"Synthesizing time-series wound prognosis factors from electronic medical
  records using generative adversarial networks",Artificial Intelligence,"Wound prognostic models not only provide an estimate of wound healing time to
motivate patients to follow up their treatments but also can help clinicians to
decide whether to use a standard care or adjuvant therapies and to assist them
with designing clinical trials. However, collecting prognosis factors from
Electronic Medical Records (EMR) of patients is challenging due to privacy,
sensitivity, and confidentiality. In this study, we developed time series
medical generative adversarial networks (GANs) to generate synthetic wound
prognosis factors using very limited information collected during routine care
in a specialized wound care facility. The generated prognosis variables are
used in developing a predictive model for chronic wound healing trajectory. Our
novel medical GAN can produce both continuous and categorical features from
EMR. Moreover, we applied temporal information to our model by considering data
collected from the weekly follow-ups of patients. Conditional training
strategies were utilized to enhance training and generate classified data in
terms of healing or non-healing. The ability of the proposed model to generate
realistic EMR data was evaluated by TSTR (test on the synthetic, train on the
real), discriminative accuracy, and visualization. We utilized samples
generated by our proposed GAN in training a prognosis model to demonstrate its
real-life application. Using the generated samples in training predictive
models improved the classification accuracy by 6.66-10.01% compared to the
previous EMR-GAN. Additionally, the suggested prognosis classifier has achieved
the area under the curve (AUC) of 0.975, 0.968, and 0.849 when training the
network using data from the first three visits, first two visits, and first
visit, respectively. These results indicate a significant improvement in wound
healing prediction compared to the previous prognosis models.","['Farnaz H. Foomani', 'D. M. Anisuzzaman', 'Jeffrey Niezgoda', 'Jonathan Niezgoda', 'William Guns', 'Sandeep Gopalakrishnan', 'Zeyun Yu']"
"ANACONDA: An Improved Dynamic Regret Algorithm for Adaptive
  Non-Stationary Dueling Bandits",Machine Learning,"We study the problem of non-stationary dueling bandits and provide the first
adaptive dynamic regret algorithm for this problem. The only two existing
attempts in this line of work fall short across multiple dimensions, including
pessimistic measures of non-stationary complexity and non-adaptive parameter
tuning that requires knowledge of the number of preference changes. We develop
an elimination-based rescheduling algorithm to overcome these shortcomings and
show a near-optimal $\tilde{O}(\sqrt{S^{\texttt{CW}} T})$ dynamic regret bound,
where $S^{\texttt{CW}}$ is the number of times the Condorcet winner changes in
$T$ rounds. This yields the first near-optimal dynamic regret algorithm for
unknown $S^{\texttt{CW}}$. We further study other related notions of
non-stationarity for which we also prove near-optimal dynamic regret guarantees
under additional assumptions on the underlying preference model.","['Thomas Kleine Buening', 'Aadirupa Saha']"
Attention-Based LSTM Network for COVID-19 Clinical Trial Parsing,Computation and Language (Natural Language Processing),"COVID-19 clinical trial design is a critical task in developing therapeutics
for the prevention and treatment of COVID-19. In this study, we apply a deep
learning approach to extract eligibility criteria variables from COVID-19
trials to enable quantitative analysis of trial design and optimization.
Specifically, we train attention-based bidirectional Long Short-Term Memory
(Att-BiLSTM) models and use the optimal model to extract entities (i.e.,
variables) from the eligibility criteria of COVID-19 trials. We compare the
performance of Att-BiLSTM with traditional ontology-based method. The result on
a benchmark dataset shows that Att-BiLSTM outperforms the ontology model.
Att-BiLSTM achieves a precision of 0.942, recall of 0.810, and F1 of 0.871,
while the ontology model only achieves a precision of 0.715, recall of 0.659,
and F1 of 0.686. Our analyses demonstrate that Att-BiLSTM is an effective
approach for characterizing patient populations in COVID-19 clinical trials.","['Xiong Liu', 'Luca A. Finelli', 'Greg L. Hersch', 'Iya Khalil']"
Neural Network Approximation: Three Hidden Layers Are Enough,Machine Learning,"A three-hidden-layer neural network with super approximation power is
introduced. This network is built with the floor function ($\lfloor x\rfloor$),
the exponential function ($2^x$), the step function ($1_{x\geq 0}$), or their
compositions as the activation function in each neuron and hence we call such
networks as Floor-Exponential-Step (FLES) networks. For any width
hyper-parameter $N\in\mathbb{N}^+$, it is shown that FLES networks with width
$\max\{d,N\}$ and three hidden layers can uniformly approximate a H\""older
continuous function $f$ on $[0,1]^d$ with an exponential approximation rate
$3\lambda (2\sqrt{d})^{\alpha} 2^{-\alpha N}$, where $\alpha \in(0,1]$ and
$\lambda>0$ are the H\""older order and constant, respectively. More generally
for an arbitrary continuous function $f$ on $[0,1]^d$ with a modulus of
continuity $\omega_f(\cdot)$, the constructive approximation rate is
$2\omega_f(2\sqrt{d}){2^{-N}}+\omega_f(2\sqrt{d}\,2^{-N})$. Moreover, we extend
such a result to general bounded continuous functions on a bounded set
$E\subseteq\mathbb{R}^d$. As a consequence, this new class of networks
overcomes the curse of dimensionality in approximation power when the variation
of $\omega_f(r)$ as $r\rightarrow 0$ is moderate (e.g., $\omega_f(r)\lesssim
r^\alpha$ for H\""older continuous functions), since the major term to be
concerned in our approximation rate is essentially $\sqrt{d}$ times a function
of $N$ independent of $d$ within the modulus of continuity. Finally, we extend
our analysis to derive similar approximation results in the $L^p$-norm for
$p\in[1,\infty)$ via replacing Floor-Exponential-Step activation functions by
continuous activation functions.","['Zuowei Shen', 'Haizhao Yang', 'Shijun Zhang']"
Homogeneity of Cluster Ensembles,Machine Learning,"The expectation and the mean of partitions generated by a cluster ensemble
are not unique in general. This issue poses challenges in statistical inference
and cluster stability. In this contribution, we state sufficient conditions for
uniqueness of expectation and mean. The proposed conditions show that a unique
mean is neither exceptional nor generic. To cope with this issue, we introduce
homogeneity as a measure of how likely is a unique mean for a sample of
partitions. We show that homogeneity is related to cluster stability. This
result points to a possible conflict between cluster stability and diversity in
consensus clustering. To assess homogeneity in a practical setting, we propose
an efficient way to compute a lower bound of homogeneity. Empirical results
using the k-means algorithm suggest that uniqueness of the mean partition is
not exceptional for real-world data. Moreover, for samples of high homogeneity,
uniqueness can be enforced by increasing the number of data points or by
removing outlier partitions. In a broader context, this contribution can be
placed as a further step towards a statistical theory of partitions.",['Brijnesh J. Jain']
Locally Differentially Private (Contextual) Bandits Learning,Machine Learning,"We study locally differentially private (LDP) bandits learning in this paper.
First, we propose simple black-box reduction frameworks that can solve a large
family of context-free bandits learning problems with LDP guarantee. Based on
our frameworks, we can improve previous best results for private bandits
learning with one-point feedback, such as private Bandits Convex Optimization,
and obtain the first result for Bandits Convex Optimization (BCO) with
multi-point feedback under LDP. LDP guarantee and black-box nature make our
frameworks more attractive in real applications compared with previous
specifically designed and relatively weaker differentially private (DP)
context-free bandits algorithms. Further, we extend our $(\varepsilon,
\delta)$-LDP algorithm to Generalized Linear Bandits, which enjoys a sub-linear
regret $\tilde{O}(T^{3/4}/\varepsilon)$ and is conjectured to be nearly
optimal. Note that given the existing $\Omega(T)$ lower bound for DP contextual
linear bandits (Shariff & Sheffe, 2018), our result shows a fundamental
difference between LDP and DP contextual bandits learning.","['Kai Zheng', 'Tianle Cai', 'Weiran Huang', 'Zhenguo Li', 'Liwei Wang']"
"Dynamic Neural Representational Decoders for High-Resolution Semantic
  Segmentation",Computer Vision and Pattern Recognition,"Semantic segmentation requires per-pixel prediction for a given image.
Typically, the output resolution of a segmentation network is severely reduced
due to the downsampling operations in the CNN backbone. Most previous methods
employ upsampling decoders to recover the spatial resolution. Various decoders
were designed in the literature. Here, we propose a novel decoder, termed
dynamic neural representational decoder (NRD), which is simple yet
significantly more efficient. As each location on the encoder's output
corresponds to a local patch of the semantic labels, in this work, we represent
these local patches of labels with compact neural networks. This neural
representation enables our decoder to leverage the smoothness prior in the
semantic label space, and thus makes our decoder more efficient. Furthermore,
these neural representations are dynamically generated and conditioned on the
outputs of the encoder networks. The desired semantic labels can be efficiently
decoded from the neural representations, resulting in high-resolution semantic
segmentation predictions. We empirically show that our proposed decoder can
outperform the decoder in DeeplabV3+ with only 30% computational complexity,
and achieve competitive performance with the methods using dilated encoders
with only 15% computation. Experiments on the Cityscapes, ADE20K, and PASCAL
Context datasets demonstrate the effectiveness and efficiency of our proposed
method.","['Bowen Zhang', 'Yifan Liu', 'Zhi Tian', 'Chunhua Shen']"
"Using qualia information to identify lexical semantic classes in an
  unsupervised clustering task",Computation and Language (Natural Language Processing),"Acquiring lexical information is a complex problem, typically approached by
relying on a number of contexts to contribute information for classification.
One of the first issues to address in this domain is the determination of such
contexts. The work presented here proposes the use of automatically obtained
FORMAL role descriptors as features used to draw nouns from the same lexical
semantic class together in an unsupervised clustering task. We have dealt with
three lexical semantic classes (HUMAN, LOCATION and EVENT) in English. The
results obtained show that it is possible to discriminate between elements from
different lexical semantic classes using only FORMAL role information, hence
validating our initial hypothesis. Also, iterating our method accurately
accounts for fine-grained distinctions within lexical classes, namely
distinctions involving ambiguous expressions. Moreover, a filtering and
bootstrapping strategy employed in extracting FORMAL role descriptors proved to
minimize effects of sparse data and noise in our task.","['Lauren Romeo', 'Sara Mendes', 'Núria Bel']"
"Electroencephalography signal processing based on textural features for
  monitoring the driver's state by a Brain-Computer Interface",Computer Vision and Pattern Recognition,"In this study we investigate a textural processing method of
electroencephalography (EEG) signal as an indicator to estimate the driver's
vigilance in a hypothetical Brain-Computer Interface (BCI) system. The novelty
of the solution proposed relies on employing the one-dimensional Local Binary
Pattern (1D-LBP) algorithm for feature extraction from pre-processed EEG data.
From the resulting feature vector, the classification is done according to
three vigilance classes: awake, tired and drowsy. The claim is that the class
transitions can be detected by describing the variations of the micro-patterns'
occurrences along the EEG signal. The 1D-LBP is able to describe them by
detecting mutual variations of the signal temporarily ""close"" as a short
bit-code. Our analysis allows to conclude that the 1D-LBP adoption has led to
significant performance improvement. Moreover, capturing the class transitions
from the EEG signal is effective, although the overall performance is not yet
good enough to develop a BCI for assessing the driver's vigilance in real
environments.","['Giulia Orrù', 'Marco Micheletto', 'Fabio Terranova', 'Gian Luca Marcialis']"
"LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert
  Networks",Artificial Intelligence,"The centralization of Large Language Models (LLMs) development has created
significant barriers to AI advancement, limiting the democratization of these
powerful technologies. This centralization, coupled with the scarcity of
high-quality training data and mounting complexity of maintaining comprehensive
expertise across rapidly expanding knowledge domains, poses critical challenges
to the continued growth of LLMs. While solutions like Retrieval-Augmented
Generation (RAG) offer potential remedies, maintaining up-to-date expert
knowledge across diverse domains remains a significant challenge, particularly
given the exponential growth of specialized information. This paper introduces
LLMs Networks (LLM-Net), a blockchain-based framework that democratizes
LLMs-as-a-Service through a decentralized network of specialized LLM providers.
By leveraging collective computational resources and distributed domain
expertise, LLM-Net incorporates fine-tuned expert models for various specific
domains, ensuring sustained knowledge growth while maintaining service quality
through collaborative prompting mechanisms. The framework's robust design
includes blockchain technology for transparent transaction and performance
validation, establishing an immutable record of service delivery. Our
simulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet,
Llama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the
reputation-based mechanism in maintaining service quality by selecting
high-performing respondents (LLM providers). Thereby it demonstrates the
potential of LLM-Net to sustain AI advancement through the integration of
decentralized expertise and blockchain-based accountability.","['Zan-Kai Chong', 'Hiroyuki Ohsaki', 'Bryan Ng']"
Learning to Scale Logits for Temperature-Conditional GFlowNets,Machine Learning,"GFlowNets are probabilistic models that sequentially generate compositional
structures through a stochastic policy. Among GFlowNets,
temperature-conditional GFlowNets can introduce temperature-based
controllability for exploration and exploitation. We propose
\textit{Logit-scaling GFlowNets} (Logit-GFN), a novel architectural design that
greatly accelerates the training of temperature-conditional GFlowNets. It is
based on the idea that previously proposed approaches introduced numerical
challenges in the deep network training, since different temperatures may give
rise to very different gradient profiles as well as magnitudes of the policy's
logits. We find that the challenge is greatly reduced if a learned function of
the temperature is used to scale the policy's logits directly. Also, using
Logit-GFN, GFlowNets can be improved by having better generalization
capabilities in offline learning and mode discovery capabilities in online
learning, which is empirically verified in various biological and chemical
tasks. Our code is available at \url{https://github.com/dbsxodud-11/logit-gfn}","['Minsu Kim', 'Joohwan Ko', 'Taeyoung Yun', 'Dinghuai Zhang', 'Ling Pan', 'Woochang Kim', 'Jinkyoo Park', 'Emmanuel Bengio', 'Yoshua Bengio']"
ImitAL: Learning Active Learning Strategies from Synthetic Data,Machine Learning,"One of the biggest challenges that complicates applied supervised machine
learning is the need for huge amounts of labeled data. Active Learning (AL) is
a well-known standard method for efficiently obtaining labeled data by first
labeling the samples that contain the most information based on a query
strategy. Although many methods for query strategies have been proposed in the
past, no clear superior method that works well in general for all domains has
been found yet. Additionally, many strategies are computationally expensive
which further hinders the widespread use of AL for large-scale annotation
projects.
  We, therefore, propose ImitAL, a novel query strategy, which encodes AL as a
learning-to-rank problem. For training the underlying neural network we chose
Imitation Learning. The required demonstrative expert experience for training
is generated from purely synthetic data.
  To show the general and superior applicability of \ImitAL{}, we perform an
extensive evaluation comparing our strategy on 15 different datasets, from a
wide range of domains, with 10 different state-of-the-art query strategies. We
also show that our approach is more runtime performant than most other
strategies, especially on very large datasets.","['Julius Gonsior', 'Maik Thiele', 'Wolfgang Lehner']"
"Group Component Analysis for Multiblock Data: Common and Individual
  Feature Extraction",Computer Vision and Pattern Recognition,"Very often data we encounter in practice is a collection of matrices rather
than a single matrix. These multi-block data are naturally linked and hence
often share some common features and at the same time they have their own
individual features, due to the background in which they are measured and
collected. In this study we proposed a new scheme of common and individual
feature analysis (CIFA) that processes multi-block data in a linked way aiming
at discovering and separating their common and individual features. According
to whether the number of common features is given or not, two efficient
algorithms were proposed to extract the common basis which is shared by all
data. Then feature extraction is performed on the common and the individual
spaces separately by incorporating the techniques such as dimensionality
reduction and blind source separation. We also discussed how the proposed CIFA
can significantly improve the performance of classification and clustering
tasks by exploiting common and individual features of samples respectively. Our
experimental results show some encouraging features of the proposed methods in
comparison to the state-of-the-art methods on synthetic and real data.","['Guoxu Zhou', 'Andrzej Cichocki', 'Yu Zhang', 'Danilo Mandic']"
"Inverse Reinforcement Learning in Large State Spaces via Function
  Approximation",Machine Learning,"This paper introduces a new method for inverse reinforcement learning in
large-scale and high-dimensional state spaces. To avoid solving the
computationally expensive reinforcement learning problems in reward learning,
we propose a function approximation method to ensure that the Bellman
Optimality Equation always holds, and then estimate a function to maximize the
likelihood of the observed motion. The time complexity of the proposed method
is linearly proportional to the cardinality of the action set, thus it can
handle large state spaces efficiently. We test the proposed method in a
simulated environment, and show that it is more accurate than existing methods
and significantly better in scalability. We also show that the proposed method
can extend many existing methods to high-dimensional state spaces. We then
apply the method to evaluating the effect of rehabilitative stimulations on
patients with spinal cord injuries based on the observed patient motions.","['Kun Li', 'Joel W. Burdick']"
"Benchmarking Parameter Control Methods in Differential Evolution for
  Mixed-Integer Black-Box Optimization",Neural and Evolutionary Computing,"Differential evolution (DE) generally requires parameter control methods
(PCMs) for the scale factor and crossover rate. Although a better understanding
of PCMs provides a useful clue to designing an efficient DE, their
effectiveness is poorly understood in mixed-integer black-box optimization. In
this context, this paper benchmarks PCMs in DE on the mixed-integer black-box
optimization benchmarking function (bbob-mixint) suite in a component-wise
manner. First, we demonstrate that the best PCM significantly depends on the
combination of the mutation strategy and repair method. Although the PCM of
SHADE is state-of-the-art for numerical black-box optimization, our results
show its poor performance for mixed-integer black-box optimization. In
contrast, our results show that some simple PCMs (e.g., the PCM of CoDE)
perform the best in most cases. Then, we demonstrate that a DE with a suitable
PCM performs significantly better than CMA-ES with integer handling for larger
budgets of function evaluations. Finally, we show how the adaptation in the PCM
of SHADE fails.",['Ryoji Tanabe']
"When to Finish? Optimal Beam Search for Neural Text Generation (modulo
  beam size)",Computation and Language (Natural Language Processing),"In neural text generation such as neural machine translation, summarization,
and image captioning, beam search is widely used to improve the output text
quality. However, in the neural generation setting, hypotheses can finish in
different steps, which makes it difficult to decide when to end beam search to
ensure optimality. We propose a provably optimal beam search algorithm that
will always return the optimal-score complete hypothesis (modulo beam size),
and finish as soon as the optimality is established (finishing no later than
the baseline). To counter neural generation's tendency for shorter hypotheses,
we also introduce a bounded length reward mechanism which allows a modified
version of our beam search algorithm to remain optimal. Experiments on neural
machine translation demonstrate that our principled beam search algorithm leads
to improvement in BLEU score over previously proposed alternatives.","['Liang Huang', 'Kai Zhao', 'Mingbo Ma']"
GEMINI: A Natural Language System for Spoken-Language Understanding,Computation and Language (Legacy category),"Gemini is a natural language understanding system developed for spoken
language applications. The paper describes the architecture of Gemini, paying
particular attention to resolving the tension between robustness and
overgeneration. Gemini features a broad-coverage unification-based grammar of
English, fully interleaved syntactic and semantic processing in an all-paths,
bottom-up parser, and an utterance-level parser to find interpretations of
sentences that might not be analyzable as complete sentences. Gemini also
includes novel components for recognizing and correcting grammatical
disfluencies, and for doing parse preferences. This paper presents a
component-by-component view of Gemini, providing detailed relevant measurements
of size, efficiency, and performance.","['John Dowding', 'Jean Mark Gawron', 'Doug Appelt', 'John Bear', 'Lynn Cherny', 'Robert Moore', 'Douglas Moran']"
RaspberryPI for mosquito neutralization by power laser,Computer Vision and Pattern Recognition,"In this article for the first time, comprehensive studies of mosquito
neutralization using machine vision and a 1 W power laser are considered.
Developed laser installation with Raspberry Pi that changing the direction of
the laser with a galvanometer. We developed a program for mosquito tracking in
real. The possibility of using deep neural networks, Haar cascades, machine
learning for mosquito recognition was considered. We considered in detail the
classification problems of mosquitoes in images. A recommendation is given for
the implementation of this device based on a microcontroller for subsequent use
as part of an unmanned aerial vehicle. Any harmful insects in the fields can be
used as objects for control.",['R. Ildar']
"Layerwise Relevance Visualization in Convolutional Text Graph
  Classifiers",Computation and Language (Natural Language Processing),"Representations in the hidden layers of Deep Neural Networks (DNN) are often
hard to interpret since it is difficult to project them into an interpretable
domain. Graph Convolutional Networks (GCN) allow this projection, but existing
explainability methods do not exploit this fact, i.e. do not focus their
explanations on intermediate states. In this work, we present a novel method
that traces and visualizes features that contribute to a classification
decision in the visible and hidden layers of a GCN. Our method exposes hidden
cross-layer dynamics in the input graph structure. We experimentally
demonstrate that it yields meaningful layerwise explanations for a GCN sentence
classifier.","['Robert Schwarzenberg', 'Marc Hübner', 'David Harbecke', 'Christoph Alt', 'Leonhard Hennig']"
Pixel Adaptive Filtering Units,Computer Vision and Pattern Recognition,"State-of-the-art methods for computer vision rely heavily on the translation
equivariance and spatial sharing properties of convolutional layers without
explicitly taking into consideration the input content. Modern techniques
employ deep sophisticated architectures in order to circumvent this issue. In
this work, we propose a Pixel Adaptive Filtering Unit (PAFU) which introduces a
differentiable kernel selection mechanism paired with a discrete, learnable and
decorrelated group of kernels to allow for content-based spatial adaptation.
First, we demonstrate the applicability of the technique in applications where
runtime is of importance. Next, we employ PAFU in deep neural networks as a
replacement of standard convolutional layers to enhance the original
architectures with spatially varying computations to achieve considerable
performance improvements. Finally, diverse and extensive experimentation
provides strong empirical evidence in favor of the proposed content-adaptive
processing scheme across different image processing and high-level computer
vision tasks.","['Filippos Kokkinos', 'Ioannis Marras', 'Matteo Maggioni', 'Gregory Slabaugh', 'Stefanos Zafeiriou']"
"Advice Conformance Verification by Reinforcement Learning agents for
  Human-in-the-Loop",Artificial Intelligence,"Human-in-the-loop (HiL) reinforcement learning is gaining traction in domains
with large action and state spaces, and sparse rewards by allowing the agent to
take advice from HiL. Beyond advice accommodation, a sequential decision-making
agent must be able to express the extent to which it was able to utilize the
human advice. Subsequently, the agent should provide a means for the HiL to
inspect parts of advice that it had to reject in favor of the overall
environment objective. We introduce the problem of Advice-Conformance
Verification which requires reinforcement learning (RL) agents to provide
assurances to the human in the loop regarding how much of their advice is being
conformed to. We then propose a Tree-based lingua-franca to support this
communication, called a Preference Tree. We study two cases of good and bad
advice scenarios in MuJoCo's Humanoid environment. Through our experiments, we
show that our method can provide an interpretable means of solving the
Advice-Conformance Verification problem by conveying whether or not the agent
is using the human's advice. Finally, we present a human-user study with 20
participants that validates our method.","['Mudit Verma', 'Ayush Kharkwal', 'Subbarao Kambhampati']"
Software and application patterns for explanation methods,Machine Learning,"Deep neural networks successfully pervaded many applications domains and are
increasingly used in critical decision processes. Understanding their workings
is desirable or even required to further foster their potential as well as to
access sensitive domains like medical applications or autonomous driving. One
key to this broader usage of explaining frameworks is the accessibility and
understanding of respective software. In this work we introduce software and
application patterns for explanation techniques that aim to explain individual
predictions of neural networks. We discuss how to code well-known algorithms
efficiently within deep learning software frameworks and describe how to embed
algorithms in downstream implementations. Building on this we show how
explanation methods can be used in applications to understand predictions for
miss-classified samples, to compare algorithms or networks, and to examine the
focus of networks. Furthermore, we review available open-source packages and
discuss challenges posed by complex and evolving neural network structures to
explanation algorithm development and implementations.",['Maximilian Alber']
HUMBI: A Large Multiview Dataset of Human Body Expressions,Computer Vision and Pattern Recognition,"This paper presents a new large multiview dataset called HUMBI for human body
expressions with natural clothing. The goal of HUMBI is to facilitate modeling
view-specific appearance and geometry of gaze, face, hand, body, and garment
from assorted people. 107 synchronized HD cameras are used to capture 772
distinctive subjects across gender, ethnicity, age, and physical condition.
With the multiview image streams, we reconstruct high fidelity body expressions
using 3D mesh models, which allows representing view-specific appearance using
their canonical atlas. We demonstrate that HUMBI is highly effective in
learning and reconstructing a complete human model and is complementary to the
existing datasets of human body expressions with limited views and subjects
such as MPII-Gaze, Multi-PIE, Human3.6M, and Panoptic Studio datasets.","['Zhixuan Yu', 'Jae Shin Yoon', 'In Kyu Lee', 'Prashanth Venkatesh', 'Jaesik Park', 'Jihun Yu', 'Hyun Soo Park']"
"CEMFormer: Learning to Predict Driver Intentions from In-Cabin and
  External Cameras via Spatial-Temporal Transformers",Computer Vision and Pattern Recognition,"Driver intention prediction seeks to anticipate drivers' actions by analyzing
their behaviors with respect to surrounding traffic environments. Existing
approaches primarily focus on late-fusion techniques, and neglect the
importance of maintaining consistency between predictions and prevailing
driving contexts. In this paper, we introduce a new framework called Cross-View
Episodic Memory Transformer (CEMFormer), which employs spatio-temporal
transformers to learn unified memory representations for an improved driver
intention prediction. Specifically, we develop a spatial-temporal encoder to
integrate information from both in-cabin and external camera views, along with
episodic memory representations to continuously fuse historical data.
Furthermore, we propose a novel context-consistency loss that incorporates
driving context as an auxiliary supervision signal to improve prediction
performance. Comprehensive experiments on the Brain4Cars dataset demonstrate
that CEMFormer consistently outperforms existing state-of-the-art methods in
driver intention prediction.","['Yunsheng Ma', 'Wenqian Ye', 'Xu Cao', 'Amr Abdelraouf', 'Kyungtae Han', 'Rohit Gupta', 'Ziran Wang']"
Efficient entity-based reinforcement learning,Machine Learning,"Recent deep reinforcement learning (DRL) successes rely on end-to-end
learning from fixed-size observational inputs (e.g. image, state-variables).
However, many challenging and interesting problems in decision making involve
observations or intermediary representations which are best described as a set
of entities: either the image-based approach would miss small but important
details in the observations (e.g. ojects on a radar, vehicles on satellite
images, etc.), the number of sensed objects is not fixed (e.g. robotic
manipulation), or the problem simply cannot be represented in a meaningful way
as an image (e.g. power grid control, or logistics). This type of structured
representations is not directly compatible with current DRL architectures,
however, there has been an increase in machine learning techniques directly
targeting structured information, potentially addressing this issue. We propose
to combine recent advances in set representations with slot attention and graph
neural networks to process structured data, broadening the range of
applications of DRL algorithms. This approach allows to address entity-based
problems in an efficient and scalable way. We show that it can improve training
time and robustness significantly, and demonstrate their potential to handle
structured as well as purely visual domains, on multiple environments from the
Atari Learning Environment and Simple Playgrounds.","['Vince Jankovics', 'Michael Garcia Ortiz', 'Eduardo Alonso']"
"Beyond Forward Shortcuts: Fully Convolutional Master-Slave Networks
  (MSNets) with Backward Skip Connections for Semantic Segmentation",Computer Vision and Pattern Recognition,"Recent deep CNNs contain forward shortcut connections; i.e. skip connections
from low to high layers. Reusing features from lower layers that have higher
resolution (location information) benefit higher layers to recover lost details
and mitigate information degradation. However, during inference the lower
layers do not know about high layer features, although they contain contextual
high semantics that benefit low layers to adaptively extract informative
features for later layers. In this paper, we study the influence of backward
skip connections which are in the opposite direction to forward shortcuts, i.e.
paths from high layers to low layers. To achieve this -- which indeed runs
counter to the nature of feed-forward networks -- we propose a new fully
convolutional model that consists of a pair of networks. A `Slave' network is
dedicated to provide the backward connections from its top layers to the
`Master' network's bottom layers. The Master network is used to produce the
final label predictions. In our experiments we validate the proposed FCN model
on ADE20K (ImageNet scene parsing), PASCAL-Context, and PASCAL VOC 2011
datasets.","['Abrar H. Abdulnabi', 'Stefan Winkler', 'Gang Wang']"
"Classifying Multilingual User Feedback using Traditional Machine
  Learning and Deep Learning",Computation and Language (Natural Language Processing),"With the rise of social media like Twitter and of software distribution
platforms like app stores, users got various ways to express their opinion
about software products. Popular software vendors get user feedback
thousandfold per day. Research has shown that such feedback contains valuable
information for software development teams such as problem reports or feature
and support inquires. Since the manual analysis of user feedback is cumbersome
and hard to manage many researchers and tool vendors suggested to use automated
analyses based on traditional supervised machine learning approaches. In this
work, we compare the results of traditional machine learning and deep learning
in classifying user feedback in English and Italian into problem reports,
inquiries, and irrelevant. Our results show that using traditional machine
learning, we can still achieve comparable results to deep learning, although we
collected thousands of labels.","['Christoph Stanik', 'Marlo Haering', 'Walid Maalej']"
A Unified Gradient Regularization Family for Adversarial Examples,Machine Learning,"Adversarial examples are augmented data points generated by imperceptible
perturbation of input samples. They have recently drawn much attention with the
machine learning and data mining community. Being difficult to distinguish from
real examples, such adversarial examples could change the prediction of many of
the best learning models including the state-of-the-art deep learning models.
Recent attempts have been made to build robust models that take into account
adversarial examples. However, these methods can either lead to performance
drops or lack mathematical motivations. In this paper, we propose a unified
framework to build robust machine learning models against adversarial examples.
More specifically, using the unified framework, we develop a family of gradient
regularization methods that effectively penalize the gradient of loss function
w.r.t. inputs. Our proposed framework is appealing in that it offers a unified
view to deal with adversarial examples. It incorporates another
recently-proposed perturbation based approach as a special case. In addition,
we present some visual effects that reveals semantic meaning in those
perturbations, and thus support our regularization method and provide another
explanation for generalizability of adversarial examples. By applying this
technique to Maxout networks, we conduct a series of experiments and achieve
encouraging results on two benchmark datasets. In particular,we attain the best
accuracy on MNIST data (without data augmentation) and competitive performance
on CIFAR-10 data.","['Chunchuan Lyu', 'Kaizhu Huang', 'Hai-Ning Liang']"
Using Database Rule for Weak Supervised Text-to-SQL Generation,Computation and Language (Natural Language Processing),"We present a simple way to do the task of text-to-SQL problem with weak
supervision. We call it Rule-SQL. Given the question and the answer from the
database table without the SQL logic form, Rule-SQL use the rules based on
table column names and question string for the SQL exploration first and then
use the explored SQL for supervised training. We design several rules for
reducing the exploration search space. For the deep model, we leverage BERT for
the representation layer and separate the model to SELECT, AGG and WHERE parts.
The experiment result on WikiSQL outperforms the strong baseline of full
supervision and is comparable to the start-of-the-art weak supervised mothods.","['Tong Guo', 'Huilin Gao']"
EMNIST: an extension of MNIST to handwritten letters,Computer Vision and Pattern Recognition,"The MNIST dataset has become a standard benchmark for learning,
classification and computer vision systems. Contributing to its widespread
adoption are the understandable and intuitive nature of the task, its
relatively small size and storage requirements and the accessibility and
ease-of-use of the database itself. The MNIST database was derived from a
larger dataset known as the NIST Special Database 19 which contains digits,
uppercase and lowercase handwritten letters. This paper introduces a variant of
the full NIST dataset, which we have called Extended MNIST (EMNIST), which
follows the same conversion paradigm used to create the MNIST dataset. The
result is a set of datasets that constitute a more challenging classification
tasks involving letters and digits, and that shares the same image structure
and parameters as the original MNIST task, allowing for direct compatibility
with all existing classifiers and systems. Benchmark results are presented
along with a validation of the conversion process through the comparison of the
classification results on converted NIST digits and the MNIST digits.","['Gregory Cohen', 'Saeed Afshar', 'Jonathan Tapson', 'André van Schaik']"
"Topology-based Representative Datasets to Reduce Neural Network Training
  Resources",Machine Learning,"One of the main drawbacks of the practical use of neural networks is the long
time required in the training process. Such a training process consists of an
iterative change of parameters trying to minimize a loss function. These
changes are driven by a dataset, which can be seen as a set of labelled points
in an n-dimensional space. In this paper, we explore the concept of are
representative dataset which is a dataset smaller than the original one,
satisfying a nearness condition independent of isometric transformations.
Representativeness is measured using persistence diagrams (a computational
topology tool) due to its computational efficiency. We prove that the accuracy
of the learning process of a neural network on a representative dataset is
""similar"" to the accuracy on the original dataset when the neural network
architecture is a perceptron and the loss function is the mean squared error.
These theoretical results accompanied by experimentation open a door to
reducing the size of the dataset to gain time in the training process of any
neural network.","['Rocio Gonzalez-Diaz', 'Miguel A. Gutiérrez-Naranjo', 'Eduardo Paluzo-Hidalgo']"
"LeanQuant: Accurate and Scalable Large Language Model Quantization with
  Loss-error-aware Grid",Machine Learning,"Large language models (LLMs) have shown immense potential across various
domains, but their high memory requirements and inference costs remain critical
challenges for deployment. Post-training quantization (PTQ) has emerged as a
promising technique to reduce memory requirements and decoding latency.
However, recent accurate quantization methods often depend on specialized
computations or custom data formats to achieve better model quality, which
limits their compatibility with popular frameworks, as they require dedicated
inference kernels tailored to specific hardware and software platforms,
hindering wider adoption. Furthermore, many competitive methods have high
resource requirements and computational overhead, making it challenging to
scale them to hundreds of billions of parameters. In response to these
challenges, we propose LeanQuant (Loss-error-aware Network Quantization), a
novel quantization method that is accurate, versatile, and scalable. In the
existing popular iterative loss-error-based quantization framework, we identify
a critical limitation in prior methods: the min-max affine quantization grid
fails to preserve model quality due to outliers in inverse Hessian diagonals.
To overcome this fundamental issue, we propose learning loss-error-aware grids,
instead of using non-adaptive min-max affine grids. Our approach not only
produces quantized models that are more accurate but also generalizes to a
wider range of quantization types, including affine and non-uniform
quantization, enhancing compatibility with more frameworks. Extensive empirical
evaluations on recent LLMs demonstrate that LeanQuant is highly accurate,
comparing favorably against recent competitive baselines in model quality, and
scalable, achieving very accurate quantization of Llama-3.1 405B, one of the
largest open-source LLMs to date, using two Quadro RTX 8000-48GB GPUs in 21
hours.","['Tianyi Zhang', 'Anshumali Shrivastava']"
"Statistical Attention Localization (SAL): Methodology and Application to
  Object Classification",Computer Vision and Pattern Recognition,"A statistical attention localization (SAL) method is proposed to facilitate
the object classification task in this work. SAL consists of three steps: 1)
preliminary attention window selection via decision statistics, 2) attention
map refinement, and 3) rectangular attention region finalization. SAL computes
soft-decision scores of local squared windows and uses them to identify salient
regions in Step 1. To accommodate object of various sizes and shapes, SAL
refines the preliminary result and obtain an attention map of more flexible
shape in Step 2. Finally, SAL yields a rectangular attention region using the
refined attention map and bounding box regularization in Step 3. As an
application, we adopt E-PixelHop, which is an object classification solution
based on successive subspace learning (SSL), as the baseline. We apply SAL so
as to obtain a cropped-out and resized attention region as an alternative
input. Classification results of the whole image as well as the attention
region are ensembled to achieve the highest classification accuracy.
Experiments on the CIFAR-10 dataset are given to demonstrate the advantage of
the SAL-assisted object classification method.","['Yijing Yang', 'Vasileios Magoulianitis', 'Xinyu Wang', 'C. -C. Jay Kuo']"
A Temporal Variational Model for Story Generation,Computation and Language (Natural Language Processing),"Recent language models can generate interesting and grammatically correct
text in story generation but often lack plot development and long-term
coherence. This paper experiments with a latent vector planning approach based
on a TD-VAE (Temporal Difference Variational Autoencoder), using the model for
conditioning and reranking for text generation. The results demonstrate strong
performance in automatic cloze and swapping evaluations. The human judgments
show stories generated with TD-VAE reranking improve on a GPT-2 medium baseline
and show comparable performance to a hierarchical LSTM reranking model.
Conditioning on the latent vectors proves disappointing and deteriorates
performance in human evaluation because it reduces the diversity of generation,
and the models don't learn to progress the narrative. This highlights an
important difference between technical task performance (e.g. cloze) and
generating interesting stories.","['David Wilmot', 'Frank Keller']"
A Neural Representation of Sketch Drawings,Neural and Evolutionary Computing,"We present sketch-rnn, a recurrent neural network (RNN) able to construct
stroke-based drawings of common objects. The model is trained on thousands of
crude human-drawn images representing hundreds of classes. We outline a
framework for conditional and unconditional sketch generation, and describe new
robust training methods for generating coherent sketch drawings in a vector
format.","['David Ha', 'Douglas Eck']"
DeepGeo: Photo Localization with Deep Neural Network,Computer Vision and Pattern Recognition,"In this paper we address the task of determining the geographical location of
an image, a pertinent problem in learning and computer vision. This research
was inspired from playing GeoGuessr, a game that tests a humans' ability to
localize themselves using just images of their surroundings. In particular, we
wish to investigate how geographical, ecological and man-made features
generalize for random location prediction. This is framed as a classification
problem: given images sampled from the USA, the most-probable state among 50 is
predicted. Previous work uses models extensively trained on large, unfiltered
online datasets that are primed towards specific locations. To this end, we
create (and open-source) the 50States10K dataset - with 0.5 million Google
Street View images of the country. A deep neural network based on the ResNet
architecture is trained, and four different strategies of incorporating
low-level cardinality information are presented. This model achieves an
accuracy 20 times better than chance on a test dataset, which rises to 71.87%
when taking the best of top-5 guesses. The network also beats human subjects in
4 out of 5 rounds of GeoGuessr.","['Sudharshan Suresh', 'Nathaniel Chodosh', 'Montiel Abello']"
"Remove Cosine Window from Correlation Filter-based Visual Trackers: When
  and How",Computer Vision and Pattern Recognition,"Correlation filters (CFs) have been continuously advancing the
state-of-the-art tracking performance and have been extensively studied in the
recent few years. Most of the existing CF trackers adopt a cosine window to
spatially reweight base image to alleviate boundary discontinuity. However,
cosine window emphasizes more on the central region of base image and has the
risk of contaminating negative training samples during model learning. On the
other hand, spatial regularization deployed in many recent CF trackers plays a
similar role as cosine window by enforcing spatial penalty on CF coefficients.
Therefore, we in this paper investigate the feasibility to remove cosine window
from CF trackers with spatial regularization. When simply removing cosine
window, CF with spatial regularization still suffers from small degree of
boundary discontinuity. To tackle this issue, binary and Gaussian shaped mask
functions are further introduced for eliminating boundary discontinuity while
reweighting the estimation error of each training sample, and can be
incorporated with multiple CF trackers with spatial regularization. In
comparison to the counterparts with cosine window, our methods are effective in
handling boundary discontinuity and sample contamination, thereby benefiting
tracking performance. Extensive experiments on three benchmarks show that our
methods perform favorably against the state-of-the-art trackers using either
handcrafted or deep CNN features. The code is publicly available at
https://github.com/lifeng9472/Removing_cosine_window_from_CF_trackers.","['Feng Li', 'Xiaohe Wu', 'Wangmeng Zuo', 'David Zhang', 'Lei Zhang']"
vireoJD-MM at Activity Detection in Extended Videos,Computer Vision and Pattern Recognition,"This notebook paper presents an overview and comparative analysis of our
system designed for activity detection in extended videos (ActEV-PC) in
ActivityNet Challenge 2019. Specifically, we exploit person/vehicle detections
in spatial level and action localization in temporal level for action detection
in surveillance videos. The mechanism of different tubelet generation and model
decomposition methods are studied as well. The detection results are finally
predicted by late fusing the results from each component.","['Fuchen Long', 'Qi Cai', 'Zhaofan Qiu', 'Zhijian Hou', 'Yingwei Pan', 'Ting Yao', 'Chong-Wah Ngo']"
How Important Is a Neuron?,Machine Learning,"The problem of attributing a deep network's prediction to its
\emph{input/base} features is well-studied. We introduce the notion of
\emph{conductance} to extend the notion of attribution to the understanding the
importance of \emph{hidden} units.
  Informally, the conductance of a hidden unit of a deep network is the
\emph{flow} of attribution via this hidden unit. We use conductance to
understand the importance of a hidden unit to the prediction for a specific
input, or over a set of inputs. We evaluate the effectiveness of conductance in
multiple ways, including theoretical properties, ablation studies, and a
feature selection task. The empirical evaluations are done using the Inception
network over ImageNet data, and a sentiment analysis network over reviews. In
both cases, we demonstrate the effectiveness of conductance in identifying
interesting insights about the internal workings of these networks.","['Kedar Dhamdhere', 'Mukund Sundararajan', 'Qiqi Yan']"
Terrain Analysis in StarCraft 1 and 2 as Combinatorial Optimization,Artificial Intelligence,"Terrain analysis in Real-Time Strategy games is a necessary step to allow
spacial reasoning. The goal of terrain analysis is to gather and process data
about the map topology and properties to have a qualitative spatial
representation. On StarCraft games, all previous works on terrain analysis
propose a crisp analysis based on connected component detection, Voronoi
diagram computation and pruning, and region merging. Those methods have been
implemented as game-specific libraries, and they can only offer the same kind
of analysis for all maps and all users. In this paper, we propose a way to
consider terrain analysis as a combinatorial optimization problem. Our method
allows different kinds of analysis by changing constraints or the objective
function in the problem model. We also present a library, Taunt, implementing
our method and able to handle both StarCraft 1 and StarCraft 2 maps. This makes
our library a universal tool for StarCraft bots with different spatial
representation needs. We believe our library unlocks the possibility to have
real adaptive AIs playing StarCraft, and can be the starting point of a new
wave of bots.",['Florian Richoux']
Deep Multimodal Fusion for Generalizable Person Re-identification,Computer Vision and Pattern Recognition,"Person re-identification plays a significant role in realistic scenarios due
to its various applications in public security and video surveillance.
Recently, leveraging the supervised or semi-unsupervised learning paradigms,
which benefits from the large-scale datasets and strong computing performance,
has achieved a competitive performance on a specific target domain. However,
when Re-ID models are directly deployed in a new domain without target samples,
they always suffer from considerable performance degradation and poor domain
generalization. To address this challenge, we propose a Deep Multimodal Fusion
network to elaborate rich semantic knowledge for assisting in representation
learning during the pre-training. Importantly, a multimodal fusion strategy is
introduced to translate the features of different modalities into the common
space, which can significantly boost generalization capability of Re-ID model.
As for the fine-tuning stage, a realistic dataset is adopted to fine-tune the
pre-trained model for better distribution alignment with real-world data.
Comprehensive experiments on benchmarks demonstrate that our method can
significantly outperform previous domain generalization or meta-learning
methods with a clear margin. Our source code will also be publicly available at
https://github.com/JeremyXSC/DMF.","['Suncheng Xiang', 'Hao Chen', 'Wei Ran', 'Zefang Yu', 'Ting Liu', 'Dahong Qian', 'Yuzhuo Fu']"
"Demographic Dialectal Variation in Social Media: A Case Study of
  African-American English",Computation and Language (Natural Language Processing),"Though dialectal language is increasingly abundant on social media, few
resources exist for developing NLP tools to handle such language. We conduct a
case study of dialectal language in online conversational text by investigating
African-American English (AAE) on Twitter. We propose a distantly supervised
model to identify AAE-like language from demographics associated with
geo-located messages, and we verify that this language follows well-known AAE
linguistic phenomena. In addition, we analyze the quality of existing language
identification and dependency parsing tools on AAE-like text, demonstrating
that they perform poorly on such text compared to text associated with white
speakers. We also provide an ensemble classifier for language identification
which eliminates this disparity and release a new corpus of tweets containing
AAE-like language.","['Su Lin Blodgett', 'Lisa Green', ""Brendan O'Connor""]"
Local Differential Privacy for Evolving Data,Machine Learning,"There are now several large scale deployments of differential privacy used to
collect statistical information about users. However, these deployments
periodically recollect the data and recompute the statistics using algorithms
designed for a single use. As a result, these systems do not provide meaningful
privacy guarantees over long time scales. Moreover, existing techniques to
mitigate this effect do not apply in the ""local model"" of differential privacy
that these systems use.
  In this paper, we introduce a new technique for local differential privacy
that makes it possible to maintain up-to-date statistics over time, with
privacy guarantees that degrade only in the number of changes in the underlying
distribution rather than the number of collection periods. We use our technique
for tracking a changing statistic in the setting where users are partitioned
into an unknown collection of groups, and at every time period each user draws
a single bit from a common (but changing) group-specific distribution. We also
provide an application to frequency and heavy-hitter estimation.","['Matthew Joseph', 'Aaron Roth', 'Jonathan Ullman', 'Bo Waggoner']"
"OBMO: One Bounding Box Multiple Objects for Monocular 3D Object
  Detection",Computer Vision and Pattern Recognition,"Compared to typical multi-sensor systems, monocular 3D object detection has
attracted much attention due to its simple configuration. However, there is
still a significant gap between LiDAR-based and monocular-based methods. In
this paper, we find that the ill-posed nature of monocular imagery can lead to
depth ambiguity. Specifically, objects with different depths can appear with
the same bounding boxes and similar visual features in the 2D image.
Unfortunately, the network cannot accurately distinguish different depths from
such non-discriminative visual features, resulting in unstable depth training.
To facilitate depth learning, we propose a simple yet effective plug-and-play
module, \underline{O}ne \underline{B}ounding Box \underline{M}ultiple
\underline{O}bjects (OBMO). Concretely, we add a set of suitable pseudo labels
by shifting the 3D bounding box along the viewing frustum. To constrain the
pseudo-3D labels to be reasonable, we carefully design two label scoring
strategies to represent their quality. In contrast to the original hard depth
labels, such soft pseudo labels with quality scores allow the network to learn
a reasonable depth range, boosting training stability and thus improving final
performance. Extensive experiments on KITTI and Waymo benchmarks show that our
method significantly improves state-of-the-art monocular 3D detectors by a
significant margin (The improvements under the moderate setting on KITTI
validation set are $\mathbf{1.82\sim 10.91\%}$ \textbf{mAP in BEV} and
$\mathbf{1.18\sim 9.36\%}$ \textbf{mAP in 3D}). Codes have been released at
\url{https://github.com/mrsempress/OBMO}.","['Chenxi Huang', 'Tong He', 'Haidong Ren', 'Wenxiao Wang', 'Binbin Lin', 'Deng Cai']"
Multilingual Language Models Predict Human Reading Behavior,Computation and Language (Natural Language Processing),"We analyze if large language models are able to predict patterns of human
reading behavior. We compare the performance of language-specific and
multilingual pretrained transformer models to predict reading time measures
reflecting natural human sentence processing on Dutch, English, German, and
Russian texts. This results in accurate models of human reading behavior, which
indicates that transformer models implicitly encode relative importance in
language in a way that is comparable to human processing mechanisms. We find
that BERT and XLM models successfully predict a range of eye tracking features.
In a series of experiments, we analyze the cross-domain and cross-language
abilities of these models and show how they reflect human sentence processing.","['Nora Hollenstein', 'Federico Pirovano', 'Ce Zhang', 'Lena Jäger', 'Lisa Beinborn']"
"Cooperative Learning of Audio and Video Models from Self-Supervised
  Synchronization",Computer Vision and Pattern Recognition,"There is a natural correlation between the visual and auditive elements of a
video. In this work we leverage this connection to learn general and effective
models for both audio and video analysis from self-supervised temporal
synchronization. We demonstrate that a calibrated curriculum learning scheme, a
careful choice of negative examples, and the use of a contrastive loss are
critical ingredients to obtain powerful multi-sensory representations from
models optimized to discern temporal synchronization of audio-video pairs.
Without further finetuning, the resulting audio features achieve performance
superior or comparable to the state-of-the-art on established audio
classification benchmarks (DCASE2014 and ESC-50). At the same time, our visual
subnet provides a very effective initialization to improve the accuracy of
video-based action recognition models: compared to learning from scratch, our
self-supervised pretraining yields a remarkable gain of +19.9% in action
recognition accuracy on UCF101 and a boost of +17.7% on HMDB51.","['Bruno Korbar', 'Du Tran', 'Lorenzo Torresani']"
"ExplaGraphs: An Explanation Graph Generation Task for Structured
  Commonsense Reasoning",Computation and Language (Natural Language Processing),"Recent commonsense-reasoning tasks are typically discriminative in nature,
where a model answers a multiple-choice question for a certain context.
Discriminative tasks are limiting because they fail to adequately evaluate the
model's ability to reason and explain predictions with underlying commonsense
knowledge. They also allow such models to use reasoning shortcuts and not be
""right for the right reasons"". In this work, we present ExplaGraphs, a new
generative and structured commonsense-reasoning task (and an associated
dataset) of explanation graph generation for stance prediction. Specifically,
given a belief and an argument, a model has to predict if the argument supports
or counters the belief and also generate a commonsense-augmented graph that
serves as non-trivial, complete, and unambiguous explanation for the predicted
stance. We collect explanation graphs through a novel Create-Verify-And-Refine
graph collection framework that improves the graph quality (up to 90%) via
multiple rounds of verification and refinement. A significant 79% of our graphs
contain external commonsense nodes with diverse structures and reasoning
depths. Next, we propose a multi-level evaluation framework, consisting of
automatic metrics and human evaluation, that check for the structural and
semantic correctness of the generated graphs and their degree of match with
ground-truth graphs. Finally, we present several structured,
commonsense-augmented, and text generation models as strong starting points for
this explanation graph generation task, and observe that there is a large gap
with human performance, thereby encouraging future work for this new
challenging task. ExplaGraphs will be publicly available at
https://explagraphs.github.io.","['Swarnadeep Saha', 'Prateek Yadav', 'Lisa Bauer', 'Mohit Bansal']"
Multiple Operator-valued Kernel Learning,Machine Learning (Statistics),"Positive definite operator-valued kernels generalize the well-known notion of
reproducing kernels, and are naturally adapted to multi-output learning
situations. This paper addresses the problem of learning a finite linear
combination of infinite-dimensional operator-valued kernels which are suitable
for extending functional data analysis methods to nonlinear contexts. We study
this problem in the case of kernel ridge regression for functional responses
with an lr-norm constraint on the combination coefficients. The resulting
optimization problem is more involved than those of multiple scalar-valued
kernel learning since operator-valued kernels pose more technical and
theoretical issues. We propose a multiple operator-valued kernel learning
algorithm based on solving a system of linear operator equations by using a
block coordinatedescent procedure. We experimentally validate our approach on a
functional regression task in the context of finger movement prediction in
brain-computer interfaces.","['Hachem Kadri', 'Alain Rakotomamonjy', 'Francis Bach', 'Philippe Preux']"
Learning to retrieve out-of-vocabulary words in speech recognition,Computation and Language (Natural Language Processing),"Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech
recognition systems used to process diachronic audio data. To help recovery of
the PNs missed by the system, relevant OOV PNs can be retrieved out of the many
OOVs by exploiting semantic context of the spoken content. In this paper, we
propose two neural network models targeted to retrieve OOV PNs relevant to an
audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b)
Document level Continuous Bag of Weighted Words (D-CBOW2). Both these models
take document words as input and learn with an objective to maximise the
retrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a new
approach in which the input embedding layer is augmented with a context anchor
layer. This layer learns to assign importance to input words and has the
ability to capture (task specific) key-words in a bag-of-word neural network
model. With experiments on French broadcast news videos we show that these two
models outperform the baseline methods based on raw embeddings from LDA,
Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models gives
faster convergence during training.","['Imran Sheikh', 'Irina Illina', 'Dominique Fohr', 'Georges Linarès']"
GeoStyle: Discovering Fashion Trends and Events,Computer Vision and Pattern Recognition,"Understanding fashion styles and trends is of great potential interest to
retailers and consumers alike. The photos people upload to social media are a
historical and public data source of how people dress across the world and at
different times. While we now have tools to automatically recognize the
clothing and style attributes of what people are wearing in these photographs,
we lack the ability to analyze spatial and temporal trends in these attributes
or make predictions about the future. In this paper, we address this need by
providing an automatic framework that analyzes large corpora of street imagery
to (a) discover and forecast long-term trends of various fashion attributes as
well as automatically discovered styles, and (b) identify spatio-temporally
localized events that affect what people wear. We show that our framework makes
long term trend forecasts that are >20% more accurate than the prior art, and
identifies hundreds of socially meaningful events that impact fashion across
the globe.","['Utkarsh Mall', 'Kevin Matzen', 'Bharath Hariharan', 'Noah Snavely', 'Kavita Bala']"
"Global-to-Local Modeling for Video-based 3D Human Pose and Shape
  Estimation",Computer Vision and Pattern Recognition,"Video-based 3D human pose and shape estimations are evaluated by intra-frame
accuracy and inter-frame smoothness. Although these two metrics are responsible
for different ranges of temporal consistency, existing state-of-the-art methods
treat them as a unified problem and use monotonous modeling structures (e.g.,
RNN or attention-based block) to design their networks. However, using a single
kind of modeling structure is difficult to balance the learning of short-term
and long-term temporal correlations, and may bias the network to one of them,
leading to undesirable predictions like global location shift, temporal
inconsistency, and insufficient local details. To solve these problems, we
propose to structurally decouple the modeling of long-term and short-term
correlations in an end-to-end framework, Global-to-Local Transformer (GLoT).
First, a global transformer is introduced with a Masked Pose and Shape
Estimation strategy for long-term modeling. The strategy stimulates the global
transformer to learn more inter-frame correlations by randomly masking the
features of several frames. Second, a local transformer is responsible for
exploiting local details on the human mesh and interacting with the global
transformer by leveraging cross-attention. Moreover, a Hierarchical Spatial
Correlation Regressor is further introduced to refine intra-frame estimations
by decoupled global-local representation and implicit kinematic constraints.
Our GLoT surpasses previous state-of-the-art methods with the lowest model
parameters on popular benchmarks, i.e., 3DPW, MPI-INF-3DHP, and Human3.6M.
Codes are available at https://github.com/sxl142/GLoT.","['Xiaolong Shen', 'Zongxin Yang', 'Xiaohan Wang', 'Jianxin Ma', 'Chang Zhou', 'Yi Yang']"
"Stereotype and Skew: Quantifying Gender Bias in Pre-trained and
  Fine-tuned Language Models",Computation and Language (Natural Language Processing),"This paper proposes two intuitive metrics, skew and stereotype, that quantify
and analyse the gender bias present in contextual language models when tackling
the WinoBias pronoun resolution task. We find evidence that gender stereotype
correlates approximately negatively with gender skew in out-of-the-box models,
suggesting that there is a trade-off between these two forms of bias. We
investigate two methods to mitigate bias. The first approach is an online
method which is effective at removing skew at the expense of stereotype. The
second, inspired by previous work on ELMo, involves the fine-tuning of BERT
using an augmented gender-balanced dataset. We show that this reduces both skew
and stereotype relative to its unaugmented fine-tuned counterpart. However, we
find that existing gender bias benchmarks do not fully probe professional bias
as pronoun resolution may be obfuscated by cross-correlations from other
manifestations of gender prejudice. Our code is available online, at
https://github.com/12kleingordon34/NLP_masters_project.","['Daniel de Vassimon Manela', 'David Errington', 'Thomas Fisher', 'Boris van Breugel', 'Pasquale Minervini']"
"A Game-Based Approximate Verification of Deep Neural Networks with
  Provable Guarantees",Machine Learning,"Despite the improved accuracy of deep neural networks, the discovery of
adversarial examples has raised serious safety concerns. In this paper, we
study two variants of pointwise robustness, the maximum safe radius problem,
which for a given input sample computes the minimum distance to an adversarial
example, and the feature robustness problem, which aims to quantify the
robustness of individual features to adversarial perturbations. We demonstrate
that, under the assumption of Lipschitz continuity, both problems can be
approximated using finite optimisation by discretising the input space, and the
approximation has provable guarantees, i.e., the error is bounded. We then show
that the resulting optimisation problems can be reduced to the solution of
two-player turn-based games, where the first player selects features and the
second perturbs the image within the feature. While the second player aims to
minimise the distance to an adversarial example, depending on the optimisation
objective the first player can be cooperative or competitive. We employ an
anytime approach to solve the games, in the sense of approximating the value of
a game by monotonically improving its upper and lower bounds. The Monte Carlo
tree search algorithm is applied to compute upper bounds for both games, and
the Admissible A* and the Alpha-Beta Pruning algorithms are, respectively, used
to compute lower bounds for the maximum safety radius and feature robustness
games. When working on the upper bound of the maximum safe radius problem, our
tool demonstrates competitive performance against existing adversarial example
crafting algorithms. Furthermore, we show how our framework can be deployed to
evaluate pointwise robustness of neural networks in safety-critical
applications such as traffic sign recognition in self-driving cars.","['Min Wu', 'Matthew Wicker', 'Wenjie Ruan', 'Xiaowei Huang', 'Marta Kwiatkowska']"
"Smooth Sparse Coding via Marginal Regression for Learning Sparse
  Representations",Machine Learning (Statistics),"We propose and analyze a novel framework for learning sparse representations,
based on two statistical techniques: kernel smoothing and marginal regression.
The proposed approach provides a flexible framework for incorporating feature
similarity or temporal information present in data sets, via non-parametric
kernel smoothing. We provide generalization bounds for dictionary learning
using smooth sparse coding and show how the sample complexity depends on the L1
norm of kernel function used. Furthermore, we propose using marginal regression
for obtaining sparse codes, which significantly improves the speed and allows
one to scale to large dictionary sizes easily. We demonstrate the advantages of
the proposed approach, both in terms of accuracy and speed by extensive
experimentation on several real data sets. In addition, we demonstrate how the
proposed approach could be used for improving semi-supervised sparse coding.","['Krishnakumar Balasubramanian', 'Kai Yu', 'Guy Lebanon']"
"HOPE: A Task-Oriented and Human-Centric Evaluation Framework Using
  Professional Post-Editing Towards More Effective MT Evaluation",Computation and Language (Natural Language Processing),"Traditional automatic evaluation metrics for machine translation have been
widely criticized by linguists due to their low accuracy, lack of transparency,
focus on language mechanics rather than semantics, and low agreement with human
quality evaluation. Human evaluations in the form of MQM-like scorecards have
always been carried out in real industry setting by both clients and
translation service providers (TSPs). However, traditional human translation
quality evaluations are costly to perform and go into great linguistic detail,
raise issues as to inter-rater reliability (IRR) and are not designed to
measure quality of worse than premium quality translations. In this work, we
introduce HOPE, a task-oriented and human-centric evaluation framework for
machine translation output based on professional post-editing annotations. It
contains only a limited number of commonly occurring error types, and use a
scoring model with geometric progression of error penalty points (EPPs)
reflecting error severity level to each translation unit. The initial
experimental work carried out on English-Russian language pair MT outputs on
marketing content type of text from highly technical domain reveals that our
evaluation framework is quite effective in reflecting the MT output quality
regarding both overall system-level performance and segment-level transparency,
and it increases the IRR for error type interpretation. The approach has
several key advantages, such as ability to measure and compare less than
perfect MT output from different systems, ability to indicate human perception
of quality, immediate estimation of the labor effort required to bring MT
output to premium quality, low-cost and faster application, as well as higher
IRR. Our experimental data is available at
\url{https://github.com/lHan87/HOPE}.","['Serge Gladkoff', 'Lifeng Han']"
Fast Regularity-Constrained Plane Reconstruction,Computer Vision and Pattern Recognition,"Man-made environments typically comprise planar structures that exhibit
numerous geometric relationships, such as parallelism, coplanarity, and
orthogonality. Making full use of these relationships can considerably improve
the robustness of algorithmic plane reconstruction of complex scenes. This
research leverages a constraint model requiring minimal prior knowledge to
implicitly establish relationships among planes. We introduce a method based on
energy minimization to reconstruct the planes consistent with our constraint
model. The proposed algorithm is efficient, easily to understand, and simple to
implement. The experimental results show that our algorithm successfully
reconstructs planes under high percentages of noise and outliers. This is
superior to other state-of-the-art regularity-constrained plane reconstruction
methods in terms of speed and robustness.","['Yangbin Lin', 'Jialian Li', 'Cheng Wang', 'Zhonggui Chen', 'Zongyue Wang', 'Jonathan Li']"
"A Multi-body Tracking Framework - From Rigid Objects to Kinematic
  Structures",Computer Vision and Pattern Recognition,"Kinematic structures are very common in the real world. They range from
simple articulated objects to complex mechanical systems. However, despite
their relevance, most model-based 3D tracking methods only consider rigid
objects. To overcome this limitation, we propose a flexible framework that
allows the extension of existing 6DoF algorithms to kinematic structures. Our
approach focuses on methods that employ Newton-like optimization techniques,
which are widely used in object tracking. The framework considers both
tree-like and closed kinematic structures and allows a flexible configuration
of joints and constraints. To project equations from individual rigid bodies to
a multi-body system, Jacobians are used. For closed kinematic chains, a novel
formulation that features Lagrange multipliers is developed. In a detailed
mathematical proof, we show that our constraint formulation leads to an exact
kinematic solution and converges in a single iteration. Based on the proposed
framework, we extend ICG, which is a state-of-the-art rigid object tracking
algorithm, to multi-body tracking. For the evaluation, we create a
highly-realistic synthetic dataset that features a large number of sequences
and various robots. Based on this dataset, we conduct a wide variety of
experiments that demonstrate the excellent performance of the developed
framework and our multi-body tracker.","['Manuel Stoiber', 'Martin Sundermeyer', 'Wout Boerdijk', 'Rudolph Triebel']"
Dynamic Collaborative Filtering with Compound Poisson Factorization,Machine Learning,"Model-based collaborative filtering analyzes user-item interactions to infer
latent factors that represent user preferences and item characteristics in
order to predict future interactions. Most collaborative filtering algorithms
assume that these latent factors are static, although it has been shown that
user preferences and item perceptions drift over time. In this paper, we
propose a conjugate and numerically stable dynamic matrix factorization (DCPF)
based on compound Poisson matrix factorization that models the smoothly
drifting latent factors using Gamma-Markov chains. We propose a numerically
stable Gamma chain construction, and then present a stochastic variational
inference approach to estimate the parameters of our model. We apply our model
to time-stamped ratings data sets: Netflix, Yelp, and Last.fm, where DCPF
achieves a higher predictive accuracy than state-of-the-art static and dynamic
factorization models.","['Ghassen Jerfel', 'Mehmet E. Basbug', 'Barbara E. Engelhardt']"
An innovative solution for breast cancer textual big data analysis,Machine Learning (Statistics),"The digitalization of stored information in hospitals now allows for the
exploitation of medical data in text format, as electronic health records
(EHRs), initially gathered for other purposes than epidemiology. Manual search
and analysis operations on such data become tedious. In recent years, the use
of natural language processing (NLP) tools was highlighted to automatize the
extraction of information contained in EHRs, structure it and perform
statistical analysis on this structured information. The main difficulties with
the existing approaches is the requirement of synonyms or ontology
dictionaries, that are mostly available in English only and do not include
local or custom notations. In this work, a team composed of oncologists as
domain experts and data scientists develop a custom NLP-based system to process
and structure textual clinical reports of patients suffering from breast
cancer. The tool relies on the combination of standard text mining techniques
and an advanced synonym detection method. It allows for a global analysis by
retrieval of indicators such as medical history, tumor characteristics,
therapeutic responses, recurrences and prognosis. The versatility of the method
allows to obtain easily new indicators, thus opening up the way for
retrospective studies with a substantial reduction of the amount of manual
work. With no need for biomedical annotators or pre-defined ontologies, this
language-agnostic method reached an good extraction accuracy for several
concepts of interest, according to a comparison with a manually structured
file, without requiring any existing corpus with local or new notations.","['Nicolas Thiebaut', 'Antoine Simoulin', 'Karl Neuberger', 'Issam Ibnouhsein', 'Nicolas Bousquet', 'Nathalie Reix', 'Sébastien Molière', 'Carole Mathelin']"
"Relating Leverage Scores and Density using Regularized Christoffel
  Functions",Machine Learning,"Statistical leverage scores emerged as a fundamental tool for matrix
sketching and column sampling with applications to low rank approximation,
regression, random feature learning and quadrature. Yet, the very nature of
this quantity is barely understood. Borrowing ideas from the orthogonal
polynomial literature, we introduce the regularized Christoffel function
associated to a positive definite kernel. This uncovers a variational
formulation for leverage scores for kernel methods and allows to elucidate
their relationships with the chosen kernel as well as population density. Our
main result quantitatively describes a decreasing relation between leverage
score and population density for a broad class of kernels on Euclidean spaces.
Numerical simulations support our findings.","['Edouard Pauwels', 'Francis Bach', 'Jean-Philippe Vert']"
"Extremal GloVe: Theoretically Accurate Distributed Word Embedding by
  Tail Inference",Computation and Language (Natural Language Processing),"Distributed word embeddings such as Word2Vec and GloVe have been widely
adopted in industrial context settings. Major technical applications of GloVe
include recommender systems and natural language processing. The fundamental
theory behind GloVe relies on the selection of a weighting function in the
weighted least squres formulation that computes the powered ratio of word
occurrence count and the maximum word count in the corpus. However, the initial
formulation of GloVe is not theoretically sound in two aspects, namely the
selection of the weighting function and its power exponent is ad-hoc. In this
paper, we utilize the theory of extreme value analysis and propose a
theoretically accurate version of GloVe. By reformulating the weighted least
squares loss function as the expected loss function and accurately choosing the
power exponent, we create a theoretically accurate version of GloVe. We
demonstrate the competitiveness of our algorithm and show that the initial
formulation of GloVe with the suggested optimal parameter can be viewed as a
special case of our paradigm.",['Hao Wang']
"SONATA: Self-adaptive Evolutionary Framework for Hardware-aware Neural
  Architecture Search",Neural and Evolutionary Computing,"Recent advancements in Artificial Intelligence (AI), driven by Neural
Networks (NN), demand innovative neural architecture designs, particularly
within the constrained environments of Internet of Things (IoT) systems, to
balance performance and efficiency. HW-aware Neural Architecture Search
(HW-aware NAS) emerges as an attractive strategy to automate the design of NN
using multi-objective optimization approaches, such as evolutionary algorithms.
However, the intricate relationship between NN design parameters and HW-aware
NAS optimization objectives remains an underexplored research area, overlooking
opportunities to effectively leverage this knowledge to guide the search
process accordingly. Furthermore, the large amount of evaluation data produced
during the search holds untapped potential for refining the optimization
strategy and improving the approximation of the Pareto front. Addressing these
issues, we propose SONATA, a self-adaptive evolutionary algorithm for HW-aware
NAS. Our method leverages adaptive evolutionary operators guided by the learned
importance of NN design parameters. Specifically, through tree-based surrogate
models and a Reinforcement Learning agent, we aspire to gather knowledge on
'How' and 'When' to evolve NN architectures. Comprehensive evaluations across
various NAS search spaces and hardware devices on the ImageNet-1k dataset have
shown the merit of SONATA with up to 0.25% improvement in accuracy and up to
2.42x gains in latency and energy. Our SONATA has seen up to sim$93.6% Pareto
dominance over the native NSGA-II, further stipulating the importance of
self-adaptive evolution operators in HW-aware NAS.","['Halima Bouzidi', 'Smail Niar', 'Hamza Ouarnoughi', 'El-Ghazali Talbi']"
d-blink: Distributed End-to-End Bayesian Entity Resolution,Computation (Statistics),"Entity resolution (ER; also known as record linkage or de-duplication) is the
process of merging noisy databases, often in the absence of unique identifiers.
A major advancement in ER methodology has been the application of Bayesian
generative models, which provide a natural framework for inferring latent
entities with rigorous quantification of uncertainty. Despite these advantages,
existing models are severely limited in practice, as standard inference
algorithms scale quadratically in the number of records. While scaling can be
managed by fitting the model on separate blocks of the data, such a na\""ive
approach may induce significant error in the posterior. In this paper, we
propose a principled model for scalable Bayesian ER, called ""distributed
Bayesian linkage"" or d-blink, which jointly performs blocking and ER without
compromising posterior correctness. Our approach relies on several key ideas,
including: (i) an auxiliary variable representation that induces a partition of
the entities and records into blocks; (ii) a method for constructing
well-balanced blocks based on k-d trees; (iii) a distributed
partially-collapsed Gibbs sampler with improved mixing; and (iv) fast
algorithms for performing Gibbs updates. Empirical studies on six data
sets---including a case study on the 2010 Decennial Census---demonstrate the
scalability and effectiveness of our approach.","['Neil G. Marchant', 'Andee Kaplan', 'Daniel N. Elazar', 'Benjamin I. P. Rubinstein', 'Rebecca C. Steorts']"
"A Framework for Intelligent Medical Diagnosis using Rough Set with
  Formal Concept Analysis",Artificial Intelligence,"Medical diagnosis process vary in the degree to which they attempt to deal
with different complicating aspects of diagnosis such as relative importance of
symptoms, varied symptom pattern and the relation between diseases them selves.
Based on decision theory, in the past many mathematical models such as crisp
set, probability distribution, fuzzy set, intuitionistic fuzzy set were
developed to deal with complicating aspects of diagnosis. But, many such models
are failed to include important aspects of the expert decisions. Therefore, an
effort has been made to process inconsistencies in data being considered by
Pawlak with the introduction of rough set theory. Though rough set has major
advantages over the other methods, but it generates too many rules that create
many difficulties while taking decisions. Therefore, it is essential to
minimize the decision rules. In this paper, we use two processes such as pre
process and post process to mine suitable rules and to explore the relationship
among the attributes. In pre process we use rough set theory to mine suitable
rules, whereas in post process we use formal concept analysis from these
suitable rules to explore better knowledge and most important factors affecting
the decision making.","['B. K. Tripathy', 'D. P. Acharjya', 'V. Cynthya']"
Arabic Sentiment Analysis with Noisy Deep Explainable Model,Computation and Language (Natural Language Processing),"Sentiment Analysis (SA) is an indispensable task for many real-world
applications. Compared to limited resourced languages (i.e., Arabic, Bengali),
most of the research on SA are conducted for high resourced languages (i.e.,
English, Chinese). Moreover, the reasons behind any prediction of the Arabic
sentiment analysis methods exploiting advanced artificial intelligence
(AI)-based approaches are like black-box - quite difficult to understand. This
paper proposes an explainable sentiment classification framework for the Arabic
language by introducing a noise layer on Bi-Directional Long Short-Term Memory
(BiLSTM) and Convolutional Neural Networks (CNN)-BiLSTM models that overcome
over-fitting problem. The proposed framework can explain specific predictions
by training a local surrogate explainable model to understand why a particular
sentiment (positive or negative) is being predicted. We carried out experiments
on public benchmark Arabic SA datasets. The results concluded that adding noise
layers improves the performance in sentiment analysis for the Arabic language
by reducing overfitting and our method outperformed some known state-of-the-art
methods. In addition, the introduced explainability with noise layer could make
the model more transparent and accountable and hence help adopting AI-enabled
system in practice.","['Md. Atabuzzaman', 'Md Shajalal', 'Maksuda Bilkis Baby', 'Alexander Boden']"
"KoReA-SFL: Knowledge Replay-based Split Federated Learning Against
  Catastrophic Forgetting",Machine Learning,"Although Split Federated Learning (SFL) is good at enabling knowledge sharing
among resource-constrained clients, it suffers from the problem of low training
accuracy due to the neglect of data heterogeneity and catastrophic forgetting.
To address this issue, we propose a novel SFL approach named KoReA-SFL, which
adopts a multi-model aggregation mechanism to alleviate gradient divergence
caused by heterogeneous data and a knowledge replay strategy to deal with
catastrophic forgetting. Specifically, in KoReA-SFL cloud servers (i.e., fed
server and main server) maintain multiple branch model portions rather than a
global portion for local training and an aggregated master-model portion for
knowledge sharing among branch portions. To avoid catastrophic forgetting, the
main server of KoReA-SFL selects multiple assistant devices for knowledge
replay according to the training data distribution of each server-side
branch-model portion. Experimental results obtained from non-IID and IID
scenarios demonstrate that KoReA-SFL significantly outperforms conventional SFL
methods (by up to 23.25\% test accuracy improvement).","['Zeke Xia', 'Ming Hu', 'Dengke Yan', 'Ruixuan Liu', 'Anran Li', 'Xiaofei Xie', 'Mingsong Chen']"
Fusion Subspace Clustering for Incomplete Data,Machine Learning,"This paper introduces {\em fusion subspace clustering}, a novel method to
learn low-dimensional structures that approximate large scale yet highly
incomplete data. The main idea is to assign each datum to a subspace of its
own, and minimize the distance between the subspaces of all data, so that
subspaces of the same cluster get {\em fused} together. Our method allows low,
high, and even full-rank data; it directly accounts for noise, and its sample
complexity approaches the information-theoretic limit. In addition, our
approach provides a natural model selection {\em clusterpath}, and a direct
completion method. We give convergence guarantees, analyze computational
complexity, and show through extensive experiments on real and synthetic data
that our approach performs comparably to the state-of-the-art with complete
data, and dramatically better if data is missing.","['Usman Mahmood', 'Daniel Pimentel-Alarcón']"
Density Propagation with Characteristics-based Deep Learning,Dynamical Systems,"Uncertainty propagation in nonlinear dynamic systems remains an outstanding
problem in scientific computing and control. Numerous approaches have been
developed, but are limited in their capability to tackle problems with more
than a few uncertain variables or require large amounts of simulation data. In
this paper, we propose a data-driven method for approximating joint probability
density functions (PDFs) of nonlinear dynamic systems with initial condition
and parameter uncertainty. Our approach leverages on the power of deep learning
to deal with high-dimensional inputs, but we overcome the need for huge
quantities of training data by encoding PDF evolution equations directly into
the optimization problem. We demonstrate the potential of the proposed method
by applying it to evaluate the robustness of a feedback controller for a
six-dimensional rigid body with parameter uncertainty.","['Tenavi Nakamura-Zimmerer', 'Daniele Venturi', 'Qi Gong', 'Wei Kang']"
"Investigating the Impact of Independent Rule Fitnesses in a Learning
  Classifier System",Machine Learning,"Achieving at least some level of explainability requires complex analyses for
many machine learning systems, such as common black-box models. We recently
proposed a new rule-based learning system, SupRB, to construct compact,
interpretable and transparent models by utilizing separate optimizers for the
model selection tasks concerning rule discovery and rule set composition.This
allows users to specifically tailor their model structure to fulfil use-case
specific explainability requirements. From an optimization perspective, this
allows us to define clearer goals and we find that -- in contrast to many state
of the art systems -- this allows us to keep rule fitnesses independent. In
this paper we investigate this system's performance thoroughly on a set of
regression problems and compare it against XCSF, a prominent rule-based
learning system. We find the overall results of SupRB's evaluation comparable
to XCSF's while allowing easier control of model structure and showing a
substantially smaller sensitivity to random seeds and data splits. This
increased control can aid in subsequently providing explanations for both
training and final structure of the model.","['Michael Heider', 'Helena Stegherr', 'Jonathan Wurth', 'Roman Sraj', 'Jörg Hähner']"
Gaussian Quadrature for Kernel Features,Machine Learning,"Kernel methods have recently attracted resurgent interest, showing
performance competitive with deep neural networks in tasks such as speech
recognition. The random Fourier features map is a technique commonly used to
scale up kernel machines, but employing the randomized feature map means that
$O(\epsilon^{-2})$ samples are required to achieve an approximation error of at
most $\epsilon$. We investigate some alternative schemes for constructing
feature maps that are deterministic, rather than random, by approximating the
kernel in the frequency domain using Gaussian quadrature. We show that
deterministic feature maps can be constructed, for any $\gamma > 0$, to achieve
error $\epsilon$ with $O(e^{e^\gamma} + \epsilon^{-1/\gamma})$ samples as
$\epsilon$ goes to 0. Our method works particularly well with sparse ANOVA
kernels, which are inspired by the convolutional layer of CNNs. We validate our
methods on datasets in different domains, such as MNIST and TIMIT, showing that
deterministic features are faster to generate and achieve accuracy comparable
to the state-of-the-art kernel methods based on random Fourier features.","['Tri Dao', 'Christopher De Sa', 'Christopher Ré']"
"SmartPortraits: Depth Powered Handheld Smartphone Dataset of Human
  Portraits for State Estimation, Reconstruction and Synthesis",Computer Vision and Pattern Recognition,"We present a dataset of 1000 video sequences of human portraits recorded in
real and uncontrolled conditions by using a handheld smartphone accompanied by
an external high-quality depth camera. The collected dataset contains 200
people captured in different poses and locations and its main purpose is to
bridge the gap between raw measurements obtained from a smartphone and
downstream applications, such as state estimation, 3D reconstruction, view
synthesis, etc. The sensors employed in data collection are the smartphone's
camera and Inertial Measurement Unit (IMU), and an external Azure Kinect DK
depth camera software synchronized with sub-millisecond precision to the
smartphone system. During the recording, the smartphone flash is used to
provide a periodic secondary source of lightning. Accurate mask of the foremost
person is provided as well as its impact on the camera alignment accuracy. For
evaluation purposes, we compare multiple state-of-the-art camera alignment
methods by using a Motion Capture system. We provide a smartphone
visual-inertial benchmark for portrait capturing, where we report results for
multiple methods and motivate further use of the provided trajectories,
available in the dataset, in view synthesis and 3D reconstruction tasks.","['Anastasiia Kornilova', 'Marsel Faizullin', 'Konstantin Pakulev', 'Andrey Sadkov', 'Denis Kukushkin', 'Azat Akhmetyanov', 'Timur Akhtyamov', 'Hekmat Taherinejad', 'Gonzalo Ferrer']"
"3D Human Keypoints Estimation From Point Clouds in the Wild Without
  Human Labels",Computer Vision and Pattern Recognition,"Training a 3D human keypoint detector from point clouds in a supervised
manner requires large volumes of high quality labels. While it is relatively
easy to capture large amounts of human point clouds, annotating 3D keypoints is
expensive, subjective, error prone and especially difficult for long-tail cases
(pedestrians with rare poses, scooterists, etc.). In this work, we propose
GC-KPL - Geometry Consistency inspired Key Point Leaning, an approach for
learning 3D human joint locations from point clouds without human labels. We
achieve this by our novel unsupervised loss formulations that account for the
structure and movement of the human body. We show that by training on a large
training set from Waymo Open Dataset without any human annotated keypoints, we
are able to achieve reasonable performance as compared to the fully supervised
approach. Further, the backbone benefits from the unsupervised training and is
useful in downstream fewshot learning of keypoints, where fine-tuning on only
10 percent of the labeled training data gives comparable performance to
fine-tuning on the entire set. We demonstrated that GC-KPL outperforms by a
large margin over SoTA when trained on entire dataset and efficiently leverages
large volumes of unlabeled data.","['Zhenzhen Weng', 'Alexander S. Gorban', 'Jingwei Ji', 'Mahyar Najibi', 'Yin Zhou', 'Dragomir Anguelov']"
"Automatic tuning of communication protocols for vehicular ad hoc
  networks using metaheuristics",Neural and Evolutionary Computing,"The emerging field of vehicular ad hoc networks (VANETs) deals with a set of
communicating vehicles which are able to spontaneously interconnect without any
pre-existing infrastructure. In such kind of networks, it is crucial to make an
optimal configuration of the communication protocols previously to the final
network deployment. This way, a human designer can obtain an optimal QoS of the
network beforehand. The problem we consider in this work lies in configuring
the File Transfer protocol Configuration (FTC) with the aim of optimizing the
transmission time, the number of lost packets, and the amount of data
transferred in realistic VANET scenarios. We face the FTC with five
representative state-of-the-art optimization techniques and compare their
performance. These algorithms are: Particle Swarm Optimization (PSO),
Differential Evolution (DE), Genetic Algorithm (GA), Evolutionary Strategy
(ES), and Simulated Annealing (SA). For our tests, two typical environment
instances of VANETs for Urban and Highway scenarios have been defined. The
experiments using ns- 2 (a well-known realistic VANET simulator) reveal that
PSO outperforms all the compared algorithms for both studied VANET instances.","['José García-Nieto', 'Jamal Toutouh', 'Enrique Alba']"
"Non-asymptotic Oracle Inequalities for the High-Dimensional Cox
  Regression via Lasso",Statistics Theory,"We consider the finite sample properties of the regularized high-dimensional
Cox regression via lasso. Existing literature focuses on linear models or
generalized linear models with Lipschitz loss functions, where the empirical
risk functions are the summations of independent and identically distributed
(iid) losses. The summands in the negative log partial likelihood function for
censored survival data, however, are neither iid nor Lipschitz. We first
approximate the negative log partial likelihood function by a sum of iid
non-Lipschitz terms, then derive the non-asymptotic oracle inequalities for the
lasso penalized Cox regression using pointwise arguments to tackle the
difficulty caused by the lack of iid and Lipschitz property.","['Shengchun Kong', 'Bin Nan']"
Sentiment Analysis in the Era of Large Language Models: A Reality Check,Computation and Language (Natural Language Processing),"Sentiment analysis (SA) has been a long-standing research area in natural
language processing. It can offer rich insights into human sentiments and
opinions and has thus seen considerable interest from both academia and
industry. With the advent of large language models (LLMs) such as ChatGPT,
there is a great potential for their employment on SA problems. However, the
extent to which existing LLMs can be leveraged for different sentiment analysis
tasks remains unclear. This paper aims to provide a comprehensive investigation
into the capabilities of LLMs in performing various sentiment analysis tasks,
from conventional sentiment classification to aspect-based sentiment analysis
and multifaceted analysis of subjective texts. We evaluate performance across
13 tasks on 26 datasets and compare the results against small language models
(SLMs) trained on domain-specific datasets. Our study reveals that while LLMs
demonstrate satisfactory performance in simpler tasks, they lag behind in more
complex tasks requiring deeper understanding or structured sentiment
information. However, LLMs significantly outperform SLMs in few-shot learning
settings, suggesting their potential when annotation resources are limited. We
also highlight the limitations of current evaluation practices in assessing
LLMs' SA abilities and propose a novel benchmark, \textsc{SentiEval}, for a
more comprehensive and realistic evaluation. Data and code during our
investigations are available at
\url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}.","['Wenxuan Zhang', 'Yue Deng', 'Bing Liu', 'Sinno Jialin Pan', 'Lidong Bing']"
A Quantum Extension of Variational Bayes Inference,Machine Learning (Statistics),"Variational Bayes (VB) inference is one of the most important algorithms in
machine learning and widely used in engineering and industry. However, VB is
known to suffer from the problem of local optima. In this Letter, we generalize
VB by using quantum mechanics, and propose a new algorithm, which we call
quantum annealing variational Bayes (QAVB) inference. We then show that QAVB
drastically improve the performance of VB by applying them to a clustering
problem described by a Gaussian mixture model. Finally, we discuss an intuitive
understanding on how QAVB works well.","['Hideyuki Miyahara', 'Yuki Sughiyama']"
Sparse Gaussian Process Based On Hat Basis Functions,Machine Learning (Statistics),"Gaussian process is one of the most popular non-parametric Bayesian
methodologies for modeling the regression problem. It is completely determined
by its mean and covariance functions. And its linear property makes it
relatively straightforward to solve the prediction problem. Although Gaussian
process has been successfully applied in many fields, it is still not enough to
deal with physical systems that satisfy inequality constraints. This issue has
been addressed by the so-called constrained Gaussian process in recent years.
In this paper, we extend the core ideas of constrained Gaussian process.
According to the range of training or test data, we redefine the hat basis
functions mentioned in the constrained Gaussian process. Based on hat basis
functions, we propose a new sparse Gaussian process method to solve the
unconstrained regression problem. Similar to the exact Gaussian process and
Gaussian process with Fully Independent Training Conditional approximation, our
method obtains satisfactory approximate results on open-source datasets or
analytical functions. In terms of performance, the proposed method reduces the
overall computational complexity from $O(n^{3})$ computation in exact Gaussian
process to $O(nm^{2})$ with $m$ hat basis functions and $n$ training data
points.","['Wenqi Fang', 'Huiyun Li', 'Hui Huang', 'Shaobo Dang', 'Zhejun Huang', 'Zheng Wang']"
Automated Top View Registration of Broadcast Football Videos,Computer Vision and Pattern Recognition,"In this paper, we propose a novel method to register football broadcast video
frames on the static top view model of the playing surface. The proposed method
is fully automatic in contrast to the current state of the art which requires
manual initialization of point correspondences between the image and the static
model. Automatic registration using existing approaches has been difficult due
to the lack of sufficient point correspondences. We investigate an alternate
approach exploiting the edge information from the line markings on the field.
We formulate the registration problem as a nearest neighbour search over a
synthetically generated dictionary of edge map and homography pairs. The
synthetic dictionary generation allows us to exhaustively cover a wide variety
of camera angles and positions and reduce this problem to a minimal per-frame
edge map matching procedure. We show that the per-frame results can be improved
in videos using an optimization framework for temporal camera stabilization. We
demonstrate the efficacy of our approach by presenting extensive results on a
dataset collected from matches of football World Cup 2014.","['Rahul Anand Sharma', 'Bharath Bhat', 'Vineet Gandhi', 'C. V. Jawahar']"
"Fuzzy c-Shape: A new algorithm for clustering finite time series
  waveforms",Machine Learning,"The existence of large volumes of time series data in many applications has
motivated data miners to investigate specialized methods for mining time series
data. Clustering is a popular data mining method due to its powerful
exploratory nature and its usefulness as a preprocessing step for other data
mining techniques. This article develops two novel clustering algorithms for
time series data that are extensions of a crisp c-shapes algorithm. The two new
algorithms are heuristic derivatives of fuzzy c-means (FCM). Fuzzy c-Shapes
plus (FCS+) replaces the inner product norm in the FCM model with a shape-based
distance function. Fuzzy c-Shapes double plus (FCS++) uses the shape-based
distance, and also replaces the FCM cluster centers with shape-extracted
prototypes. Numerical experiments on 48 real time series data sets show that
the two new algorithms outperform state-of-the-art shape-based clustering
algorithms in terms of accuracy and efficiency. Four external cluster validity
indices (the Rand index, Adjusted Rand Index, Variation of Information, and
Normalized Mutual Information) are used to match candidate partitions generated
by each of the studied algorithms. All four indices agree that for these finite
waveform data sets, FCS++ gives a small improvement over FCS+, and in turn,
FCS+ is better than the original crisp c-shapes method. Finally, we apply two
tests of statistical significance to the three algorithms. The Wilcoxon and
Friedman statistics both rank the three algorithms in exactly the same way as
the four cluster validity indices.","['Fateme Fahiman', 'Jame C. Bezdek', 'Sarah M. Erfani', 'Christopher Leckie', 'Marimuthu Palaniswami']"
"Three dimensional unique identifier based automated georeferencing and
  coregistration of point clouds in underground environment",Computer Vision and Pattern Recognition,"Spatially and geometrically accurate laser scans are essential in modelling
infrastructure for applications in civil, mining and transportation. Monitoring
of underground or indoor environments such as mines or tunnels is challenging
due to unavailability of a sensor positioning framework, complicated
structurally symmetric layouts, repetitive features and occlusions. Current
practices largely include a manual selection of discernable reference points
for georeferencing and coregistration purpose. This study aims at overcoming
these practical challenges in underground or indoor laser scanning. The
developed approach involves automatically and uniquely identifiable three
dimensional unique identifiers (3DUIDs) in laser scans, and a 3D registration
(3DReG) workflow. Field testing of the method in an underground tunnel has been
found accurate, effective and efficient. Additionally, a method for
automatically extracting roadway tunnel profile has been exhibited. The
developed 3DUID can be used in roadway profile extraction, guided automation,
sensor calibration, reference targets for routine survey and deformation
monitoring.","['Sarvesh Kumar Singh', 'Bikram Pratap Banerjee', 'Simit Raval']"
Mechanisms for Automated Negotiation in State Oriented Domains,Artificial Intelligence,"This paper lays part of the groundwork for a domain theory of negotiation,
that is, a way of classifying interactions so that it is clear, given a domain,
which negotiation mechanisms and strategies are appropriate. We define State
Oriented Domains, a general category of interaction. Necessary and sufficient
conditions for cooperation are outlined. We use the notion of worth in an
altered definition of utility, thus enabling agreements in a wider class of
joint-goal reachable situations. An approach is offered for conflict
resolution, and it is shown that even in a conflict situation, partial
cooperative steps can be taken by interacting agents (that is, agents in
fundamental conflict might still agree to cooperate up to a certain point). A
Unified Negotiation Protocol (UNP) is developed that can be used in all types
of encounters. It is shown that in certain borderline cooperative situations, a
partial cooperative agreement (i.e., one that does not achieve all agents'
goals) might be preferred by all agents, even though there exists a rational
agreement that would achieve all their goals. Finally, we analyze cases where
agents have incomplete information on the goals and worth of other agents.
First we consider the case where agents' goals are private information, and we
analyze what goal declaration strategies the agents might adopt to increase
their utility. Then, we consider the situation where the agents' goals (and
therefore stand-alone costs) are common knowledge, but the worth they attach to
their goals is private information. We introduce two mechanisms, one 'strict',
the other 'tolerant', and analyze their affects on the stability and efficiency
of negotiation outcomes.","['G. Zlotkin', 'J. S. Rosenschein']"
Boosting Few-shot Semantic Segmentation with Transformers,Computer Vision and Pattern Recognition,"Due to the fact that fully supervised semantic segmentation methods require
sufficient fully-labeled data to work well and can not generalize to unseen
classes, few-shot segmentation has attracted lots of research attention.
Previous arts extract features from support and query images, which are
processed jointly before making predictions on query images. The whole process
is based on convolutional neural networks (CNN), leading to the problem that
only local information is used. In this paper, we propose a TRansformer-based
Few-shot Semantic segmentation method (TRFS). Specifically, our model consists
of two modules: Global Enhancement Module (GEM) and Local Enhancement Module
(LEM). GEM adopts transformer blocks to exploit global information, while LEM
utilizes conventional convolutions to exploit local information, across query
and support features. Both GEM and LEM are complementary, helping to learn
better feature representations for segmenting query images. Extensive
experiments on PASCAL-5i and COCO datasets show that our approach achieves new
state-of-the-art performance, demonstrating its effectiveness.","['Guolei Sun', 'Yun Liu', 'Jingyun Liang', 'Luc Van Gool']"
"Alleviating Search Bias in Bayesian Evolutionary Optimization with Many
  Heterogeneous Objectives",Neural and Evolutionary Computing,"Multi-objective optimization problems whose objectives have different
evaluation costs are commonly seen in the real world. Such problems are now
known as multi-objective optimization problems with heterogeneous objectives
(HE-MOPs). So far, however, only a few studies have been reported to address
HE-MOPs, and most of them focus on bi-objective problems with one fast
objective and one slow objective. In this work, we aim to deal with HE-MOPs
having more than two black-box and heterogeneous objectives. To this end, we
develop a multi-objective Bayesian evolutionary optimization approach to
HE-MOPs by exploiting the different data sets on the cheap and expensive
objectives in HE-MOPs to alleviate the search bias caused by the heterogeneous
evaluation costs for evaluating different objectives. To make the best use of
two different training data sets, one with solutions evaluated on all
objectives and the other with those only evaluated on the fast objectives, two
separate Gaussian process models are constructed. In addition, a new
acquisition function that mitigates search bias towards the fast objectives is
suggested, thereby achieving a balance between convergence and diversity. We
demonstrate the effectiveness of the proposed algorithm by testing it on widely
used multi-/many-objective benchmark problems whose objectives are assumed to
be heterogeneously expensive.","['Xilu Wang', 'Yaochu Jin', 'Sebastian Schmitt', 'Markus Olhofer']"
"Exploring Non-Convex Discrete Energy Landscapes: A Langevin-Like Sampler
  with Replica Exchange",Machine Learning,"Gradient-based Discrete Samplers (GDSs) are effective for sampling discrete
energy landscapes. However, they often stagnate in complex, non-convex
settings. To improve exploration, we introduce the Discrete Replica EXchangE
Langevin (DREXEL) sampler and its variant with Adjusted Metropolis (DREAM).
These samplers use two GDSs at different temperatures and step sizes: one
focuses on local exploitation, while the other explores broader energy
landscapes. When energy differences are significant, sample swaps occur, which
are determined by a mechanism tailored for discrete sampling to ensure detailed
balance. Theoretically, we prove both DREXEL and DREAM converge asymptotically
to the target energy and exhibit faster mixing than a single GDS. Experiments
further confirm their efficiency in exploring non-convex discrete energy
landscapes.","['Haoyang Zheng', 'Ruqi Zhang', 'Guang Lin']"
"Hierarchical Recurrent Neural Encoder for Video Representation with
  Application to Captioning",Computer Vision and Pattern Recognition,"Recently, deep learning approach, especially deep Convolutional Neural
Networks (ConvNets), have achieved overwhelming accuracy with fast processing
speed for image classification. Incorporating temporal structure with deep
ConvNets for video representation becomes a fundamental problem for video
content analysis. In this paper, we propose a new approach, namely Hierarchical
Recurrent Neural Encoder (HRNE), to exploit temporal information of videos.
Compared to recent video representation inference approaches, this paper makes
the following three contributions. First, our HRNE is able to efficiently
exploit video temporal structure in a longer range by reducing the length of
input information flow, and compositing multiple consecutive inputs at a higher
level. Second, computation operations are significantly lessened while
attaining more non-linearity. Third, HRNE is able to uncover temporal
transitions between frame chunks with different granularities, i.e., it can
model the temporal transitions between frames as well as the transitions
between segments. We apply the new method to video captioning where temporal
information plays a crucial role. Experiments demonstrate that our method
outperforms the state-of-the-art on video captioning benchmarks. Notably, even
using a single network with only RGB stream as input, HRNE beats all the recent
systems which combine multiple inputs, such as RGB ConvNet plus 3D ConvNet.","['Pingbo Pan', 'Zhongwen Xu', 'Yi Yang', 'Fei Wu', 'Yueting Zhuang']"
Dynamic Fault Analysis in Substations Based on Knowledge Graphs,Computation and Language (Natural Language Processing),"To address the challenge of identifying hidden danger in substations from
unstructured text, a novel dynamic analysis method is proposed. We first
extract relevant information from the unstructured text, and then leverages a
flexible distributed search engine built on Elastic-Search to handle the data.
Following this, the hidden Markov model is employed to train the data within
the engine. The Viterbi algorithm is integrated to decipher the hidden state
sequences, facilitating the segmentation and labeling of entities related to
hidden dangers. The final step involves using the Neo4j graph database to
dynamically create a knowledge graph that visualizes hidden dangers in the
substation. The effectiveness of the proposed method is demonstrated through a
case analysis from a specific substation with hidden dangers revealed in the
text records.","['Weiwei Li', 'Xing Liu', 'Wei Wang', 'Lu Chen', 'Sizhe Li', 'Hui Fan']"
"Analysing Multi-Task Regression via Random Matrix Theory with
  Application to Time Series Forecasting",Machine Learning (Statistics),"In this paper, we introduce a novel theoretical framework for multi-task
regression, applying random matrix theory to provide precise performance
estimations, under high-dimensional, non-Gaussian data distributions. We
formulate a multi-task optimization problem as a regularization technique to
enable single-task models to leverage multi-task learning information. We
derive a closed-form solution for multi-task optimization in the context of
linear models. Our analysis provides valuable insights by linking the
multi-task learning performance to various model statistics such as raw data
covariances, signal-generating hyperplanes, noise levels, as well as the size
and number of datasets. We finally propose a consistent estimation of training
and testing errors, thereby offering a robust foundation for hyperparameter
optimization in multi-task regression scenarios. Experimental validations on
both synthetic and real-world datasets in regression and multivariate time
series forecasting demonstrate improvements on univariate models, incorporating
our method into the training loss and thus leveraging multivariate information.","['Romain Ilbert', 'Malik Tiomoko', 'Cosme Louart', 'Ambroise Odonnat', 'Vasilii Feofanov', 'Themis Palpanas', 'Ievgen Redko']"
Assessing the Reliability of Large Language Model Knowledge,Computation and Language (Natural Language Processing),"Large language models (LLMs) have been treated as knowledge bases due to
their strong performance in knowledge probing tasks. LLMs are typically
evaluated using accuracy, yet this metric does not capture the vulnerability of
LLMs to hallucination-inducing factors like prompt and context variability. How
do we evaluate the capabilities of LLMs to consistently produce factually
correct answers? In this paper, we propose MOdel kNowledge relIabiliTy scORe
(MONITOR), a novel metric designed to directly measure LLMs' factual
reliability. MONITOR computes the distance between the probability
distributions of a valid output and its counterparts produced by the same LLM
probing the same fact using different styles of prompts and
contexts.Experiments on a comprehensive range of 12 LLMs demonstrate the
effectiveness of MONITOR in evaluating the factual reliability of LLMs while
maintaining a low computational overhead. In addition, we release the FKTC
(Factual Knowledge Test Corpus) test set, containing 210,158 prompts in total
to foster research along this line (https://github.com/Vicky-Wil/MONITOR).","['Weixuan Wang', 'Barry Haddow', 'Alexandra Birch', 'Wei Peng']"
A Contextual Bandit Approach for Stream-Based Active Learning,Machine Learning,"Contextual bandit algorithms -- a class of multi-armed bandit algorithms that
exploit the contextual information -- have been shown to be effective in
solving sequential decision making problems under uncertainty. A common
assumption adopted in the literature is that the realized (ground truth) reward
by taking the selected action is observed by the learner at no cost, which,
however, is not realistic in many practical scenarios. When observing the
ground truth reward is costly, a key challenge for the learner is how to
judiciously acquire the ground truth by assessing the benefits and costs in
order to balance learning efficiency and learning cost. From the information
theoretic perspective, a perhaps even more interesting question is how much
efficiency might be lost due to this cost. In this paper, we design a novel
contextual bandit-based learning algorithm and endow it with the active
learning capability. The key feature of our algorithm is that in addition to
sending a query to an annotator for the ground truth, prior information about
the ground truth learned by the learner is sent together, thereby reducing the
query cost. We prove that by carefully choosing the algorithm parameters, the
learning regret of the proposed algorithm achieves the same order as that of
conventional contextual bandit algorithms in cost-free scenarios, implying
that, surprisingly, cost due to acquiring the ground truth does not increase
the learning regret in the long-run. Our analysis shows that prior information
about the ground truth plays a critical role in improving the system
performance in scenarios where active learning is necessary.","['Linqi Song', 'Jie Xu']"
"Lost in Interpretation: Predicting Untranslated Terminology in
  Simultaneous Interpretation",Computation and Language (Natural Language Processing),"Simultaneous interpretation, the translation of speech from one language to
another in real-time, is an inherently difficult and strenuous task. One of the
greatest challenges faced by interpreters is the accurate translation of
difficult terminology like proper names, numbers, or other entities.
Intelligent computer-assisted interpreting (CAI) tools that could analyze the
spoken word and detect terms likely to be untranslated by an interpreter could
reduce translation error and improve interpreter performance. In this paper, we
propose a task of predicting which terminology simultaneous interpreters will
leave untranslated, and examine methods that perform this task using supervised
sequence taggers. We describe a number of task-specific features explicitly
designed to indicate when an interpreter may struggle with translating a word.
Experimental results on a newly-annotated version of the NAIST Simultaneous
Translation Corpus (Shimizu et al., 2014) indicate the promise of our proposed
method.","['Nikolai Vogler', 'Craig Stewart', 'Graham Neubig']"
PMODE: Prototypical Mask based Object Dimension Estimation,Computer Vision and Pattern Recognition,"Can a neural network estimate an object's dimension in the wild? In this
paper, we propose a method and deep learning architecture to estimate the
dimensions of a quadrilateral object of interest in videos using a monocular
camera. The proposed technique does not use camera calibration or handcrafted
geometric features; however, features are learned with the help of coefficients
of a segmentation neural network during the training process. A real-time
instance segmentation-based Deep Neural Network with a ResNet50 backbone is
employed, giving the object's prototype mask and thus provides a region of
interest to regress its dimensions. The instance segmentation network is
trained to look at only the nearest object of interest. The regression is
performed using an MLP head which looks only at the mask coefficients of the
bounding box detector head and the prototype segmentation mask. We trained the
system with three different random cameras achieving 22% MAPE for the test
dataset for the dimension estimation","['Thariq Khalid', 'Mohammed Yahya Hakami', 'Riad Souissi']"
The Six Fronts of the Generative Adversarial Networks,Computer Vision and Pattern Recognition,"Generative Adversarial Networks fostered a newfound interest in generative
models, resulting in a swelling wave of new works that new-coming researchers
may find formidable to surf. In this paper, we intend to help those
researchers, by splitting that incoming wave into six ""fronts"": Architectural
Contributions, Conditional Techniques, Normalization and Constraint
Contributions, Loss Functions, Image-to-image Translations, and Validation
Metrics. The division in fronts organizes literature into approachable blocks,
ultimately communicating to the reader how the area is evolving. Previous
surveys in the area, which this works also tabulates, focus on a few of those
fronts, leaving a gap that we propose to fill with a more integrated,
comprehensive overview. Here, instead of an exhaustive survey, we opt for a
straightforward review: our target is to be an entry point to this vast
literature, and also to be able to update experienced researchers to the newest
techniques.","['Alceu Bissoto', 'Eduardo Valle', 'Sandra Avila']"
Region-Based Incremental Pruning for POMDPs,Artificial Intelligence,"We present a major improvement to the incremental pruning algorithm for
solving partially observable Markov decision processes. Our technique targets
the cross-sum step of the dynamic programming (DP) update, a key source of
complexity in POMDP algorithms. Instead of reasoning about the whole belief
space when pruning the cross-sums, our algorithm divides the belief space into
smaller regions and performs independent pruning in each region. We evaluate
the benefits of the new technique both analytically and experimentally, and
show that it produces very significant performance gains. The results
contribute to the scalability of POMDP algorithms to domains that cannot be
handled by the best existing techniques.","['Zhengzhu Feng', 'Shlomo Zilberstein']"
"Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained
  Language Models",Computation and Language (Natural Language Processing),"Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich
in world knowledge. This fact has sparked the interest of the community in
quantifying the amount of factual knowledge present in PLMs, as this explains
their performance on downstream tasks, and potentially justifies their use as
knowledge bases. In this work, we survey methods and datasets that are used to
probe PLMs for factual knowledge. Our contributions are: (1) We propose a
categorization scheme for factual probing methods that is based on how their
inputs, outputs and the probed PLMs are adapted; (2) We provide an overview of
the datasets used for factual probing; (3) We synthesize insights about
knowledge retention and prompt optimization in PLMs, analyze obstacles to
adopting PLMs as knowledge bases and outline directions for future work.","['Paul Youssef', 'Osman Alperen Koraş', 'Meijie Li', 'Jörg Schlötterer', 'Christin Seifert']"
"Leveraging Constraint Programming in a Deep Learning Approach for
  Dynamically Solving the Flexible Job-Shop Scheduling Problem",Artificial Intelligence,"Recent advancements in the flexible job-shop scheduling problem (FJSSP) are
primarily based on deep reinforcement learning (DRL) due to its ability to
generate high-quality, real-time solutions. However, DRL approaches often fail
to fully harness the strengths of existing techniques such as exact methods or
constraint programming (CP), which can excel at finding optimal or near-optimal
solutions for smaller instances. This paper aims to integrate CP within a deep
learning (DL) based methodology, leveraging the benefits of both. In this
paper, we introduce a method that involves training a DL model using optimal
solutions generated by CP, ensuring the model learns from high-quality data,
thereby eliminating the need for the extensive exploration typical in DRL and
enhancing overall performance. Further, we integrate CP into our DL framework
to jointly construct solutions, utilizing DL for the initial complex stages and
transitioning to CP for optimal resolution as the problem is simplified. Our
hybrid approach has been extensively tested on three public FJSSP benchmarks,
demonstrating superior performance over five state-of-the-art DRL approaches
and a widely-used CP solver. Additionally, with the objective of exploring the
application to other combinatorial optimization problems, promising preliminary
results are presented on applying our hybrid approach to the traveling salesman
problem, combining an exact method with a well-known DRL method.","['Imanol Echeverria', 'Maialen Murua', 'Roberto Santana']"
"Representation Shattering in Transformers: A Synthetic Study with
  Knowledge Editing",Machine Learning,"Knowledge Editing (KE) algorithms alter models' weights to perform targeted
updates to incorrect, outdated, or otherwise unwanted factual associations. To
better identify the possibilities and limitations of these approaches, recent
work has shown that applying KE can adversely affect models' factual recall
accuracy and diminish their general reasoning abilities. While these studies
give broad insights into the potential harms of KE algorithms, e.g., via
performance evaluations on benchmarks, we argue little is understood as to why
such destructive failures occur. Is it possible KE methods distort
representations of concepts beyond the targeted fact, hence hampering abilities
at broad? If so, what is the extent of this distortion? Motivated by such
questions, we define a novel synthetic task wherein a Transformer is trained
from scratch to internalize a ""structured"" knowledge graph. The structure
enforces relationships between entities of the graph, such that editing a
factual association has ""trickling effects"" on other entities in the graph
(e.g., altering X's parent is Y to Z affects who X's siblings' parent is).
Through evaluations of edited models and analysis of extracted representations,
we show that KE inadvertently affects representations of entities beyond the
targeted one, distorting relevant structures that allow a model to infer unseen
knowledge about an entity. We call this phenomenon representation shattering
and demonstrate that it results in degradation of factual recall and reasoning
performance more broadly. To corroborate our findings in a more naturalistic
setup, we perform preliminary experiments with pre-trained Llama and Mamba
models, reproducing the representation shattering effect therein as well.
Overall, our work yields a precise mechanistic hypothesis to explain why KE has
adverse effects on model abilities.","['Kento Nishi', 'Maya Okawa', 'Rahul Ramesh', 'Mikail Khona', 'Hidenori Tanaka', 'Ekdeep Singh Lubana']"
FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine,Machine Learning,"Click through rate (CTR) estimation is a fundamental task in personalized
advertising and recommender systems. Recent years have witnessed the success of
both the deep learning based model and attention mechanism in various tasks in
computer vision (CV) and natural language processing (NLP). How to combine the
attention mechanism with deep CTR model is a promising direction because it may
ensemble the advantages of both sides. Although some CTR model such as
Attentional Factorization Machine (AFM) has been proposed to model the weight
of second order interaction features, we posit the evaluation of feature
importance before explicit feature interaction procedure is also important for
CTR prediction tasks because the model can learn to selectively highlight the
informative features and suppress less useful ones if the task has many input
features. In this paper, we propose a new neural CTR model named Field
Attentive Deep Field-aware Factorization Machine (FAT-DeepFFM) by combining the
Deep Field-aware Factorization Machine (DeepFFM) with Compose-Excitation
network (CENet) field attention mechanism which is proposed by us as an
enhanced version of Squeeze-Excitation network (SENet) to highlight the feature
importance. We conduct extensive experiments on two real-world datasets and the
experiment results show that FAT-DeepFFM achieves the best performance and
obtains different improvements over the state-of-the-art methods. We also
compare two kinds of attention mechanisms (attention before explicit feature
interaction vs. attention after explicit feature interaction) and demonstrate
that the former one outperforms the latter one significantly.","['Junlin Zhang', 'Tongwen Huang', 'Zhiqi Zhang']"
Adaptation and Self-Organization in Evolutionary Algorithms,Neural and Evolutionary Computing,"Abbreviated Abstract: The objective of Evolutionary Computation is to solve
practical problems (e.g. optimization, data mining) by simulating the
mechanisms of natural evolution. This thesis addresses several topics related
to adaptation and self-organization in evolving systems with the overall aims
of improving the performance of Evolutionary Algorithms (EA), understanding its
relation to natural evolution, and incorporating new mechanisms for mimicking
complex biological systems.",['James M Whitacre']
"Explainable Video Action Reasoning via Prior Knowledge and State
  Transitions",Computer Vision and Pattern Recognition,"Human action analysis and understanding in videos is an important and
challenging task. Although substantial progress has been made in past years,
the explainability of existing methods is still limited. In this work, we
propose a novel action reasoning framework that uses prior knowledge to explain
semantic-level observations of video state changes. Our method takes advantage
of both classical reasoning and modern deep learning approaches. Specifically,
prior knowledge is defined as the information of a target video domain,
including a set of objects, attributes and relationships in the target video
domain, as well as relevant actions defined by the temporal attribute and
relationship changes (i.e. state transitions). Given a video sequence, we first
generate a scene graph on each frame to represent concerned objects, attributes
and relationships. Then those scene graphs are linked by tracking objects
across frames to form a spatio-temporal graph (also called video graph), which
represents semantic-level video states. Finally, by sequentially examining each
state transition in the video graph, our method can detect and explain how
those actions are executed with prior knowledge, just like the logical manner
of thinking by humans. Compared to previous works, the action reasoning results
of our method can be explained by both logical rules and semantic-level
observations of video content changes. Besides, the proposed method can be used
to detect multiple concurrent actions with detailed information, such as who
(particular objects), when (time), where (object locations) and how (what kind
of changes). Experiments on a re-annotated dataset CAD-120 show the
effectiveness of our method.","['Tao Zhuo', 'Zhiyong Cheng', 'Peng Zhang', 'Yongkang Wong', 'Mohan Kankanhalli']"
Progressive Batching for Efficient Non-linear Least Squares,Computer Vision and Pattern Recognition,"Non-linear least squares solvers are used across a broad range of offline and
real-time model fitting problems. Most improvements of the basic Gauss-Newton
algorithm tackle convergence guarantees or leverage the sparsity of the
underlying problem structure for computational speedup. With the success of
deep learning methods leveraging large datasets, stochastic optimization
methods received recently a lot of attention. Our work borrows ideas from both
stochastic machine learning and statistics, and we present an approach for
non-linear least-squares that guarantees convergence while at the same time
significantly reduces the required amount of computation. Empirical results
show that our proposed method achieves competitive convergence rates compared
to traditional second-order approaches on common computer vision problems, such
as image alignment and essential matrix estimation, with very large numbers of
residuals.","['Huu Le', 'Christopher Zach', 'Edward Rosten', 'Oliver J. Woodford']"
Causally motivated Shortcut Removal Using Auxiliary Labels,Machine Learning,"Shortcut learning, in which models make use of easy-to-represent but unstable
associations, is a major failure mode for robust machine learning. We study a
flexible, causally-motivated approach to training robust predictors by
discouraging the use of specific shortcuts, focusing on a common setting where
a robust predictor could achieve optimal \emph{iid} generalization in
principle, but is overshadowed by a shortcut predictor in practice. Our
approach uses auxiliary labels, typically available at training time, to
enforce conditional independences implied by the causal graph. We show both
theoretically and empirically that causally-motivated regularization schemes
(a) lead to more robust estimators that generalize well under distribution
shift, and (b) have better finite sample efficiency compared to usual
regularization schemes, even when no shortcut is present. Our analysis
highlights important theoretical properties of training techniques commonly
used in the causal inference, fairness, and disentanglement literatures. Our
code is available at
https://github.com/mymakar/causally_motivated_shortcut_removal","['Maggie Makar', 'Ben Packer', 'Dan Moldovan', 'Davis Blalock', 'Yoni Halpern', ""Alexander D'Amour""]"
Deep Bayesian Bandits: Exploring in Online Personalized Recommendations,Machine Learning,"Recommender systems trained in a continuous learning fashion are plagued by
the feedback loop problem, also known as algorithmic bias. This causes a newly
trained model to act greedily and favor items that have already been engaged by
users. This behavior is particularly harmful in personalised ads
recommendations, as it can also cause new campaigns to remain unexplored.
Exploration aims to address this limitation by providing new information about
the environment, which encompasses user preference, and can lead to higher
long-term reward. In this work, we formulate a display advertising recommender
as a contextual bandit and implement exploration techniques that require
sampling from the posterior distribution of click-through-rates in a
computationally tractable manner. Traditional large-scale deep learning models
do not provide uncertainty estimates by default. We approximate these
uncertainty measurements of the predictions by employing a bootstrapped model
with multiple heads and dropout units. We benchmark a number of different
models in an offline simulation environment using a publicly available dataset
of user-ads engagements. We test our proposed deep Bayesian bandits algorithm
in the offline simulation and online AB setting with large-scale production
traffic, where we demonstrate a positive gain of our exploration model.","['Dalin Guo', 'Sofia Ira Ktena', 'Ferenc Huszar', 'Pranay Kumar Myana', 'Wenzhe Shi', 'Alykhan Tejani']"
Bayesian Nonparametric View to Spawning,Machine Learning,"In tracking multiple objects, it is often assumed that each observation
(measurement) is originated from one and only one object. However, we may
encounter a situation that each measurement may or may not be associated with
multiple objects at each time step --spawning. Therefore, the association of
each measurement to multiple objects is a crucial task to perform in order to
track multiple objects with birth and death. In this paper, we introduce a
novel Bayesian nonparametric approach that models a scenario where each
observation may be drawn from an unknown number of objects for which it
provides a tractable Markov chain Monte Carlo (MCMC) approach to sample from
the posterior distribution. The number of objects at each time step, itself, is
also assumed to be unknown. We, then, show through experiments the advantage of
nonparametric modeling to scenarios with spawning events. Our experiment
results also demonstrate the advantages of our framework over the existing
methods.",['Bahman Moraffah']
"A New General Method to Generate Random Modal Formulae for Testing
  Decision Procedures",Artificial Intelligence,"The recent emergence of heavily-optimized modal decision procedures has
highlighted the key role of empirical testing in this domain. Unfortunately,
the introduction of extensive empirical tests for modal logics is recent, and
so far none of the proposed test generators is very satisfactory. To cope with
this fact, we present a new random generation method that provides benefits
over previous methods for generating empirical tests. It fixes and much
generalizes one of the best-known methods, the random CNF_[]m test, allowing
for generating a much wider variety of problems, covering in principle the
whole input space. Our new method produces much more suitable test sets for the
current generation of modal decision procedures. We analyze the features of the
new method by means of an extensive collection of empirical tests.","['P. F. Patel-Schneider', 'R. Sebastiani']"
"Seeded Laplaican: An Eigenfunction Solution for Scribble Based
  Interactive Image Segmentation",Computer Vision and Pattern Recognition,"In this paper, we cast the scribble-based interactive image segmentation as a
semi-supervised learning problem. Our novel approach alleviates the need to
solve an expensive generalized eigenvector problem by approximating the
eigenvectors using efficiently computed eigenfunctions. The smoothness operator
defined on feature densities at the limit n tends to infinity recovers the
exact eigenvectors of the graph Laplacian, where n is the number of nodes in
the graph. To further reduce the computational complexity without scarifying
our accuracy, we select pivots pixels from user annotations. In our
experiments, we evaluate our approach using both human scribble and ""robot
user"" annotations to guide the foreground/background segmentation. We developed
a new unbiased collection of five annotated images datasets to standardize the
evaluation procedure for any scribble-based segmentation method. We
experimented with several variations, including different feature vectors,
pivot count and the number of eigenvectors. Experiments are carried out on
datasets that contain a wide variety of natural images. We achieve better
qualitative and quantitative results compared to state-of-the-art interactive
segmentation algorithms.","['Ahmed Taha', 'Marwan Torki']"
"Risk-Sensitive Reinforcement Learning Applied to Control under
  Constraints",Machine Learning,"In this paper, we consider Markov Decision Processes (MDPs) with error
states. Error states are those states entering which is undesirable or
dangerous. We define the risk with respect to a policy as the probability of
entering such a state when the policy is pursued. We consider the problem of
finding good policies whose risk is smaller than some user-specified threshold,
and formalize it as a constrained MDP with two criteria. The first criterion
corresponds to the value function originally given. We will show that the risk
can be formulated as a second criterion function based on a cumulative return,
whose definition is independent of the original value function. We present a
model free, heuristic reinforcement learning algorithm that aims at finding
good deterministic policies. It is based on weighting the original value
function and the risk. The weight parameter is adapted in order to find a
feasible solution for the constrained problem that has a good performance with
respect to the value function. The algorithm was successfully applied to the
control of a feed tank with stochastic inflows that lies upstream of a
distillation column. This control task was originally formulated as an optimal
control problem with chance constraints, and it was solved under certain
assumptions on the model to obtain an optimal solution. The power of our
learning algorithm is that it can be used even when some of these restrictive
assumptions are relaxed.","['P. Geibel', 'F. Wysotzki']"
An EM Approach to Non-autoregressive Conditional Sequence Generation,Machine Learning,"Autoregressive (AR) models have been the dominating approach to conditional
sequence generation, but are suffering from the issue of high inference
latency. Non-autoregressive (NAR) models have been recently proposed to reduce
the latency by generating all output tokens in parallel but could only achieve
inferior accuracy compared to their autoregressive counterparts, primarily due
to a difficulty in dealing with the multi-modality in sequence generation. This
paper proposes a new approach that jointly optimizes both AR and NAR models in
a unified Expectation-Maximization (EM) framework. In the E-step, an AR model
learns to approximate the regularized posterior of the NAR model. In the
M-step, the NAR model is updated on the new posterior and selects the training
examples for the next AR model. This iterative process can effectively guide
the system to remove the multi-modality in the output sequences. To our
knowledge, this is the first EM approach to NAR sequence generation. We
evaluate our method on the task of machine translation. Experimental results on
benchmark data sets show that the proposed approach achieves competitive, if
not better, performance with existing NAR models and significantly reduces the
inference latency.","['Zhiqing Sun', 'Yiming Yang']"
Self-supervised Graph Learning for Occasional Group Recommendation,Information Retrieval,"As an important branch in Recommender System, occasional group recommendation
has received more and more attention. In this scenario, each occasional group
(cold-start group) has no or few historical interacted items. As each
occasional group has extremely sparse interactions with items, traditional
group recommendation methods can not learn high-quality group representations.
The recent proposed Graph Neural Networks (GNNs), which incorporate the
high-order neighbors of the target occasional group, can alleviate the above
problem in some extent. However, these GNNs still can not explicitly strengthen
the embedding quality of the high-order neighbors with few interactions.
Motivated by the Self-supervised Learning technique, which is able to find the
correlations within the data itself, we propose a self-supervised graph
learning framework, which takes the user/item/group embedding reconstruction as
the pretext task to enhance the embeddings of the cold-start
users/items/groups. In order to explicitly enhance the high-order cold-start
neighbors' embedding quality, we further introduce an embedding enhancer, which
leverages the self-attention mechanism to improve the embedding quality for
them. Comprehensive experiments show the advantages of our proposed framework
than the state-of-the-art methods.","['Bowen Hao', 'Hongzhi Yin', 'Cuiping Li', 'Hong Chen']"
HeadlineCause: A Dataset of News Headlines for Detecting Causalities,Computation and Language (Natural Language Processing),"Detecting implicit causal relations in texts is a task that requires both
common sense and world knowledge. Existing datasets are focused either on
commonsense causal reasoning or explicit causal relations. In this work, we
present HeadlineCause, a dataset for detecting implicit causal relations
between pairs of news headlines. The dataset includes over 5000 headline pairs
from English news and over 9000 headline pairs from Russian news labeled
through crowdsourcing. The pairs vary from totally unrelated or belonging to
the same general topic to the ones including causation and refutation
relations. We also present a set of models and experiments that demonstrates
the dataset validity, including a multilingual XLM-RoBERTa based model for
causality detection and a GPT-2 based model for possible effects prediction.","['Ilya Gusev', 'Alexey Tikhonov']"
Machine-Assisted Map Editing,Computer Vision and Pattern Recognition,"Mapping road networks today is labor-intensive. As a result, road maps have
poor coverage outside urban centers in many countries. Systems to automatically
infer road network graphs from aerial imagery and GPS trajectories have been
proposed to improve coverage of road maps. However, because of high error
rates, these systems have not been adopted by mapping communities. We propose
machine-assisted map editing, where automatic map inference is integrated into
existing, human-centric map editing workflows. To realize this, we build
Machine-Assisted iD (MAiD), where we extend the web-based OpenStreetMap editor,
iD, with machine-assistance functionality. We complement MAiD with a novel
approach for inferring road topology from aerial imagery that combines the
speed of prior segmentation approaches with the accuracy of prior iterative
graph construction methods. We design MAiD to tackle the addition of major,
arterial roads in regions where existing maps have poor coverage, and the
incremental improvement of coverage in regions where major roads are already
mapped. We conduct two user studies and find that, when participants are given
a fixed time to map roads, they are able to add as much as 3.5x more roads with
MAiD.","['Favyen Bastani', 'Songtao He', 'Sofiane Abbar', 'Mohammad Alizadeh', 'Hari Balakrishnan', 'Sanjay Chawla', 'Sam Madden']"
Relaxed Contrastive Learning for Federated Learning,Machine Learning,"We propose a novel contrastive learning framework to effectively address the
challenges of data heterogeneity in federated learning. We first analyze the
inconsistency of gradient updates across clients during local training and
establish its dependence on the distribution of feature representations,
leading to the derivation of the supervised contrastive learning (SCL)
objective to mitigate local deviations. In addition, we show that a na\""ive
adoption of SCL in federated learning leads to representation collapse,
resulting in slow convergence and limited performance gains. To address this
issue, we introduce a relaxed contrastive learning loss that imposes a
divergence penalty on excessively similar sample pairs within each class. This
strategy prevents collapsed representations and enhances feature
transferability, facilitating collaborative training and leading to significant
performance improvements. Our framework outperforms all existing federated
learning approaches by huge margins on the standard benchmarks through
extensive experimental results.","['Seonguk Seo', 'Jinkyu Kim', 'Geeho Kim', 'Bohyung Han']"
pyBART: Evidence-based Syntactic Transformations for IE,Computation and Language (Natural Language Processing),"Syntactic dependencies can be predicted with high accuracy, and are useful
for both machine-learned and pattern-based information extraction tasks.
However, their utility can be improved. These syntactic dependencies are
designed to accurately reflect syntactic relations, and they do not make
semantic relations explicit. Therefore, these representations lack many
explicit connections between content words, that would be useful for downstream
applications. Proposals like English Enhanced UD improve the situation by
extending universal dependency trees with additional explicit arcs. However,
they are not available to Python users, and are also limited in coverage. We
introduce a broad-coverage, data-driven and linguistically sound set of
transformations, that makes event-structure and many lexical relations
explicit. We present pyBART, an easy-to-use open-source Python library for
converting English UD trees either to Enhanced UD graphs or to our
representation. The library can work as a standalone package or be integrated
within a spaCy NLP pipeline. When evaluated in a pattern-based relation
extraction scenario, our representation results in higher extraction scores
than Enhanced UD, while requiring fewer patterns.","['Aryeh Tiktinsky', 'Yoav Goldberg', 'Reut Tsarfaty']"
Business Intelligence from Web Usage Mining,Artificial Intelligence,"The rapid e-commerce growth has made both business community and customers
face a new situation. Due to intense competition on one hand and the customer's
option to choose from several alternatives business community has realized the
necessity of intelligent marketing strategies and relationship management. Web
usage mining attempts to discover useful knowledge from the secondary data
obtained from the interactions of the users with the Web. Web usage mining has
become very critical for effective Web site management, creating adaptive Web
sites, business and support services, personalization, network traffic flow
analysis and so on. In this paper, we present the important concepts of Web
usage mining and its various practical applications. We further present a novel
approach 'intelligent-miner' (i-Miner) to optimize the concurrent architecture
of a fuzzy clustering algorithm (to discover web data clusters) and a fuzzy
inference system to analyze the Web site visitor trends. A hybrid evolutionary
fuzzy clustering algorithm is proposed in this paper to optimally segregate
similar user interests. The clustered data is then used to analyze the trends
using a Takagi-Sugeno fuzzy inference system learned using a combination of
evolutionary algorithm and neural network learning. Proposed approach is
compared with self-organizing maps (to discover patterns) and several function
approximation techniques like neural networks, linear genetic programming and
Takagi-Sugeno fuzzy inference system (to analyze the clusters). The results are
graphically illustrated and the practical significance is discussed in detail.
Empirical results clearly show that the proposed Web usage-mining framework is
efficient.",['Ajith Abraham']
"Orthogonalized ALS: A Theoretically Principled Tensor Decomposition
  Algorithm for Practical Use",Machine Learning,"The popular Alternating Least Squares (ALS) algorithm for tensor
decomposition is efficient and easy to implement, but often converges to poor
local optima---particularly when the weights of the factors are non-uniform. We
propose a modification of the ALS approach that is as efficient as standard
ALS, but provably recovers the true factors with random initialization under
standard incoherence assumptions on the factors of the tensor. We demonstrate
the significant practical superiority of our approach over traditional ALS for
a variety of tasks on synthetic data---including tensor factorization on exact,
noisy and over-complete tensors, as well as tensor completion---and for
computing word embeddings from a third-order word tri-occurrence tensor.","['Vatsal Sharan', 'Gregory Valiant']"
"Detection of Real-world Driving-induced Affective State Using
  Physiological Signals and Multi-view Multi-task Machine Learning",Machine Learning,"Affective states have a critical role in driving performance and safety. They
can degrade driver situation awareness and negatively impact cognitive
processes, severely diminishing road safety. Therefore, detecting and assessing
drivers' affective states is crucial in order to help improve the driving
experience, and increase safety, comfort and well-being. Recent advances in
affective computing have enabled the detection of such states. This may lead to
empathic automotive user interfaces that account for the driver's emotional
state and influence the driver in order to improve safety. In this work, we
propose a multiview multi-task machine learning method for the detection of
driver's affective states using physiological signals. The proposed approach is
able to account for inter-drive variability in physiological responses while
enabling interpretability of the learned models, a factor that is especially
important in systems deployed in the real world. We evaluate the models on
three different datasets containing real-world driving experiences. Our results
indicate that accounting for drive-specific differences significantly improves
model performance.","['Daniel Lopez-Martinez', 'Neska El-Haouij', 'Rosalind Picard']"
Online Cluster Validity Indices for Streaming Data,Machine Learning (Statistics),"Cluster analysis is used to explore structure in unlabeled data sets in a
wide range of applications. An important part of cluster analysis is validating
the quality of computationally obtained clusters. A large number of different
internal indices have been developed for validation in the offline setting.
However, this concept has not been extended to the online setting. A key
challenge is to find an efficient incremental formulation of an index that can
capture both cohesion and separation of the clusters over potentially infinite
data streams. In this paper, we develop two online versions (with and without
forgetting factors) of the Xie-Beni and Davies-Bouldin internal validity
indices, and analyze their characteristics, using two streaming clustering
algorithms (sk-means and online ellipsoidal clustering), and illustrate their
use in monitoring evolving clusters in streaming data. We also show that
incremental cluster validity indices are capable of sending a distress signal
to online monitors when evolving clusters go awry. Our numerical examples
indicate that the incremental Xie-Beni index with forgetting factor is superior
to the other three indices tested.","['Masud Moshtaghi', 'James C. Bezdek', 'Sarah M. Erfani', 'Christopher Leckie', 'James Bailey']"
ReVar: Strengthening Policy Evaluation via Reduced Variance Sampling,Machine Learning,"This paper studies the problem of data collection for policy evaluation in
Markov decision processes (MDPs). In policy evaluation, we are given a target
policy and asked to estimate the expected cumulative reward it will obtain in
an environment formalized as an MDP. We develop theory for optimal data
collection within the class of tree-structured MDPs by first deriving an oracle
data collection strategy that uses knowledge of the variance of the reward
distributions. We then introduce the Reduced Variance Sampling (ReVar)
algorithm that approximates the oracle strategy when the reward variances are
unknown a priori and bound its sub-optimality compared to the oracle strategy.
Finally, we empirically validate that ReVar leads to policy evaluation with
mean squared error comparable to the oracle strategy and significantly lower
than simply running the target policy.","['Subhojyoti Mukherjee', 'Josiah P. Hanna', 'Robert Nowak']"
A Confidence-Based Approach for Balancing Fairness and Accuracy,Machine Learning,"We study three classical machine learning algorithms in the context of
algorithmic fairness: adaptive boosting, support vector machines, and logistic
regression. Our goal is to maintain the high accuracy of these learning
algorithms while reducing the degree to which they discriminate against
individuals because of their membership in a protected group.
  Our first contribution is a method for achieving fairness by shifting the
decision boundary for the protected group. The method is based on the theory of
margins for boosting. Our method performs comparably to or outperforms previous
algorithms in the fairness literature in terms of accuracy and low
discrimination, while simultaneously allowing for a fast and transparent
quantification of the trade-off between bias and error.
  Our second contribution addresses the shortcomings of the bias-error
trade-off studied in most of the algorithmic fairness literature. We
demonstrate that even hopelessly naive modifications of a biased algorithm,
which cannot be reasonably said to be fair, can still achieve low bias and high
accuracy. To help to distinguish between these naive algorithms and more
sensible algorithms we propose a new measure of fairness, called resilience to
random bias (RRB). We demonstrate that RRB distinguishes well between our naive
and sensible fairness algorithms. RRB together with bias and accuracy provides
a more complete picture of the fairness of an algorithm.","['Benjamin Fish', 'Jeremy Kun', 'Ádám D. Lelkes']"
cycle text2face: cycle text-to-face gan via transformers,Computer Vision and Pattern Recognition,"Text-to-face is a subset of text-to-image that require more complex
architecture due to their more detailed production. In this paper, we present
an encoder-decoder model called Cycle Text2Face. Cycle Text2Face is a new
initiative in the encoder part, it uses a sentence transformer and GAN to
generate the image described by the text. The Cycle is completed by reproducing
the text of the face in the decoder part of the model. Evaluating the model
using the CelebA dataset, leads to better results than previous GAN-based
models. In measuring the quality of the generate face, in addition to
satisfying the human audience, we obtain an FID score of 3.458. This model,
with high-speed processing, provides quality face images in the short time.","['Faezeh Gholamrezaie', 'Mohammad Manthouri']"
Class Equilibrium using Coulomb's Law,Computer Vision and Pattern Recognition,"Projection algorithms learn a transformation function to project the data
from input space to the feature space, with the objective of increasing the
inter-class distance. However, increasing the inter-class distance can affect
the intra-class distance. Maintaining an optimal inter-class separation among
the classes without affecting the intra-class distance of the data distribution
is a challenging task. In this paper, inspired by the Coulomb's law of
Electrostatics, we propose a new algorithm to compute the equilibrium space of
any data distribution where the separation among the classes is optimal. The
algorithm further learns the transformation between the input space and
equilibrium space to perform classification in the equilibrium space. The
performance of the proposed algorithm is evaluated on four publicly available
datasets at three different resolutions. It is observed that the proposed
algorithm performs well for low-resolution images.","['Saheb Chhabra', 'Puspita Majumdar', 'Mayank Vatsa', 'Richa Singh']"
"The Stable Entropy Hypothesis and Entropy-Aware Decoding: An Analysis
  and Algorithm for Robust Natural Language Generation",Computation and Language (Natural Language Processing),"State-of-the-art language generation models can degenerate when applied to
open-ended generation problems such as text completion, story generation, or
dialog modeling. This degeneration usually shows up in the form of incoherence,
lack of vocabulary diversity, and self-repetition or copying from the context.
In this paper, we postulate that ``human-like'' generations usually lie in a
narrow and nearly flat entropy band, and violation of these entropy bounds
correlates with degenerate behavior. Our experiments show that this stable
narrow entropy zone exists across models, tasks, and domains and confirm the
hypothesis that violations of this zone correlate with degeneration. We then
use this insight to propose an entropy-aware decoding algorithm that respects
these entropy bounds resulting in less degenerate, more contextual, and
""human-like"" language generation in open-ended text generation settings.","['Kushal Arora', ""Timothy J. O'Donnell"", 'Doina Precup', 'Jason Weston', 'Jackie C. K. Cheung']"
"A framework for fake review detection in online consumer electronics
  retailers",Computation and Language (Natural Language Processing),"The impact of online reviews on businesses has grown significantly during
last years, being crucial to determine business success in a wide array of
sectors, ranging from restaurants, hotels to e-commerce. Unfortunately, some
users use unethical means to improve their online reputation by writing fake
reviews of their businesses or competitors. Previous research has addressed
fake review detection in a number of domains, such as product or business
reviews in restaurants and hotels. However, in spite of its economical
interest, the domain of consumer electronics businesses has not yet been
thoroughly studied. This article proposes a feature framework for detecting
fake reviews that has been evaluated in the consumer electronics domain. The
contributions are fourfold: (i) Construction of a dataset for classifying fake
reviews in the consumer electronics domain in four different cities based on
scraping techniques; (ii) definition of a feature framework for fake review
detection; (iii) development of a fake review classification method based on
the proposed framework and (iv) evaluation and analysis of the results for each
of the cities under study. We have reached an 82% F-Score on the classification
task and the Ada Boost classifier has been proven to be the best one by
statistical means according to the Friedman test.","['Rodrigo Barbado', 'Oscar Araque', 'Carlos A. Iglesias']"
K-BERT: Enabling Language Representation with Knowledge Graph,Computation and Language (Natural Language Processing),"Pre-trained language representation models, such as BERT, capture a general
language representation from large-scale corpora, but lack domain-specific
knowledge. When reading a domain text, experts make inferences with relevant
knowledge. For machines to achieve this capability, we propose a
knowledge-enabled language representation model (K-BERT) with knowledge graphs
(KGs), in which triples are injected into the sentences as domain knowledge.
However, too much knowledge incorporation may divert the sentence from its
correct meaning, which is called knowledge noise (KN) issue. To overcome KN,
K-BERT introduces soft-position and visible matrix to limit the impact of
knowledge. K-BERT can easily inject domain knowledge into the models by
equipped with a KG without pre-training by-self because it is capable of
loading model parameters from the pre-trained BERT. Our investigation reveals
promising results in twelve NLP tasks. Especially in domain-specific tasks
(including finance, law, and medicine), K-BERT significantly outperforms BERT,
which demonstrates that K-BERT is an excellent choice for solving the
knowledge-driven problems that require experts.","['Weijie Liu', 'Peng Zhou', 'Zhe Zhao', 'Zhiruo Wang', 'Qi Ju', 'Haotang Deng', 'Ping Wang']"
"CHOPT : Automated Hyperparameter Optimization Framework for Cloud-Based
  Machine Learning Platforms",Machine Learning,"Many hyperparameter optimization (HyperOpt) methods assume restricted
computing resources and mainly focus on enhancing performance. Here we propose
a novel cloud-based HyperOpt (CHOPT) framework which can efficiently utilize
shared computing resources while supporting various HyperOpt algorithms. We
incorporate convenient web-based user interfaces, visualization, and analysis
tools, enabling users to easily control optimization procedures and build up
valuable insights with an iterative analysis procedure. Furthermore, our
framework can be incorporated with any cloud platform, thus complementarily
increasing the efficiency of conventional deep learning frameworks. We
demonstrate applications of CHOPT with tasks such as image recognition and
question-answering, showing that our framework can find hyperparameter
configurations competitive with previous work. We also show CHOPT is capable of
providing interesting observations through its analysing tools","['Jinwoong Kim', 'Minkyu Kim', 'Heungseok Park', 'Ernar Kusdavletov', 'Dongjun Lee', 'Adrian Kim', 'Ji-Hoon Kim', 'Jung-Woo Ha', 'Nako Sung']"
Bayesian Optimisation over Multiple Continuous and Categorical Inputs,Machine Learning (Statistics),"Efficient optimisation of black-box problems that comprise both continuous
and categorical inputs is important, yet poses significant challenges. We
propose a new approach, Continuous and Categorical Bayesian Optimisation
(CoCaBO), which combines the strengths of multi-armed bandits and Bayesian
optimisation to select values for both categorical and continuous inputs. We
model this mixed-type space using a Gaussian Process kernel, designed to allow
sharing of information across multiple categorical variables, each with
multiple possible values; this allows CoCaBO to leverage all available data
efficiently. We extend our method to the batch setting and propose an efficient
selection procedure that dynamically balances exploration and exploitation
whilst encouraging batch diversity. We demonstrate empirically that our method
outperforms existing approaches on both synthetic and real-world optimisation
tasks with continuous and categorical inputs.","['Binxin Ru', 'Ahsan S. Alvi', 'Vu Nguyen', 'Michael A. Osborne', 'Stephen J Roberts']"
Interpretable Word Embeddings via Informative Priors,Computation and Language (Natural Language Processing),"Word embeddings have demonstrated strong performance on NLP tasks. However,
lack of interpretability and the unsupervised nature of word embeddings have
limited their use within computational social science and digital humanities.
We propose the use of informative priors to create interpretable and
domain-informed dimensions for probabilistic word embeddings. Experimental
results show that sensible priors can capture latent semantic concepts better
than or on-par with the current state of the art, while retaining the
simplicity and generalizability of using priors.","['Miriam Hurtado Bodell', 'Martin Arvidsson', 'Måns Magnusson']"
FLIC: Fast Linear Iterative Clustering with Active Search,Computer Vision and Pattern Recognition,"Benefiting from its high efficiency and simplicity, Simple Linear Iterative
Clustering (SLIC) remains one of the most popular over-segmentation tools.
However, due to explicit enforcement of spatial similarity for region
continuity, the boundary adaptation of SLIC is sub-optimal. It also has
drawbacks on convergence rate as a result of both the fixed search region and
separately doing the assignment step and the update step. In this paper, we
propose an alternative approach to fix the inherent limitations of SLIC. In our
approach, each pixel actively searches its corresponding segment under the help
of its neighboring pixels, which naturally enables region coherence without
being harmful to boundary adaptation. We also jointly perform the assignment
and update steps, allowing high convergence rate. Extensive evaluations on
Berkeley segmentation benchmark verify that our method outperforms competitive
methods under various evaluation metrics. It also has the lowest time cost
among existing methods (approximately 30fps for a 481x321 image on a single CPU
core).","['Jiaxing Zhao', 'Ren Bo', 'Qibin Hou', 'Ming-Ming Cheng', 'Paul L. Rosin']"
"MSS-PAE: Saving Autoencoder-based Outlier Detection from Unexpected
  Reconstruction",Machine Learning,"AutoEncoders (AEs) are commonly used for machine learning tasks due to their
intrinsic learning ability. This unique characteristic can be capitalized for
Outlier Detection (OD). However conventional AE-based methods face the issue of
overconfident decisions and unexpected reconstruction results of outliers,
limiting their performance in OD. To mitigate these issues, the Mean Squared
Error (MSE) and Negative Logarithmic Likelihood (NLL) were firstly analyzed,
and the importance of incorporating aleatoric uncertainty to AE-based OD was
elucidated. Then the Weighted Negative Logarithmic Likelihood (WNLL) was
proposed to adjust for the effect of uncertainty for different OD scenarios.
Moreover, the Mean-Shift Scoring (MSS) method was proposed to utilize the local
relationship of data to reduce the issue of false inliers caused by AE.
Experiments on 32 real-world OD datasets proved the effectiveness of the
proposed methods. The combination of WNLL and MSS achieved 41% relative
performance improvement compared to the best baseline. In addition, MSS
improved the detection performance of multiple AE-based outlier detectors by an
average of 20%. The proposed methods have the potential to advance AE's
development in OD.","['Xu Tan', 'Jiawei Yang', 'Junqi Chen', 'Sylwan Rahardja', 'Susanto Rahardja']"
The Ikshana Hypothesis of Human Scene Understanding,Computer Vision and Pattern Recognition,"In recent years, deep neural networks (DNNs) achieved state-of-the-art
performance on several computer vision tasks. However, the one typical drawback
of these DNNs is the requirement of massive labeled data. Even though few-shot
learning methods address this problem, they often use techniques such as
meta-learning and metric-learning on top of the existing methods. In this work,
we address this problem from a neuroscience perspective by proposing a
hypothesis named Ikshana, which is supported by several findings in
neuroscience. Our hypothesis approximates the refining process of conceptual
gist in the human brain while understanding a natural scene/image. While our
hypothesis holds no particular novelty in neuroscience, it provides a novel
perspective for designing DNNs for vision tasks. By following the Ikshana
hypothesis, we design a novel neural-inspired CNN architecture named
IkshanaNet. The empirical results demonstrate the effectiveness of our method
by outperforming several baselines on the entire and subsets of the Cityscapes
and the CamVid semantic segmentation benchmarks.",['Venkata Satya Sai Ajay Daliparthi']
Dynamic Privacy For Distributed Machine Learning Over Network,Machine Learning,"Privacy-preserving distributed machine learning becomes increasingly
important due to the recent rapid growth of data. This paper focuses on a class
of regularized empirical risk minimization (ERM) machine learning problems, and
develops two methods to provide differential privacy to distributed learning
algorithms over a network. We first decentralize the learning algorithm using
the alternating direction method of multipliers (ADMM), and propose the methods
of dual variable perturbation and primal variable perturbation to provide
dynamic differential privacy. The two mechanisms lead to algorithms that can
provide privacy guarantees under mild conditions of the convexity and
differentiability of the loss function and the regularizer. We study the
performance of the algorithms, and show that the dual variable perturbation
outperforms its primal counterpart. To design an optimal privacy mechanisms, we
analyze the fundamental tradeoff between privacy and accuracy, and provide
guidelines to choose privacy parameters. Numerical experiments using customer
information database are performed to corroborate the results on privacy and
utility tradeoffs and design.","['Tao Zhang', 'Quanyan Zhu']"
"PANDA: AdaPtive Noisy Data Augmentation for Regularization of Undirected
  Graphical Models",Machine Learning (Statistics),"We propose an AdaPtive Noise Augmentation (PANDA) technique to regularize the
estimation and construction of undirected graphical models. PANDA iteratively
optimizes the objective function given the noise augmented data until
convergence to achieve regularization on model parameters. The augmented noises
can be designed to achieve various regularization effects on graph estimation,
such as the bridge (including lasso and ridge), elastic net, adaptive lasso,
and SCAD penalization; it also realizes the group lasso and fused ridge. We
examine the tail bound of the noise-augmented loss function and establish that
the noise-augmented loss function and its minimizer converge almost surely to
the expected penalized loss function and its minimizer, respectively. We derive
the asymptotic distributions for the regularized parameters through PANDA in
generalized linear models, based on which, inferences for the parameters can be
obtained simultaneously with variable selection. We show the non-inferior
performance of PANDA in constructing graphs of different types in simulation
studies and apply PANDA to an autism spectrum disorder data to construct a
mixed-node graph. We also show that the inferences based on the asymptotic
distribution of regularized parameter estimates via PANDA achieve nominal or
near-nominal coverage and are far more efficient, compared to some existing
post-selection procedures. Computationally, PANDA can be easily programmed in
software that implements (GLMs) without resorting to complicated optimization
techniques.","['Yinan Li', 'Xiao Liu', 'Fang Liu']"
"Forecasting Individualized Disease Trajectories using Interpretable Deep
  Learning",Machine Learning,"Disease progression models are instrumental in predicting individual-level
health trajectories and understanding disease dynamics. Existing models are
capable of providing either accurate predictions of patients prognoses or
clinically interpretable representations of disease pathophysiology, but not
both. In this paper, we develop the phased attentive state space (PASS) model
of disease progression, a deep probabilistic model that captures complex
representations for disease progression while maintaining clinical
interpretability. Unlike Markovian state space models which assume memoryless
dynamics, PASS uses an attention mechanism to induce ""memoryful"" state
transitions, whereby repeatedly updated attention weights are used to focus on
past state realizations that best predict future states. This gives rise to
complex, non-stationary state dynamics that remain interpretable through the
generated attention weights, which designate the relationships between the
realized state variables for individual patients. PASS uses phased LSTM units
(with time gates controlled by parametrized oscillations) to generate the
attention weights in continuous time, which enables handling
irregularly-sampled and potentially missing medical observations. Experiments
on data from a realworld cohort of patients show that PASS successfully
balances the tradeoff between accuracy and interpretability: it demonstrates
superior predictive accuracy and learns insightful individual-level
representations of disease progression.","['Ahmed M. Alaa', 'Mihaela van der Schaar']"
"Contrastive learning of global and local features for medical image
  segmentation with limited annotations",Computer Vision and Pattern Recognition,"A key requirement for the success of supervised deep learning is a large
labeled dataset - a condition that is difficult to meet in medical image
analysis. Self-supervised learning (SSL) can help in this regard by providing a
strategy to pre-train a neural network with unlabeled data, followed by
fine-tuning for a downstream task with limited annotations. Contrastive
learning, a particular variant of SSL, is a powerful technique for learning
image-level representations. In this work, we propose strategies for extending
the contrastive learning framework for segmentation of volumetric medical
images in the semi-supervised setting with limited annotations, by leveraging
domain-specific and problem-specific cues. Specifically, we propose (1) novel
contrasting strategies that leverage structural similarity across volumetric
medical images (domain-specific cue) and (2) a local version of the contrastive
loss to learn distinctive representations of local regions that are useful for
per-pixel segmentation (problem-specific cue). We carry out an extensive
evaluation on three Magnetic Resonance Imaging (MRI) datasets. In the limited
annotation setting, the proposed method yields substantial improvements
compared to other self-supervision and semi-supervised learning techniques.
When combined with a simple data augmentation technique, the proposed method
reaches within 8% of benchmark performance using only two labeled MRI volumes
for training, corresponding to only 4% (for ACDC) of the training data used to
train the benchmark. The code is made public at
https://github.com/krishnabits001/domain_specific_cl.","['Krishna Chaitanya', 'Ertunc Erdil', 'Neerav Karani', 'Ender Konukoglu']"
"No Free Lunch But A Cheaper Supper: A General Framework for Streaming
  Anomaly Detection",Machine Learning,"In recent years, there has been increased research interest in detecting
anomalies in temporal streaming data. A variety of algorithms have been
developed in the data mining community, which can be divided into two
categories (i.e., general and ad hoc). In most cases, general approaches assume
the one-size-fits-all solution model where a single anomaly detector can detect
all anomalies in any domain. To date, there exists no single general method
that has been shown to outperform the others across different anomaly types,
use cases and datasets. In this paper, we propose SAFARI, a general framework
formulated by abstracting and unifying the fundamental tasks in streaming
anomaly detection, which provides a flexible and extensible anomaly detection
procedure to overcome the limitations of one-size-fits-all solutions. SAFARI
helps to facilitate more elaborate algorithm comparisons by allowing us to
isolate the effects of shared and unique characteristics of different
algorithms on detection performance. Using SAFARI, we have implemented various
anomaly detectors and identified a research gap that motivates us to propose a
novel learning strategy in this work. We conducted an extensive evaluation
study of 20 detectors that are composed using SAFARI and compared their
performances using real-world benchmark datasets with different properties. The
results indicate that there is no single superior detector that works well for
every case, proving our hypothesis that ""there is no free lunch"" in the
streaming anomaly detection world. Finally, we discuss the benefits and
drawbacks of each method in-depth and draw a set of conclusions to guide future
users of SAFARI.","['Ece Calikus', 'Slawomir Nowaczyk', ""Anita Sant'Anna"", 'Onur Dikmen']"
Beyond SOT: Tracking Multiple Generic Objects at Once,Computer Vision and Pattern Recognition,"Generic Object Tracking (GOT) is the problem of tracking target objects,
specified by bounding boxes in the first frame of a video. While the task has
received much attention in the last decades, researchers have almost
exclusively focused on the single object setting. Multi-object GOT benefits
from a wider applicability, rendering it more attractive in real-world
applications. We attribute the lack of research interest into this problem to
the absence of suitable benchmarks. In this work, we introduce a new
large-scale GOT benchmark, LaGOT, containing multiple annotated target objects
per sequence. Our benchmark allows users to tackle key remaining challenges in
GOT, aiming to increase robustness and reduce computation through joint
tracking of multiple objects simultaneously. In addition, we propose a
transformer-based GOT tracker baseline capable of joint processing of multiple
objects through shared computation. Our approach achieves a 4x faster run-time
in case of 10 concurrent objects compared to tracking each object independently
and outperforms existing single object trackers on our new benchmark. In
addition, our approach achieves highly competitive results on single-object GOT
datasets, setting a new state of the art on TrackingNet with a success rate AUC
of 84.4%. Our benchmark, code, and trained models will be made publicly
available.","['Christoph Mayer', 'Martin Danelljan', 'Ming-Hsuan Yang', 'Vittorio Ferrari', 'Luc Van Gool', 'Alina Kuznetsova']"
"Bayesian Inference of Regular Expressions from Human-Generated Example
  Strings",Artificial Intelligence,"In programming by example, users ""write"" programs by generating a small
number of input-output examples and asking the computer to synthesize
consistent programs. We consider a challenging problem in this domain: learning
regular expressions (regexes) from positive and negative example strings. This
problem is challenging, as (1) user-generated examples may not be informative
enough to sufficiently constrain the hypothesis space, and (2) even if
user-generated examples are in principle informative, there is still a massive
search space to examine. We frame regex induction as the problem of inferring a
probabilistic regular grammar and propose an efficient inference approach that
uses a novel stochastic process recognition model. This model incrementally
""grows"" a grammar using positive examples as a scaffold. We show that this
approach is competitive with human ability to learn regexes from examples.",['Long Ouyang']
"A Multilingual Information Extraction Pipeline for Investigative
  Journalism",Computation and Language (Natural Language Processing),"We introduce an advanced information extraction pipeline to automatically
process very large collections of unstructured textual data for the purpose of
investigative journalism. The pipeline serves as a new input processor for the
upcoming major release of our New/s/leak 2.0 software, which we develop in
cooperation with a large German news organization. The use case is that
journalists receive a large collection of files up to several Gigabytes
containing unknown contents. Collections may originate either from official
disclosures of documents, e.g. Freedom of Information Act requests, or
unofficial data leaks. Our software prepares a visually-aided exploration of
the collection to quickly learn about potential stories contained in the data.
It is based on the automatic extraction of entities and their co-occurrence in
documents. In contrast to comparable projects, we focus on the following three
major requirements particularly serving the use case of investigative
journalism in cross-border collaborations: 1) composition of multiple
state-of-the-art NLP tools for entity extraction, 2) support of multi-lingual
document sets up to 40 languages, 3) fast and easy-to-use extraction of
full-text, metadata and entities from various file formats.","['Gregor Wiedemann', 'Seid Muhie Yimam', 'Chris Biemann']"
Adaptive Training of Random Mapping for Data Quantization,Machine Learning,"Data quantization learns encoding results of data with certain requirements,
and provides a broad perspective of many real-world applications to data
handling. Nevertheless, the results of encoder is usually limited to
multivariate inputs with the random mapping, and side information of binary
codes are hardly to mostly depict the original data patterns as possible. In
the literature, cosine based random quantization has attracted much attentions
due to its intrinsic bounded results. Nevertheless, it usually suffers from the
uncertain outputs, and information of original data fails to be fully preserved
in the reduced codes. In this work, a novel binary embedding method, termed
adaptive training quantization (ATQ), is proposed to learn the ideal transform
of random encoder, where the limitation of cosine random mapping is tackled. As
an adaptive learning idea, the reduced mapping is adaptively calculated with
idea of data group, while the bias of random transform is to be improved to
hold most matching information. Experimental results show that the proposed
method is able to obtain outstanding performance compared with other random
quantization methods.","['Miao Cheng', 'Ah Chung Tsoi']"
"Evolutionary Algorithm Enhanced Neural Architecture Search for
  Text-Independent Speaker Verification",Audio and Speech Processing,"State-of-the-art speaker verification models are based on deep learning
techniques, which heavily depend on the handdesigned neural architectures from
experts or engineers. We borrow the idea of neural architecture search(NAS) for
the textindependent speaker verification task. As NAS can learn deep network
structures automatically, we introduce the NAS conception into the well-known
x-vector network. Furthermore, this paper proposes an evolutionary algorithm
enhanced neural architecture search method called Auto-Vector to automatically
discover promising networks for the speaker verification task. The experimental
results demonstrate our NAS-based model outperforms state-of-the-art speaker
verification models.","['Xiaoyang Qu', 'Jianzong Wang', 'Jing Xiao']"
Pushing the boundaries of parallel Deep Learning -- A practical approach,"Distributed, Parallel, and Cluster Computing","This work aims to assess the state of the art of data parallel deep neural
network training, trying to identify potential research tracks to be exploited
for performance improvement. Beside, it presents a design for a practical C++
library dedicated at implementing and unifying the current state of the art
methodologies for parallel training in a performance-conscious framework,
allowing the user to explore novel strategies without departing significantly
from its usual work-flow.","['Paolo Viviani', 'Maurizio Drocco', 'Marco Aldinucci']"
Free Space Estimation using Occupancy Grids and Dynamic Object Detection,Computer Vision and Pattern Recognition,"In this paper we present an approach to estimate Free Space from a Stereo
image pair using stochastic occupancy grids. We do this in the domain of
autonomous driving on the famous benchmark dataset KITTI. Later based on the
generated occupancy grid we match 2 image sequences to compute the top view
representation of the map. We do this to map the environment. We compute a
transformation between the occupancy grids of two successive images and use it
to compute the top view map. Two issues need to be addressed for mapping are
discussed - computing a map and dealing with dynamic objects for computing the
map. Dynamic Objects are detected in successive images based on an idea similar
to tracking of foreground objects from the background objects based on motion
flow. A novel RANSAC based segmentation approach has been proposed here to
address this issue.",['Raghavender Sahdev']
"Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge
  Conflicts in Event Temporal Reasoning",Computation and Language (Natural Language Processing),"Event temporal reasoning aims at identifying the temporal relations between
two or more events from narratives. However, knowledge conflicts arise when
there is a mismatch between the actual temporal relations of events in the
context and the prior knowledge or biases learned by the model. In this paper,
we propose to detect knowledge-conflict examples in event temporal reasoning
using bias indicators, which include event relation prior bias, tense bias,
narrative bias, and dependency bias. We define conflict examples as those where
event relations are opposite to biased or prior relations. To mitigate
event-related knowledge conflicts, we introduce a Counterfactual Data
Augmentation (CDA) based method that can be applied to both Pre-trained
Language Models (PLMs) and Large Language Models (LLMs) either as additional
training data or demonstrations for In-Context Learning. Experiments suggest
both PLMs and LLMs suffer from knowledge conflicts in event temporal reasoning,
and CDA has the potential for reducing hallucination and improving model
performance.","['Tianqing Fang', 'Zhaowei Wang', 'Wenxuan Zhou', 'Hongming Zhang', 'Yangqiu Song', 'Muhao Chen']"
Printed Arabic Text Recognition using Linear and Nonlinear Regression,Computer Vision and Pattern Recognition,"Arabic language is one of the most popular languages in the world. Hundreds
of millions of people in many countries around the world speak Arabic as their
native speaking. However, due to complexity of Arabic language, recognition of
printed and handwritten Arabic text remained untouched for a very long time
compared with English and Chinese. Although, in the last few years, significant
number of researches has been done in recognizing printed and handwritten
Arabic text, it stills an open research field due to cursive nature of Arabic
script. This paper proposes automatic printed Arabic text recognition technique
based on linear and ellipse regression techniques. After collecting all
possible forms of each character, unique code is generated to represent each
character form. Each code contains a sequence of lines and ellipses. To
recognize fonts, a unique list of codes is identified to be used as a
fingerprint of font. The proposed technique has been evaluated using over 14000
different Arabic words with different fonts and experimental results show that
average recognition rate of the proposed technique is 86%.",['Ashraf A. Shahin']
Attention-based Domain Adaptation for Single Stage Detectors,Computer Vision and Pattern Recognition,"While domain adaptation has been used to improve the performance of object
detectors when the training and test data follow different distributions,
previous work has mostly focused on two-stage detectors. This is because their
use of region proposals makes it possible to perform local adaptation, which
has been shown to significantly improve the adaptation effectiveness. Here, by
contrast, we target single-stage architectures, which are better suited to
resource-constrained detection than two-stage ones but do not provide region
proposals. To nonetheless benefit from the strength of local adaptation, we
introduce an attention mechanism that lets us identify the important regions on
which adaptation should focus. Our method gradually adapts the features from
global, image-level to local, instance-level. Our approach is generic and can
be integrated into any single-stage detector. We demonstrate this on standard
benchmark datasets by applying it to both SSD and YOLOv5. Furthermore, for
equivalent single-stage architectures, our method outperforms the
state-of-the-art domain adaptation techniques even though they were designed
for specific detectors.","['Vidit Vidit', 'Mathieu Salzmann']"
Seeing the Unseen: Errors and Bias in Visual Datasets,Computer Vision and Pattern Recognition,"From face recognition in smartphones to automatic routing on self-driving
cars, machine vision algorithms lie in the core of these features. These
systems solve image based tasks by identifying and understanding objects,
subsequently making decisions from these information. However, errors in
datasets are usually induced or even magnified in algorithms, at times
resulting in issues such as recognising black people as gorillas and
misrepresenting ethnicities in search results. This paper tracks the errors in
datasets and their impacts, revealing that a flawed dataset could be a result
of limited categories, incomprehensive sourcing and poor classification.",['Hongrui Jin']
Metaoptimization on a Distributed System for Deep Reinforcement Learning,Machine Learning,"Training intelligent agents through reinforcement learning is a notoriously
unstable procedure. Massive parallelization on GPUs and distributed systems has
been exploited to generate a large amount of training experiences and
consequently reduce instabilities, but the success of training remains strongly
influenced by the choice of the hyperparameters. To overcome this issue, we
introduce HyperTrick, a new metaoptimization algorithm, and show its effective
application to tune hyperparameters in the case of deep reinforcement learning,
while learning to play different Atari games on a distributed system. Our
analysis provides evidence of the interaction between the identification of the
optimal hyperparameters and the learned policy, that is typical of the case of
metaoptimization for deep reinforcement learning. When compared with
state-of-the-art metaoptimization algorithms, HyperTrick is characterized by a
simpler implementation and it allows learning similar policies, while making a
more effective use of the computational resources in a distributed system.","['Greg Heinrich', 'Iuri Frosio']"
"RLOC: Neurobiologically Inspired Hierarchical Reinforcement Learning
  Algorithm for Continuous Control of Nonlinear Dynamical Systems",Machine Learning,"Nonlinear optimal control problems are often solved with numerical methods
that require knowledge of system's dynamics which may be difficult to infer,
and that carry a large computational cost associated with iterative
calculations. We present a novel neurobiologically inspired hierarchical
learning framework, Reinforcement Learning Optimal Control, which operates on
two levels of abstraction and utilises a reduced number of controllers to solve
nonlinear systems with unknown dynamics in continuous state and action spaces.
Our approach is inspired by research at two levels of abstraction: first, at
the level of limb coordination human behaviour is explained by linear optimal
feedback control theory. Second, in cognitive tasks involving learning symbolic
level action selection, humans learn such problems using model-free and
model-based reinforcement learning algorithms. We propose that combining these
two levels of abstraction leads to a fast global solution of nonlinear control
problems using reduced number of controllers. Our framework learns the local
task dynamics from naive experience and forms locally optimal infinite horizon
Linear Quadratic Regulators which produce continuous low-level control. A
top-level reinforcement learner uses the controllers as actions and learns how
to best combine them in state space while maximising a long-term reward. A
single optimal control objective function drives high-level symbolic learning
by providing training signals on desirability of each selected controller. We
show that a small number of locally optimal linear controllers are able to
solve global nonlinear control problems with unknown dynamics when combined
with a reinforcement learner in this hierarchical framework. Our algorithm
competes in terms of computational cost and solution quality with sophisticated
control algorithms and we illustrate this with solutions to benchmark problems.","['Ekaterina Abramova', 'Luke Dickens', 'Daniel Kuhn', 'Aldo Faisal']"
PAC-Bayesian Learning of Optimization Algorithms,Machine Learning,"We apply the PAC-Bayes theory to the setting of learning-to-optimize. To the
best of our knowledge, we present the first framework to learn optimization
algorithms with provable generalization guarantees (PAC-bounds) and explicit
trade-off between a high probability of convergence and a high convergence
speed. Even in the limit case, where convergence is guaranteed, our learned
optimization algorithms provably outperform related algorithms based on a
(deterministic) worst-case analysis. Our results rely on PAC-Bayes bounds for
general, unbounded loss-functions based on exponential families. By
generalizing existing ideas, we reformulate the learning procedure into a
one-dimensional minimization problem and study the possibility to find a global
minimum, which enables the algorithmic realization of the learning procedure.
As a proof-of-concept, we learn hyperparameters of standard optimization
algorithms to empirically underline our theory.","['Michael Sucker', 'Peter Ochs']"
Statistical Foundations of Prior-Data Fitted Networks,Machine Learning (Statistics),"Prior-data fitted networks (PFNs) were recently proposed as a new paradigm
for machine learning. Instead of training the network to an observed training
set, a fixed model is pre-trained offline on small, simulated training sets
from a variety of tasks. The pre-trained model is then used to infer class
probabilities in-context on fresh training sets with arbitrary size and
distribution. Empirically, PFNs achieve state-of-the-art performance on tasks
with similar size to the ones used in pre-training. Surprisingly, their
accuracy further improves when passed larger data sets during inference. This
article establishes a theoretical foundation for PFNs and illuminates the
statistical mechanisms governing their behavior. While PFNs are motivated by
Bayesian ideas, a purely frequentistic interpretation of PFNs as pre-tuned, but
untrained predictors explains their behavior. A predictor's variance vanishes
if its sensitivity to individual training samples does and the bias vanishes
only if it is appropriately localized around the test feature. The transformer
architecture used in current PFN implementations ensures only the former. These
findings shall prove useful for designing architectures with favorable
empirical behavior.",['Thomas Nagler']
Model-agnostic interpretation by visualization of feature perturbations,Machine Learning,"Interpretation of machine learning models has become one of the most
important research topics due to the necessity of maintaining control and
avoiding bias in these algorithms. Since many machine learning algorithms are
published every day, there is a need for novel model-agnostic interpretation
approaches that could be used to interpret a great variety of algorithms. Thus,
one advantageous way to interpret machine learning models is to feed different
input data to understand the changes in the prediction. Using such an approach,
practitioners can define relations among data patterns and a model's decision.
This work proposes a model-agnostic interpretation approach that uses
visualization of feature perturbations induced by the PSO algorithm. We
validate our approach on publicly available datasets, showing the capability to
enhance the interpretation of different classifiers while yielding very stable
results compared with state-of-the-art algorithms.","['Wilson E. Marcílio-Jr', 'Danilo M. Eler', 'Fabrício Breve']"
Preliminary Report on WASP 2.0,Artificial Intelligence,"Answer Set Programming (ASP) is a declarative programming paradigm. The
intrinsic complexity of the evaluation of ASP programs makes the development of
more effective and faster systems a challenging research topic. This paper
reports on the recent improvements of the ASP solver WASP. WASP is undergoing a
refactoring process which will end up in the release of a new and more
performant version of the software. In particular the paper focus on the
improvements to the core evaluation algorithms working on normal programs. A
preliminary experiment on benchmarks from the 3rd ASP competition belonging to
the NP class is reported. The previous version of WASP was often not
competitive with alternative solutions on this class. The new version of WASP
shows a substantial increase in performance.","['Mario Alviano', 'Carmine Dodaro', 'Francesco Ricca']"
"An Adaptive Dimension Reduction Estimation Method for High-dimensional
  Bayesian Optimization",Machine Learning (Statistics),"Bayesian optimization (BO) has shown impressive results in a variety of
applications within low-to-moderate dimensional Euclidean spaces. However,
extending BO to high-dimensional settings remains a significant challenge. We
address this challenge by proposing a two-step optimization framework.
Initially, we identify the effective dimension reduction (EDR) subspace for the
objective function using the minimum average variance estimation (MAVE) method.
Subsequently, we construct a Gaussian process model within this EDR subspace
and optimize it using the expected improvement criterion. Our algorithm offers
the flexibility to operate these steps either concurrently or in sequence. In
the sequential approach, we meticulously balance the exploration-exploitation
trade-off by distributing the sampling budget between subspace estimation and
function optimization, and the convergence rate of our algorithm in
high-dimensional contexts has been established. Numerical experiments validate
the efficacy of our method in challenging scenarios.","['Shouri Hu', 'Jiawei Li', 'Zhibo Cai']"
"Retrofitting Light-weight Language Models for Emotions using Supervised
  Contrastive Learning",Computation and Language (Natural Language Processing),"We present a novel retrofitting method to induce emotion aspects into
pre-trained language models (PLMs) such as BERT and RoBERTa. Our method updates
pre-trained network weights using contrastive learning so that the text
fragments exhibiting similar emotions are encoded nearby in the representation
space, and the fragments with different emotion content are pushed apart. While
doing so, it also ensures that the linguistic knowledge already present in PLMs
is not inadvertently perturbed. The language models retrofitted by our method,
i.e., BERTEmo and RoBERTaEmo, produce emotion-aware text representations, as
evaluated through different clustering and retrieval metrics. For the
downstream tasks on sentiment analysis and sarcasm detection, they perform
better than their pre-trained counterparts (about 1% improvement in F1-score)
and other existing approaches. Additionally, a more significant boost in
performance is observed for the retrofitted models over pre-trained ones in
few-shot learning setting.","['Sapan Shah', 'Sreedhar Reddy', 'Pushpak Bhattacharyya']"
Efficient Inference of Flexible Interaction in Spiking-neuron Networks,Machine Learning (Statistics),"Hawkes process provides an effective statistical framework for analyzing the
time-dependent interaction of neuronal spiking activities. Although utilized in
many real applications, the classic Hawkes process is incapable of modelling
inhibitory interactions among neurons. Instead, the nonlinear Hawkes process
allows for a more flexible influence pattern with excitatory or inhibitory
interactions. In this paper, three sets of auxiliary latent variables
(P\'{o}lya-Gamma variables, latent marked Poisson processes and sparsity
variables) are augmented to make functional connection weights in a Gaussian
form, which allows for a simple iterative algorithm with analytical updates. As
a result, an efficient expectation-maximization (EM) algorithm is derived to
obtain the maximum a posteriori (MAP) estimate. We demonstrate the accuracy and
efficiency performance of our algorithm on synthetic and real data. For real
neural recordings, we show our algorithm can estimate the temporal dynamics of
interaction and reveal the interpretable functional connectivity underlying
neural spike trains.","['Feng Zhou', 'Yixuan Zhang', 'Jun Zhu']"
"Vecchia Gaussian Process Ensembles on Internal Representations of Deep
  Neural Networks",Machine Learning (Statistics),"For regression tasks, standard Gaussian processes (GPs) provide natural
uncertainty quantification, while deep neural networks (DNNs) excel at
representation learning. We propose to synergistically combine these two
approaches in a hybrid method consisting of an ensemble of GPs built on the
output of hidden layers of a DNN. GP scalability is achieved via Vecchia
approximations that exploit nearest-neighbor conditional independence. The
resulting deep Vecchia ensemble not only imbues the DNN with uncertainty
quantification but can also provide more accurate and robust predictions. We
demonstrate the utility of our model on several datasets and carry out
experiments to understand the inner workings of the proposed method.","['Felix Jimenez', 'Matthias Katzfuss']"
Optimal Schatten-q and Ky-Fan-k Norm Rate of Low Rank Matrix Estimation,Machine Learning (Statistics),"In this paper, we consider low rank matrix estimation using either
matrix-version Dantzig Selector $\hat{A}_{\lambda}^d$ or matrix-version LASSO
estimator $\hat{A}_{\lambda}^L$. We consider sub-Gaussian measurements, $i.e.$,
the measurements $X_1,\ldots,X_n\in\mathbb{R}^{m\times m}$ have $i.i.d.$
sub-Gaussian entries. Suppose $\textrm{rank}(A_0)=r$. We proved that, when
$n\geq Cm[r^2\vee r\log(m)\log(n)]$ for some $C>0$, both $\hat{A}_{\lambda}^d$
and $\hat{A}_{\lambda}^L$ can obtain optimal upper bounds(except some
logarithmic terms) for estimation accuracy under spectral norm. By applying
metric entropy of Grassmann manifolds, we construct (near) matching minimax
lower bound for estimation accuracy under spectral norm. We also give upper
bounds and matching minimax lower bound(except some logarithmic terms) for
estimation accuracy under Schatten-q norm for every $1\leq q\leq\infty$. As a
direct corollary, we show both upper bounds and minimax lower bounds of
estimation accuracy under Ky-Fan-k norms for every $1\leq k\leq m$.",['Dong Xia']
Neural Network Model for Path-Planning of Robotic Rover Systems,Neural and Evolutionary Computing,"Today, robotics is an auspicious and fast-growing branch of technology that
involves the manufacturing, design, and maintenance of robot machines that can
operate in an autonomous fashion and can be used in a wide variety of
applications including space exploration, weaponry, household, and
transportation. More particularly, in space applications, a common type of
robots has been of widespread use in the recent years. It is called planetary
rover which is a robot vehicle that moves across the surface of a planet and
conducts detailed geological studies pertaining to the properties of the
landing cosmic environment. However, rovers are always impeded by obstacles
along the traveling path which can destabilize the rover's body and prevent it
from reaching its goal destination. This paper proposes an ANN model that
allows rover systems to carry out autonomous path-planning to successfully
navigate through challenging planetary terrains and follow their goal location
while avoiding dangerous obstacles. The proposed ANN is a multilayer network
made out of three layers: an input, a hidden, and an output layer. The network
is trained in offline mode using back-propagation supervised learning
algorithm. A software-simulated rover was experimented and it revealed that it
was able to follow the safest trajectory despite existing obstacles. As future
work, the proposed ANN is to be parallelized so as to speed-up the execution
time of the training process.",['Youssef Bassil']
"Construction of Rough graph to handle uncertain pattern from an
  Information System",Artificial Intelligence,"Rough membership function defines the measurement of relationship between
conditional and decision attribute from an Information system. In this paper we
propose a new method to construct rough graph through rough membership function
$\omega_{G}^F(f)$. Rough graph identifies the pattern between the objects with
imprecise and uncertain information. We explore the operations and properties
of rough graph in various stages of its structure.","['R. Aruna Devi', 'K. Anitha']"
"An Integrated Inverse Space Sparse Representation Framework for Tumor
  Classification",Computer Vision and Pattern Recognition,"Microarray gene expression data-based tumor classification is an active and
challenging issue. In this paper, an integrated tumor classification framework
is presented, which aims to exploit information in existing available samples,
and focuses on the small sample problem and unbalanced classification problem.
Firstly, an inverse space sparse representation based classification (ISSRC)
model is proposed by considering the characteristics of gene-based tumor data,
such as sparsity and a small number of training samples. A decision information
factors (DIF)-based gene selection method is constructed to enhance the
representation ability of the ISSRC. It is worth noting that the DIF is
established from reducing clinical misdiagnosis rate and dimension of small
sample data. For further improving the representation ability and
classification stability of the ISSRC, feature learning is conducted on the
selected gene subset. The feature learning method is constructed by
complementing the advantages of non-negative matrix factorization (NMF) and
deep learning. Without confusion, the ISSRC combined with gene selection and
feature learning is called the integrated ISSRC, whose stability, optimization
and the corresponding convergence are analyzed. Extensive experiments on six
public microarray gene expression datasets show the integrated ISSRC-based
tumor classification framework is superior to classical and state-of-the-art
methods. There are significant improvements in classification accuracy,
specificity and sensitivity, whether there is a tumor in the early diagnosis,
what kind of tumor, or whether metastasis occurs after tumor surgery.","['Xiaohui Yang', 'Wenming Wu', 'Yunmei Chen', 'Xianqi Li', 'Juan Zhang', 'Dan Long', 'Lijun Yang']"
"Explaining Deep Tractable Probabilistic Models: The sum-product network
  case",Machine Learning,"We consider the problem of explaining a class of tractable deep probabilistic
models, the Sum-Product Networks (SPNs) and present an algorithm ExSPN to
generate explanations. To this effect, we define the notion of a
context-specific independence tree(CSI-tree) and present an iterative algorithm
that converts an SPN to a CSI-tree. The resulting CSI-tree is both
interpretable and explainable to the domain expert. We achieve this by
extracting the conditional independencies encoded by the SPN and approximating
the local context specified by the structure of the SPN. Our extensive
empirical evaluations on synthetic, standard, and real-world clinical data sets
demonstrate that the CSI-tree exhibits superior explainability.","['Athresh Karanam', 'Saurabh Mathur', 'Predrag Radivojac', 'David M. Haas', 'Kristian Kersting', 'Sriraam Natarajan']"
Compressive Embedding and Visualization using Graphs,Machine Learning,"Visualizing high-dimensional data has been a focus in data analysis
communities for decades, which has led to the design of many algorithms, some
of which are now considered references (such as t-SNE for example). In our era
of overwhelming data volumes, the scalability of such methods have become more
and more important. In this work, we present a method which allows to apply any
visualization or embedding algorithm on very large datasets by considering only
a fraction of the data as input and then extending the information to all data
points using a graph encoding its global similarity. We show that in most
cases, using only $\mathcal{O}(\log(N))$ samples is sufficient to diffuse the
information to all $N$ data points. In addition, we propose quantitative
methods to measure the quality of embeddings and demonstrate the validity of
our technique on both synthetic and real-world datasets.","['Johan Paratte', 'Nathanaël Perraudin', 'Pierre Vandergheynst']"
Robust Depth-based Person Re-identification,Computer Vision and Pattern Recognition,"Person re-identification (re-id) aims to match people across non-overlapping
camera views. So far the RGB-based appearance is widely used in most existing
works. However, when people appeared in extreme illumination or changed
clothes, the RGB appearance-based re-id methods tended to fail. To overcome
this problem, we propose to exploit depth information to provide more invariant
body shape and skeleton information regardless of illumination and color
change. More specifically, we exploit depth voxel covariance descriptor and
further propose a locally rotation invariant depth shape descriptor called
Eigen-depth feature to describe pedestrian body shape. We prove that the
distance between any two covariance matrices on the Riemannian manifold is
equivalent to the Euclidean distance between the corresponding Eigen-depth
features. Furthermore, we propose a kernelized implicit feature transfer scheme
to estimate Eigen-depth feature implicitly from RGB image when depth
information is not available. We find that combining the estimated depth
features with RGB-based appearance features can sometimes help to better reduce
visual ambiguities of appearance features caused by illumination and similar
clothes. The effectiveness of our models was validated on publicly available
depth pedestrian datasets as compared to related methods for person
re-identification.","['Ancong Wu', 'Wei-Shi Zheng', 'Jianhuang Lai']"
Enhancing the Association in Multi-Object Tracking via Neighbor Graph,Computer Vision and Pattern Recognition,"Most modern multi-object tracking (MOT) systems follow the
tracking-by-detection paradigm. It first localizes the objects of interest,
then extracting their individual appearance features to make data association.
The individual features, however, are susceptible to the negative effects as
occlusions, illumination variations and inaccurate detections, thus resulting
in the mismatch in the association inference. In this work, we propose to
handle this problem via making full use of the neighboring information. Our
motivations derive from the observations that people tend to move in a group.
As such, when an individual target's appearance is seriously changed, we can
still identify it with the help of its neighbors. To this end, we first utilize
the spatio-temporal relations produced by the tracking self to efficiently
select suitable neighbors for the targets. Subsequently, we construct neighbor
graph of the target and neighbors then employ the graph convolution networks
(GCN) to learn the graph features. To the best of our knowledge, it is the
first time to exploit neighbor cues via GCN in MOT. Finally, we test our
approach on the MOT benchmarks and achieve state-of-the-art performance in
online tracking.","['Tianyi Liang', 'Long Lan', 'Zhigang Luo']"
"DECOrrelated feature space partitioning for distributed sparse
  regression",Methodology (Statistics),"Fitting statistical models is computationally challenging when the sample
size or the dimension of the dataset is huge. An attractive approach for
down-scaling the problem size is to first partition the dataset into subsets
and then fit using distributed algorithms. The dataset can be partitioned
either horizontally (in the sample space) or vertically (in the feature space).
While the majority of the literature focuses on sample space partitioning,
feature space partitioning is more effective when $p\gg n$. Existing methods
for partitioning features, however, are either vulnerable to high correlations
or inefficient in reducing the model dimension. In this paper, we solve these
problems through a new embarrassingly parallel framework named DECO for
distributed variable selection and parameter estimation. In DECO, variables are
first partitioned and allocated to $m$ distributed workers. The decorrelated
subset data within each worker are then fitted via any algorithm designed for
high-dimensional problems. We show that by incorporating the decorrelation
step, DECO can achieve consistent variable selection and parameter estimation
on each subset with (almost) no assumptions. In addition, the convergence rate
is nearly minimax optimal for both sparse and weakly sparse models and does NOT
depend on the partition number $m$. Extensive numerical experiments are
provided to illustrate the performance of the new framework.","['Xiangyu Wang', 'David Dunson', 'Chenlei Leng']"
Semantic Video Segmentation by Gated Recurrent Flow Propagation,Computer Vision and Pattern Recognition,"Semantic video segmentation is challenging due to the sheer amount of data
that needs to be processed and labeled in order to construct accurate models.
In this paper we present a deep, end-to-end trainable methodology to video
segmentation that is capable of leveraging information present in unlabeled
data in order to improve semantic estimates. Our model combines a convolutional
architecture and a spatio-temporal transformer recurrent layer that are able to
temporally propagate labeling information by means of optical flow, adaptively
gated based on its locally estimated uncertainty. The flow, the recognition and
the gated temporal propagation modules can be trained jointly, end-to-end. The
temporal, gated recurrent flow propagation component of our model can be
plugged into any static semantic segmentation architecture and turn it into a
weakly supervised video processing one. Our extensive experiments in the
challenging CityScapes and Camvid datasets, and based on multiple deep
architectures, indicate that the resulting model can leverage unlabeled
temporal frames, next to a labeled one, in order to improve both the video
segmentation accuracy and the consistency of its temporal labeling, at no
additional annotation cost and with little extra computation.","['David Nilsson', 'Cristian Sminchisescu']"
"Harmonic analysis on directed graphs and applications: from Fourier
  analysis to wavelets",Functional Analysis,"We introduce a novel harmonic analysis for functions defined on the vertices
of a strongly connected directed graph of which the random walk operator is the
cornerstone. As a first step, we consider the set of eigenvectors of the random
walk operator as a non-orthogonal Fourier-type basis for functions over
directed graphs. We found a frequency interpretation by linking the variation
of the eigenvectors of the random walk operator obtained from their Dirichlet
energy to the real part of their associated eigenvalues. From this Fourier
basis, we can proceed further and build multi-scale analyses on directed
graphs. We propose both a redundant wavelet transform and a decimated wavelet
transform by extending the diffusion wavelets framework by Coifman and Maggioni
for directed graphs. The development of our harmonic analysis on directed
graphs thus leads us to consider both semi-supervised learning problems and
signal modeling problems on graphs applied to directed graphs highlighting the
efficiency of our framework.","['Harry Sevi', 'Gabriel Rilling', 'Pierre Borgnat']"
"FedDQ: Communication-Efficient Federated Learning with Descending
  Quantization",Machine Learning,"Federated learning (FL) is an emerging learning paradigm without violating
users' privacy. However, large model size and frequent model aggregation cause
serious communication bottleneck for FL. To reduce the communication volume,
techniques such as model compression and quantization have been proposed.
Besides the fixed-bit quantization, existing adaptive quantization schemes use
ascending-trend quantization, where the quantization level increases with the
training stages. In this paper, we first investigate the impact of quantization
on model convergence, and show that the optimal quantization level is directly
related to the range of the model updates. Given the model is supposed to
converge with the progress of the training, the range of the model updates will
gradually shrink, indicating that the quantization level should decrease with
the training stages. Based on the theoretical analysis, a descending
quantization scheme named FedDQ is proposed. Experimental results show that the
proposed descending quantization scheme can save up to 65.2% of the
communicated bit volume and up to 68% of the communication rounds, when
compared with existing schemes.","['Linping Qu', 'Shenghui Song', 'Chi-Ying Tsui']"
"Jointly spatial-temporal representation learning for individual
  trajectories",Machine Learning,"Individual trajectories, rich in human-environment interaction information
across space and time, serve as vital inputs for geospatial foundation models
(GeoFMs). However, existing attempts at learning trajectory representations
have overlooked the implicit spatial-temporal dependency within trajectories,
failing to encode such dependency in a deep learning-friendly format. That
poses a challenge in obtaining general-purpose trajectory representations.
Therefore, this paper proposes a spatial-temporal joint representation learning
method (ST-GraphRL) to formalize learnable spatial-temporal dependencies into
trajectory representations. The proposed ST-GraphRL consists of three
compositions: (i) a weighted directed spatial-temporal graph to explicitly
construct mobility interactions in both space and time dimensions; (ii) a
two-stage jointly encoder (i.e., decoupling and fusion), to learn entangled
spatial-temporal dependencies by independently decomposing and jointly
aggregating space and time information; (iii) a decoder guides ST-GraphRL to
learn explicit mobility regularities by simulating the spatial-temporal
distributions of trajectories. Tested on three real-world human mobility
datasets, the proposed ST-GraphRL outperformed all the baseline models in
predicting movement spatial-temporal distributions and preserving trajectory
similarity with high spatial-temporal correlations. Analyzing spatial-temporal
features presented in latent space validates that ST-GraphRL understands
spatial-temporal patterns. This study may also benefit representation learnings
of other geospatial data to achieve general-purpose data representations and
advance GeoFMs development.","['Fei Huang', 'Jianrong Lv', 'Yang Yue']"
Speeding up Deep Model Training by Sharing Weights and Then Unsharing,Machine Learning,"We propose a simple and efficient approach for training the BERT model. Our
approach exploits the special structure of BERT that contains a stack of
repeated modules (i.e., transformer encoders). Our proposed approach first
trains BERT with the weights shared across all the repeated modules till some
point. This is for learning the commonly shared component of weights across all
repeated layers. We then stop weight sharing and continue training until
convergence. We present theoretic insights for training by sharing weights then
unsharing with analysis for simplified models. Empirical experiments on the
BERT model show that our method yields better performance of trained models,
and significantly reduces the number of training iterations.","['Shuo Yang', 'Le Hou', 'Xiaodan Song', 'Qiang Liu', 'Denny Zhou']"
"Adaptive Population-based Simulated Annealing for Uncertain Resource
  Constrained Job Scheduling",Neural and Evolutionary Computing,"Transporting ore from mines to ports is of significant interest in mining
supply chains. These operations are commonly associated with growing costs and
a lack of resources. Large mining companies are interested in optimally
allocating their resources to reduce operational costs. This problem has been
previously investigated in the literature as resource constrained job
scheduling (RCJS). While a number of optimisation methods have been proposed to
tackle the deterministic problem, the uncertainty associated with resource
availability, an inevitable challenge in mining operations, has received less
attention. RCJS with uncertainty is a hard combinatorial optimisation problem
that cannot be solved efficiently with existing optimisation methods. This
study proposes an adaptive population-based simulated annealing algorithm that
can overcome the limitations of existing methods for RCJS with uncertainty
including the premature convergence, the excessive number of hyper-parameters,
and the inefficiency in coping with different uncertainty levels. This new
algorithm is designed to effectively balance exploration and exploitation, by
using a population, modifying the cooling schedule in the Metropolis-Hastings
algorithm, and using an adaptive mechanism to select perturbation operators.
The results show that the proposed algorithm outperforms existing methods
across a wide range of benchmark RCJS instances and uncertainty levels.
Moreover, new best known solutions are discovered for all but one problem
instance across all uncertainty levels.","['Dhananjay Thiruvady', 'Su Nguyen', 'Yuan Sun', 'Fatemeh Shiri', 'Nayyar Zaidi', 'Xiaodong Li']"
"HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven
  Harmony Search and Genetic Algorithm Using LLMs",Neural and Evolutionary Computing,"Automatic Heuristic Design (AHD) is an active research area due to its
utility in solving complex search and NP-hard combinatorial optimization
problems in the real world. The recent advancements in Large Language Models
(LLMs) introduce new possibilities by coupling LLMs with evolutionary
computation to automatically generate heuristics, known as LLM-based
Evolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained
great performance on various tasks, there is still a gap in understanding the
properties of heuristic search spaces and achieving a balance between
exploration and exploitation, which is a critical factor in large heuristic
search spaces. In this study, we address this gap by proposing two diversity
measurement metrics and perform an analysis on previous LLM-EPS approaches,
including FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal
that while EoH demonstrates higher diversity than FunSearch and ReEvo, its
objective score is unstable. Conversely, ReEvo's reflection mechanism yields
good objective scores but fails to optimize diversity effectively. With this
finding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that
maintains a balance between diversity and convergence with a harmony search
algorithm. Through experimentation, we find that HSEvo achieved high diversity
indices and good objective scores while remaining cost-effective. These results
underscore the importance of balancing exploration and exploitation and
understanding heuristic search spaces in designing frameworks in LLM-EPS.","['Pham Vu Tuan Dat', 'Long Doan', 'Huynh Thi Thanh Binh']"
Neural Architecture Search using Progressive Evolution,Neural and Evolutionary Computing,"Vanilla neural architecture search using evolutionary algorithms (EA)
involves evaluating each architecture by training it from scratch, which is
extremely time-consuming. This can be reduced by using a supernet to estimate
the fitness of every architecture in the search space due to its weight sharing
nature. However, the estimated fitness is very noisy due to the co-adaptation
of the operations in the supernet. In this work, we propose a method called
pEvoNAS wherein the whole neural architecture search space is progressively
reduced to smaller search space regions with good architectures. This is
achieved by using a trained supernet for architecture evaluation during the
architecture search using genetic algorithm to find search space regions with
good architectures. Upon reaching the final reduced search space, the supernet
is then used to search for the best architecture in that search space using
evolution. The search is also enhanced by using weight inheritance wherein the
supernet for the smaller search space inherits its weights from previous
trained supernet for the bigger search space. Exerimentally, pEvoNAS gives
better results on CIFAR-10 and CIFAR-100 while using significantly less
computational resources as compared to previous EA-based methods. The code for
our paper can be found in https://github.com/nightstorm0909/pEvoNAS","['Nilotpal Sinha', 'Kuan-Wen Chen']"
"Safety through Permissibility: Shield Construction for Fast and Safe
  Reinforcement Learning",Machine Learning,"Designing Reinforcement Learning (RL) solutions for real-life problems
remains a significant challenge. A major area of concern is safety. ""Shielding""
is a popular technique to enforce safety in RL by turning user-defined safety
specifications into safe agent behavior. However, these methods either suffer
from extreme learning delays, demand extensive human effort in designing models
and safe domains in the problem, or require pre-computation. In this paper, we
propose a new permissibility-based framework to deal with safety and shield
construction. Permissibility was originally designed for eliminating
(non-permissible) actions that will not lead to an optimal solution to improve
RL training efficiency. This paper shows that safety can be naturally
incorporated into this framework, i.e. extending permissibility to include
safety, and thereby we can achieve both safety and improved efficiency.
Experimental evaluation using three standard RL applications shows the
effectiveness of the approach.","['Alexander Politowicz', 'Sahisnu Mazumder', 'Bing Liu']"
"Hypergraph Random Walks, Laplacians, and Clustering",Machine Learning,"We propose a flexible framework for clustering hypergraph-structured data
based on recently proposed random walks utilizing edge-dependent vertex
weights. When incorporating edge-dependent vertex weights (EDVW), a weight is
associated with each vertex-hyperedge pair, yielding a weighted incidence
matrix of the hypergraph. Such weightings have been utilized in term-document
representations of text data sets. We explain how random walks with EDVW serve
to construct different hypergraph Laplacian matrices, and then develop a suite
of clustering methods that use these incidence matrices and Laplacians for
hypergraph clustering. Using several data sets from real-life applications, we
compare the performance of these clustering algorithms experimentally against a
variety of existing hypergraph clustering methods. We show that the proposed
methods produce higher-quality clusters and conclude by highlighting avenues
for future work.","['Koby Hayashi', 'Sinan G. Aksoy', 'Cheong Hee Park', 'Haesun Park']"
"CPU- and GPU-based Distributed Sampling in Dirichlet Process Mixtures
  for Large-scale Analysis",Machine Learning,"In the realm of unsupervised learning, Bayesian nonparametric mixture models,
exemplified by the Dirichlet Process Mixture Model (DPMM), provide a principled
approach for adapting the complexity of the model to the data. Such models are
particularly useful in clustering tasks where the number of clusters is
unknown. Despite their potential and mathematical elegance, however, DPMMs have
yet to become a mainstream tool widely adopted by practitioners. This is
arguably due to a misconception that these models scale poorly as well as the
lack of high-performance (and user-friendly) software tools that can handle
large datasets efficiently. In this paper we bridge this practical gap by
proposing a new, easy-to-use, statistical software package for scalable DPMM
inference. More concretely, we provide efficient and easily-modifiable
implementations for high-performance distributed sampling-based inference in
DPMMs where the user is free to choose between either a multiple-machine,
multiple-core, CPU implementation (written in Julia) and a multiple-stream GPU
implementation (written in CUDA/C++). Both the CPU and GPU implementations come
with a common (and optional) python wrapper, providing the user with a single
point of entry with the same interface. On the algorithmic side, our
implementations leverage a leading DPMM sampler from (Chang and Fisher III,
2013). While Chang and Fisher III's implementation (written in MATLAB/C++) used
only CPU and was designed for a single multi-core machine, the packages we
proposed here distribute the computations efficiently across either multiple
multi-core machines or across mutiple GPU streams. This leads to speedups,
alleviates memory and storage limitations, and lets us fit DPMMs to
significantly larger datasets and of higher dimensionality than was possible
previously by either (Chang and Fisher III, 2013) or other DPMM methods.","['Or Dinari', 'Raz Zamir', 'John W. Fisher III', 'Oren Freifeld']"
"Align, Mask and Select: A Simple Method for Incorporating Commonsense
  Knowledge into Language Representation Models",Computation and Language (Natural Language Processing),"The state-of-the-art pre-trained language representation models, such as
Bidirectional Encoder Representations from Transformers (BERT), rarely
incorporate commonsense knowledge or other knowledge explicitly. We propose a
pre-training approach for incorporating commonsense knowledge into language
representation models. We construct a commonsense-related multi-choice question
answering dataset for pre-training a neural language representation model. The
dataset is created automatically by our proposed ""align, mask, and select""
(AMS) method. We also investigate different pre-training tasks. Experimental
results demonstrate that pre-training models using the proposed approach
followed by fine-tuning achieve significant improvements over previous
state-of-the-art models on two commonsense-related benchmarks, including
CommonsenseQA and Winograd Schema Challenge. We also observe that fine-tuned
models after the proposed pre-training approach maintain comparable performance
on other NLP tasks, such as sentence classification and natural language
inference tasks, compared to the original BERT models. These results verify
that the proposed approach, while significantly improving commonsense-related
NLP tasks, does not degrade the general language representation capabilities.","['Zhi-Xiu Ye', 'Qian Chen', 'Wen Wang', 'Zhen-Hua Ling']"
Calibrated Model-Based Deep Reinforcement Learning,Machine Learning,"Estimates of predictive uncertainty are important for accurate model-based
planning and reinforcement learning. However, predictive
uncertainties---especially ones derived from modern deep learning systems---can
be inaccurate and impose a bottleneck on performance. This paper explores which
uncertainties are needed for model-based reinforcement learning and argues that
good uncertainties must be calibrated, i.e. their probabilities should match
empirical frequencies of predicted events. We describe a simple way to augment
any model-based reinforcement learning agent with a calibrated model and show
that doing so consistently improves planning, sample complexity, and
exploration. On the \textsc{HalfCheetah} MuJoCo task, our system achieves
state-of-the-art performance using 50\% fewer samples than the current leading
approach. Our findings suggest that calibration can improve the performance of
model-based reinforcement learning with minimal computational and
implementation overhead.","['Ali Malik', 'Volodymyr Kuleshov', 'Jiaming Song', 'Danny Nemer', 'Harlan Seymour', 'Stefano Ermon']"
"Hierarchical Reinforcement Learning: Approximating Optimal Discounted
  TSP Using Local Policies",Machine Learning,"In this work, we provide theoretical guarantees for reward decomposition in
deterministic MDPs. Reward decomposition is a special case of Hierarchical
Reinforcement Learning, that allows one to learn many policies in parallel and
combine them into a composite solution. Our approach builds on mapping this
problem into a Reward Discounted Traveling Salesman Problem, and then deriving
approximate solutions for it. In particular, we focus on approximate solutions
that are local, i.e., solutions that only observe information about the current
state. Local policies are easy to implement and do not require substantial
computational resources as they do not perform planning. While local
deterministic policies, like Nearest Neighbor, are being used in practice for
hierarchical reinforcement learning, we propose three stochastic policies that
guarantee better performance than any deterministic policy.","['Tom Zahavy', 'Avinatan Hasidim', 'Haim Kaplan', 'Yishay Mansour']"
"Optimization Methods for Interpretable Differentiable Decision Trees in
  Reinforcement Learning",Machine Learning,"Decision trees are ubiquitous in machine learning for their ease of use and
interpretability. Yet, these models are not typically employed in reinforcement
learning as they cannot be updated online via stochastic gradient descent. We
overcome this limitation by allowing for a gradient update over the entire tree
that improves sample complexity affords interpretable policy extraction. First,
we include theoretical motivation on the need for policy-gradient learning by
examining the properties of gradient descent over differentiable decision
trees. Second, we demonstrate that our approach equals or outperforms a neural
network on all domains and can learn discrete decision trees online with
average rewards up to 7x higher than a batch-trained decision tree. Third, we
conduct a user study to quantify the interpretability of a decision tree, rule
list, and a neural network with statistically significant results ($p <
0.001$).","['Andrew Silva', 'Taylor Killian', 'Ivan Dario Jimenez Rodriguez', 'Sung-Hyun Son', 'Matthew Gombolay']"
R-MADDPG for Partially Observable Environments and Limited Communication,Multiagent Systems,"There are several real-world tasks that would benefit from applying
multiagent reinforcement learning (MARL) algorithms, including the coordination
among self-driving cars. The real world has challenging conditions for
multiagent learning systems, such as its partial observable and nonstationary
nature. Moreover, if agents must share a limited resource (e.g. network
bandwidth) they must all learn how to coordinate resource use. This paper
introduces a deep recurrent multiagent actor-critic framework (R-MADDPG) for
handling multiagent coordination under partial observable set-tings and limited
communication. We investigate recurrency effects on performance and
communication use of a team of agents. We demonstrate that the resulting
framework learns time dependencies for sharing missing observations, handling
resource limitations, and developing different communication patterns among
agents.","['Rose E. Wang', 'Michael Everett', 'Jonathan P. How']"
REP: Predicting the Time-Course of Drug Sensitivity,Machine Learning,"The biological processes involved in a drug's mechanisms of action are
oftentimes dynamic, complex and difficult to discern. Time-course gene
expression data is a rich source of information that can be used to unravel
these complex processes, identify biomarkers of drug sensitivity and predict
the response to a drug. However, the majority of previous work has not fully
utilized this temporal dimension. In these studies, the gene expression data is
either considered at one time-point (before the administration of the drug) or
two timepoints (before and after the administration of the drug). This is
clearly inadequate in modeling dynamic gene-drug interactions, especially for
applications such as long-term drug therapy.
  In this work, we present a novel REcursive Prediction (REP) framework for
drug response prediction by taking advantage of time-course gene expression
data. Our goal is to predict drug response values at every stage of a long-term
treatment, given the expression levels of genes collected in the previous
time-points. To this end, REP employs a built-in recursive structure that
exploits the intrinsic time-course nature of the data and integrates past
values of drug responses for subsequent predictions. It also incorporates
tensor completion that can not only alleviate the impact of noise and missing
data, but also predict unseen gene expression levels (GELs). These advantages
enable REP to estimate drug response at any stage of a given treatment from
some GELs measured in the beginning of the treatment. Extensive experiments on
a dataset corresponding to 53 multiple sclerosis patients treated with
interferon are included to showcase the effectiveness of REP.","['Cheng Qian', 'Amin Emad', 'Nicholas D. Sidiropoulos']"
Image Inpainting for Irregular Holes Using Partial Convolutions,Computer Vision and Pattern Recognition,"Existing deep learning based image inpainting methods use a standard
convolutional network over the corrupted image, using convolutional filter
responses conditioned on both valid pixels as well as the substitute values in
the masked holes (typically the mean value). This often leads to artifacts such
as color discrepancy and blurriness. Post-processing is usually used to reduce
such artifacts, but are expensive and may fail. We propose the use of partial
convolutions, where the convolution is masked and renormalized to be
conditioned on only valid pixels. We further include a mechanism to
automatically generate an updated mask for the next layer as part of the
forward pass. Our model outperforms other methods for irregular masks. We show
qualitative and quantitative comparisons with other methods to validate our
approach.","['Guilin Liu', 'Fitsum A. Reda', 'Kevin J. Shih', 'Ting-Chun Wang', 'Andrew Tao', 'Bryan Catanzaro']"
An Effective Semi-supervised Divisive Clustering Algorithm,Machine Learning,"Nowadays, data are generated massively and rapidly from scientific fields as
bioinformatics, neuroscience and astronomy to business and engineering fields.
Cluster analysis, as one of the major data analysis tools, is therefore more
significant than ever. We propose in this work an effective Semi-supervised
Divisive Clustering algorithm (SDC). Data points are first organized by a
minimal spanning tree. Next, this tree structure is transitioned to the in-tree
structure, and then divided into sub-trees under the supervision of the labeled
data, and in the end, all points in the sub-trees are directly associated with
specific cluster centers. SDC is fully automatic, non-iterative, involving no
free parameter, insensitive to noise, able to detect irregularly shaped cluster
structures, applicable to the data sets of high dimensionality and different
attributes. The power of SDC is demonstrated on several datasets.","['Teng Qiu', 'Yongjie Li']"
"Efficient and Flexible Method for Reducing Moderate-size Deep Neural
  Networks with Condensation",Machine Learning,"Neural networks have been extensively applied to a variety of tasks,
achieving astounding results. Applying neural networks in the scientific field
is an important research direction that is gaining increasing attention. In
scientific applications, the scale of neural networks is generally
moderate-size, mainly to ensure the speed of inference during application.
Additionally, comparing neural networks to traditional algorithms in scientific
applications is inevitable. These applications often require rapid
computations, making the reduction of neural network sizes increasingly
important. Existing work has found that the powerful capabilities of neural
networks are primarily due to their non-linearity. Theoretical work has
discovered that under strong non-linearity, neurons in the same layer tend to
behave similarly, a phenomenon known as condensation. Condensation offers an
opportunity to reduce the scale of neural networks to a smaller subnetwork with
similar performance. In this article, we propose a condensation reduction
algorithm to verify the feasibility of this idea in practical problems. Our
reduction method can currently be applied to both fully connected networks and
convolutional networks, achieving positive results. In complex combustion
acceleration tasks, we reduced the size of the neural network to 41.7% of its
original scale while maintaining prediction accuracy. In the CIFAR10 image
classification task, we reduced the network size to 11.5% of the original
scale, still maintaining a satisfactory validation accuracy. Our method can be
applied to most trained neural networks, reducing computational pressure and
improving inference speed.","['Tianyi Chen', 'Zhi-Qin John Xu']"
"Three dimensional Deep Learning approach for remote sensing image
  classification",Computer Vision and Pattern Recognition,"Recently, a variety of approaches has been enriching the field of Remote
Sensing (RS) image processing and analysis. Unfortunately, existing methods
remain limited faced to the rich spatio-spectral content of today's large
datasets. It would seem intriguing to resort to Deep Learning (DL) based
approaches at this stage with regards to their ability to offer accurate
semantic interpretation of the data. However, the specificity introduced by the
coexistence of spectral and spatial content in the RS datasets widens the scope
of the challenges presented to adapt DL methods to these contexts. Therefore,
the aim of this paper is firstly to explore the performance of DL architectures
for the RS hyperspectral dataset classification and secondly to introduce a new
three-dimensional DL approach that enables a joint spectral and spatial
information process. A set of three-dimensional schemes is proposed and
evaluated. Experimental results based on well knownhyperspectral datasets
demonstrate that the proposed method is able to achieve a better classification
rate than state of the art methods with lower computational costs.","['Amina Ben Hamida', 'A Benoit', 'Patrick Lambert', 'Chokri Ben Amar']"
"The Multiple Subnetwork Hypothesis: Enabling Multidomain Learning by
  Isolating Task-Specific Subnetworks in Feedforward Neural Networks",Machine Learning,"Neural networks have seen an explosion of usage and research in the past
decade, particularly within the domains of computer vision and natural language
processing. However, only recently have advancements in neural networks yielded
performance improvements beyond narrow applications and translated to expanded
multitask models capable of generalizing across multiple data types and
modalities. Simultaneously, it has been shown that neural networks are
overparameterized to a high degree, and pruning techniques have proved capable
of significantly reducing the number of active weights within the network while
largely preserving performance. In this work, we identify a methodology and
network representational structure which allows a pruned network to employ
previously unused weights to learn subsequent tasks. We employ these
methodologies on well-known benchmarking datasets for testing purposes and show
that networks trained using our approaches are able to learn multiple tasks,
which may be related or unrelated, in parallel or in sequence without
sacrificing performance on any task or exhibiting catastrophic forgetting.","['Jacob Renn', 'Ian Sotnek', 'Benjamin Harvey', 'Brian Caffo']"
"Transfer Learning in Biomedical Natural Language Processing: An
  Evaluation of BERT and ELMo on Ten Benchmarking Datasets",Computation and Language (Natural Language Processing),"Inspired by the success of the General Language Understanding Evaluation
benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE)
benchmark to facilitate research in the development of pre-training language
representations in the biomedicine domain. The benchmark consists of five tasks
with ten datasets that cover both biomedical and clinical texts with different
dataset sizes and difficulties. We also evaluate several baselines based on
BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and
MIMIC-III clinical notes achieves the best results. We make the datasets,
pre-trained models, and codes publicly available at
https://github.com/ncbi-nlp/BLUE_Benchmark.","['Yifan Peng', 'Shankai Yan', 'Zhiyong Lu']"
MAC: A Meta-Learning Approach for Feature Learning and Recombination,Machine Learning,"Optimization-based meta-learning aims to learn an initialization so that a
new unseen task can be learned within a few gradient updates. Model Agnostic
Meta-Learning (MAML) is a benchmark algorithm comprising two optimization
loops. The inner loop is dedicated to learning a new task and the outer loop
leads to meta-initialization. However, ANIL (almost no inner loop) algorithm
shows that feature reuse is an alternative to rapid learning in MAML. Thus, the
meta-initialization phase makes MAML primed for feature reuse and obviates the
need for rapid learning. Contrary to ANIL, we hypothesize that there may be a
need to learn new features during meta-testing. A new unseen task from
non-similar distribution would necessitate rapid learning in addition reuse and
recombination of existing features. In this paper, we invoke the width-depth
duality of neural networks, wherein, we increase the width of the network by
adding extra computational units (ACU). The ACUs enable the learning of new
atomic features in the meta-testing task, and the associated increased width
facilitates information propagation in the forwarding pass. The newly learnt
features combine with existing features in the last layer for meta-learning.
Experimental results show that our proposed MAC method outperformed existing
ANIL algorithm for non-similar task distribution by approximately 13% (5-shot
task setting)","['S. Tiwari', 'M. Gogoi', 'S. Verma', 'K. P. Singh']"
"Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive
  Learning",Computation and Language (Natural Language Processing),"Aspect Sentiment Triplet Extraction (ASTE) is a burgeoning subtask of
fine-grained sentiment analysis, aiming to extract structured sentiment
triplets from unstructured textual data. Existing approaches to ASTE often
complicate the task with additional structures or external data. In this
research, we propose a novel tagging scheme and employ a contrastive learning
approach to mitigate these challenges. The proposed approach demonstrates
comparable or superior performance in comparison to state-of-the-art
techniques, while featuring a more compact design and reduced computational
overhead. Notably, even in the era of Large Language Models (LLMs), our method
exhibits superior efficacy compared to GPT 3.5 and GPT 4 in a few-shot learning
scenarios. This study also provides valuable insights for the advancement of
ASTE techniques within the paradigm of large language models.","['Qiao Sun', 'Liujia Yang', 'Minghao Ma', 'Nanyang Ye', 'Qinying Gu']"
"Penalized matrix decomposition for denoising, compression, and improved
  demixing of functional imaging data",Neurons and Cognition,"Calcium imaging has revolutionized systems neuroscience, providing the
ability to image large neural populations with single-cell resolution. The
resulting datasets are quite large, which has presented a barrier to routine
open sharing of this data, slowing progress in reproducible research. State of
the art methods for analyzing this data are based on non-negative matrix
factorization (NMF); these approaches solve a non-convex optimization problem,
and are effective when good initializations are available, but can break down
in low-SNR settings where common initialization approaches fail. Here we
introduce an approach to compressing and denoising functional imaging data. The
method is based on a spatially-localized penalized matrix decomposition (PMD)
of the data to separate (low-dimensional) signal from (temporally-uncorrelated)
noise. This approach can be applied in parallel on local spatial patches and is
therefore highly scalable, does not impose non-negativity constraints or
require stringent identifiability assumptions (leading to significantly more
robust results compared to NMF), and estimates all parameters directly from the
data, so no hand-tuning is required. We have applied the method to a wide range
of functional imaging data (including one-photon, two-photon, three-photon,
widefield, somatic, axonal, dendritic, calcium, and voltage imaging datasets):
in all cases, we observe ~2-4x increases in SNR and compression rates of
20-300x with minimal visible loss of signal, with no adjustment of
hyperparameters; this in turn facilitates the process of demixing the observed
activity into contributions from individual neurons. We focus on two
challenging applications: dendritic calcium imaging data and voltage imaging
data in the context of optogenetic stimulation. In both cases, we show that our
new approach leads to faster and much more robust extraction of activity from
the data.","['E. Kelly Buchanan', 'Ian Kinsella', 'Ding Zhou', 'Rong Zhu', 'Pengcheng Zhou', 'Felipe Gerhard', 'John Ferrante', 'Ying Ma', 'Sharon Kim', 'Mohammed Shaik', 'Yajie Liang', 'Rongwen Lu', 'Jacob Reimer', 'Paul Fahey', 'Taliah Muhammad', 'Graham Dempsey', 'Elizabeth Hillman', 'Na Ji', 'Andreas Tolias', 'Liam Paninski']"
Uncertainty in Graph Neural Networks: A Survey,Machine Learning,"Graph Neural Networks (GNNs) have been extensively used in various real-world
applications. However, the predictive uncertainty of GNNs stemming from diverse
sources such as inherent randomness in data and model training errors can lead
to unstable and erroneous predictions. Therefore, identifying, quantifying, and
utilizing uncertainty are essential to enhance the performance of the model for
the downstream tasks as well as the reliability of the GNN predictions. This
survey aims to provide a comprehensive overview of the GNNs from the
perspective of uncertainty with an emphasis on its integration in graph
learning. We compare and summarize existing graph uncertainty theory and
methods, alongside the corresponding downstream tasks. Thereby, we bridge the
gap between theory and practice, meanwhile connecting different GNN
communities. Moreover, our work provides valuable insights into promising
directions in this field.","['Fangxin Wang', 'Yuqing Liu', 'Kay Liu', 'Yibo Wang', 'Sourav Medya', 'Philip S. Yu']"
Mean Field Methods for a Special Class of Belief Networks,Artificial Intelligence,"The chief aim of this paper is to propose mean-field approximations for a
broad class of Belief networks, of which sigmoid and noisy-or networks can be
seen as special cases. The approximations are based on a powerful mean-field
theory suggested by Plefka. We show that Saul, Jaakkola and Jordan' s approach
is the first order approximation in Plefka's approach, via a variational
derivation. The application of Plefka's theory to belief networks is not
computationally tractable. To tackle this problem we propose new approximations
based on Taylor series. Small scale experiments show that the proposed schemes
are attractive.","['C. Bhattacharyya', 'S. S. Keerthi']"
BibRank: Automatic Keyphrase Extraction Platform Using~Metadata,Computation and Language (Natural Language Processing),"Automatic Keyphrase Extraction involves identifying essential phrases in a
document. These keyphrases are crucial in various tasks such as document
classification, clustering, recommendation, indexing, searching, summarization,
and text simplification. This paper introduces a platform that integrates
keyphrase datasets and facilitates the evaluation of keyphrase extraction
algorithms. The platform includes BibRank, an automatic keyphrase extraction
algorithm that leverages a rich dataset obtained by parsing bibliographic data
in BibTeX format. BibRank combines innovative weighting techniques with
positional, statistical, and word co-occurrence information to extract
keyphrases from documents. The platform proves valuable for researchers and
developers seeking to enhance their keyphrase extraction algorithms and advance
the field of natural language processing.","['Abdelrhman Eldallal', 'Eduard Barbu']"
"Extraction of V-N-Collocations from Text Corpora: A Feasibility Study
  for German",Computation and Language (Legacy category),"The usefulness of a statistical approach suggested by Church et al. (1991) is
evaluated for the extraction of verb-noun (V-N) collocations from German text
corpora. Some problematic issues of that method arising from properties of the
German language are discussed and various modifications of the method are
considered that might improve extraction results for German. The precision and
recall of all variant methods is evaluated for V-N collocations containing
support verbs, and the consequences for further work on the extraction of
collocations from German corpora are discussed.
  With a sufficiently large corpus (>= 6 mio. word-tokens), the average error
rate of wrong extractions can be reduced to 2.2% (97.8% precision) with the
most restrictive method, however with a loss in data of almost 50% compared to
a less restrictive method with still 87.6% precision. Depending on the goal to
be achieved, emphasis can be put on a high recall for lexicographic purposes or
on high precision for automatic lexical acquisition, in each case unfortunately
leading to a decrease of the corresponding other variable. Low recall can still
be acceptable if very large corpora (i.e. 50 - 100 million words) are available
or if corpora for special domains are used in addition to the data found in
machine readable (collocation) dictionaries.",['Elisabeth Breidt']
Fast Temporal Wavelet Graph Neural Networks,Machine Learning,"Spatio-temporal signals forecasting plays an important role in numerous
domains, especially in neuroscience and transportation. The task is challenging
due to the highly intricate spatial structure, as well as the non-linear
temporal dynamics of the network. To facilitate reliable and timely forecast
for the human brain and traffic networks, we propose the Fast Temporal Wavelet
Graph Neural Networks (FTWGNN) that is both time- and memory-efficient for
learning tasks on timeseries data with the underlying graph structure, thanks
to the theories of multiresolution analysis and wavelet theory on discrete
spaces. We employ Multiresolution Matrix Factorization (MMF) (Kondor et al.,
2014) to factorize the highly dense graph structure and compute the
corresponding sparse wavelet basis that allows us to construct fast wavelet
convolution as the backbone of our novel architecture. Experimental results on
real-world PEMS-BAY, METR-LA traffic datasets and AJILE12 ECoG dataset show
that FTWGNN is competitive with the state-of-the-arts while maintaining a low
computational footprint. Our PyTorch implementation is publicly available at
https://github.com/HySonLab/TWGNN","['Duc Thien Nguyen', 'Manh Duc Tuan Nguyen', 'Truong Son Hy', 'Risi Kondor']"
"A Semi-supervised Approach for a Better Translation of Sentiment in
  Dialectical Arabic UGT",Computation and Language (Natural Language Processing),"In the online world, Machine Translation (MT) systems are extensively used to
translate User-Generated Text (UGT) such as reviews, tweets, and social media
posts, where the main message is often the author's positive or negative
attitude towards the topic of the text. However, MT systems still lack accuracy
in some low-resource languages and sometimes make critical translation errors
that completely flip the sentiment polarity of the target word or phrase and
hence delivers a wrong affect message. This is particularly noticeable in texts
that do not follow common lexico-grammatical standards such as the dialectical
Arabic (DA) used on online platforms. In this research, we aim to improve the
translation of sentiment in UGT written in the dialectical versions of the
Arabic language to English. Given the scarcity of gold-standard parallel data
for DA-EN in the UGT domain, we introduce a semi-supervised approach that
exploits both monolingual and parallel data for training an NMT system
initialised by a cross-lingual language model trained with supervised and
unsupervised modeling objectives. We assess the accuracy of sentiment
translation by our proposed system through a numerical 'sentiment-closeness'
measure as well as human evaluation. We will show that our semi-supervised MT
system can significantly help with correcting sentiment errors detected in the
online translation of dialectical Arabic UGT.","['Hadeel Saadany', 'Constantin Orasan', 'Emad Mohamed', 'Ashraf Tantawy']"
Feature and Parameter Selection in Stochastic Linear Bandits,Machine Learning,"We study two model selection settings in stochastic linear bandits (LB). In
the first setting, which we refer to as feature selection, the expected reward
of the LB problem is in the linear span of at least one of $M$ feature maps
(models). In the second setting, the reward parameter of the LB problem is
arbitrarily selected from $M$ models represented as (possibly) overlapping
balls in $\mathbb R^d$. However, the agent only has access to misspecified
models, i.e.,~estimates of the centers and radii of the balls. We refer to this
setting as parameter selection. For each setting, we develop and analyze a
computationally efficient algorithm that is based on a reduction from bandits
to full-information problems. This allows us to obtain regret bounds that are
not worse (up to a $\sqrt{\log M}$ factor) than the case where the true model
is known. This is the best-reported dependence on the number of models $M$ in
these settings. Finally, we empirically show the effectiveness of our
algorithms using synthetic and real-world experiments.","['Ahmadreza Moradipari', 'Berkay Turan', 'Yasin Abbasi-Yadkori', 'Mahnoosh Alizadeh', 'Mohammad Ghavamzadeh']"
"TypeShift: A User Interface for Visualizing the Typing Production
  Process",Computation and Language (Natural Language Processing),"TypeShift is a tool for visualizing linguistic patterns in the timing of
typing production. Language production is a complex process which draws on
linguistic, cognitive and motor skills. By visualizing holistic trends in the
typing process, TypeShift aims to elucidate the often noisy information signals
that are used to represent typing patterns, both at the word-level and
character-level. It accomplishes this by enabling a researcher to compare and
contrast specific linguistic phenomena, and compare an individual typing
session to multiple group averages. Finally, although TypeShift was originally
designed for typing data, it can easy be adapted to accommodate speech data, as
well. A web demo is available at https://angoodkind.shinyapps.io/TypeShift/.
The source code can be accessed at https://github.com/angoodkind/TypeShift.",['Adam Goodkind']
Learning and Evaluating Sparse Interpretable Sentence Embeddings,Computation and Language (Natural Language Processing),"Previous research on word embeddings has shown that sparse representations,
which can be either learned on top of existing dense embeddings or obtained
through model constraints during training time, have the benefit of increased
interpretability properties: to some degree, each dimension can be understood
by a human and associated with a recognizable feature in the data. In this
paper, we transfer this idea to sentence embeddings and explore several
approaches to obtain a sparse representation. We further introduce a novel,
quantitative and automated evaluation metric for sentence embedding
interpretability, based on topic coherence methods. We observe an increase in
interpretability compared to dense models, on a dataset of movie dialogs and on
the scene descriptions from the MS COCO dataset.","['Valentin Trifonov', 'Octavian-Eugen Ganea', 'Anna Potapenko', 'Thomas Hofmann']"
"BINOCULARS for Efficient, Nonmyopic Sequential Experimental Design",Machine Learning,"Finite-horizon sequential experimental design (SED) arises naturally in many
contexts, including hyperparameter tuning in machine learning among more
traditional settings. Computing the optimal policy for such problems requires
solving Bellman equations, which are generally intractable. Most existing work
resorts to severely myopic approximations by limiting the decision horizon to
only a single time-step, which can underweight exploration in favor of
exploitation. We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using
Long-horizons for Adaptive, Rapid SED, a general framework for deriving
efficient, nonmyopic approximations to the optimal experimental policy. Our key
idea is simple and surprisingly effective: we first compute a one-step optimal
batch of experiments, then select a single point from this batch to evaluate.
We realize BINOCULARS for Bayesian optimization and Bayesian quadrature -- two
notable SED problems with radically different objectives -- and demonstrate
that BINOCULARS significantly outperforms myopic alternatives in real-world
scenarios.","['Shali Jiang', 'Henry Chai', 'Javier Gonzalez', 'Roman Garnett']"
DNA Reservoir Computing: A Novel Molecular Computing Approach,Neural and Evolutionary Computing,"We propose a novel molecular computing approach based on reservoir computing.
In reservoir computing, a dynamical core, called a reservoir, is perturbed with
an external input signal while a readout layer maps the reservoir dynamics to a
target output. Computation takes place as a transformation from the input space
to a high-dimensional spatiotemporal feature space created by the transient
dynamics of the reservoir. The readout layer then combines these features to
produce the target output. We show that coupled deoxyribozyme oscillators can
act as the reservoir. We show that despite using only three coupled
oscillators, a molecular reservoir computer could achieve 90% accuracy on a
benchmark temporal problem.","['Alireza Goudarzi', 'Matthew R. Lakin', 'Darko Stefanovic']"
"RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report
  Classification",Machine Learning,"Radiology reports are unstructured and contain the imaging findings and
corresponding diagnoses transcribed by radiologists which include clinical
facts and negated and/or uncertain statements. Extracting pathologic findings
and diagnoses from radiology reports is important for quality control,
population health, and monitoring of disease progress. Existing works,
primarily rely either on rule-based systems or transformer-based pre-trained
model fine-tuning, but could not take the factual and uncertain information
into consideration, and therefore generate false-positive outputs. In this
work, we introduce three sedulous augmentation techniques which retain factual
and critical information while generating augmentations for contrastive
learning. We introduce RadBERT-CL, which fuses these information into BlueBert
via a self-supervised contrastive loss. Our experiments on MIMIC-CXR show
superior performance of RadBERT-CL on fine-tuning for multi-class, multi-label
report classification. We illustrate that when few labeled data are available,
RadBERT-CL outperforms conventional SOTA transformers (BERT/BlueBert) by
significantly larger margins (6-11%). We also show that the representations
learned by RadBERT-CL can capture critical medical information in the latent
space.","['Ajay Jaiswal', 'Liyan Tang', 'Meheli Ghosh', 'Justin Rousseau', 'Yifan Peng', 'Ying Ding']"
"High Performance Human Face Recognition using Independent High Intensity
  Gabor Wavelet Responses: A Statistical Approach",Computer Vision and Pattern Recognition,"In this paper, we present a technique by which high-intensity feature vectors
extracted from the Gabor wavelet transformation of frontal face images, is
combined together with Independent Component Analysis (ICA) for enhanced face
recognition. Firstly, the high-intensity feature vectors are automatically
extracted using the local characteristics of each individual face from the
Gabor transformed images. Then ICA is applied on these locally extracted
high-intensity feature vectors of the facial images to obtain the independent
high intensity feature (IHIF) vectors. These IHIF forms the basis of the work.
Finally, the image classification is done using these IHIF vectors, which are
considered as representatives of the images. The importance behind implementing
ICA along with the high-intensity features of Gabor wavelet transformation is
twofold. On the one hand, selecting peaks of the Gabor transformed face images
exhibit strong characteristics of spatial locality, scale, and orientation
selectivity. Thus these images produce salient local features that are most
suitable for face recognition. On the other hand, as the ICA employs locally
salient features from the high informative facial parts, it reduces redundancy
and represents independent features explicitly. These independent features are
most useful for subsequent facial discrimination and associative recall. The
efficiency of IHIF method is demonstrated by the experiment on frontal facial
images dataset, selected from the FERET, FRAV2D, and the ORL database.","['Arindam Kar', 'Debotosh Bhattacharjee', 'Dipak Kumar Basu', 'Mita Nasipuri', 'Mahantapas Kundu']"
The Assumptions Behind Dempster's Rule,Artificial Intelligence,"This paper examines the concept of a combination rule for belief functions.
It is shown that two fairly simple and apparently reasonable assumptions
determine Dempster's rule, giving a new justification for it.",['Nic Wilson']
"Monadic Pavlovian associative learning in a backpropagation-free
  photonic network",Optics,"Over a century ago, Ivan P. Pavlov, in a classic experiment, demonstrated how
dogs can learn to associate a ringing bell with food, thereby causing a ring to
result in salivation. Today, it is rare to find the use of Pavlovian type
associative learning for artificial intelligence (AI) applications even though
other learning concepts, in particular backpropagation on artificial neural
networks (ANNs) have flourished. However, training using the backpropagation
method on 'conventional' ANNs, especially in the form of modern deep neural
networks (DNNs), is computationally and energy intensive. Here we
experimentally demonstrate a form of backpropagation-free learning using a
single (or monadic) associative hardware element. We realize this on an
integrated photonic platform using phase-change materials combined with on-chip
cascaded directional couplers. We then develop a scaled-up circuit network
using our monadic Pavlovian photonic hardware that delivers a distinct
machine-learning framework based on single-element associations and,
importantly, using backpropagation-free architectures to address general
learning tasks. Our approach reduces the computational burden imposed by
learning in conventional neural network approaches, thereby increasing speed,
whilst also offering higher bandwidth inherent to our photonic implementation.","['James Y. S. Tan', 'Zengguang Cheng', 'Johannes Feldmann', 'Xuan Li', 'Nathan Youngblood', 'Utku E. Ali', 'C. David Wright', 'Wolfram H. P. Pernice', 'Harish Bhaskaran']"
"NLP-CUET@DravidianLangTech-EACL2021: Offensive Language Detection from
  Multilingual Code-Mixed Text using Transformers",Computation and Language (Natural Language Processing),"The increasing accessibility of the internet facilitated social media usage
and encouraged individuals to express their opinions liberally. Nevertheless,
it also creates a place for content polluters to disseminate offensive posts or
contents. Most of such offensive posts are written in a cross-lingual manner
and can easily evade the online surveillance systems. This paper presents an
automated system that can identify offensive text from multilingual code-mixed
data. In the task, datasets provided in three languages including Tamil,
Malayalam and Kannada code-mixed with English where participants are asked to
implement separate models for each language. To accomplish the tasks, we
employed two machine learning techniques (LR, SVM), three deep learning (LSTM,
LSTM+Attention) techniques and three transformers (m-BERT, Indic-BERT, XLM-R)
based methods. Results show that XLM-R outperforms other techniques in Tamil
and Malayalam languages while m-BERT achieves the highest score in the Kannada
language. The proposed models gained weighted $f_1$ score of $0.76$ (for
Tamil), $0.93$ (for Malayalam), and $0.71$ (for Kannada) with a rank of
$3^{rd}$, $5^{th}$ and $4^{th}$ respectively.","['Omar Sharif', 'Eftekhar Hossain', 'Mohammed Moshiul Hoque']"
The ABBE Corpus: Animate Beings Being Emotional,Computation and Language (Natural Language Processing),"Emotion detection is an established NLP task of demonstrated utility for text
understanding. However, basic emotion detection leaves out key information,
namely, who is experiencing the emotion in question. For example, it may be the
author, the narrator, or a character; or the emotion may correspond to
something the audience is supposed to feel, or even be unattributable to a
specific being, e.g., when emotions are being discussed per se. We provide the
ABBE corpus -- Animate Beings Being Emotional -- a new double-annotated corpus
of texts that captures this key information for one class of emotion
experiencer, namely, animate beings in the world described by the text. Such a
corpus is useful for developing systems that seek to model or understand this
specific type of expressed emotion. Our corpus contains 30 chapters, comprising
134,513 words, drawn from the Corpus of English Novels, and contains 2,010
unique emotion expressions attributable to 2,227 animate beings. The emotion
expressions are categorized according to Plutchik's 8-category emotion model,
and the overall inter-annotator agreement for the annotations was 0.83 Cohen's
Kappa, indicating excellent agreement. We describe in detail our annotation
scheme and procedure, and also release the corpus for use by other researchers.","['Samira Zad', 'Joshuan Jimenez', 'Mark A. Finlayson']"
"NeuroLGP-SM: Scalable Surrogate-Assisted Neuroevolution for Deep Neural
  Networks",Neural and Evolutionary Computing,"Evolutionary Algorithms (EAs) play a crucial role in the architectural
configuration and training of Artificial Deep Neural Networks (DNNs), a process
known as neuroevolution. However, neuroevolution is hindered by its inherent
computational expense, requiring multiple generations, a large population, and
numerous epochs. The most computationally intensive aspect lies in evaluating
the fitness function of a single candidate solution. To address this challenge,
we employ Surrogate-assisted EAs (SAEAs). While a few SAEAs approaches have
been proposed in neuroevolution, none have been applied to truly large DNNs due
to issues like intractable information usage. In this work, drawing inspiration
from Genetic Programming semantics, we use phenotypic distance vectors,
outputted from DNNs, alongside Kriging Partial Least Squares (KPLS), an
approach that is effective in handling these large vectors, making them
suitable for search. Our proposed approach, named Neuro-Linear Genetic
Programming surrogate model (NeuroLGP-SM), efficiently and accurately estimates
DNN fitness without the need for complete evaluations. NeuroLGP-SM demonstrates
competitive or superior results compared to 12 other methods, including
NeuroLGP without SM, convolutional neural networks, support vector machines,
and autoencoders. Additionally, it is worth noting that NeuroLGP-SM is 25% more
energy-efficient than its NeuroLGP counterpart. This efficiency advantage adds
to the overall appeal of our proposed NeuroLGP-SM in optimising the
configuration of large DNNs.","['Fergal Stapleton', 'Edgar Galván']"
"Learning MDPs from Features: Predict-Then-Optimize for Sequential
  Decision Problems by Reinforcement Learning",Machine Learning,"In the predict-then-optimize framework, the objective is to train a
predictive model, mapping from environment features to parameters of an
optimization problem, which maximizes decision quality when the optimization is
subsequently solved. Recent work on decision-focused learning shows that
embedding the optimization problem in the training pipeline can improve
decision quality and help generalize better to unseen tasks compared to relying
on an intermediate loss function for evaluating prediction quality. We study
the predict-then-optimize framework in the context of sequential decision
problems (formulated as MDPs) that are solved via reinforcement learning. In
particular, we are given environment features and a set of trajectories from
training MDPs, which we use to train a predictive model that generalizes to
unseen test MDPs without trajectories. Two significant computational challenges
arise in applying decision-focused learning to MDPs: (i) large state and action
spaces make it infeasible for existing techniques to differentiate through MDP
problems, and (ii) the high-dimensional policy space, as parameterized by a
neural network, makes differentiating through a policy expensive. We resolve
the first challenge by sampling provably unbiased derivatives to approximate
and differentiate through optimality conditions, and the second challenge by
using a low-rank approximation to the high-dimensional sample-based
derivatives. We implement both Bellman--based and policy gradient--based
decision-focused learning on three different MDP problems with missing
parameters, and show that decision-focused learning performs better in
generalization to unseen tasks.","['Kai Wang', 'Sanket Shah', 'Haipeng Chen', 'Andrew Perrault', 'Finale Doshi-Velez', 'Milind Tambe']"
"Higher Order of Motion Magnification for Vessel Localisation in Surgical
  Video",Computer Vision and Pattern Recognition,"Locating vessels during surgery is critical for avoiding inadvertent damage,
yet vasculature can be difficult to identify. Video motion magnification can
potentially highlight vessels by exaggerating subtle motion embedded within the
video to become perceivable to the surgeon. In this paper, we explore a
physiological model of artery distension to extend motion magnification to
incorporate higher orders of motion, leveraging the difference in acceleration
over time (jerk) in pulsatile motion to highlight the vascular pulse wave. Our
method is compared to first and second order motion based Eulerian video
magnification algorithms. Using data from a surgical video retrieved during a
robotic prostatectomy, we show that our method can accentuate
cardio-physiological features and produce a more succinct and clearer video for
motion magnification, with more similarities in areas without motion to the
source video at large magnifications. We validate the approach with a Structure
Similarity (SSIM) and Peak Signal to Noise Ratio (PSNR) assessment of three
videos at an increasing working distance, using three different levels of
optical magnification. Spatio-temporal cross sections are presented to show the
effectiveness of our proposal and video samples are provided to demonstrates
qualitatively our results.","['Mirek Janatka', 'Ashwin Sridhar', 'John Kelly', 'Danail Stoyanov']"
"Rethinking RGB-D Salient Object Detection: Models, Data Sets, and
  Large-Scale Benchmarks",Computer Vision and Pattern Recognition,"The use of RGB-D information for salient object detection has been
extensively explored in recent years. However, relatively few efforts have been
put towards modeling salient object detection in real-world human activity
scenes with RGBD. In this work, we fill the gap by making the following
contributions to RGB-D salient object detection. (1) We carefully collect a new
SIP (salient person) dataset, which consists of ~1K high-resolution images that
cover diverse real-world scenes from various viewpoints, poses, occlusions,
illuminations, and backgrounds. (2) We conduct a large-scale (and, so far, the
most comprehensive) benchmark comparing contemporary methods, which has long
been missing in the field and can serve as a baseline for future research. We
systematically summarize 32 popular models and evaluate 18 parts of 32 models
on seven datasets containing a total of about 97K images. (3) We propose a
simple general architecture, called Deep Depth-Depurator Network (D3Net). It
consists of a depth depurator unit (DDU) and a three-stream feature learning
module (FLM), which performs low-quality depth map filtering and cross-modal
feature learning respectively. These components form a nested structure and are
elaborately designed to be learned jointly. D3Net exceeds the performance of
any prior contenders across all five metrics under consideration, thus serving
as a strong model to advance research in this field. We also demonstrate that
D3Net can be used to efficiently extract salient object masks from real scenes,
enabling effective background changing application with a speed of 65fps on a
single GPU. All the saliency maps, our new SIP dataset, the D3Net model, and
the evaluation tools are publicly available at
https://github.com/DengPingFan/D3NetBenchmark.","['Deng-Ping Fan', 'Zheng Lin', 'Jia-Xing Zhao', 'Yun Liu', 'Zhao Zhang', 'Qibin Hou', 'Menglong Zhu', 'Ming-Ming Cheng']"
"""You Are An Expert Linguistic Annotator"": Limits of LLMs as Analyzers of
  Abstract Meaning Representation",Computation and Language (Natural Language Processing),"Large language models (LLMs) show amazing proficiency and fluency in the use
of language. Does this mean that they have also acquired insightful linguistic
knowledge about the language, to an extent that they can serve as an ""expert
linguistic annotator""? In this paper, we examine the successes and limitations
of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning
structure, focusing on the Abstract Meaning Representation (AMR; Banarescu et
al. 2013) parsing formalism, which provides rich graphical representations of
sentence meaning structure while abstracting away from surface forms. We
compare models' analysis of this semantic structure across two settings: 1)
direct production of AMR parses based on zero- and few-shot prompts, and 2)
indirect partial reconstruction of AMR via metalinguistic natural language
queries (e.g., ""Identify the primary event of this sentence, and the predicate
corresponding to that event.""). Across these settings, we find that models can
reliably reproduce the basic format of AMR, and can often capture core event,
argument, and modifier structure -- however, model outputs are prone to
frequent and major errors, and holistic analysis of parse acceptability shows
that even with few-shot demonstrations, models have virtually 0% success in
producing fully accurate parses. Eliciting natural language responses produces
similar patterns of errors. Overall, our findings indicate that these models
out-of-the-box can capture aspects of semantic structure, but there remain key
limitations in their ability to support fully accurate semantic analyses or
parses.","['Allyson Ettinger', 'Jena D. Hwang', 'Valentina Pyatkin', 'Chandra Bhagavatula', 'Yejin Choi']"
"Evaluating and Optimizing Educational Content with Large Language Model
  Judgments",Artificial Intelligence,"Creating effective educational materials generally requires expensive and
time-consuming studies of student learning outcomes. To overcome this barrier,
one idea is to build computational models of student learning and use them to
optimize instructional materials. However, it is difficult to model the
cognitive processes of learning dynamics. We propose an alternative approach
that uses Language Models (LMs) as educational experts to assess the impact of
various instructions on learning outcomes. Specifically, we use GPT-3.5 to
evaluate the overall effect of instructional materials on different student
groups and find that it can replicate well-established educational findings
such as the Expertise Reversal Effect and the Variability Effect. This
demonstrates the potential of LMs as reliable evaluators of educational
content. Building on this insight, we introduce an instruction optimization
approach in which one LM generates instructional materials using the judgments
of another LM as a reward function. We apply this approach to create math word
problem worksheets aimed at maximizing student learning gains. Human teachers'
evaluations of these LM-generated worksheets show a significant alignment
between the LM judgments and human teacher preferences. We conclude by
discussing potential divergences between human and LM opinions and the
resulting pitfalls of automating instructional design.","['Joy He-Yueya', 'Noah D. Goodman', 'Emma Brunskill']"
"Nonlinear Conjugate Gradients For Scaling Synchronous Distributed DNN
  Training",Machine Learning,"Nonlinear conjugate gradient (NLCG) based optimizers have shown superior loss
convergence properties compared to gradient descent based optimizers for
traditional optimization problems. However, in Deep Neural Network (DNN)
training, the dominant optimization algorithm of choice is still Stochastic
Gradient Descent (SGD) and its variants. In this work, we propose and evaluate
the stochastic preconditioned nonlinear conjugate gradient algorithm for large
scale DNN training tasks. We show that a nonlinear conjugate gradient algorithm
improves the convergence speed of DNN training, especially in the large
mini-batch scenario, which is essential for scaling synchronous distributed DNN
training to large number of workers. We show how to efficiently use second
order information in the NLCG pre-conditioner for improving DNN training
convergence. For the ImageNet classification task, at extremely large
mini-batch sizes of greater than 65k, NLCG optimizer is able to improve top-1
accuracy by more than 10 percentage points for standard training of the
Resnet-50 model for 90 epochs. For the CIFAR-100 classification task, at
extremely large mini-batch sizes of greater than 16k, NLCG optimizer is able to
improve top-1 accuracy by more than 15 percentage points for standard training
of the Resnet-32 model for 200 epochs.","['Saurabh Adya', 'Vinay Palakkode', 'Oncel Tuzel']"
Fast Asymmetric Factorization for Large Scale Multiple Kernel Clustering,Machine Learning,"Kernel methods are extensively employed for nonlinear data clustering, yet
their effectiveness heavily relies on selecting suitable kernels and associated
parameters, posing challenges in advance determination. In response, Multiple
Kernel Clustering (MKC) has emerged as a solution, allowing the fusion of
information from multiple base kernels for clustering. However, both early
fusion and late fusion methods for large-scale MKC encounter challenges in
memory and time constraints, necessitating simultaneous optimization of both
aspects. To address this issue, we propose Efficient Multiple Kernel Concept
Factorization (EMKCF), which constructs a new sparse kernel matrix inspired by
local regression to achieve memory efficiency. EMKCF learns consensus and
individual representations by extending orthogonal concept factorization to
handle multiple kernels for time efficiency. Experimental results demonstrate
the efficiency and effectiveness of EMKCF on benchmark datasets compared to
state-of-the-art methods. The proposed method offers a straightforward,
scalable, and effective solution for large-scale MKC tasks.","['Yan Chen', 'Liang Du', 'Lei Duan']"
"ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine
  Translation",Computation and Language (Natural Language Processing),"Large language model (LLM) has achieved promising performance in multilingual
machine translation tasks through zero/few-shot prompts or prompt-tuning.
However, due to the mixture of multilingual data during the pre-training of
LLM, the LLM-based translation models face the off-target issue in both
prompt-based methods, including a series of phenomena, namely instruction
misunderstanding, translation with wrong language and over-generation. For this
issue, this paper introduces an
\textbf{\underline{A}}uto-\textbf{\underline{C}}onstriction
\textbf{\underline{T}}urning mechanism for \textbf{\underline{M}}ultilingual
\textbf{\underline{N}}eural \textbf{\underline{M}}achine
\textbf{\underline{T}}ranslation (\model), which is a novel supervised
fine-tuning mechanism and orthogonal to the traditional prompt-based methods.
In this method, \model automatically constructs a constrained template in the
target side by adding trigger tokens ahead of the ground truth. Furthermore,
trigger tokens can be arranged and combined freely to represent different task
semantics, and they can be iteratively updated to maximize the label
likelihood. Experiments are performed on WMT test sets with multiple metrics,
and the experimental results demonstrate that \model achieves substantially
improved performance across multiple translation directions and reduce the
off-target phenomena in the translation.","['Shaojie Dai', 'Xin Liu', 'Ping Luo', 'Yue Yu']"
Deep Mixtures of Factor Analysers,Machine Learning,"An efficient way to learn deep density models that have many layers of latent
variables is to learn one layer at a time using a model that has only one layer
of latent variables. After learning each layer, samples from the posterior
distributions for that layer are used as training data for learning the next
layer. This approach is commonly used with Restricted Boltzmann Machines, which
are undirected graphical models with a single hidden layer, but it can also be
used with Mixtures of Factor Analysers (MFAs) which are directed graphical
models. In this paper, we present a greedy layer-wise learning algorithm for
Deep Mixtures of Factor Analysers (DMFAs). Even though a DMFA can be converted
to an equivalent shallow MFA by multiplying together the factor loading
matrices at different levels, learning and inference are much more efficient in
a DMFA and the sharing of each lower-level factor loading matrix by many
different higher level MFAs prevents overfitting. We demonstrate empirically
that DMFAs learn better density models than both MFAs and two types of
Restricted Boltzmann Machine on a wide variety of datasets.","['Yichuan Tang', 'Ruslan Salakhutdinov', 'Geoffrey Hinton']"
"Artificial intelligence and radiation protection. A game changer or an
  update?",Machine Learning,"Artificial intelligence (AI) is regarded as one of the most disruptive
technology of the century and with countless applications. What does it mean
for radiation protection? This article describes the fundamentals of machine
learning (ML) based methods and presents the inaugural applications in
different fields of radiation protection. It is foreseen that the usage of AI
will increase in radiation protection. Consequently, this article explores some
of the benefits and also the potential barriers and questions, including
ethical ones, that can come out. The article proposes that collaboration
between radiation protection professionals and data scientist experts can
accelerate and guide the development of the algorithms for effective scientific
and technological outcomes.","['Sylvain Andresz', 'A Zéphir', 'Jeremy Bez', 'Maxime Karst', 'J. Danieli']"
"Coupling semantic and statistical techniques for dynamically enriching
  web ontologies",Computation and Language (Natural Language Processing),"With the development of the Semantic Web technology, the use of ontologies to
store and retrieve information covering several domains has increased. However,
very few ontologies are able to cope with the ever-growing need of frequently
updated semantic information or specific user requirements in specialized
domains. As a result, a critical issue is related to the unavailability of
relational information between concepts, also coined missing background
knowledge. One solution to address this issue relies on the manual enrichment
of ontologies by domain experts which is however a time consuming and costly
process, hence the need for dynamic ontology enrichment. In this paper we
present an automatic coupled statistical/semantic framework for dynamically
enriching large-scale generic ontologies from the World Wide Web. Using the
massive amount of information encoded in texts on the Web as a corpus, missing
background knowledge can therefore be discovered through a combination of
semantic relatedness measures and pattern acquisition techniques and
subsequently exploited. The benefits of our approach are: (i) proposing the
dynamic enrichment of large-scale generic ontologies with missing background
knowledge, and thus, enabling the reuse of such knowledge, (ii) dealing with
the issue of costly ontological manual enrichment by domain experts.
Experimental results in a precision-based evaluation setting demonstrate the
effectiveness of the proposed techniques.","['Mohammed Maree', 'Mohammed Belkhatir']"
"Towards explainable evaluation of language models on the semantic
  similarity of visual concepts",Computation and Language (Natural Language Processing),"Recent breakthroughs in NLP research, such as the advent of Transformer
models have indisputably contributed to major advancements in several tasks.
However, few works research robustness and explainability issues of their
evaluation strategies. In this work, we examine the behavior of high-performing
pre-trained language models, focusing on the task of semantic similarity for
visual vocabularies. First, we address the need for explainable evaluation
metrics, necessary for understanding the conceptual quality of retrieved
instances. Our proposed metrics provide valuable insights in local and global
level, showcasing the inabilities of widely used approaches. Secondly,
adversarial interventions on salient query semantics expose vulnerabilities of
opaque metrics and highlight patterns in learned linguistic representations.","['Maria Lymperaiou', 'George Manoliadis', 'Orfeas Menis Mastromichalakis', 'Edmund G. Dervakos', 'Giorgos Stamou']"
Federated Learning: Strategies for Improving Communication Efficiency,Machine Learning,"Federated Learning is a machine learning setting where the goal is to train a
high-quality centralized model while training data remains distributed over a
large number of clients each with unreliable and relatively slow network
connections. We consider learning algorithms for this setting where on each
round, each client independently computes an update to the current model based
on its local data, and communicates this update to a central server, where the
client-side updates are aggregated to compute a new global model. The typical
clients in this setting are mobile phones, and communication efficiency is of
the utmost importance.
  In this paper, we propose two ways to reduce the uplink communication costs:
structured updates, where we directly learn an update from a restricted space
parametrized using a smaller number of variables, e.g. either low-rank or a
random mask; and sketched updates, where we learn a full model update and then
compress it using a combination of quantization, random rotations, and
subsampling before sending it to the server. Experiments on both convolutional
and recurrent networks show that the proposed methods can reduce the
communication cost by two orders of magnitude.","['Jakub Konečný', 'H. Brendan McMahan', 'Felix X. Yu', 'Peter Richtárik', 'Ananda Theertha Suresh', 'Dave Bacon']"
"Pyramid Network with Online Hard Example Mining for Accurate Left Atrium
  Segmentation",Computer Vision and Pattern Recognition,"Accurately segmenting left atrium in MR volume can benefit the ablation
procedure of atrial fibrillation. Traditional automated solutions often fail in
relieving experts from the labor-intensive manual labeling. In this paper, we
propose a deep neural network based solution for automated left atrium
segmentation in gadolinium-enhanced MR volumes with promising performance. We
firstly argue that, for this volumetric segmentation task, networks in 2D
fashion can present great superiorities in time efficiency and segmentation
accuracy than networks with 3D fashion. Considering the highly varying shape of
atrium and the branchy structure of associated pulmonary veins, we propose to
adopt a pyramid module to collect semantic cues in feature maps from multiple
scales for fine-grained segmentation. Also, to promote our network in
classifying the hard examples, we propose an Online Hard Negative Example
Mining strategy to identify voxels in slices with low classification
certainties and penalize the wrong predictions on them. Finally, we devise a
competitive training scheme to further boost the generalization ability of
networks. Extensively verified on 20 testing volumes, our proposed framework
achieves an average Dice of 92.83% in segmenting the left atria and pulmonary
veins.","['Cheng Bian', 'Xin Yang', 'Jianqiang Ma', 'Shen Zheng', 'Yu-An Liu', 'Reza Nezafat', 'Pheng-Ann Heng', 'Yefeng Zheng']"
A survey on practical adversarial examples for malware classifiers,Cryptography and Security,"Machine learning based solutions have been very helpful in solving problems
that deal with immense amounts of data, such as malware detection and
classification. However, deep neural networks have been found to be vulnerable
to adversarial examples, or inputs that have been purposefully perturbed to
result in an incorrect label. Researchers have shown that this vulnerability
can be exploited to create evasive malware samples. However, many proposed
attacks do not generate an executable and instead generate a feature vector. To
fully understand the impact of adversarial examples on malware detection, we
review practical attacks against malware classifiers that generate executable
adversarial malware examples. We also discuss current challenges in this area
of research, as well as suggestions for improvement and future research
directions.","['Daniel Park', 'Bülent Yener']"
"Performance Analysis of Deep Autoencoder and NCA Dimensionality
  Reduction Techniques with KNN, ENN and SVM Classifiers",Machine Learning,"The central aim of this paper is to implement Deep Autoencoder and
Neighborhood Components Analysis (NCA) dimensionality reduction methods in
Matlab and to observe the application of these algorithms on nine unlike
datasets from UCI machine learning repository. These datasets are CNAE9,
Movement Libras, Pima Indians diabetes, Parkinsons, Knowledge, Segmentation,
Seeds, Mammographic Masses, and Ionosphere. First of all, the dimension of
these datasets has been reduced to fifty percent of their original dimension by
selecting and extracting the most relevant and appropriate features or
attributes using Deep Autoencoder and NCA dimensionality reduction techniques.
Afterward, each dataset is classified applying K-Nearest Neighbors (KNN),
Extended Nearest Neighbors (ENN) and Support Vector Machine (SVM)
classification algorithms. All classification algorithms are developed in the
Matlab environment. In each classification, the training test data ratio is
always set to ninety percent: ten percent. Upon classification, variation
between accuracies is observed and analyzed to find the degree of compatibility
of each dimensionality reduction technique with each classifier and to evaluate
each classifier performance on each dataset.","['Md. Abu Bakr Siddique', 'Shadman Sakib', 'Md. Abdur Rahman']"
"Exponentially-Modified Gaussian Mixture Model: Applications in
  Spectroscopy",Machine Learning (Statistics),"We propose a novel exponentially-modified Gaussian (EMG) mixture residual
model. The EMG mixture is well suited to model residuals that are contaminated
by a distribution with positive support. This is in contrast to commonly used
robust residual models, like the Huber loss or $\ell_1$, which assume a
symmetric contaminating distribution and are otherwise asymptotically biased.
We propose an expectation-maximization algorithm to optimize an arbitrary model
with respect to the EMG mixture. We apply the approach to linear regression and
probabilistic matrix factorization (PMF). We compare against other residual
models, including quantile regression. Our numerical experiments demonstrate
the strengths of the EMG mixture on both tasks. The PMF model arises from
considering spectroscopic data. In particular, we demonstrate the effectiveness
of PMF in conjunction with the EMG mixture model on synthetic data and two
real-world applications: X-ray diffraction and Raman spectroscopy. We show how
our approach is effective in inferring background signals and systematic errors
in data arising from these experimental settings, dramatically outperforming
existing approaches and revealing the data's physically meaningful components.","['Sebastian Ament', 'John Gregoire', 'Carla Gomes']"
"Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data
  Analysis",Machine Learning,"We analyze large, multi-dimensional, sparse counting data sets, finding
unsupervised groups to provide unique insights into genetic data. We create
gene and biological pathway groups based on patients' variants to find common
risk factors for four common types of cancer (breast, lung, prostate, and
colorectal) and autism spectrum disorder. To accomplish this, we extend latent
Dirichlet allocation to multiple dimensions and design distinct methods for
hierarchical topic modeling. We find that our conditional hierarchical Bayesian
Tucker decomposition models are more coherent than baseline models.","['Adam Sandler', 'Diego Klabjan', 'Yuan Luo']"
Alternating Direction Graph Matching,Computer Vision and Pattern Recognition,"In this paper, we introduce a graph matching method that can account for
constraints of arbitrary order, with arbitrary potential functions. Unlike
previous decomposition approaches that rely on the graph structures, we
introduce a decomposition of the matching constraints. Graph matching is then
reformulated as a non-convex non-separable optimization problem that can be
split into smaller and much-easier-to-solve subproblems, by means of the
alternating direction method of multipliers. The proposed framework is modular,
scalable, and can be instantiated into different variants. Two instantiations
are studied exploring pairwise and higher-order constraints. Experimental
results on widely adopted benchmarks involving synthetic and real examples
demonstrate that the proposed solutions outperform existing pairwise graph
matching methods, and competitive with the state of the art in higher-order
settings.","['D. Khuê Lê-Huu', 'Nikos Paragios']"
"CIA-Net: Robust Nuclei Instance Segmentation with Contour-aware
  Information Aggregation",Computer Vision and Pattern Recognition,"Accurate segmenting nuclei instances is a crucial step in computer-aided
image analysis to extract rich features for cellular estimation and following
diagnosis as well as treatment. While it still remains challenging because the
wide existence of nuclei clusters, along with the large morphological variances
among different organs make nuclei instance segmentation susceptible to
over-/under-segmentation. Additionally, the inevitably subjective annotating
and mislabeling prevent the network learning from reliable samples and
eventually reduce the generalization capability for robustly segmenting unseen
organ nuclei. To address these issues, we propose a novel deep neural network,
namely Contour-aware Informative Aggregation Network (CIA-Net) with multi-level
information aggregation module between two task-specific decoders. Rather than
independent decoders, it leverages the merit of spatial and texture
dependencies between nuclei and contour by bi-directionally aggregating
task-specific features. Furthermore, we proposed a novel smooth truncated loss
that modulates losses to reduce the perturbation from outliers. Consequently,
the network can focus on learning from reliable and informative samples, which
inherently improves the generalization capability. Experiments on the 2018
MICCAI challenge of Multi-Organ-Nuclei-Segmentation validated the effectiveness
of our proposed method, surpassing all the other 35 competitive teams by a
significant margin.","['Yanning Zhou', 'Omer Fahri Onder', 'Qi Dou', 'Efstratios Tsougenis', 'Hao Chen', 'Pheng-Ann Heng']"
Leveraging Transformers for StarCraft Macromanagement Prediction,Machine Learning,"Inspired by the recent success of transformers in natural language processing
and computer vision applications, we introduce a transformer-based neural
architecture for two key StarCraft II (SC2) macromanagement tasks: global state
and build order prediction. Unlike recurrent neural networks which suffer from
a recency bias, transformers are able to capture patterns across very long time
horizons, making them well suited for full game analysis. Our model utilizes
the MSC (Macromanagement in StarCraft II) dataset and improves on the top
performing gated recurrent unit (GRU) architecture in predicting global state
and build order as measured by mean accuracy over multiple time horizons. We
present ablation studies on our proposed architecture that support our design
decisions. One key advantage of transformers is their ability to generalize
well, and we demonstrate that our model achieves an even better accuracy when
used in a transfer learning setting in which models trained on games with one
racial matchup (e.g., Terran vs. Protoss) are transferred to a different one.
We believe that transformers' ability to model long games, potential for
parallelization, and generalization performance make them an excellent choice
for StarCraft agents.","['Muhammad Junaid Khan', 'Shah Hassan', 'Gita Sukthankar']"
"Improving Training Stability for Multitask Ranking Models in Recommender
  Systems",Machine Learning,"Recommender systems play an important role in many content platforms. While
most recommendation research is dedicated to designing better models to improve
user experience, we found that research on stabilizing the training for such
models is severely under-explored. As recommendation models become larger and
more sophisticated, they are more susceptible to training instability issues,
i.e., loss divergence, which can make the model unusable, waste significant
resources and block model developments. In this paper, we share our findings
and best practices we learned for improving the training stability of a
real-world multitask ranking model for YouTube recommendations. We show some
properties of the model that lead to unstable training and conjecture on the
causes. Furthermore, based on our observations of training dynamics near the
point of training instability, we hypothesize why existing solutions would
fail, and propose a new algorithm to mitigate the limitations of existing
solutions. Our experiments on YouTube production dataset show the proposed
algorithm can significantly improve training stability while not compromising
convergence, comparing with several commonly used baseline methods.","['Jiaxi Tang', 'Yoel Drori', 'Daryl Chang', 'Maheswaran Sathiamoorthy', 'Justin Gilmer', 'Li Wei', 'Xinyang Yi', 'Lichan Hong', 'Ed H. Chi']"
"Regions of Reliability in the Evaluation of Multivariate Probabilistic
  Forecasts",Machine Learning,"Multivariate probabilistic time series forecasts are commonly evaluated via
proper scoring rules, i.e., functions that are minimal in expectation for the
ground-truth distribution. However, this property is not sufficient to
guarantee good discrimination in the non-asymptotic regime. In this paper, we
provide the first systematic finite-sample study of proper scoring rules for
time-series forecasting evaluation. Through a power analysis, we identify the
""region of reliability"" of a scoring rule, i.e., the set of practical
conditions where it can be relied on to identify forecasting errors. We carry
out our analysis on a comprehensive synthetic benchmark, specifically designed
to test several key discrepancies between ground-truth and forecast
distributions, and we gauge the generalizability of our findings to real-world
tasks with an application to an electricity production problem. Our results
reveal critical shortcomings in the evaluation of multivariate probabilistic
forecasts as commonly performed in the literature.","['Étienne Marcotte', 'Valentina Zantedeschi', 'Alexandre Drouin', 'Nicolas Chapados']"
"LDW-SCSA: Logistic Dynamic Weight based Sine Cosine Search Algorithm for
  Numerical Functions Optimization",Neural and Evolutionary Computing,"Particle swarm optimization (PSO) and Sine Cosine algorithm (SCA) have been
widely used optimization methods but these methods have some disadvantages such
as trapped local optimum point. In order to solve this problem and obtain more
successful results than others, a novel logistic dynamic weight based sine
cosine search algorithm (LDW-SCSA) is presented in this paper. In the LDW-SCSA
method, logistic map is used as dynamic weight generator. Logistic map is one
of the famous and widely used chaotic map in the literature. Search process of
SCA is modified in the LDW-SCSA. To evaluate performance of the LDW-SCSA, the
widely used numerical benchmark functions were utilized as test suite and other
swarm optimization methods were used to obtain the comparison results. Superior
performances of the LDW-SCSA are proved success of this method.",['Turker Tuncer']
"A New Representation of Successor Features for Transfer across
  Dissimilar Environments",Machine Learning,"Transfer in reinforcement learning is usually achieved through generalisation
across tasks. Whilst many studies have investigated transferring knowledge when
the reward function changes, they have assumed that the dynamics of the
environments remain consistent. Many real-world RL problems require transfer
among environments with different dynamics. To address this problem, we propose
an approach based on successor features in which we model successor feature
functions with Gaussian Processes permitting the source successor features to
be treated as noisy measurements of the target successor feature function. Our
theoretical analysis proves the convergence of this approach as well as the
bounded error on modelling successor feature functions with Gaussian Processes
in environments with both different dynamics and rewards. We demonstrate our
method on benchmark datasets and show that it outperforms current baselines.","['Majid Abdolshah', 'Hung Le', 'Thommen Karimpanal George', 'Sunil Gupta', 'Santu Rana', 'Svetha Venkatesh']"
"Yseop at FinSim-3 Shared Task 2021: Specializing Financial Domain
  Learning with Phrase Representations",Computation and Language (Natural Language Processing),"In this paper, we present our approaches for the FinSim-3 Shared Task 2021:
Learning Semantic Similarities for the Financial Domain. The aim of this shared
task is to correctly classify a list of given terms from the financial domain
into the most relevant hypernym (or top-level) concept in an external ontology.
For our system submission, we evaluate two methods: a Sentence-RoBERTa
(SRoBERTa) embeddings model pre-trained on a custom corpus, and a dual
word-sentence embeddings model that builds on the first method by improving the
proposed baseline word embeddings construction using the FastText model to
boost the classification performance. Our system ranks 2nd overall on both
metrics, scoring 0.917 on Average Accuracy and 1.141 on Mean Rank.","['Hanna Abi Akl', 'Dominique Mariko', 'Hugues de Mazancourt']"
E2F-Net: Eyes-to-Face Inpainting via StyleGAN Latent Space,Computer Vision and Pattern Recognition,"Face inpainting, the technique of restoring missing or damaged regions in
facial images, is pivotal for applications like face recognition in occluded
scenarios and image analysis with poor-quality captures. This process not only
needs to produce realistic visuals but also preserve individual identity
characteristics. The aim of this paper is to inpaint a face given periocular
region (eyes-to-face) through a proposed new Generative Adversarial Network
(GAN)-based model called Eyes-to-Face Network (E2F-Net). The proposed approach
extracts identity and non-identity features from the periocular region using
two dedicated encoders have been used. The extracted features are then mapped
to the latent space of a pre-trained StyleGAN generator to benefit from its
state-of-the-art performance and its rich, diverse and expressive latent space
without any additional training. We further improve the StyleGAN output to find
the optimal code in the latent space using a new optimization for GAN inversion
technique. Our E2F-Net requires a minimum training process reducing the
computational complexity as a secondary benefit. Through extensive experiments,
we show that our method successfully reconstructs the whole face with high
quality, surpassing current techniques, despite significantly less training and
supervision efforts. We have generated seven eyes-to-face datasets based on
well-known public face datasets for training and verifying our proposed
methods. The code and datasets are publicly available.","['Ahmad Hassanpour', 'Fatemeh Jamalbafrani', 'Bian Yang', 'Kiran Raja', 'Raymond Veldhuis', 'Julian Fierrez']"
"GCExplainer: Human-in-the-Loop Concept-based Explanations for Graph
  Neural Networks",Machine Learning,"While graph neural networks (GNNs) have been shown to perform well on
graph-based data from a variety of fields, they suffer from a lack of
transparency and accountability, which hinders trust and consequently the
deployment of such models in high-stake and safety-critical scenarios. Even
though recent research has investigated methods for explaining GNNs, these
methods are limited to single-instance explanations, also known as local
explanations. Motivated by the aim of providing global explanations, we adapt
the well-known Automated Concept-based Explanation approach (Ghorbani et al.,
2019) to GNN node and graph classification, and propose GCExplainer.
GCExplainer is an unsupervised approach for post-hoc discovery and extraction
of global concept-based explanations for GNNs, which puts the human in the
loop. We demonstrate the success of our technique on five node classification
datasets and two graph classification datasets, showing that we are able to
discover and extract high-quality concept representations by putting the human
in the loop. We achieve a maximum completeness score of 1 and an average
completeness score of 0.753 across the datasets. Finally, we show that the
concept-based explanations provide an improved insight into the datasets and
GNN models compared to the state-of-the-art explanations produced by
GNNExplainer (Ying et al., 2019).","['Lucie Charlotte Magister', 'Dmitry Kazhdan', 'Vikash Singh', 'Pietro Liò']"
Solving the vehicle routing problem with deep reinforcement learning,Optimization and Control,"Recently, the applications of the methodologies of Reinforcement Learning
(RL) to NP-Hard Combinatorial optimization problems have become a popular
topic. This is essentially due to the nature of the traditional combinatorial
algorithms, often based on a trial-and-error process. RL aims at automating
this process. At this regard, this paper focuses on the application of RL for
the Vehicle Routing Problem (VRP), a famous combinatorial problem that belongs
to the class of NP-Hard problems. In this work, first, the problem is modeled
as a Markov Decision Process (MDP) and then the PPO method (which belongs to
the Actor-Critic class of Reinforcement learning methods) is applied. In a
second phase, the neural architecture behind the Actor and Critic has been
established, choosing to adopt a neural architecture based on the Convolutional
neural networks, both for the Actor and the Critic. This choice resulted in
effectively addressing problems of different sizes. Experiments performed on a
wide range of instances show that the algorithm has good generalization
capabilities and can reach good solutions in a short time. Comparisons between
the algorithm proposed and the state-of-the-art solver OR-TOOLS show that the
latter still outperforms the Reinforcement learning algorithm. However, there
are future research perspectives, that aim to upgrade the current performance
of the algorithm proposed.","['Simone Foa', 'Corrado Coppola', 'Giorgio Grani', 'Laura Palagi']"
Network Motifs Analysis of Croatian Literature,Computation and Language (Natural Language Processing),"In this paper we analyse network motifs in the co-occurrence directed
networks constructed from five different texts (four books and one portal) in
the Croatian language. After preparing the data and network construction, we
perform the network motif analysis. We analyse the motif frequencies and
Z-scores in the five networks. We present the triad significance profile for
five datasets. Furthermore, we compare our results with the existing results
for the linguistic networks. Firstly, we show that the triad significance
profile for the Croatian language is very similar with the other languages and
all the networks belong to the same family of networks. However, there are
certain differences between the Croatian language and other analysed languages.
We conclude that this is due to the free word-order of the Croatian language.","['Hana Rizvić', 'Sanda Martinčić-Ipšić', 'Ana Meštrović']"
"AutoPCF: Efficient Product Carbon Footprint Accounting with Large
  Language Models",Artificial Intelligence,"The product carbon footprint (PCF) is crucial for decarbonizing the supply
chain, as it measures the direct and indirect greenhouse gas emissions caused
by all activities during the product's life cycle. However, PCF accounting
often requires expert knowledge and significant time to construct life cycle
models. In this study, we test and compare the emergent ability of five large
language models (LLMs) in modeling the 'cradle-to-gate' life cycles of products
and generating the inventory data of inputs and outputs, revealing their
limitations as a generalized PCF knowledge database. By utilizing LLMs, we
propose an automatic AI-driven PCF accounting framework, called AutoPCF, which
also applies deep learning algorithms to automatically match calculation
parameters, and ultimately calculate the PCF. The results of estimating the
carbon footprint for three case products using the AutoPCF framework
demonstrate its potential in achieving automatic modeling and estimation of PCF
with a large reduction in modeling time from days to minutes.","['Zhu Deng', 'Jinjie Liu', 'Biao Luo', 'Can Yuan', 'Qingrun Yang', 'Lei Xiao', 'Wenwen Zhou', 'Zhu Liu']"
Noisy Networks for Exploration,Machine Learning,"We introduce NoisyNet, a deep reinforcement learning agent with parametric
noise added to its weights, and show that the induced stochasticity of the
agent's policy can be used to aid efficient exploration. The parameters of the
noise are learned with gradient descent along with the remaining network
weights. NoisyNet is straightforward to implement and adds little computational
overhead. We find that replacing the conventional exploration heuristics for
A3C, DQN and dueling agents (entropy reward and $\epsilon$-greedy respectively)
with NoisyNet yields substantially higher scores for a wide range of Atari
games, in some cases advancing the agent from sub to super-human performance.","['Meire Fortunato', 'Mohammad Gheshlaghi Azar', 'Bilal Piot', 'Jacob Menick', 'Ian Osband', 'Alex Graves', 'Vlad Mnih', 'Remi Munos', 'Demis Hassabis', 'Olivier Pietquin', 'Charles Blundell', 'Shane Legg']"
"Revisiting Salient Object Detection: Simultaneous Detection, Ranking,
  and Subitizing of Multiple Salient Objects",Computer Vision and Pattern Recognition,"Salient object detection is a problem that has been considered in detail and
many solutions proposed. In this paper, we argue that work to date has
addressed a problem that is relatively ill-posed. Specifically, there is not
universal agreement about what constitutes a salient object when multiple
observers are queried. This implies that some objects are more likely to be
judged salient than others, and implies a relative rank exists on salient
objects. The solution presented in this paper solves this more general problem
that considers relative rank, and we propose data and metrics suitable to
measuring success in a relative object saliency landscape. A novel deep
learning solution is proposed based on a hierarchical representation of
relative saliency and stage-wise refinement. We also show that the problem of
salient object subitizing can be addressed with the same network, and our
approach exceeds performance of any prior work across all metrics considered
(both traditional and newly proposed).","['Md Amirul Islam', 'Mahmoud Kalash', 'Neil D. B. Bruce']"
"MaxCutPool: differentiable feature-aware Maxcut for pooling in graph
  neural networks",Machine Learning,"We propose a novel approach to compute the MAXCUT in attributed graphs, i.e.,
graphs with features associated with nodes and edges. Our approach is robust to
the underlying graph topology and is fully differentiable, making it possible
to find solutions that jointly optimize the MAXCUT along with other objectives.
Based on the obtained MAXCUT partition, we implement a hierarchical graph
pooling layer for Graph Neural Networks, which is sparse, differentiable, and
particularly suitable for downstream tasks on heterophilic graphs.","['Carlo Abate', 'Filippo Maria Bianchi']"
Hyperbolic Deep Learning for Chinese Natural Language Understanding,Computation and Language (Natural Language Processing),"Recently hyperbolic geometry has proven to be effective in building
embeddings that encode hierarchical and entailment information. This makes it
particularly suited to modelling the complex asymmetrical relationships between
Chinese characters and words. In this paper we first train a large scale
hyperboloid skip-gram model on a Chinese corpus, then apply the character
embeddings to a downstream hyperbolic Transformer model derived from the
principles of gyrovector space for Poincare disk model. In our experiments the
character-based Transformer outperformed its word-based Euclidean equivalent.
To the best of our knowledge, this is the first time in Chinese NLP that a
character-based model outperformed its word-based counterpart, allowing the
circumvention of the challenging and domain-dependent task of Chinese Word
Segmentation (CWS).","['Marko Valentin Micic', 'Hugo Chu']"
A Relation-Oriented Clustering Method for Open Relation Extraction,Computation and Language (Natural Language Processing),"The clustering-based unsupervised relation discovery method has gradually
become one of the important methods of open relation extraction (OpenRE).
However, high-dimensional vectors can encode complex linguistic information
which leads to the problem that the derived clusters cannot explicitly align
with the relational semantic classes. In this work, we propose a
relation-oriented clustering model and use it to identify the novel relations
in the unlabeled data. Specifically, to enable the model to learn to cluster
relational data, our method leverages the readily available labeled data of
pre-defined relations to learn a relation-oriented representation. We minimize
distance between the instance with same relation by gathering the instances
towards their corresponding relation centroids to form a cluster structure, so
that the learned representation is cluster-friendly. To reduce the clustering
bias on predefined classes, we optimize the model by minimizing a joint
objective on both labeled and unlabeled data. Experimental results show that
our method reduces the error rate by 29.2% and 15.7%, on two datasets
respectively, compared with current SOTA methods.","['Jun Zhao', 'Tao Gui', 'Qi Zhang', 'Yaqian Zhou']"
Leveraging World Knowledge in Implicit Hate Speech Detection,Computation and Language (Natural Language Processing),"While much attention has been paid to identifying explicit hate speech,
implicit hateful expressions that are disguised in coded or indirect language
are pervasive and remain a major challenge for existing hate speech detection
systems. This paper presents the first attempt to apply Entity Linking (EL)
techniques to both explicit and implicit hate speech detection, where we show
that such real world knowledge about entity mentions in a text does help models
better detect hate speech, and the benefit of adding it into the model is more
pronounced when explicit entity triggers (e.g., rally, KKK) are present. We
also discuss cases where real world knowledge does not add value to hate speech
detection, which provides more insights into understanding and modeling the
subtleties of hate speech.",['Jessica Lin']
Part-Of-Speech Sensitivity of Routers in Mixture of Experts Models,Computation and Language (Natural Language Processing),"This study investigates the behavior of model-integrated routers in Mixture
of Experts (MoE) models, focusing on how tokens are routed based on their
linguistic features, specifically Part-of-Speech (POS) tags. The goal is to
explore across different MoE architectures whether experts specialize in
processing tokens with similar linguistic traits. By analyzing token
trajectories across experts and layers, we aim to uncover how MoE models handle
linguistic information. Findings from six popular MoE models reveal expert
specialization for specific POS categories, with routing paths showing high
predictive accuracy for POS, highlighting the value of routing paths in
characterizing tokens.","['Elie Antoine', 'Frédéric Béchet', 'Philippe Langlais']"
"Dynamic operator management in meta-heuristics using reinforcement
  learning: an application to permutation flowshop scheduling problems",Machine Learning,"This study develops a framework based on reinforcement learning to
dynamically manage a large portfolio of search operators within
meta-heuristics. Using the idea of tabu search, the framework allows for
continuous adaptation by temporarily excluding less efficient operators and
updating the portfolio composition during the search. A Q-learning-based
adaptive operator selection mechanism is used to select the most suitable
operator from the dynamically updated portfolio at each stage. Unlike
traditional approaches, the proposed framework requires no input from the
experts regarding the search operators, allowing domain-specific non-experts to
effectively use the framework. The performance of the proposed framework is
analyzed through an application to the permutation flowshop scheduling problem.
The results demonstrate the superior performance of the proposed framework
against state-of-the-art algorithms in terms of optimality gap and convergence
speed.","['Maryam Karimi Mamaghan', 'Mehrdad Mohammadi', 'Wout Dullaert', 'Daniele Vigo', 'Amir Pirayesh']"
Multi-Period Flexibility Forecast for Low Voltage Prosumers,Neural and Evolutionary Computing,"Near-future electric distribution grids operation will have to rely on
demand-side flexibility, both by implementation of demand response strategies
and by taking advantage of the intelligent management of increasingly common
small-scale energy storage. The Home energy management system (HEMS), installed
at low voltage residential clients, will play a crucial role on the flexibility
provision to both system operators and market players like aggregators.
Modeling and forecasting multi-period flexibility from residential prosumers,
such as battery storage and electric water heater, while complying with
internal constraints (comfort levels, data privacy) and uncertainty is a
complex task. This papers describes a computational method that is capable of
efficiently learn and define the feasibility flexibility space from
controllable resources connected to a HEMS. An Evolutionary Particle Swarm
Optimization (EPSO) algorithm is adopted and reshaped to derive a set of
feasible temporal trajectories for the residential net-load, considering
storage, flexible appliances, and predefined costumer preferences, as well as
load and photovoltaic (PV) forecast uncertainty. A support vector data
description (SVDD) algorithm is used to build models capable of classifying
feasible and non-feasible HEMS operating trajectories upon request from an
optimization/control algorithm operated by a DSO or market player.","['Rui Pinto', 'Ricardo Bessa', 'Manuel Matos']"
s-DRN: Stabilized Developmental Resonance Network,Computer Vision and Pattern Recognition,"Online incremental clustering of sequentially incoming data without prior
knowledge suffers from changing cluster numbers and tends to fall into local
extrema according to given data order. To overcome these limitations, we
propose a stabilized developmental resonance network (s-DRN). First, we analyze
the instability of the conventional choice function during the node activation
process and design a scalable activation function to make clustering
performance stable over all input data scales. Next, we devise three criteria
for the node grouping algorithm: distance, intersection over union (IoU) and
size criteria. The proposed node grouping algorithm effectively excludes
unnecessary clusters from incrementally created clusters, diminishes the
performance dependency on vigilance parameters and makes the clustering process
robust. To verify the performance of the proposed s-DRN model, comparative
studies are conducted on six real-world datasets whose statistical
characteristics are distinctive. The comparative studies demonstrate the
proposed s-DRN outperforms baselines in terms of stability and accuracy.","['In-Ug Yoon', 'Ue-Hwan Kim', ' Jong-Hwan']"
Regression-Enhanced Random Forests,Machine Learning (Statistics),"Random forest (RF) methodology is one of the most popular machine learning
techniques for prediction problems. In this article, we discuss some cases
where random forests may suffer and propose a novel generalized RF method,
namely regression-enhanced random forests (RERFs), that can improve on RFs by
borrowing the strength of penalized parametric regression. The algorithm for
constructing RERFs and selecting its tuning parameters is described. Both
simulation study and real data examples show that RERFs have better predictive
performance than RFs in important situations often encountered in practice.
Moreover, RERFs may incorporate known relationships between the response and
the predictors, and may give reliable predictions in extrapolation problems
where predictions are required at points out of the domain of the training
dataset. Strategies analogous to those described here can be used to improve
other machine learning methods via combination with penalized parametric
regression techniques.","['Haozhe Zhang', 'Dan Nettleton', 'Zhengyuan Zhu']"
"Beyond exploding and vanishing gradients: analysing RNN training using
  attractors and smoothness",Machine Learning,"The exploding and vanishing gradient problem has been the major conceptual
principle behind most architecture and training improvements in recurrent
neural networks (RNNs) during the last decade. In this paper, we argue that
this principle, while powerful, might need some refinement to explain recent
developments. We refine the concept of exploding gradients by reformulating the
problem in terms of the cost function smoothness, which gives insight into
higher-order derivatives and the existence of regions with many close local
minima. We also clarify the distinction between vanishing gradients and the
need for the RNN to learn attractors to fully use its expressive power. Through
the lens of these refinements, we shed new light on recent developments in the
RNN field, namely stable RNN and unitary (or orthogonal) RNNs.","['Antônio H. Ribeiro', 'Koen Tiels', 'Luis A. Aguirre', 'Thomas B. Schön']"
"Variational Exploration Module VEM: A Cloud-Native Optimization and
  Validation Tool for Geospatial Modeling and AI Workflows",Software Engineering,"Geospatial observations combined with computational models have become key to
understanding the physical systems of our environment and enable the design of
best practices to reduce societal harm. Cloud-based deployments help to scale
up these modeling and AI workflows. Yet, for practitioners to make robust
conclusions, model tuning and testing is crucial, a resource intensive process
which involves the variation of model input variables. We have developed the
Variational Exploration Module which facilitates the optimization and
validation of modeling workflows deployed in the cloud by orchestrating
workflow executions and using Bayesian and machine learning-based methods to
analyze model behavior. User configurations allow the combination of diverse
sampling strategies in multi-agent environments. The flexibility and robustness
of the model-agnostic module is demonstrated using real-world applications.","['Julian Kuehnert', 'Hiwot Tadesse', 'Chris Dearden', 'Rosie Lickorish', 'Paolo Fraccaro', 'Anne Jones', 'Blair Edwards', 'Sekou L. Remy', 'Peter Melling', 'Tim Culmer']"
"Selection, Ignorability and Challenges With Causal Fairness",Machine Learning (Statistics),"In this paper we look at popular fairness methods that use causal
counterfactuals. These methods capture the intuitive notion that a prediction
is fair if it coincides with the prediction that would have been made if
someone's race, gender or religion were counterfactually different. In order to
achieve this, we must have causal models that are able to capture what someone
would be like if we were to counterfactually change these traits. However, we
argue that any model that can do this must lie outside the particularly well
behaved class that is commonly considered in the fairness literature. This is
because in fairness settings, models in this class entail a particularly strong
causal assumption, normally only seen in a randomised controlled trial. We
argue that in general this is unlikely to hold. Furthermore, we show in many
cases it can be explicitly rejected due to the fact that samples are selected
from a wider population. We show this creates difficulties for counterfactual
fairness as well as for the application of more general causal fairness
methods.","['Jake Fawkes', 'Robin Evans', 'Dino Sejdinovic']"
High-Dimensional Wide Gap $k$-Means Versus Clustering Axioms,Machine Learning,"Kleinberg's axioms for distance based clustering proved to be contradictory.
  Various efforts have been made to overcome this problem.
  Here we make an attempt to handle the issue by embedding in high-dimensional
space and granting wide gaps between clusters.",['Mieczysław A. Kłopotek']
Quantum algorithms for training Gaussian Processes,Quantum Physics,"Gaussian processes (GPs) are important models in supervised machine learning.
Training in Gaussian processes refers to selecting the covariance functions and
the associated parameters in order to improve the outcome of predictions, the
core of which amounts to evaluating the logarithm of the marginal likelihood
(LML) of a given model. LML gives a concrete measure of the quality of
prediction that a GP model is expected to achieve. The classical computation of
LML typically carries a polynomial time overhead with respect to the input
size. We propose a quantum algorithm that computes the logarithm of the
determinant of a Hermitian matrix, which runs in logarithmic time for sparse
matrices. This is applied in conjunction with a variant of the quantum linear
system algorithm that allows for logarithmic time computation of the form
$\mathbf{y}^TA^{-1}\mathbf{y}$, where $\mathbf{y}$ is a dense vector and $A$ is
the covariance matrix. We hence show that quantum computing can be used to
estimate the LML of a GP with exponentially improved efficiency under certain
conditions.","['Zhikuan Zhao', 'Jack K. Fitzsimons', 'Michael A. Osborne', 'Stephen J. Roberts', 'Joseph F. Fitzsimons']"
Sequential Model Selection for Word Sense Disambiguation,Computation and Language (Legacy category),"Statistical models of word-sense disambiguation are often based on a small
number of contextual features or on a model that is assumed to characterize the
interactions among a set of features. Model selection is presented as an
alternative to these approaches, where a sequential search of possible models
is conducted in order to find the model that best characterizes the
interactions among features. This paper expands existing model selection
methodology and presents the first comparative study of model selection search
strategies and evaluation criteria when applied to the problem of building
probabilistic classifiers for word-sense disambiguation.","['Ted Pedersen', 'Rebecca Bruce', 'Janyce Wiebe']"
"Using Quantifier Elimination to Enhance the Safety Assurance of Deep
  Neural Networks",Machine Learning,"Advances in the field of Machine Learning and Deep Neural Networks (DNNs) has
enabled rapid development of sophisticated and autonomous systems. However, the
inherent complexity to rigorously assure the safe operation of such systems
hinders their real-world adoption in safety-critical domains such as aerospace
and medical devices. Hence, there is a surge in interest to explore the use of
advanced mathematical techniques such as formal methods to address this
challenge. In fact, the initial results of such efforts are promising. Along
these lines, we propose the use of quantifier elimination (QE) - a formal
method technique, as a complimentary technique to the state-of-the-art static
analysis and verification procedures. Using an airborne collision avoidance DNN
as a case example, we illustrate the use of QE to formulate the precise range
forward propagation through a network as well as analyze its robustness. We
discuss the initial results of this ongoing work and explore the future
possibilities of extending this approach and/or integrating it with other
approaches to perform advanced safety assurance of DNNs.","['Hao Ren', 'Sai Krishnan Chandrasekar', 'Anitha Murugesan']"
"Dynamic Partial Removal: A Neural Network Heuristic for Large
  Neighborhood Search",Neural and Evolutionary Computing,"This paper presents a novel neural network design that learns the heuristic
for Large Neighborhood Search (LNS). LNS consists of a destroy operator and a
repair operator that specify a way to carry out the neighborhood search to
solve the Combinatorial Optimization problems. The proposed approach in this
paper applies a Hierarchical Recurrent Graph Convolutional Network (HRGCN) as a
LNS heuristic, namely Dynamic Partial Removal, with the advantage of adaptive
destruction and the potential to search across a large scale, as well as the
context-awareness in both spatial and temporal perspective. This model is
generalized as an efficient heuristic approach to different combinatorial
optimization problems, especially to the problems with relatively tight
constraints. We apply this model to vehicle routing problem (VRP) in this paper
as an example. The experimental results show that this approach outperforms the
traditional LNS heuristics on the same problem as well. The source code is
available at
\href{https://github.com/water-mirror/DPR}{https://github.com/water-mirror/DPR}.","['Mingxiang Chen', 'Lei Gao', 'Qichang Chen', 'Zhixin Liu']"
Edge Detection: A Collection of Pixel based Approach for Colored Images,Computer Vision and Pattern Recognition,"The existing traditional edge detection algorithms process a single pixel on
an image at a time, thereby calculating a value which shows the edge magnitude
of the pixel and the edge orientation. Most of these existing algorithms
convert the coloured images into gray scale before detection of edges. However,
this process leads to inaccurate precision of recognized edges, thus producing
false and broken edges in the image. This paper presents a profile modelling
scheme for collection of pixels based on the step and ramp edges, with a view
to reducing the false and broken edges present in the image. The collection of
pixel scheme generated is used with the Vector Order Statistics to reduce the
imprecision of recognized edges when converting from coloured to gray scale
images. The Pratt Figure of Merit (PFOM) is used as a quantitative comparison
between the existing traditional edge detection algorithm and the developed
algorithm as a means of validation. The PFOM value obtained for the developed
algorithm is 0.8480, which showed an improvement over the existing traditional
edge detection algorithms.","['B. O Sadiq', 'S. M Sani', 'S Garba']"
"Learning classifier systems with memory condition to solve non-Markov
  problems",Neural and Evolutionary Computing,"In the family of Learning Classifier Systems, the classifier system XCS has
been successfully used for many applications. However, the standard XCS has no
memory mechanism and can only learn optimal policy in Markov environments,
where the optimal action is determined solely by the state of current sensory
input. In practice, most environments are partially observable environments on
agent's sensation, which are also known as non-Markov environments. Within
these environments, XCS either fails, or only develops a suboptimal policy,
since it has no memory. In this work, we develop a new classifier system based
on XCS to tackle this problem. It adds an internal message list to XCS as the
memory list to record input sensation history, and extends a small number of
classifiers with memory conditions. The classifier's memory condition, as a
foothold to disambiguate non-Markov states, is used to sense a specified
element in the memory list. Besides, a detection method is employed to
recognize non-Markov states in environments, to avoid these states controlling
over classifiers' memory conditions. Furthermore, four sets of different
complex maze environments have been tested by the proposed method. Experimental
results show that our system is one of the best techniques to solve partially
observable environments, compared with some well-known classifier systems
proposed for these environments.","['Zhaoxiang Zang', 'Dehua Li', 'Junying Wang']"
Detecting Syntactic Features of Translated Chinese,Computation and Language (Natural Language Processing),"We present a machine learning approach to distinguish texts translated to
Chinese (by humans) from texts originally written in Chinese, with a focus on a
wide range of syntactic features. Using Support Vector Machines (SVMs) as
classifier on a genre-balanced corpus in translation studies of Chinese, we
find that constituent parse trees and dependency triples as features without
lexical information perform very well on the task, with an F-measure above 90%,
close to the results of lexical n-gram features, without the risk of learning
topic information rather than translation features. Thus, we claim syntactic
features alone can accurately distinguish translated from original Chinese.
Translated Chinese exhibits an increased use of determiners, subject position
pronouns, NP + 'de' as NP modifiers, multiple NPs or VPs conjoined by a Chinese
specific punctuation, among other structures. We also interpret the syntactic
features with reference to previous translation studies in Chinese,
particularly the usage of pronouns.","['Hai Hu', 'Wen Li', 'Sandra Kübler']"
StrassenNets: Deep Learning with a Multiplication Budget,Machine Learning,"A large fraction of the arithmetic operations required to evaluate deep
neural networks (DNNs) consists of matrix multiplications, in both convolution
and fully connected layers. We perform end-to-end learning of low-cost
approximations of matrix multiplications in DNN layers by casting matrix
multiplications as 2-layer sum-product networks (SPNs) (arithmetic circuits)
and learning their (ternary) edge weights from data. The SPNs disentangle
multiplication and addition operations and enable us to impose a budget on the
number of multiplication operations. Combining our method with knowledge
distillation and applying it to image classification DNNs (trained on ImageNet)
and language modeling DNNs (using LSTMs), we obtain a first-of-a-kind reduction
in number of multiplications (over 99.5%) while maintaining the predictive
performance of the full-precision models. Finally, we demonstrate that the
proposed framework is able to rediscover Strassen's matrix multiplication
algorithm, learning to multiply $2 \times 2$ matrices using only 7
multiplications instead of 8.","['Michael Tschannen', 'Aran Khanna', 'Anima Anandkumar']"
Gaussian Process Structural Equation Models with Latent Variables,Machine Learning,"In a variety of disciplines such as social sciences, psychology, medicine and
economics, the recorded data are considered to be noisy measurements of latent
variables connected by some causal structure. This corresponds to a family of
graphical models known as the structural equation model with latent variables.
While linear non-Gaussian variants have been well-studied, inference in
nonparametric structural equation models is still underdeveloped. We introduce
a sparse Gaussian process parameterization that defines a non-linear structure
connecting latent variables, unlike common formulations of Gaussian process
latent variable models. The sparse parameterization is given a full Bayesian
treatment without compromising Markov chain Monte Carlo efficiency. We compare
the stability of the sampling procedure and the predictive ability of the model
against the current practice.","['Ricardo Silva', 'Robert B. Gramacy']"
"Taking ROCKET on an Efficiency Mission: Multivariate Time Series
  Classification with LightWaveS",Machine Learning,"Nowadays, with the rising number of sensors in sectors such as healthcare and
industry, the problem of multivariate time series classification (MTSC) is
getting increasingly relevant and is a prime target for machine and deep
learning approaches. Their expanding adoption in real-world environments is
causing a shift in focus from the pursuit of ever-higher prediction accuracy
with complex models towards practical, deployable solutions that balance
accuracy and parameters such as prediction speed. An MTSC model that has
attracted attention recently is ROCKET, based on random convolutional kernels,
both because of its very fast training process and its state-of-the-art
accuracy. However, the large number of features it utilizes may be detrimental
to inference time. Examining its theoretical background and limitations enables
us to address potential drawbacks and present LightWaveS: a framework for
accurate MTSC, which is fast both during training and inference. Specifically,
utilizing wavelet scattering transformation and distributed feature selection,
we manage to create a solution that employs just 2.5% of the ROCKET features,
while achieving accuracy comparable to recent MTSC models. LightWaveS also
scales well across multiple compute nodes and with the number of input channels
during training. In addition, it can significantly reduce the input size and
provide insight to an MTSC problem by keeping only the most useful channels. We
present three versions of our algorithm and their results on distributed
training time and scalability, accuracy, and inference speedup. We show that we
achieve speedup ranging from 9x to 53x compared to ROCKET during inference on
an edge device, on datasets with comparable accuracy.","['Leonardos Pantiskas', 'Kees Verstoep', 'Mark Hoogendoorn', 'Henri Bal']"
"Data Selection: A General Principle for Building Small Interpretable
  Models",Machine Learning,"We present convincing empirical evidence for an effective and general
strategy for building accurate small models. Such models are attractive for
interpretability and also find use in resource-constrained environments. The
strategy is to learn the training distribution and sample accordingly from the
provided training data. The distribution learning algorithm is not a
contribution of this work; our contribution is a rigorous demonstration of the
broad utility of this strategy in various practical settings. We apply it to
the tasks of (1) building cluster explanation trees, (2) prototype-based
classification, and (3) classification using Random Forests, and show that it
improves the accuracy of decades-old weak traditional baselines to be
competitive with specialized modern techniques.
  This strategy is also versatile wrt the notion of model size. In the first
two tasks, model size is considered to be number of leaves in the tree and the
number of prototypes respectively. In the final task involving Random Forests,
the strategy is shown to be effective even when model size comprises of more
than one factor: number of trees and their maximum depth.
  Positive results using multiple datasets are presented that are shown to be
statistically significant.",['Abhishek Ghose']
Meta-learning of Pooling Layers for Character Recognition,Computer Vision and Pattern Recognition,"In convolutional neural network-based character recognition, pooling layers
play an important role in dimensionality reduction and deformation
compensation. However, their kernel shapes and pooling operations are
empirically predetermined; typically, a fixed-size square kernel shape and max
pooling operation are used. In this paper, we propose a meta-learning framework
for pooling layers. As part of our framework, a parameterized pooling layer is
proposed in which the kernel shape and pooling operation are trainable using
two parameters, thereby allowing flexible pooling of the input data. We also
propose a meta-learning algorithm for the parameterized pooling layer, which
allows us to acquire a suitable pooling layer across multiple tasks. In the
experiment, we applied the proposed meta-learning framework to character
recognition tasks. The results demonstrate that a pooling layer that is
suitable across character recognition tasks was obtained via meta-learning, and
the obtained pooling layer improved the performance of the model in both
few-shot character recognition and noisy image recognition tasks.","['Takato Otsuzuki', 'Heon Song', 'Seiichi Uchida', 'Hideaki Hayashi']"
"CPMetric: Deep Siamese Networks for Learning Distances Between
  Structured Preferences",Machine Learning,"Preference are central to decision making by both machines and humans.
Representing, learning, and reasoning with preferences is an important area of
study both within computer science and across the sciences. When working with
preferences it is necessary to understand and compute the distance between sets
of objects, e.g., the preferences of a user and a the descriptions of objects
to be recommended. We present CPDist, a novel neural network to address the
problem of learning to measure the distance between structured preference
representations. We use the popular CP-net formalism to represent preferences
and then leverage deep neural networks to learn a recently proposed metric
function that is computationally hard to compute directly. CPDist is a novel
metric learning approach based on the use of deep siamese networks which learn
the Kendal Tau distance between partial orders that are induced by compact
preference representations. We find that CPDist is able to learn the distance
function with high accuracy and outperform existing approximation algorithms on
both the regression and classification task using less computation time.
Performance remains good even when CPDist is trained with only a small number
of samples compared to the dimension of the solution space, indicating the
network generalizes well.","['Andrea Loreggia', 'Nicholas Mattei', 'Francesca Rossi', 'K. Brent Venable']"
"From Asset Flow to Status, Action and Intention Discovery: Early Malice
  Detection in Cryptocurrency",Machine Learning,"Cryptocurrency has been subject to illicit activities probably more often
than traditional financial assets due to the pseudo-anonymous nature of its
transacting entities. An ideal detection model is expected to achieve all three
critical properties of (I) early detection, (II) good interpretability, and
(III) versatility for various illicit activities. However, existing solutions
cannot meet all these requirements, as most of them heavily rely on deep
learning without interpretability and are only available for retrospective
analysis of a specific illicit type. To tackle all these challenges, we propose
Intention-Monitor for early malice detection in Bitcoin (BTC), where the
on-chain record data for a certain address are much scarcer than other
cryptocurrency platforms. We first define asset transfer paths with the
Decision-Tree based feature Selection and Complement (DT-SC) to build different
feature sets for different malice types. Then, the Status/Action Proposal
Module (S/A-PM) and the Intention-VAE module generate the status, action,
intent-snippet, and hidden intent-snippet embedding. With all these modules,
our model is highly interpretable and can detect various illegal activities.
Moreover, well-designed loss functions further enhance the prediction speed and
model's interpretability. Extensive experiments on three real-world datasets
demonstrate that our proposed algorithm outperforms the state-of-the-art
methods. Furthermore, additional case studies justify our model can not only
explain existing illicit patterns but can also find new suspicious characters.","['Ling Cheng', 'Feida Zhu', 'Yong Wang', 'Ruicheng Liang', 'Huiwen Liu']"
Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks,Machine Learning,"Recent research shows that the following two models are equivalent: (a)
infinitely wide neural networks (NNs) trained under l2 loss by gradient descent
with infinitesimally small learning rate (b) kernel regression with respect to
so-called Neural Tangent Kernels (NTKs) (Jacot et al., 2018). An efficient
algorithm to compute the NTK, as well as its convolutional counterparts,
appears in Arora et al. (2019a), which allowed studying performance of
infinitely wide nets on datasets like CIFAR-10. However, super-quadratic
running time of kernel methods makes them best suited for small-data tasks. We
report results suggesting neural tangent kernels perform strongly on low-data
tasks.
  1. On a standard testbed of classification/regression tasks from the UCI
database, NTK SVM beats the previous gold standard, Random Forests (RF), and
also the corresponding finite nets.
  2. On CIFAR-10 with 10 - 640 training samples, Convolutional NTK consistently
beats ResNet-34 by 1% - 3%.
  3. On VOC07 testbed for few-shot image classification tasks on ImageNet with
transfer learning (Goyal et al., 2019), replacing the linear SVM currently used
with a Convolutional NTK SVM consistently improves performance.
  4. Comparing the performance of NTK with the finite-width net it was derived
from, NTK behavior starts at lower net widths than suggested by theoretical
analysis(Arora et al., 2019a). NTK's efficacy may trace to lower variance of
output.","['Sanjeev Arora', 'Simon S. Du', 'Zhiyuan Li', 'Ruslan Salakhutdinov', 'Ruosong Wang', 'Dingli Yu']"
"Exact Risk Curves of signSGD in High-Dimensions: Quantifying
  Preconditioning and Noise-Compression Effects",Machine Learning (Statistics),"In recent years, signSGD has garnered interest as both a practical optimizer
as well as a simple model to understand adaptive optimizers like Adam. Though
there is a general consensus that signSGD acts to precondition optimization and
reshapes noise, quantitatively understanding these effects in theoretically
solvable settings remains difficult. We present an analysis of signSGD in a
high dimensional limit, and derive a limiting SDE and ODE to describe the risk.
Using this framework we quantify four effects of signSGD: effective learning
rate, noise compression, diagonal preconditioning, and gradient noise
reshaping. Our analysis is consistent with experimental observations but moves
beyond that by quantifying the dependence of these effects on the data and
noise distributions. We conclude with a conjecture on how these results might
be extended to Adam.","['Ke Liang Xiao', 'Noah Marshall', 'Atish Agarwala', 'Elliot Paquette']"
"A Survey on Dynamic Job Scheduling in Grid Environment Based on
  Heuristic Algorithms","Distributed, Parallel, and Cluster Computing","Computational Grids are a new trend in distributed computing systems. They
allow the sharing of geographically distributed resources in an efficient way,
extending the boundaries of what we perceive as distributed computing. Various
sciences can benefit from the use of grids to solve CPU-intensive problems,
creating potential benefits to the entire society. Job scheduling is an
integrated part of parallel and distributed computing. It allows selecting
correct match of resource for a particular job and thus increases the job
throughput and utilization of resources. Job should be scheduled in an
automatic way to make the system more reliable, accessible and less sensitive
to subsystem failures. This paper provides a survey on various heuristic
algorithms, used for scheduling in grid.","['D. Thilagavathi', 'Antony Selvadoss Thanamani']"
Intelligent wayfinding vehicle design based on visual recognition,Computer Vision and Pattern Recognition,"Intelligent drug delivery trolley is an advanced intelligent drug delivery
equipment. Compared with traditional manual drug delivery, it has higher drug
delivery efficiency and lower error rate. In this project, an intelligent drug
delivery car is designed and manufactured, which can recognize the road route
and the room number of the target ward through visual recognition technology.
The trolley selects the corresponding route according to the identified room
number, accurately transports the drugs to the target ward, and can return to
the pharmacy after the drugs are delivered. The intelligent drug delivery car
uses DC power supply, and the motor drive module controls two DC motors, which
overcomes the problem of excessive deviation of turning angle. The trolley line
inspection function uses closed-loop control to improve the accuracy of line
inspection and the controllability of trolley speed. The identification of ward
number is completed by the camera module with microcontroller, and has the
functions of adaptive adjustment of ambient brightness, distortion correction,
automatic calibration and so on. The communication between two cooperative drug
delivery vehicles is realized by Bluetooth module, which achieves efficient and
accurate communication and interaction. Experiments show that the intelligent
drug delivery car can accurately identify the room number and plan the route to
deliver drugs to the far, middle and near wards, and has the characteristics of
fast speed and accurate judgment. In addition, two drug delivery trolleys can
cooperate to deliver drugs to the same ward, with high efficiency and high
cooperation.","['Zhanyu Guo', 'Shenyuan Guo', 'Jialong Wang', 'Yifan Feng']"
KerGM: Kernelized Graph Matching,Machine Learning,"Graph matching plays a central role in such fields as computer vision,
pattern recognition, and bioinformatics. Graph matching problems can be cast as
two types of quadratic assignment problems (QAPs): Koopmans-Beckmann's QAP or
Lawler's QAP. In our paper, we provide a unifying view for these two problems
by introducing new rules for array operations in Hilbert spaces. Consequently,
Lawler's QAP can be considered as the Koopmans-Beckmann's alignment between two
arrays in reproducing kernel Hilbert spaces (RKHS), making it possible to
efficiently solve the problem without computing a huge affinity matrix.
Furthermore, we develop the entropy-regularized Frank-Wolfe (EnFW) algorithm
for optimizing QAPs, which has the same convergence rate as the original FW
algorithm while dramatically reducing the computational burden for each outer
iteration. We conduct extensive experiments to evaluate our approach, and show
that our algorithm significantly outperforms the state-of-the-art in both
matching accuracy and scalability.","['Zhen Zhang', 'Yijian Xiang', 'Lingfei Wu', 'Bing Xue', 'Arye Nehorai']"
"PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric
  Space",Computer Vision and Pattern Recognition,"Few prior works study deep learning on point sets. PointNet by Qi et al. is a
pioneer in this direction. However, by design PointNet does not capture local
structures induced by the metric space points live in, limiting its ability to
recognize fine-grained patterns and generalizability to complex scenes. In this
work, we introduce a hierarchical neural network that applies PointNet
recursively on a nested partitioning of the input point set. By exploiting
metric space distances, our network is able to learn local features with
increasing contextual scales. With further observation that point sets are
usually sampled with varying densities, which results in greatly decreased
performance for networks trained on uniform densities, we propose novel set
learning layers to adaptively combine features from multiple scales.
Experiments show that our network called PointNet++ is able to learn deep point
set features efficiently and robustly. In particular, results significantly
better than state-of-the-art have been obtained on challenging benchmarks of 3D
point clouds.","['Charles R. Qi', 'Li Yi', 'Hao Su', 'Leonidas J. Guibas']"
A Common XML-based Framework for Syntactic Annotations,Computation and Language (Natural Language Processing),"It is widely recognized that the proliferation of annotation schemes runs
counter to the need to re-use language resources, and that standards for
linguistic annotation are becoming increasingly mandatory. To answer this need,
we have developed a framework comprised of an abstract model for a variety of
different annotation types (e.g., morpho-syntactic tagging, syntactic
annotation, co-reference annotation, etc.), which can be instantiated in
different ways depending on the annotator's approach and goals. In this paper
we provide an overview of the framework, demonstrate its applicability to
syntactic annotation, and show how it can contribute to comparative evaluation
of parser output and diverse syntactic annotation schemes.","['Nancy Ide', 'Laurent Romary', 'Tomaz Erjavec']"
Data-Augmentation-Based Dialectal Adaptation for LLMs,Computation and Language (Natural Language Processing),"This report presents GMUNLP's participation to the Dialect-Copa shared task
at VarDial 2024, which focuses on evaluating the commonsense reasoning
capabilities of large language models (LLMs) on South Slavic micro-dialects.
The task aims to assess how well LLMs can handle non-standard dialectal
varieties, as their performance on standard languages is already
well-established. We propose an approach that combines the strengths of
different types of language models and leverages data augmentation techniques
to improve task performance on three South Slavic dialects: Chakavian,
Cherkano, and Torlak. We conduct experiments using a language-family-focused
encoder-based model (BERTi\'c) and a domain-agnostic multilingual model
(AYA-101). Our results demonstrate that the proposed data augmentation
techniques lead to substantial performance gains across all three test datasets
in the open-source model category. This work highlights the practical utility
of data augmentation and the potential of LLMs in handling non-standard
dialectal varieties, contributing to the broader goal of advancing natural
language understanding in low-resource and dialectal settings.
Code:https://github.com/ffaisal93/dialect_copa","['Fahim Faisal', 'Antonios Anastasopoulos']"
Memory-Efficient Incremental Learning Through Feature Adaptation,Computer Vision and Pattern Recognition,"We introduce an approach for incremental learning that preserves feature
descriptors of training images from previously learned classes, instead of the
images themselves, unlike most existing work. Keeping the much
lower-dimensional feature embeddings of images reduces the memory footprint
significantly. We assume that the model is updated incrementally for new
classes as new data becomes available sequentially.This requires adapting the
previously stored feature vectors to the updated feature space without having
access to the corresponding original training images. Feature adaptation is
learned with a multi-layer perceptron, which is trained on feature pairs
corresponding to the outputs of the original and updated network on a training
image. We validate experimentally that such a transformation generalizes well
to the features of the previous set of classes, and maps features to a
discriminative subspace in the feature space. As a result, the classifier is
optimized jointly over new and old classes without requiring old class images.
Experimental results show that our method achieves state-of-the-art
classification accuracy in incremental learning benchmarks, while having at
least an order of magnitude lower memory footprint compared to image-preserving
strategies.","['Ahmet Iscen', 'Jeffrey Zhang', 'Svetlana Lazebnik', 'Cordelia Schmid']"
AISHELL-2: Transforming Mandarin ASR Research Into Industrial Scale,Computation and Language (Natural Language Processing),"AISHELL-1 is by far the largest open-source speech corpus available for
Mandarin speech recognition research. It was released with a baseline system
containing solid training and testing pipelines for Mandarin ASR. In AISHELL-2,
1000 hours of clean read-speech data from iOS is published, which is free for
academic usage. On top of AISHELL-2 corpus, an improved recipe is developed and
released, containing key components for industrial applications, such as
Chinese word segmentation, flexible vocabulary expension and phone set
transformation etc. Pipelines support various state-of-the-art techniques, such
as time-delayed neural networks and Lattic-Free MMI objective funciton. In
addition, we also release dev and test data from other channels(Android and
Mic). For research community, we hope that AISHELL-2 corpus can be a solid
resource for topics like transfer learning and robust ASR. For industry, we
hope AISHELL-2 recipe can be a helpful reference for building meaningful
industrial systems and products.","['Jiayu Du', 'Xingyu Na', 'Xuechen Liu', 'Hui Bu']"
"Final-Model-Only Data Attribution with a Unifying View of Gradient-Based
  Methods",Machine Learning,"Training data attribution (TDA) is the task of attributing model behavior to
elements in the training data. This paper draws attention to the common setting
where one has access only to the final trained model, and not the training
algorithm or intermediate information from training. To serve as a gold
standard for TDA in this ""final-model-only"" setting, we propose further
training, with appropriate adjustment and averaging, to measure the sensitivity
of the given model to training instances. We then unify existing gradient-based
methods for TDA by showing that they all approximate the further training gold
standard in different ways. We investigate empirically the quality of these
gradient-based approximations to further training, for tabular, image, and text
datasets and models. We find that the approximation quality of first-order
methods is sometimes high but decays with the amount of further training. In
contrast, the approximations given by influence function methods are more
stable but surprisingly lower in quality.","['Dennis Wei', 'Inkit Padhi', 'Soumya Ghosh', 'Amit Dhurandhar', 'Karthikeyan Natesan Ramamurthy', 'Maria Chang']"
Online Deep Learning: Growing RBM on the fly,Neural and Evolutionary Computing,"We propose a novel online learning algorithm for Restricted Boltzmann
Machines (RBM), namely, the Online Generative Discriminative Restricted
Boltzmann Machine (OGD-RBM), that provides the ability to build and adapt the
network architecture of RBM according to the statistics of streaming data. The
OGD-RBM is trained in two phases: (1) an online generative phase for
unsupervised feature representation at the hidden layer and (2) a
discriminative phase for classification. The online generative training begins
with zero neurons in the hidden layer, adds and updates the neurons to adapt to
statistics of streaming data in a single pass unsupervised manner, resulting in
a feature representation best suited to the data. The discriminative phase is
based on stochastic gradient descent and associates the represented features to
the class labels. We demonstrate the OGD-RBM on a set of multi-category and
binary classification problems for data sets having varying degrees of
class-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST
dataset to characterize the network evolution. We demonstrate that the online
generative phase converges to a stable, concise network architecture, wherein
individual neurons are inherently discriminative to the class labels despite
unsupervised training. We then benchmark OGD-RBM performance to other machine
learning, neural network and ClassRBM techniques for credit scoring
applications using 3 public non-stationary two-class credit datasets with
varying degrees of class-imbalance. We report that OGD-RBM improves accuracy by
2.5-3% over batch learning techniques while requiring at least 24%-70% fewer
neurons and fewer training samples. This online generative training approach
can be extended greedily to multiple layers for training Deep Belief Networks
in non-stationary data mining applications without the need for a priori fixed
architectures.","['Savitha Ramasamy', 'Kanagasabai Rajaraman', 'Pavitra Krishnaswamy', 'Vijay Chandrasekhar']"
AI Stories: An Interactive Narrative System for Children,Computation and Language (Natural Language Processing),"AI Stories is a proposed interactive dialogue system, that lets children
co-create narrative worlds through conversation. Over the next three years this
system will be developed and tested within pediatric wards, where it offers a
useful resource between the gap of education and play. Telling and making
stories is a fundamental part of language play, and its chatty and nonsensical
qualities are important; therefore, the prologued usage an automated system
offers is a benefit to children. In this paper I will present the current state
of this project, in its more experimental and general guise. Conceptually
story-telling through dialogue relates to the preprint interpretation of story,
beyond the static and linear medium, where stories were performative, temporal,
and social.",['Ben Burtenshaw']
"VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for
  Enhanced Detection",Machine Learning,"Fraud detection presents a challenging task characterized by ever-evolving
fraud patterns and scarce labeled data. Existing methods predominantly rely on
graph-based or sequence-based approaches. While graph-based approaches connect
users through shared entities to capture structural information, they remain
vulnerable to fraudsters who can disrupt or manipulate these connections. In
contrast, sequence-based approaches analyze users' behavioral patterns,
offering robustness against tampering but overlooking the interactions between
similar users. Inspired by cohort analysis in retention and healthcare, this
paper introduces VecAug, a novel cohort-augmented learning framework that
addresses these challenges by enhancing the representation learning of target
users with personalized cohort information. To this end, we first propose a
vector burn-in technique for automatic cohort identification, which retrieves a
task-specific cohort for each target user. Then, to fully exploit the cohort
information, we introduce an attentive cohort aggregation technique for
augmenting target user representations. To improve the robustness of such
cohort augmentation, we also propose a novel label-aware cohort neighbor
separation mechanism to distance negative cohort neighbors and calibrate the
aggregated cohort information. By integrating this cohort information with
target user representations, VecAug enhances the modeling capacity and
generalization capabilities of the model to be augmented. Our framework is
flexible and can be seamlessly integrated with existing fraud detection models.
We deploy our framework on e-commerce platforms and evaluate it on three fraud
detection datasets, and results show that VecAug improves the detection
performance of base models by up to 2.48\% in AUC and 22.5\% in R@P$_{0.9}$,
outperforming state-of-the-art methods significantly.","['Fei Xiao', 'Shaofeng Cai', 'Gang Chen', 'H. V. Jagadish', 'Beng Chin Ooi', 'Meihui Zhang']"
"SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial
  Networks",Computer Vision and Pattern Recognition,"Autonomous driving is one of the most recent topics of interest which is
aimed at replicating human driving behavior keeping in mind the safety issues.
We approach the problem of learning synthetic driving using generative neural
networks. The main idea is to make a controller trainer network using images
plus key press data to mimic human learning. We used the architecture of a
stable GAN to make predictions between driving scenes using key presses. We
train our model on one video game (Road Rash) and tested the accuracy and
compared it by running the model on other maps in Road Rash to determine the
extent of learning.","['Arna Ghosh', 'Biswarup Bhattacharya', 'Somnath Basu Roy Chowdhury']"
Variational Inference based on Robust Divergences,Machine Learning (Statistics),"Robustness to outliers is a central issue in real-world machine learning
applications. While replacing a model to a heavy-tailed one (e.g., from
Gaussian to Student-t) is a standard approach for robustification, it can only
be applied to simple models. In this paper, based on Zellner's optimization and
variational formulation of Bayesian inference, we propose an outlier-robust
pseudo-Bayesian variational method by replacing the Kullback-Leibler divergence
used for data fitting to a robust divergence such as the beta- and
gamma-divergences. An advantage of our approach is that superior but complex
models such as deep networks can also be handled. We theoretically prove that,
for deep networks with ReLU activation functions, the \emph{influence function}
in our proposed method is bounded, while it is unbounded in the ordinary
variational inference. This implies that our proposed method is robust to both
of input and output outliers, while the ordinary variational method is not. We
experimentally demonstrate that our robust variational method outperforms
ordinary variational inference in regression and classification with deep
networks.","['Futoshi Futami', 'Issei Sato', 'Masashi Sugiyama']"
"CLoVe: Encoding Compositional Language in Contrastive Vision-Language
  Models",Computer Vision and Pattern Recognition,"Recent years have witnessed a significant increase in the performance of
Vision and Language tasks. Foundational Vision-Language Models (VLMs), such as
CLIP, have been leveraged in multiple settings and demonstrated remarkable
performance across several tasks. Such models excel at object-centric
recognition yet learn text representations that seem invariant to word order,
failing to compose known concepts in novel ways. However, no evidence exists
that any VLM, including large-scale single-stream models such as GPT-4V,
identifies compositions successfully. In this paper, we introduce a framework
to significantly improve the ability of existing models to encode compositional
language, with over 10% absolute improvement on compositionality benchmarks,
while maintaining or improving the performance on standard object-recognition
and retrieval benchmarks. Our code and pre-trained models are publicly
available at https://github.com/netflix/clove.","['Santiago Castro', 'Amir Ziai', 'Avneesh Saluja', 'Zhuoning Yuan', 'Rada Mihalcea']"
"Unsupervised Learning on Neural Network Outputs: with Application in
  Zero-shot Learning",Machine Learning,"The outputs of a trained neural network contain much richer information than
just an one-hot classifier. For example, a neural network might give an image
of a dog the probability of one in a million of being a cat but it is still
much larger than the probability of being a car. To reveal the hidden structure
in them, we apply two unsupervised learning algorithms, PCA and ICA, to the
outputs of a deep Convolutional Neural Network trained on the ImageNet of 1000
classes. The PCA/ICA embedding of the object classes reveals their visual
similarity and the PCA/ICA components can be interpreted as common visual
features shared by similar object classes. For an application, we proposed a
new zero-shot learning method, in which the visual features learned by PCA/ICA
are employed. Our zero-shot learning method achieves the state-of-the-art
results on the ImageNet of over 20000 classes.",['Yao Lu']
A New Approach Towards Autoformalization,Computation and Language (Natural Language Processing),"Verifying mathematical proofs is difficult, but can be automated with the
assistance of a computer. Autoformalization is the task of automatically
translating natural language mathematics into a formal language that can be
verified by a program. This is a challenging task, and especially for
higher-level mathematics found in research papers. Research paper mathematics
requires large amounts of background and context. In this paper, we propose an
avenue towards tackling autoformalization for research-level mathematics, by
breaking the task into easier and more approachable subtasks: unlinked
formalization (formalization with unlinked definitions and theorems), entity
linking (linking to the proper theorems and definitions), and finally adjusting
types so it passes the type checker. In addition, we present arXiv2Formal, a
benchmark dataset for unlinked formalization consisting of 50 theorems
formalized for the Lean theorem prover sampled from papers on arXiv.org. We
welcome any contributions from the community to future versions of this
dataset.","['Nilay Patel', 'Rahul Saha', 'Jeffrey Flanigan']"
"Anomaly Detection in Video Using Predictive Convolutional Long
  Short-Term Memory Networks",Computer Vision and Pattern Recognition,"Automating the detection of anomalous events within long video sequences is
challenging due to the ambiguity of how such events are defined. We approach
the problem by learning generative models that can identify anomalies in videos
using limited supervision. We propose end-to-end trainable composite
Convolutional Long Short-Term Memory (Conv-LSTM) networks that are able to
predict the evolution of a video sequence from a small number of input frames.
Regularity scores are derived from the reconstruction errors of a set of
predictions with abnormal video sequences yielding lower regularity scores as
they diverge further from the actual sequence over time. The models utilize a
composite structure and examine the effects of conditioning in learning more
meaningful representations. The best model is chosen based on the
reconstruction and prediction accuracy. The Conv-LSTM models are evaluated both
qualitatively and quantitatively, demonstrating competitive results on anomaly
detection datasets. Conv-LSTM units are shown to be an effective tool for
modeling and predicting video sequences.","['Jefferson Ryan Medel', 'Andreas Savakis']"
The Inverse G-Wishart Distribution and Variational Message Passing,Machine Learning (Statistics),"Message passing on a factor graph is a powerful paradigm for the coding of
approximate inference algorithms for arbitrarily graphical large models. The
notion of a factor graph fragment allows for compartmentalization of algebra
and computer code. We show that the Inverse G-Wishart family of distributions
enables fundamental variational message passing factor graph fragments to be
expressed elegantly and succinctly. Such fragments arise in models for which
approximate inference concerning covariance matrix or variance parameters is
made, and are ubiquitous in contemporary statistics and machine learning.","['L. Maestrini', 'M. P. Wand']"
"Adaptive Sparse Convolutional Networks with Global Context Enhancement
  for Faster Object Detection on Drone Images",Computer Vision and Pattern Recognition,"Object detection on drone images with low-latency is an important but
challenging task on the resource-constrained unmanned aerial vehicle (UAV)
platform. This paper investigates optimizing the detection head based on the
sparse convolution, which proves effective in balancing the accuracy and
efficiency. Nevertheless, it suffers from inadequate integration of contextual
information of tiny objects as well as clumsy control of the mask ratio in the
presence of foreground with varying scales. To address the issues above, we
propose a novel global context-enhanced adaptive sparse convolutional network
(CEASC). It first develops a context-enhanced group normalization (CE-GN)
layer, by replacing the statistics based on sparsely sampled features with the
global contextual ones, and then designs an adaptive multi-layer masking
strategy to generate optimal mask ratios at distinct scales for compact
foreground coverage, promoting both the accuracy and efficiency. Extensive
experimental results on two major benchmarks, i.e. VisDrone and UAVDT,
demonstrate that CEASC remarkably reduces the GFLOPs and accelerates the
inference procedure when plugging into the typical state-of-the-art detection
frameworks (e.g. RetinaNet and GFL V1) with competitive performance. Code is
available at https://github.com/Cuogeihong/CEASC.","['Bowei Du', 'Yecheng Huang', 'Jiaxin Chen', 'Di Huang']"
"A Noise-Sensitivity-Analysis-Based Test Prioritization Technique for
  Deep Neural Networks",Computer Vision and Pattern Recognition,"Deep neural networks (DNNs) have been widely used in the fields such as
natural language processing, computer vision and image recognition. But several
studies have been shown that deep neural networks can be easily fooled by
artificial examples with some perturbations, which are widely known as
adversarial examples. Adversarial examples can be used to attack deep neural
networks or to improve the robustness of deep neural networks. A common way of
generating adversarial examples is to first generate some noises and then add
them into original examples. In practice, different examples have different
noise-sensitive. To generate an effective adversarial example, it may be
necessary to add a lot of noise to low noise-sensitive example, which may make
the adversarial example meaningless. In this paper, we propose a
noise-sensitivity-analysis-based test prioritization technique to pick out
examples by their noise sensitivity. We construct an experiment to validate our
approach on four image sets and two DNN models, which shows that examples are
sensitive to noise and our method can effectively pick out examples by their
noise sensitivity.","['Long Zhang', 'Xuechao Sun', 'Yong Li', 'Zhenyu Zhang']"
"Training Deep Architectures Without End-to-End Backpropagation: A Survey
  on the Provably Optimal Methods",Machine Learning,"This tutorial paper surveys provably optimal alternatives to end-to-end
backpropagation (E2EBP) -- the de facto standard for training deep
architectures. Modular training refers to strictly local training without both
the forward and the backward pass, i.e., dividing a deep architecture into
several nonoverlapping modules and training them separately without any
end-to-end operation. Between the fully global E2EBP and the strictly local
modular training, there are weakly modular hybrids performing training without
the backward pass only. These alternatives can match or surpass the performance
of E2EBP on challenging datasets such as ImageNet, and are gaining increasing
attention primarily because they offer practical advantages over E2EBP, which
will be enumerated herein. In particular, they allow for greater modularity and
transparency in deep learning workflows, aligning deep learning with the
mainstream computer science engineering that heavily exploits modularization
for scalability. Modular training has also revealed novel insights about
learning and has further implications on other important research domains.
Specifically, it induces natural and effective solutions to some important
practical problems such as data efficiency and transferability estimation.","['Shiyu Duan', 'Jose C. Principe']"
Source-Free Domain Adaptation via Distribution Estimation,Computer Vision and Pattern Recognition,"Domain Adaptation aims to transfer the knowledge learned from a labeled
source domain to an unlabeled target domain whose data distributions are
different. However, the training data in source domain required by most of the
existing methods is usually unavailable in real-world applications due to
privacy preserving policies. Recently, Source-Free Domain Adaptation (SFDA) has
drawn much attention, which tries to tackle domain adaptation problem without
using source data. In this work, we propose a novel framework called SFDA-DE to
address SFDA task via source Distribution Estimation. Firstly, we produce
robust pseudo-labels for target data with spherical k-means clustering, whose
initial class centers are the weight vectors (anchors) learned by the
classifier of pretrained model. Furthermore, we propose to estimate the
class-conditioned feature distribution of source domain by exploiting target
data and corresponding anchors. Finally, we sample surrogate features from the
estimated distribution, which are then utilized to align two domains by
minimizing a contrastive adaptation loss function. Extensive experiments show
that the proposed method achieves state-of-the-art performance on multiple DA
benchmarks, and even outperforms traditional DA methods which require plenty of
source data.","['Ning Ding', 'Yixing Xu', 'Yehui Tang', 'Chao Xu', 'Yunhe Wang', 'Dacheng Tao']"
Recurrent Convolutional Neural Networks for Scene Parsing,Computer Vision and Pattern Recognition,"Scene parsing is a technique that consist on giving a label to all pixels in
an image according to the class they belong to. To ensure a good visual
coherence and a high class accuracy, it is essential for a scene parser to
capture image long range dependencies. In a feed-forward architecture, this can
be simply achieved by considering a sufficiently large input context patch,
around each pixel to be labeled. We propose an approach consisting of a
recurrent convolutional neural network which allows us to consider a large
input context, while limiting the capacity of the model. Contrary to most
standard approaches, our method does not rely on any segmentation methods, nor
any task-specific features. The system is trained in an end-to-end manner over
raw pixels, and models complex spatial dependencies with low inference cost. As
the context size increases with the built-in recurrence, the system identifies
and corrects its own errors. Our approach yields state-of-the-art performance
on both the Stanford Background Dataset and the SIFT Flow Dataset, while
remaining very fast at test time.","['Pedro H. O. Pinheiro', 'Ronan Collobert']"
"Agent-Oriented Approach for Detecting and Managing Risks in Emergency
  Situations",Artificial Intelligence,"This paper presents an agent-oriented approach to build a decision support
system aimed at helping emergency managers to detect and to manage risks. We
stress the flexibility and the adaptivity characteristics that are crucial to
build a robust and efficient system, able to resolve complex problems. The
system should be independent as much as possible from the subject of study.
Thereby, an original approach based on a mechanism of perception,
representation, characterisation and assessment is proposed. The work described
here is applied on the RoboCupRescue application. Experimentations and results
are provided.","['Fahem Kebair', 'Frederic Serin']"
"The Concept of the Tactile Signature System for Individuals with Visual
  Impairments",Human-Computer Interaction,"The lack of an accessible and effective system for blind individuals to
create handwritten signatures presents a significant barrier to their
independence and full participation in various aspects of life. This research
introduces the Tactile Signature System, a groundbreaking approach that
empowers individuals with visual impairments to form their unique handwritten
signatures. Key features of the system include: Personalized customization:
Through tactile interaction and voice algorithmic guidance, individuals create
signatures reflecting their preferences and natural writing style. Real-time
feedback: AI-powered voice prompts and analysis ensure accuracy and consistency
in signature formation. Accessibility: Installation in local service centers
provides a secure and supervised environment for signature creation. The
system's impact reaches beyond the individual level: Promotes inclusivity and
independence: Blind individuals can engage in legal and financial transactions
without relying on others. Empowers and fosters equal opportunities:
Participation in education, employment, and civic engagement becomes more
accessible. Aligns with international conventions: Upholds the right of persons
with disabilities to participate fully in society. The Tactile Signature System
represents a significant step towards an inclusive and accessible future for
individuals with visual impairments.","['Anatoliy Kremenchutskiy', 'Galymzhan Gabdreshov']"
"Handwritten digit string recognition by combination of residual network
  and RNN-CTC",Computer Vision and Pattern Recognition,"Recurrent neural network (RNN) and connectionist temporal classification
(CTC) have showed successes in many sequence labeling tasks with the strong
ability of dealing with the problems where the alignment between the inputs and
the target labels is unknown. Residual network is a new structure of
convolutional neural network and works well in various computer vision tasks.
In this paper, we take advantage of the architectures mentioned above to create
a new network for handwritten digit string recognition. First we design a
residual network to extract features from input images, then we employ a RNN to
model the contextual information within feature sequences and predict
recognition results. At the top of this network, a standard CTC is applied to
calculate the loss and yield the final results. These three parts compose an
end-to-end trainable network. The proposed new architecture achieves the
highest performances on ORAND-CAR-A and ORAND-CAR-B with recognition rates
89.75% and 91.14%, respectively. In addition, the experiments on a generated
captcha dataset which has much longer string length show the potential of the
proposed network to handle long strings.","['Hongjian Zhan', 'Qingqing Wang', 'Yue Lu']"
A3T: Adversarially Augmented Adversarial Training,Machine Learning,"Recent research showed that deep neural networks are highly sensitive to
so-called adversarial perturbations, which are tiny perturbations of the input
data purposely designed to fool a machine learning classifier. Most
classification models, including deep learning models, are highly vulnerable to
adversarial attacks. In this work, we investigate a procedure to improve
adversarial robustness of deep neural networks through enforcing representation
invariance. The idea is to train the classifier jointly with a discriminator
attached to one of its hidden layer and trained to filter the adversarial
noise. We perform preliminary experiments to test the viability of the approach
and to compare it to other standard adversarial training methods.","['Akram Erraqabi', 'Aristide Baratin', 'Yoshua Bengio', 'Simon Lacoste-Julien']"
"Exploit Multiple Reference Graphs for Semi-supervised Relation
  Extraction",Computation and Language (Natural Language Processing),"Manual annotation of the labeled data for relation extraction is
time-consuming and labor-intensive. Semi-supervised methods can offer helping
hands for this problem and have aroused great research interests. Existing work
focuses on mapping the unlabeled samples to the classes to augment the labeled
dataset. However, it is hard to find an overall good mapping function,
especially for the samples with complicated syntactic components in one
sentence.
  To tackle this limitation, we propose to build the connection between the
unlabeled data and the labeled ones rather than directly mapping the unlabeled
samples to the classes. Specifically, we first use three kinds of information
to construct reference graphs, including entity reference, verb reference, and
semantics reference. The goal is to semantically or lexically connect the
unlabeled sample(s) to the labeled one(s). Then, we develop a Multiple
Reference Graph (MRefG) model to exploit the reference information for better
recognizing high-quality unlabeled samples. The effectiveness of our method is
demonstrated by extensive comparison experiments with the state-of-the-art
baselines on two public datasets.","['Wanli Li', 'Tieyun Qian']"
"TMPNN: High-Order Polynomial Regression Based on Taylor Map
  Factorization",Machine Learning,"Polynomial regression is widely used and can help to express nonlinear
patterns. However, considering very high polynomial orders may lead to
overfitting and poor extrapolation ability for unseen data. The paper presents
a method for constructing a high-order polynomial regression based on the
Taylor map factorization. This method naturally implements multi-target
regression and can capture internal relationships between targets.
Additionally, we introduce an approach for model interpretation in the form of
systems of differential equations. By benchmarking on UCI open access datasets,
Feynman symbolic regression datasets, and Friedman-1 datasets, we demonstrate
that the proposed method performs comparable to the state-of-the-art regression
methods and outperforms them on specific tasks.","['Andrei Ivanov', 'Stefan Maria Ailuro']"
"Webly Supervised Image Classification with Metadata: Automatic Noisy
  Label Correction via Visual-Semantic Graph",Computer Vision and Pattern Recognition,"Webly supervised learning becomes attractive recently for its efficiency in
data expansion without expensive human labeling. However, adopting search
queries or hashtags as web labels of images for training brings massive noise
that degrades the performance of DNNs. Especially, due to the semantic
confusion of query words, the images retrieved by one query may contain
tremendous images belonging to other concepts. For example, searching `tiger
cat' on Flickr will return a dominating number of tiger images rather than the
cat images. These realistic noisy samples usually have clear visual semantic
clusters in the visual space that mislead DNNs from learning accurate semantic
labels. To correct real-world noisy labels, expensive human annotations seem
indispensable. Fortunately, we find that metadata can provide extra knowledge
to discover clean web labels in a labor-free fashion, making it feasible to
automatically provide correct semantic guidance among the massive label-noisy
web data. In this paper, we propose an automatic label corrector VSGraph-LC
based on the visual-semantic graph. VSGraph-LC starts from anchor selection
referring to the semantic similarity between metadata and correct label
concepts, and then propagates correct labels from anchors on a visual graph
using graph neural network (GNN). Experiments on realistic webly supervised
learning datasets Webvision-1000 and NUS-81-Web show the effectiveness and
robustness of VSGraph-LC. Moreover, VSGraph-LC reveals its advantage on the
open-set validation set.","['Jingkang Yang', 'Weirong Chen', 'Litong Feng', 'Xiaopeng Yan', 'Huabin Zheng', 'Wayne Zhang']"
"Weakly Supervised Foreground Learning for Weakly Supervised Localization
  and Detection",Computer Vision and Pattern Recognition,"Modern deep learning models require large amounts of accurately annotated
data, which is often difficult to satisfy. Hence, weakly supervised tasks,
including weakly supervised object localization~(WSOL) and detection~(WSOD),
have recently received attention in the computer vision community. In this
paper, we motivate and propose the weakly supervised foreground learning (WSFL)
task by showing that both WSOL and WSOD can be greatly improved if groundtruth
foreground masks are available. More importantly, we propose a complete WSFL
pipeline with low computational cost, which generates pseudo boxes, learns
foreground masks, and does not need any localization annotations. With the help
of foreground masks predicted by our WSFL model, we achieve 72.97% correct
localization accuracy on CUB for WSOL, and 55.7% mean average precision on
VOC07 for WSOD, thereby establish new state-of-the-art for both tasks. Our WSFL
model also shows excellent transfer ability.","['Chen-Lin Zhang', 'Yin Li', 'Jianxin Wu']"
Shared Mobile-Cloud Inference for Collaborative Intelligence,Artificial Intelligence,"As AI applications for mobile devices become more prevalent, there is an
increasing need for faster execution and lower energy consumption for neural
model inference. Historically, the models run on mobile devices have been
smaller and simpler in comparison to large state-of-the-art research models,
which can only run on the cloud. However, cloud-only inference has drawbacks
such as increased network bandwidth consumption and higher latency. In
addition, cloud-only inference requires the input data (images, audio) to be
fully transferred to the cloud, creating concerns about potential privacy
breaches. We demonstrate an alternative approach: shared mobile-cloud
inference. Partial inference is performed on the mobile in order to reduce the
dimensionality of the input data and arrive at a compact feature tensor, which
is a latent space representation of the input signal. The feature tensor is
then transmitted to the server for further inference. This strategy can improve
inference latency, energy consumption, and network bandwidth usage, as well as
provide privacy protection, because the original signal never leaves the
mobile. Further performance gain can be achieved by compressing the feature
tensor before its transmission.","['Mateen Ulhaq', 'Ivan V. Bajić']"
Open-TI: Open Traffic Intelligence with Augmented Language Model,Artificial Intelligence,"Transportation has greatly benefited the cities' development in the modern
civilization process. Intelligent transportation, leveraging advanced computer
algorithms, could further increase people's daily commuting efficiency.
However, intelligent transportation, as a cross-discipline, often requires
practitioners to comprehend complicated algorithms and obscure neural networks,
bringing a challenge for the advanced techniques to be trusted and deployed in
practical industries. Recognizing the expressiveness of the pre-trained large
language models, especially the potential of being augmented with abilities to
understand and execute intricate commands, we introduce Open-TI. Serving as a
bridge to mitigate the industry-academic gap, Open-TI is an innovative model
targeting the goal of Turing Indistinguishable Traffic Intelligence, it is
augmented with the capability to harness external traffic analysis packages
based on existing conversations. Marking its distinction, Open-TI is the first
method capable of conducting exhaustive traffic analysis from scratch -
spanning from map data acquisition to the eventual execution in complex
simulations. Besides, Open-TI is able to conduct task-specific embodiment like
training and adapting the traffic signal control policies (TSC), explore demand
optimizations, etc. Furthermore, we explored the viability of LLMs directly
serving as control agents, by understanding the expected intentions from
Open-TI, we designed an agent-to-agent communication mode to support Open-TI
conveying messages to ChatZero (control agent), and then the control agent
would choose from the action space to proceed the execution. We eventually
provide the formal implementation structure, and the open-ended design invites
further community-driven enhancements.","['Longchao Da', 'Kuanru Liou', 'Tiejin Chen', 'Xuesong Zhou', 'Xiangyong Luo', 'Yezhou Yang', 'Hua Wei']"
"ColonFormer: An Efficient Transformer based Method for Colon Polyp
  Segmentation",Computer Vision and Pattern Recognition,"Identifying polyps is challenging for automatic analysis of endoscopic images
in computer-aided clinical support systems. Models based on convolutional
networks (CNN), transformers, and their combinations have been proposed to
segment polyps with promising results. However, those approaches have
limitations either in modeling the local appearance of the polyps only or lack
of multi-level features for spatial dependency in the decoding process. This
paper proposes a novel network, namely ColonFormer, to address these
limitations. ColonFormer is an encoder-decoder architecture capable of modeling
long-range semantic information at both encoder and decoder branches. The
encoder is a lightweight architecture based on transformers for modeling global
semantic relations at multi scales. The decoder is a hierarchical network
structure designed for learning multi-level features to enrich feature
representation. Besides, a refinement module is added with a new skip
connection technique to refine the boundary of polyp objects in the global map
for accurate segmentation. Extensive experiments have been conducted on five
popular benchmark datasets for polyp segmentation, including Kvasir, CVC-Clinic
DB, CVC-ColonDB, CVC-T, and ETIS-Larib. Experimental results show that our
ColonFormer outperforms other state-of-the-art methods on all benchmark
datasets.","['Nguyen Thanh Duc', 'Nguyen Thi Oanh', 'Nguyen Thi Thuy', 'Tran Minh Triet', 'Dinh Viet Sang']"
A Study on Encodings for Neural Architecture Search,Machine Learning,"Neural architecture search (NAS) has been extensively studied in the past few
years. A popular approach is to represent each neural architecture in the
search space as a directed acyclic graph (DAG), and then search over all DAGs
by encoding the adjacency matrix and list of operations as a set of
hyperparameters. Recent work has demonstrated that even small changes to the
way each architecture is encoded can have a significant effect on the
performance of NAS algorithms.
  In this work, we present the first formal study on the effect of architecture
encodings for NAS, including a theoretical grounding and an empirical study.
First we formally define architecture encodings and give a theoretical
characterization on the scalability of the encodings we study Then we identify
the main encoding-dependent subroutines which NAS algorithms employ, running
experiments to show which encodings work best with each subroutine for many
popular algorithms. The experiments act as an ablation study for prior work,
disentangling the algorithmic and encoding-based contributions, as well as a
guideline for future work. Our results demonstrate that NAS encodings are an
important design decision which can have a significant impact on overall
performance. Our code is available at
https://github.com/naszilla/nas-encodings.","['Colin White', 'Willie Neiswanger', 'Sam Nolen', 'Yash Savani']"
"DotFAN: A Domain-transferred Face Augmentation Network for Pose and
  Illumination Invariant Face Recognition",Computer Vision and Pattern Recognition,"The performance of a convolutional neural network (CNN) based face
recognition model largely relies on the richness of labelled training data.
Collecting a training set with large variations of a face identity under
different poses and illumination changes, however, is very expensive, making
the diversity of within-class face images a critical issue in practice. In this
paper, we propose a 3D model-assisted domain-transferred face augmentation
network (DotFAN) that can generate a series of variants of an input face based
on the knowledge distilled from existing rich face datasets collected from
other domains. DotFAN is structurally a conditional CycleGAN but has two
additional subnetworks, namely face expert network (FEM) and face shape
regressor (FSR), for latent code control. While FSR aims to extract face
attributes, FEM is designed to capture a face identity. With their aid, DotFAN
can learn a disentangled face representation and effectively generate face
images of various facial attributes while preserving the identity of augmented
faces. Experiments show that DotFAN is beneficial for augmenting small face
datasets to improve their within-class diversity so that a better face
recognition model can be learned from the augmented dataset.","['Hao-Chiang Shao', 'Kang-Yu Liu', 'Chia-Wen Lin', 'Jiwen Lu']"
"The Group Robustness is in the Details: Revisiting Finetuning under
  Spurious Correlations",Machine Learning,"Modern machine learning models are prone to over-reliance on spurious
correlations, which can often lead to poor performance on minority groups. In
this paper, we identify surprising and nuanced behavior of finetuned models on
worst-group accuracy via comprehensive experiments on four well-established
benchmarks across vision and language tasks. We first show that the commonly
used class-balancing techniques of mini-batch upsampling and loss upweighting
can induce a decrease in worst-group accuracy (WGA) with training epochs,
leading to performance no better than without class-balancing. While in some
scenarios, removing data to create a class-balanced subset is more effective,
we show this depends on group structure and propose a mixture method which can
outperform both techniques. Next, we show that scaling pretrained models is
generally beneficial for worst-group accuracy, but only in conjunction with
appropriate class-balancing. Finally, we identify spectral imbalance in
finetuning features as a potential source of group disparities -- minority
group covariance matrices incur a larger spectral norm than majority groups
once conditioned on the classes. Our results show more nuanced interactions of
modern finetuned models with group robustness than was previously known. Our
code is available at https://github.com/tmlabonte/revisiting-finetuning.","['Tyler LaBonte', 'John C. Hill', 'Xinchen Zhang', 'Vidya Muthukumar', 'Abhishek Kumar']"
AutoGraph: Imperative-style Coding with Graph-based Performance,Programming Languages,"There is a perceived trade-off between machine learning code that is easy to
write, and machine learning code that is scalable or fast to execute. In
machine learning, imperative style libraries like Autograd and PyTorch are easy
to write, but suffer from high interpretive overhead and are not easily
deployable in production or mobile settings. Graph-based libraries like
TensorFlow and Theano benefit from whole-program optimization and can be
deployed broadly, but make expressing complex models more cumbersome. We
describe how the use of staged programming in Python, via source code
transformation, offers a midpoint between these two library design patterns,
capturing the benefits of both. A key insight is to delay all type-dependent
decisions until runtime, via dynamic dispatch. We instantiate these principles
in AutoGraph, a software system that improves the programming experience of the
TensorFlow library, and demonstrate usability improvements with no loss in
performance compared to native TensorFlow graphs. We also show that our system
is backend agnostic, and demonstrate targeting an alternate IR with
characteristics not found in TensorFlow graphs.","['Dan Moldovan', 'James M Decker', 'Fei Wang', 'Andrew A Johnson', 'Brian K Lee', 'Zachary Nado', 'D Sculley', 'Tiark Rompf', 'Alexander B Wiltschko']"
"Finite-Sample Bounds for Adaptive Inverse Reinforcement Learning using
  Passive Langevin Dynamics",Machine Learning,"This paper provides a finite-sample analysis of a passive stochastic gradient
Langevin dynamics (PSGLD) algorithm. This algorithm is designed to achieve
adaptive inverse reinforcement learning (IRL). Adaptive IRL aims to estimate
the cost function of a forward learner performing a stochastic gradient
algorithm (e.g., policy gradient reinforcement learning) by observing their
estimates in real-time. The PSGLD algorithm is considered passive because it
incorporates noisy gradients provided by an external stochastic gradient
algorithm (forward learner), of which it has no control. The PSGLD algorithm
acts as a randomized sampler to achieve adaptive IRL by reconstructing the
forward learner's cost function nonparametrically from the stationary measure
of a Langevin diffusion. This paper analyzes the non-asymptotic (finite-sample)
performance; we provide explicit bounds on the 2-Wasserstein distance between
PSGLD algorithm sample measure and the stationary measure encoding the cost
function, and provide guarantees for a kernel density estimation scheme which
reconstructs the cost function from empirical samples. Our analysis uses tools
from the study of Markov diffusion operators. The derived bounds have both
practical and theoretical significance. They provide finite-time guarantees for
an adaptive IRL mechanism, and substantially generalize the analytical
framework of a line of research in passive stochastic gradient algorithms.","['Luke Snow', 'Vikram Krishnamurthy']"
"SceneAdapt: Scene-based domain adaptation for semantic segmentation
  using adversarial learning",Computer Vision and Pattern Recognition,"Semantic segmentation methods have achieved outstanding performance thanks to
deep learning. Nevertheless, when such algorithms are deployed to new contexts
not seen during training, it is necessary to collect and label scene-specific
data in order to adapt them to the new domain using fine-tuning. This process
is required whenever an already installed camera is moved or a new camera is
introduced in a camera network due to the different scene layouts induced by
the different viewpoints. To limit the amount of additional training data to be
collected, it would be ideal to train a semantic segmentation method using
labeled data already available and only unlabeled data coming from the new
camera. We formalize this problem as a domain adaptation task and introduce a
novel dataset of urban scenes with the related semantic labels. As a first
approach to address this challenging task, we propose SceneAdapt, a method for
scene adaptation of semantic segmentation algorithms based on adversarial
learning. Experiments and comparisons with state-of-the-art approaches to
domain adaptation highlight that promising performance can be achieved using
adversarial learning both when the two scenes have different but points of
view, and when they comprise images of completely different scenes. To
encourage research on this topic, we made our code available at our web page:
https://iplab.dmi.unict.it/ParkSmartSceneAdaptation/.","['Daniele Di Mauro', 'Antonino Furnari', 'Giuseppe Patanè', 'Sebastiano Battiato', 'Giovanni Maria Farinella']"
"SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning
  Dynamics and Interpretability",Machine Learning (Statistics),"We propose a new technique, Singular Vector Canonical Correlation Analysis
(SVCCA), a tool for quickly comparing two representations in a way that is both
invariant to affine transform (allowing comparison between different layers and
networks) and fast to compute (allowing more comparisons to be calculated than
with previous methods). We deploy this tool to measure the intrinsic
dimensionality of layers, showing in some cases needless over-parameterization;
to probe learning dynamics throughout training, finding that networks converge
to final representations from the bottom up; to show where class-specific
information in networks is formed; and to suggest new training regimes that
simultaneously save computation and overfit less. Code:
https://github.com/google/svcca/","['Maithra Raghu', 'Justin Gilmer', 'Jason Yosinski', 'Jascha Sohl-Dickstein']"
A Method for Planning Given Uncertain and Incomplete Information,Artificial Intelligence,"This paper describes ongoing research into planning in an uncertain
environment. In particular, it introduces U-Plan, a planning system that
constructs quantitatively ranked plans given an incomplete description of the
state of the world. U-Plan uses a DempsterShafer interval to characterise
uncertain and incomplete information about the state of the world. The planner
takes as input what is known about the world, and constructs a number of
possible initial states with representations at different abstraction levels. A
plan is constructed for the initial state with the greatest support, and this
plan is tested to see if it will work for other possible initial states. All,
part, or none of the existing plans may be used in the generation of the plans
for the remaining possible worlds. Planning takes place in an abstraction
hierarchy where strategic decisions are made before tactical decisions. A
super-plan is then constructed, based on merging the set of plans and the
appropriately timed acquisition of essential knowledge, which is used to decide
between plan alternatives. U-Plan usually produces a super-plan in less time
than a classical planner would take to produce a set of plans, one for each
possible world.",['Todd Michael Mansell']
Entity Embeddings of Categorical Variables,Machine Learning,"We map categorical variables in a function approximation problem into
Euclidean spaces, which are the entity embeddings of the categorical variables.
The mapping is learned by a neural network during the standard supervised
training process. Entity embedding not only reduces memory usage and speeds up
neural networks compared with one-hot encoding, but more importantly by mapping
similar values close to each other in the embedding space it reveals the
intrinsic properties of the categorical variables. We applied it successfully
in a recent Kaggle competition and were able to reach the third position with
relative simple features. We further demonstrate in this paper that entity
embedding helps the neural network to generalize better when the data is sparse
and statistics is unknown. Thus it is especially useful for datasets with lots
of high cardinality features, where other methods tend to overfit. We also
demonstrate that the embeddings obtained from the trained neural network boost
the performance of all tested machine learning methods considerably when used
as the input features instead. As entity embedding defines a distance measure
for categorical variables it can be used for visualizing categorical data and
for data clustering.","['Cheng Guo', 'Felix Berkhahn']"
"Investigating Premature Convergence in Co-optimization of Morphology and
  Control in Evolved Virtual Soft Robots",Robotics,"Evolving virtual creatures is a field with a rich history and recently it has
been getting more attention, especially in the soft robotics domain. The
compliance of soft materials endows soft robots with complex behavior, but it
also makes their design process unintuitive and in need of automated design.
Despite the great interest, evolved virtual soft robots lack the complexity,
and co-optimization of morphology and control remains a challenging problem.
Prior work identifies and investigates a major issue with the co-optimization
process -- fragile co-adaptation of brain and body resulting in premature
convergence of morphology. In this work, we expand the investigation of this
phenomenon by comparing learnable controllers with proprioceptive observations
and fixed controllers without any observations, whereas in the latter case, we
only have the optimization of the morphology. Our experiments in two morphology
spaces and two environments that vary in complexity show, concrete examples of
the existence of high-performing regions in the morphology space that are not
able to be discovered during the co-optimization of the morphology and control,
yet exist and are easily findable when optimizing morphologies alone. Thus this
work clearly demonstrates and characterizes the challenges of optimizing
morphology during co-optimization. Based on these results, we propose a new
body-centric framework to think about the co-optimization problem which helps
us understand the issue from a search perspective. We hope the insights we
share with this work attract more attention to the problem and help us to
enable efficient brain-body co-optimization.","['Alican Mertan', 'Nick Cheney']"
Controlling keywords and their positions in text generation,Computation and Language (Natural Language Processing),"One of the challenges in text generation is to control text generation as
intended by the user. Previous studies proposed specifying the keywords that
should be included in the generated text. However, this approach is
insufficient to generate text that reflect the user's intent. For example,
placing an important keyword at the beginning of the text would help attract
the reader's attention; however, existing methods do not enable such flexible
control. In this paper, we tackle a novel task of controlling not only keywords
but also the position of each keyword in the text generation. To this end, we
propose a task-independent method that uses special tokens to control the
relative position of keywords. Experimental results on summarization and story
generation tasks show that the proposed method can control keywords and their
positions. The experimental results also demonstrate that controlling the
keyword positions can generate summary texts that are closer to the user's
intent than baseline.","['Yuichi Sasazawa', 'Terufumi Morishita', 'Hiroaki Ozaki', 'Osamu Imaichi', 'Yasuhiro Sogawa']"
"The phase transition for the existence of the maximum likelihood
  estimate in high-dimensional logistic regression",Methodology (Statistics),"This paper rigorously establishes that the existence of the maximum
likelihood estimate (MLE) in high-dimensional logistic regression models with
Gaussian covariates undergoes a sharp `phase transition'. We introduce an
explicit boundary curve $h_{\text{MLE}}$, parameterized by two scalars
measuring the overall magnitude of the unknown sequence of regression
coefficients, with the following property: in the limit of large sample sizes
$n$ and number of features $p$ proportioned in such a way that $p/n \rightarrow
\kappa$, we show that if the problem is sufficiently high dimensional in the
sense that $\kappa > h_{\text{MLE}}$, then the MLE does not exist with
probability one. Conversely, if $\kappa < h_{\text{MLE}}$, the MLE
asymptotically exists with probability one.","['Emmanuel J. Candes', 'Pragya Sur']"
CODEX: A Cluster-Based Method for Explainable Reinforcement Learning,Machine Learning,"Despite the impressive feats demonstrated by Reinforcement Learning (RL),
these algorithms have seen little adoption in high-risk, real-world
applications due to current difficulties in explaining RL agent actions and
building user trust. We present Counterfactual Demonstrations for Explanation
(CODEX), a method that incorporates semantic clustering, which can effectively
summarize RL agent behavior in the state-action space. Experimentation on the
MiniGrid and StarCraft II gaming environments reveals the semantic clusters
retain temporal as well as entity information, which is reflected in the
constructed summary of agent behavior. Furthermore, clustering the
discrete+continuous game-state latent representations identifies the most
crucial episodic events, demonstrating a relationship between the latent and
semantic spaces. This work contributes to the growing body of work that strives
to unlock the power of RL for widespread use by leveraging and extending
techniques from Natural Language Processing.","['Timothy K. Mathes', 'Jessica Inman', 'Andrés Colón', 'Simon Khan']"
"Can neural networks extrapolate? Discussion of a theorem by Pedro
  Domingos",Computer Vision and Pattern Recognition,"Neural networks trained on large datasets by minimizing a loss have become
the state-of-the-art approach for resolving data science problems, particularly
in computer vision, image processing and natural language processing. In spite
of their striking results, our theoretical understanding about how neural
networks operate is limited. In particular, what are the interpolation
capabilities of trained neural networks? In this paper we discuss a theorem of
Domingos stating that ""every machine learned by continuous gradient descent is
approximately a kernel machine"". According to Domingos, this fact leads to
conclude that all machines trained on data are mere kernel machines. We first
extend Domingo's result in the discrete case and to networks with vector-valued
output. We then study its relevance and significance on simple examples. We
find that in simple cases, the ""neural tangent kernel"" arising in Domingos'
theorem does provide understanding of the networks' predictions. Furthermore,
when the task given to the network grows in complexity, the interpolation
capability of the network can be effectively explained by Domingos' theorem,
and therefore is limited. We illustrate this fact on a classic perception
theory problem: recovering a shape from its boundary.","['Adrien Courtois', 'Jean-Michel Morel', 'Pablo Arias']"
Online Feature Screening for Data Streams with Concept Drift,Machine Learning (Statistics),"Screening feature selection methods are often used as a preprocessing step
for reducing the number of variables before training step. Traditional
screening methods only focus on dealing with complete high dimensional
datasets. Modern datasets not only have higher dimension and larger sample
size, but also have properties such as streaming input, sparsity and concept
drift. Therefore a considerable number of online feature selection methods were
introduced to handle these kind of problems in recent years. Online screening
methods are one of the categories of online feature selection methods. The
methods that we proposed in this research are capable of handling all three
situations mentioned above. Our research study focuses on classification
datasets. Our experiments show proposed methods can generate the same feature
importance as their offline version with faster speed and less storage
consumption. Furthermore, the results show that online screening methods with
integrated model adaptation have a higher true feature detection rate than
without model adaptation on data streams with the concept drift property. Among
the two large real datasets that potentially have the concept drift property,
online screening methods with model adaptation show advantages in either saving
computing time and space, reducing model complexity, or improving prediction
accuracy.","['Mingyuan Wang', 'Adrian Barbu']"
Can Optimization Trajectories Explain Multi-Task Transfer?,Machine Learning,"Despite the widespread adoption of multi-task training in deep learning,
little is understood about how multi-task learning (MTL) affects
generalization. Prior work has conjectured that the negative effects of MTL are
due to optimization challenges that arise during training, and many
optimization methods have been proposed to improve multi-task performance.
However, recent work has shown that these methods fail to consistently improve
multi-task generalization. In this work, we seek to improve our understanding
of these failures by empirically studying how MTL impacts the optimization of
tasks, and whether this impact can explain the effects of MTL on
generalization. We show that MTL results in a generalization gap-a gap in
generalization at comparable training loss-between single-task and multi-task
trajectories early into training. However, we find that factors of the
optimization trajectory previously proposed to explain generalization gaps in
single-task settings cannot explain the generalization gaps between single-task
and multi-task models. Moreover, we show that the amount of gradient conflict
between tasks is correlated with negative effects to task optimization, but is
not predictive of generalization. Our work sheds light on the underlying causes
for failures in MTL and, importantly, raises questions about the role of
general purpose multi-task optimization algorithms.","['David Mueller', 'Mark Dredze', 'Nicholas Andrews']"
"Efficient Relative Pose Estimation for Cameras and Generalized Cameras
  in Case of Known Relative Rotation Angle",Computer Vision and Pattern Recognition,"We propose two minimal solutions to the problem of relative pose estimation
of (i) a calibrated camera from four points in two views and (ii) a calibrated
generalized camera from five points in two views. In both cases, the relative
rotation angle between the views is assumed to be known. In practice, such
angle can be derived from the readings of a 3d gyroscope. We represent the
rotation part of the motion in terms of unit quaternions in order to construct
polynomial equations encoding the epipolar constraints. The Gr\""{o}bner basis
technique is then used to efficiently derive the solutions. Our first solver
for regular cameras significantly improves the existing state-of-the-art
solution. The second solver for generalized cameras is novel.
  The presented minimal solvers can be used in a hypothesize-and-test
architecture such as RANSAC for reliable pose estimation. Experiments on
synthetic and real datasets confirm that our algorithms are numerically stable,
fast and robust.","['Evgeniy Martyushev', 'Bo Li']"
"Deliberate then Generate: Enhanced Prompting Framework for Text
  Generation",Computation and Language (Natural Language Processing),"Large language models (LLMs) have shown remarkable success across a wide
range of natural language generation tasks, where proper prompt designs make
great impacts. While existing prompting methods are normally restricted to
providing correct information, in this paper, we encourage the model to
deliberate by proposing a novel Deliberate then Generate (DTG) prompting
framework, which consists of error detection instructions and candidates that
may contain errors. DTG is a simple yet effective technique that can be applied
to various text generation tasks with minimal modifications. We conduct
extensive experiments on 20+ datasets across 7 text generation tasks, including
summarization, translation, dialogue, and more. We show that DTG consistently
outperforms existing prompting methods and achieves state-of-the-art
performance on multiple text generation tasks. We also provide in-depth
analyses to reveal the underlying mechanisms of DTG, which may inspire future
research on prompting for LLMs.","['Bei Li', 'Rui Wang', 'Junliang Guo', 'Kaitao Song', 'Xu Tan', 'Hany Hassan', 'Arul Menezes', 'Tong Xiao', 'Jiang Bian', 'JingBo Zhu']"
"MACRONYM: A Large-Scale Dataset for Multilingual and Multi-Domain
  Acronym Extraction",Computation and Language (Natural Language Processing),"Acronym extraction is the task of identifying acronyms and their expanded
forms in texts that is necessary for various NLP applications. Despite major
progress for this task in recent years, one limitation of existing AE research
is that they are limited to the English language and certain domains (i.e.,
scientific and biomedical). As such, challenges of AE in other languages and
domains is mainly unexplored. Lacking annotated datasets in multiple languages
and domains has been a major issue to hinder research in this area. To address
this limitation, we propose a new dataset for multilingual multi-domain AE.
Specifically, 27,200 sentences in 6 typologically different languages and 2
domains, i.e., Legal and Scientific, is manually annotated for AE. Our
extensive experiments on the proposed dataset show that AE in different
languages and different learning settings has unique challenges, emphasizing
the necessity of further research on multilingual and multi-domain AE.","['Amir Pouran Ben Veyseh', 'Nicole Meister', 'Seunghyun Yoon', 'Rajiv Jain', 'Franck Dernoncourt', 'Thien Huu Nguyen']"
An Optimized Recurrent Unit for Ultra-Low-Power Keyword Spotting,Machine Learning,"There is growing interest in being able to run neural networks on sensors,
wearables and internet-of-things (IoT) devices. However, the computational
demands of neural networks make them difficult to deploy on
resource-constrained edge devices.
  To meet this need, our work introduces a new recurrent unit architecture that
is specifically adapted for on-device low power acoustic event detection (AED).
The proposed architecture is based on the gated recurrent unit (`GRU') but
features optimizations that make it implementable on ultra-low power
micro-controllers such as the Arm Cortex M0+.
  Our new architecture, the Embedded Gated Recurrent Unit (eGRU) is
demonstrated to be highly efficient and suitable for short-duration AED and
keyword spotting tasks. A single eGRU cell is 60x faster and 10x smaller than a
GRU cell. Despite its optimizations, eGRU compares well with GRU across tasks
of varying complexities.
  The practicality of eGRU is investigated in a wearable acoustic event
detection application. An eGRU model is implemented and tested on the Arm
Cortex M0-based Atmel ATSAMD21E18 processor. The Arm M0+ implementation of the
eGRU model compares favorably with a full precision GRU that is running on a
workstation. The embedded eGRU model achieves a classification accuracy 95.3%,
which is only 2% less than the full precision GRU.","['Justice Amoh', 'Kofi Odame']"
Semiparametric Bayesian Difference-in-Differences,Econometrics,"This paper studies semiparametric Bayesian inference for the average
treatment effect on the treated (ATT) within the difference-in-differences
research design. We propose two new Bayesian methods with frequentist validity.
The first one places a standard Gaussian process prior on the conditional mean
function of the control group. We obtain asymptotic equivalence of our Bayesian
estimator and an efficient frequentist estimator by establishing a
semiparametric Bernstein-von Mises (BvM) theorem. The second method is a double
robust Bayesian procedure that adjusts the prior distribution of the
conditional mean function and subsequently corrects the posterior distribution
of the resulting ATT. We establish a semiparametric BvM result under double
robust smoothness conditions; i.e., the lack of smoothness of conditional mean
functions can be compensated by high regularity of the propensity score, and
vice versa. Monte Carlo simulations and an empirical application demonstrate
that the proposed Bayesian DiD methods exhibit strong finite-sample performance
compared to existing frequentist methods. Finally, we outline an extension to
difference-in-differences with multiple periods and staggered entry.","['Christoph Breunig', 'Ruixuan Liu', 'Zhengfei Yu']"
"Nowcasting day-ahead marginal emissions using multi-headed CNNs and deep
  generative models",Machine Learning,"Nowcasting day-ahead marginal emissions factors is increasingly important for
power systems with high flexibility and penetration of distributed energy
resources. With a significant share of firm generation from natural gas and
coal power plants, forecasting day-ahead emissions in the current energy system
has been widely studied. In contrast, as we shift to an energy system
characterized by flexible power markets, dispatchable sources, and competing
low-cost generation such as large-scale battery or hydrogen storage, system
operators will be able to choose from a mix of different generation as well as
emission pathways. To fully develop the emissions implications of a given
dispatch schedule, we need a near real-time workflow with two layers. The first
layer is a market model that continuously solves a security-constrained
economic dispatch model. The second layer determines the marginal emissions
based on the output of the market model, which is the subject of this paper. We
propose using multi-headed convolutional neural networks to generate day-ahead
forecasts of marginal and average emissions for a given independent system
operator.","['Dhruv Suri', 'Anela Arifi', 'Ines Azevedo']"
ORCa: Glossy Objects as Radiance Field Cameras,Computer Vision and Pattern Recognition,"Reflections on glossy objects contain valuable and hidden information about
the surrounding environment. By converting these objects into cameras, we can
unlock exciting applications, including imaging beyond the camera's
field-of-view and from seemingly impossible vantage points, e.g. from
reflections on the human eye. However, this task is challenging because
reflections depend jointly on object geometry, material properties, the 3D
environment, and the observer viewing direction. Our approach converts glossy
objects with unknown geometry into radiance-field cameras to image the world
from the object's perspective. Our key insight is to convert the object surface
into a virtual sensor that captures cast reflections as a 2D projection of the
5D environment radiance field visible to the object. We show that recovering
the environment radiance fields enables depth and radiance estimation from the
object to its surroundings in addition to beyond field-of-view novel-view
synthesis, i.e. rendering of novel views that are only directly-visible to the
glossy object present in the scene, but not the observer. Moreover, using the
radiance field we can image around occluders caused by close-by objects in the
scene. Our method is trained end-to-end on multi-view images of the object and
jointly estimates object geometry, diffuse radiance, and the 5D environment
radiance field.","['Kushagra Tiwary', 'Akshat Dave', 'Nikhil Behari', 'Tzofi Klinghoffer', 'Ashok Veeraraghavan', 'Ramesh Raskar']"
"Creation and Evaluation of a Pre-tertiary Artificial Intelligence (AI)
  Curriculum",Artificial Intelligence,"Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for
the Future Project (AI4Future) co-created an AI curriculum for pre-tertiary
education and evaluated its efficacy. While AI is conventionally taught in
tertiary level education, our co-creation process successfully developed the
curriculum that has been used in secondary school teaching in Hong Kong and
received positive feedback. Background: AI4Future is a cross-sector project
that engages five major partners - CUHK Faculty of Engineering and Faculty of
Education, Hong Kong secondary schools, the government and the AI industry. A
team of 14 professors with expertise in engineering and education collaborated
with 17 principals and teachers from 6 secondary schools to co-create the
curriculum. This team formation bridges the gap between researchers in
engineering and education, together with practitioners in education context.
Research Questions: What are the main features of the curriculum content
developed through the co-creation process? Would the curriculum significantly
improve the students perceived competence in, as well as attitude and
motivation towards AI? What are the teachers perceptions of the co-creation
process that aims to accommodate and foster teacher autonomy? Methodology: This
study adopted a mix of quantitative and qualitative methods and involved 335
student participants. Findings: 1) two main features of learning resources, 2)
the students perceived greater competence, and developed more positive attitude
to learn AI, and 3) the co-creation process generated a variety of resources
which enhanced the teachers knowledge in AI, as well as fostered teachers
autonomy in bringing the subject matter into their classrooms.","['Thomas K. F. Chiu', 'Helen Meng', 'Ching-Sing Chai', 'Irwin King', 'Savio Wong', 'Yeung Yam']"
Hyperparameter Learning via Distributional Transfer,Machine Learning (Statistics),"Bayesian optimisation is a popular technique for hyperparameter learning but
typically requires initial exploration even in cases where similar prior tasks
have been solved. We propose to transfer information across tasks using learnt
representations of training datasets used in those tasks. This results in a
joint Gaussian process model on hyperparameters and data representations.
Representations make use of the framework of distribution embeddings into
reproducing kernel Hilbert spaces. The developed method has a faster
convergence compared to existing baselines, in some cases requiring only a few
evaluations of the target objective.","['Ho Chung Leon Law', 'Peilin Zhao', 'Lucian Chan', 'Junzhou Huang', 'Dino Sejdinovic']"
"Towards Deeper Graph Neural Networks with Differentiable Group
  Normalization",Machine Learning,"Graph neural networks (GNNs), which learn the representation of a node by
aggregating its neighbors, have become an effective computational tool in
downstream applications. Over-smoothing is one of the key issues which limit
the performance of GNNs as the number of layers increases. It is because the
stacked aggregators would make node representations converge to
indistinguishable vectors. Several attempts have been made to tackle the issue
by bringing linked node pairs close and unlinked pairs distinct. However, they
often ignore the intrinsic community structures and would result in sub-optimal
performance. The representations of nodes within the same community/class need
be similar to facilitate the classification, while different classes are
expected to be separated in embedding space. To bridge the gap, we introduce
two over-smoothing metrics and a novel technique, i.e., differentiable group
normalization (DGN). It normalizes nodes within the same group independently to
increase their smoothness, and separates node distributions among different
groups to significantly alleviate the over-smoothing issue. Experiments on
real-world datasets demonstrate that DGN makes GNN models more robust to
over-smoothing and achieves better performance with deeper GNNs.","['Kaixiong Zhou', 'Xiao Huang', 'Yuening Li', 'Daochen Zha', 'Rui Chen', 'Xia Hu']"
Neural Unsupervised Reconstruction of Protolanguage Word Forms,Computation and Language (Natural Language Processing),"We present a state-of-the-art neural approach to the unsupervised
reconstruction of ancient word forms. Previous work in this domain used
expectation-maximization to predict simple phonological changes between ancient
word forms and their cognates in modern languages. We extend this work with
neural models that can capture more complicated phonological and morphological
changes. At the same time, we preserve the inductive biases from classical
methods by building monotonic alignment constraints into the model and
deliberately underfitting during the maximization step. We evaluate our
performance on the task of reconstructing Latin from a dataset of cognates
across five Romance languages, achieving a notable reduction in edit distance
from the target word forms compared to previous methods.","['Andre He', 'Nicholas Tomlin', 'Dan Klein']"
"Condition-Adaptive Graph Convolution Learning for Skeleton-Based Gait
  Recognition",Computer Vision and Pattern Recognition,"Graph convolutional networks have been widely applied in skeleton-based gait
recognition. A key challenge in this task is to distinguish the individual
walking styles of different subjects across various views. Existing
state-of-the-art methods employ uniform convolutions to extract features from
diverse sequences and ignore the effects of viewpoint changes. To overcome
these limitations, we propose a condition-adaptive graph (CAG) convolution
network that can dynamically adapt to the specific attributes of each skeleton
sequence and the corresponding view angle. In contrast to using fixed weights
for all joints and sequences, we introduce a joint-specific filter learning
(JSFL) module in the CAG method, which produces sequence-adaptive filters at
the joint level. The adaptive filters capture fine-grained patterns that are
unique to each joint, enabling the extraction of diverse spatial-temporal
information about body parts. Additionally, we design a view-adaptive topology
learning (VATL) module that generates adaptive graph topologies. These graph
topologies are used to correlate the joints adaptively according to the
specific view conditions. Thus, CAG can simultaneously adjust to various
walking styles and viewpoints. Experiments on the two most widely used datasets
(i.e., CASIA-B and OU-MVLP) show that CAG surpasses all previous skeleton-based
methods. Moreover, the recognition performance can be enhanced by simply
combining CAG with appearance-based methods, demonstrating the ability of CAG
to provide useful complementary information.The source code will be available
at https://github.com/OliverHxh/CAG.","['Xiaohu Huang', 'Xinggang Wang', 'Zhidianqiu Jin', 'Bo Yang', 'Botao He', 'Bin Feng', 'Wenyu Liu']"
Using Reed-Muller Codes for Classification with Rejection and Recovery,Machine Learning,"When deploying classifiers in the real world, users expect them to respond to
inputs appropriately. However, traditional classifiers are not equipped to
handle inputs which lie far from the distribution they were trained on.
Malicious actors can exploit this defect by making adversarial perturbations
designed to cause the classifier to give an incorrect output.
Classification-with-rejection methods attempt to solve this problem by allowing
networks to refuse to classify an input in which they have low confidence. This
works well for strongly adversarial examples, but also leads to the rejection
of weakly perturbed images, which intuitively could be correctly classified. To
address these issues, we propose Reed-Muller Aggregation Networks (RMAggNet), a
classifier inspired by Reed-Muller error-correction codes which can correct and
reject inputs. This paper shows that RMAggNet can minimise incorrectness while
maintaining good correctness over multiple adversarial attacks at different
perturbation budgets by leveraging the ability to correct errors in the
classification process. This provides an alternative
classification-with-rejection method which can reduce the amount of additional
processing in situations where a small number of incorrect classifications are
permissible.","['Daniel Fentham', 'David Parker', 'Mark Ryan']"
"Can AI Relate: Testing Large Language Model Response for Mental Health
  Support",Computation and Language (Natural Language Processing),"Large language models (LLMs) are already being piloted for clinical use in
hospital systems like NYU Langone, Dana-Farber and the NHS. A proposed
deployment use case is psychotherapy, where a LLM-powered chatbot can treat a
patient undergoing a mental health crisis. Deployment of LLMs for mental health
response could hypothetically broaden access to psychotherapy and provide new
possibilities for personalizing care. However, recent high-profile failures,
like damaging dieting advice offered by the Tessa chatbot to patients with
eating disorders, have led to doubt about their reliability in high-stakes and
safety-critical settings.
  In this work, we develop an evaluation framework for determining whether LLM
response is a viable and ethical path forward for the automation of mental
health treatment. Our framework measures equity in empathy and adherence of LLM
responses to motivational interviewing theory. Using human evaluation with
trained clinicians and automatic quality-of-care metrics grounded in psychology
research, we compare the responses provided by peer-to-peer responders to those
provided by a state-of-the-art LLM.
  We show that LLMs like GPT-4 use implicit and explicit cues to infer patient
demographics like race. We then show that there are statistically significant
discrepancies between patient subgroups: Responses to Black posters
consistently have lower empathy than for any other demographic group (2%-13%
lower than the control group). Promisingly, we do find that the manner in which
responses are generated significantly impacts the quality of the response. We
conclude by proposing safety guidelines for the potential deployment of LLMs
for mental health response.","['Saadia Gabriel', 'Isha Puri', 'Xuhai Xu', 'Matteo Malgaroli', 'Marzyeh Ghassemi']"
Benchmarks for Physical Reasoning AI,Artificial Intelligence,"Physical reasoning is a crucial aspect in the development of general AI
systems, given that human learning starts with interacting with the physical
world before progressing to more complex concepts. Although researchers have
studied and assessed the physical reasoning of AI approaches through various
specific benchmarks, there is no comprehensive approach to evaluating and
measuring progress. Therefore, we aim to offer an overview of existing
benchmarks and their solution approaches and propose a unified perspective for
measuring the physical reasoning capacity of AI systems. We select benchmarks
that are designed to test algorithmic performance in physical reasoning tasks.
While each of the selected benchmarks poses a unique challenge, their ensemble
provides a comprehensive proving ground for an AI generalist agent with a
measurable skill level for various physical reasoning concepts. This gives an
advantage to such an ensemble of benchmarks over other holistic benchmarks that
aim to simulate the real world by intertwining its complexity and many
concepts. We group the presented set of physical reasoning benchmarks into
subcategories so that more narrow generalist AI agents can be tested first on
these groups.","['Andrew Melnik', 'Robin Schiewer', 'Moritz Lange', 'Andrei Muresanu', 'Mozhgan Saeidi', 'Animesh Garg', 'Helge Ritter']"
"Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding
  Model Mechanisms",Machine Learning,"Many recent language model (LM) interpretability studies have adopted the
circuits framework, which aims to find the minimal computational subgraph, or
circuit, that explains LM behavior on a given task. Most studies determine
which edges belong in a LM's circuit by performing causal interventions on each
edge independently, but this scales poorly with model size. Edge attribution
patching (EAP), gradient-based approximation to interventions, has emerged as a
scalable but imperfect solution to this problem. In this paper, we introduce a
new method - EAP with integrated gradients (EAP-IG) - that aims to better
maintain a core property of circuits: faithfulness. A circuit is faithful if
all model edges outside the circuit can be ablated without changing the model's
performance on the task; faithfulness is what justifies studying circuits,
rather than the full model. Our experiments demonstrate that circuits found
using EAP are less faithful than those found using EAP-IG, even though both
have high node overlap with circuits found previously using causal
interventions. We conclude more generally that when using circuits to compare
the mechanisms models use to solve tasks, faithfulness, not overlap, is what
should be measured.","['Michael Hanna', 'Sandro Pezzelle', 'Yonatan Belinkov']"
Blocking Bandits,Machine Learning,"We consider a novel stochastic multi-armed bandit setting, where playing an
arm makes it unavailable for a fixed number of time slots thereafter. This
models situations where reusing an arm too often is undesirable (e.g. making
the same product recommendation repeatedly) or infeasible (e.g. compute job
scheduling on machines). We show that with prior knowledge of the rewards and
delays of all the arms, the problem of optimizing cumulative reward does not
admit any pseudo-polynomial time algorithm (in the number of arms) unless
randomized exponential time hypothesis is false, by mapping to the PINWHEEL
scheduling problem. Subsequently, we show that a simple greedy algorithm that
plays the available arm with the highest reward is asymptotically $(1-1/e)$
optimal. When the rewards are unknown, we design a UCB based algorithm which is
shown to have $c \log T + o(\log T)$ cumulative regret against the greedy
algorithm, leveraging the free exploration of arms due to the unavailability.
Finally, when all the delays are equal the problem reduces to Combinatorial
Semi-bandits providing us with a lower bound of $c' \log T+ \omega(\log T)$.","['Soumya Basu', 'Rajat Sen', 'Sujay Sanghavi', 'Sanjay Shakkottai']"
Self-Supervised and Few-Shot Learning for Robust Bioaerosol Monitoring,Machine Learning,"Real-time bioaerosol monitoring is improving the quality of life for people
affected by allergies, but it often relies on deep-learning models which pose
challenges for widespread adoption. These models are typically trained in a
supervised fashion and require considerable effort to produce large amounts of
annotated data, an effort that must be repeated for new particles, geographical
regions, or measurement systems. In this work, we show that self-supervised
learning and few-shot learning can be combined to classify holographic images
of bioaerosol particles using a large collection of unlabelled data and only a
few examples for each particle type. We first demonstrate that self-supervision
on pictures of unidentified particles from ambient air measurements enhances
identification even when labelled data is abundant. Most importantly, it
greatly improves few-shot classification when only a handful of labelled images
are available. Our findings suggest that real-time bioaerosol monitoring
workflows can be substantially optimized, and the effort required to adapt
models for different situations considerably reduced.","['Adrian Willi', 'Pascal Baumann', 'Sophie Erb', 'Fabian Gröger', 'Yanick Zeder', 'Simone Lionetti']"
Distributional Robustness and Regularization in Reinforcement Learning,Optimization and Control,"Distributionally Robust Optimization (DRO) has enabled to prove the
equivalence between robustness and regularization in classification and
regression, thus providing an analytical reason why regularization generalizes
well in statistical learning. Although DRO's extension to sequential
decision-making overcomes $\textit{external uncertainty}$ through the robust
Markov Decision Process (MDP) setting, the resulting formulation is hard to
solve, especially on large domains. On the other hand, existing regularization
methods in reinforcement learning only address $\textit{internal uncertainty}$
due to stochasticity. Our study aims to facilitate robust reinforcement
learning by establishing a dual relation between robust MDPs and
regularization. We introduce Wasserstein distributionally robust MDPs and prove
that they hold out-of-sample performance guarantees. Then, we introduce a new
regularizer for empirical value functions and show that it lower bounds the
Wasserstein distributionally robust value function. We extend the result to
linear value function approximation for large state spaces. Our approach
provides an alternative formulation of robustness with guaranteed finite-sample
performance. Moreover, it suggests using regularization as a practical tool for
dealing with $\textit{external uncertainty}$ in reinforcement learning methods.","['Esther Derman', 'Shie Mannor']"
"Enhancing ICA Performance by Exploiting Sparsity: Application to FMRI
  Analysis",Machine Learning (Statistics),"Independent component analysis (ICA) is a powerful method for blind source
separation based on the assumption that sources are statistically independent.
Though ICA has proven useful and has been employed in many applications,
complete statistical independence can be too restrictive an assumption in
practice. Additionally, important prior information about the data, such as
sparsity, is usually available. Sparsity is a natural property of the data, a
form of diversity, which, if incorporated into the ICA model, can relax the
independence assumption, resulting in an improvement in the overall separation
performance. In this work, we propose a new variant of ICA by entropy bound
minimization (ICA-EBM)-a flexible, yet parameter-free algorithm-through the
direct exploitation of sparsity. Using this new SparseICA-EBM algorithm, we
study the synergy of independence and sparsity through simulations on synthetic
as well as functional magnetic resonance imaging (fMRI)-like data.","['Zois Boukouvalas', 'Yuri Levin-Schwartz', 'Tulay Adali']"
"Do All Languages Cost the Same? Tokenization in the Era of Commercial
  Language Models",Computation and Language (Natural Language Processing),"Language models have graduated from being research prototypes to
commercialized products offered as web APIs, and recent works have highlighted
the multilingual capabilities of these products. The API vendors charge their
users based on usage, more specifically on the number of ``tokens'' processed
or generated by the underlying language models. What constitutes a token,
however, is training data and model dependent with a large variance in the
number of tokens required to convey the same information in different
languages. In this work, we analyze the effect of this non-uniformity on the
fairness of an API's pricing policy across languages. We conduct a systematic
analysis of the cost and utility of OpenAI's language model API on multilingual
benchmarks in 22 typologically diverse languages. We show evidence that
speakers of a large number of the supported languages are overcharged while
obtaining poorer results. These speakers tend to also come from regions where
the APIs are less affordable to begin with. Through these analyses, we aim to
increase transparency around language model APIs' pricing policies and
encourage the vendors to make them more equitable.","['Orevaoghene Ahia', 'Sachin Kumar', 'Hila Gonen', 'Jungo Kasai', 'David R. Mortensen', 'Noah A. Smith', 'Yulia Tsvetkov']"
"Efficient Multidimensional Functional Data Analysis Using Marginal
  Product Basis Systems",Methodology (Statistics),"Many modern datasets, from areas such as neuroimaging and geostatistics, come
in the form of a random sample of tensor-valued data which can be understood as
noisy observations of a smooth multidimensional random function. Most of the
traditional techniques from functional data analysis are plagued by the curse
of dimensionality and quickly become intractable as the dimension of the domain
increases. In this paper, we propose a framework for learning continuous
representations from a sample of multidimensional functional data that is
immune to several manifestations of the curse. These representations are
constructed using a set of separable basis functions that are defined to be
optimally adapted to the data. We show that the resulting estimation problem
can be solved efficiently by the tensor decomposition of a carefully defined
reduction transformation of the observed data. Roughness-based regularization
is incorporated using a class of differential operator-based penalties.
Relevant theoretical properties are also established. The advantages of our
method over competing methods are demonstrated in a simulation study. We
conclude with a real data application in neuroimaging.","['William Consagra', 'Arun Venkataraman', 'Xing Qiu']"
DeepSphere: towards an equivariant graph-based spherical CNN,Machine Learning,"Spherical data is found in many applications. By modeling the discretized
sphere as a graph, we can accommodate non-uniformly distributed, partial, and
changing samplings. Moreover, graph convolutions are computationally more
efficient than spherical convolutions. As equivariance is desired to exploit
rotational symmetries, we discuss how to approach rotation equivariance using
the graph neural network introduced in Defferrard et al. (2016). Experiments
show good performance on rotation-invariant learning problems. Code and
examples are available at https://github.com/SwissDataScienceCenter/DeepSphere","['Michaël Defferrard', 'Nathanaël Perraudin', 'Tomasz Kacprzak', 'Raphael Sgier']"
A Tree-based Dictionary Learning Framework,Machine Learning,"We propose a new outline for adaptive dictionary learning methods for sparse
encoding based on a hierarchical clustering of the training data. Through
recursive application of a clustering method, the data is organized into a
binary partition tree representing a multiscale structure. The dictionary atoms
are defined adaptively based on the data clusters in the partition tree. This
approach can be interpreted as a generalization of a discrete Haar wavelet
transform. Furthermore, any prior knowledge on the wanted structure of the
dictionary elements can be simply incorporated. The computational complexity of
our proposed algorithm depends on the employed clustering method and on the
chosen similarity measure between data points. Thanks to the multiscale
properties of the partition tree, our dictionary is structured: when using
Orthogonal Matching Pursuit to reconstruct patches from a natural image,
dictionary atoms corresponding to nodes being closer to the root node in the
tree have a tendency to be used with greater coefficients.","['Renato Budinich', 'Gerlind Plonka']"
"One-Class Graph Neural Networks for Anomaly Detection in Attributed
  Networks",Machine Learning,"Nowadays, graph-structured data are increasingly used to model complex
systems. Meanwhile, detecting anomalies from graph has become a vital research
problem of pressing societal concerns. Anomaly detection is an unsupervised
learning task of identifying rare data that differ from the majority. As one of
the dominant anomaly detection algorithms, One Class Support Vector Machine has
been widely used to detect outliers. However, those traditional anomaly
detection methods lost their effectiveness in graph data. Since traditional
anomaly detection methods are stable, robust and easy to use, it is vitally
important to generalize them to graph data. In this work, we propose One Class
Graph Neural Network (OCGNN), a one-class classification framework for graph
anomaly detection. OCGNN is designed to combine the powerful representation
ability of Graph Neural Networks along with the classical one-class objective.
Compared with other baselines, OCGNN achieves significant improvements in
extensive experiments.","['Xuhong Wang', 'Baihong Jin', 'Ying Du', 'Ping Cui', 'Yupu Yang']"
Crowdsourcing Argumentation Structures in Chinese Hotel Reviews,Computation and Language (Natural Language Processing),"Argumentation mining aims at automatically extracting the premises-claim
discourse structures in natural language texts. There is a great demand for
argumentation corpora for customer reviews. However, due to the controversial
nature of the argumentation annotation task, there exist very few large-scale
argumentation corpora for customer reviews. In this work, we novelly use the
crowdsourcing technique to collect argumentation annotations in Chinese hotel
reviews. As the first Chinese argumentation dataset, our corpus includes 4814
argument component annotations and 411 argument relation annotations, and its
annotations qualities are comparable to some widely used argumentation corpora
in other languages.","['Mengxue Li', 'Shiqiang Geng', 'Yang Gao', 'Haijing Liu', 'Hao Wang']"
"Extended Gauss-Newton and ADMM-Gauss-Newton Algorithms for Low-Rank
  Matrix Optimization",Optimization and Control,"In this paper, we develop a variant of the well-known Gauss-Newton (GN)
method to solve a class of nonconvex optimization problems involving low-rank
matrix variables. As opposed to the standard GN method, our algorithm allows
one to handle general smooth convex objective function. We show, under mild
conditions, that the proposed algorithm globally and locally converges to a
stationary point of the original problem. We also show empirically that the GN
algorithm achieves higher accurate solutions than the alternating minimization
algorithm (AMA). Then, we specify our GN scheme to handle the symmetric case
and prove its convergence, where AMA is not applicable. Next, we incorporate
our GN scheme into the alternating direction method of multipliers (ADMM) to
develop an ADMM-GN algorithm. We prove that, under mild conditions and a proper
choice of the penalty parameter, our ADMM-GN globally converges to a stationary
point of the original problem. Finally, we provide several numerical
experiments to illustrate the proposed algorithms. Our results show that the
new algorithms have encouraging performance compared to existing methods.",['Quoc Tran-Dinh']
"CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using
  Transformer-based Neural Representations",Computer Vision and Pattern Recognition,"Cryo-electron microscopy (cryo-EM) allows for the high-resolution
reconstruction of 3D structures of proteins and other biomolecules. Successful
reconstruction of both shape and movement greatly helps understand the
fundamental processes of life. However, it is still challenging to reconstruct
the continuous motions of 3D structures from hundreds of thousands of noisy and
randomly oriented 2D cryo-EM images. Recent advancements use Fourier domain
coordinate-based neural networks to continuously model 3D conformations, yet
they often struggle to capture local flexible regions accurately. We propose
CryoFormer, a new approach for continuous heterogeneous cryo-EM reconstruction.
Our approach leverages an implicit feature volume directly in the real domain
as the 3D representation. We further introduce a novel query-based deformation
transformer decoder to improve the reconstruction quality. Our approach is
capable of refining pre-computed pose estimations and locating flexible
regions. In experiments, our method outperforms current approaches on three
public datasets (1 synthetic and 2 experimental) and a new synthetic dataset of
PEDV spike protein. The code and new synthetic dataset will be released for
better reproducibility of our results. Project page:
https://cryoformer.github.io.","['Xinhang Liu', 'Yan Zeng', 'Yifan Qin', 'Hao Li', 'Jiakai Zhang', 'Lan Xu', 'Jingyi Yu']"
"Bootstrapping NLP tools across low-resourced African languages: an
  overview and prospects",Computation and Language (Natural Language Processing),"Computing and Internet access are substantially growing markets in Southern
Africa, which brings with it increasing demands for local content and tools in
indigenous African languages. Since most of those languages are low-resourced,
efforts have gone into the notion of bootstrapping tools for one African
language from another. This paper provides an overview of these efforts for
Niger-Congo B (`Bantu') languages. Bootstrapping grammars for geographically
distant languages has been shown to still have positive outcomes for morphology
and rules or grammar-based natural language generation. Bootstrapping with
data-driven approaches to NLP tasks is difficult to use meaningfully regardless
geographic proximity, which is largely due to lexical diversity due to both
orthography and vocabulary. Cladistic approaches in comparative linguistics may
inform bootstrapping strategies and similarity measures might serve as proxy
for bootstrapping potential as well, with both fertile ground for further
research.",['C. Maria Keet']
"SGQuant: Squeezing the Last Bit on Graph Neural Networks with
  Specialized Quantization",Machine Learning,"With the increasing popularity of graph-based learning, Graph Neural Networks
(GNNs) win lots of attention from the research and industry field because of
their high accuracy. However, existing GNNs suffer from high memory footprints
(e.g., node embedding features). This high memory footprint hurdles the
potential applications towards memory-constrained devices, such as the
widely-deployed IoT devices. To this end, we propose a specialized GNN
quantization scheme, SGQuant, to systematically reduce the GNN memory
consumption. Specifically, we first propose a GNN-tailored quantization
algorithm design and a GNN quantization fine-tuning scheme to reduce memory
consumption while maintaining accuracy. Then, we investigate the
multi-granularity quantization strategy that operates at different levels
(components, graph topology, and layers) of GNN computation. Moreover, we offer
an automatic bit-selecting (ABS) to pinpoint the most appropriate quantization
bits for the above multi-granularity quantizations. Intensive experiments show
that SGQuant can effectively reduce the memory footprint from 4.25x to 31.9x
compared with the original full-precision GNNs while limiting the accuracy drop
to 0.4% on average.","['Boyuan Feng', 'Yuke Wang', 'Xu Li', 'Shu Yang', 'Xueqiao Peng', 'Yufei Ding']"
A Recurrent Graph Neural Network for Multi-Relational Data,Machine Learning,"The era of data deluge has sparked the interest in graph-based learning
methods in a number of disciplines such as sociology, biology, neuroscience, or
engineering. In this paper, we introduce a graph recurrent neural network
(GRNN) for scalable semi-supervised learning from multi-relational data. Key
aspects of the novel GRNN architecture are the use of multi-relational graphs,
the dynamic adaptation to the different relations via learnable weights, and
the consideration of graph-based regularizers to promote smoothness and
alleviate over-parametrization. Our ultimate goal is to design a powerful
learning architecture able to: discover complex and highly non-linear data
associations, combine (and select) multiple types of relations, and scale
gracefully with respect to the size of the graph. Numerical tests with real
data sets corroborate the design goals and illustrate the performance gains
relative to competing alternatives.","['Vassilis N. Ioannidis', 'Antonio G. Marques', 'Georgios B. Giannakis']"
Invariant Priors for Bayesian Quadrature,Machine Learning (Statistics),"Bayesian quadrature (BQ) is a model-based numerical integration method that
is able to increase sample efficiency by encoding and leveraging known
structure of the integration task at hand. In this paper, we explore priors
that encode invariance of the integrand under a set of bijective
transformations in the input domain, in particular some unitary
transformations, such as rotations, axis-flips, or point symmetries. We show
initial results on superior performance in comparison to standard Bayesian
quadrature on several synthetic and one real world application.","['Masha Naslidnyk', 'Javier Gonzalez', 'Maren Mahsereci']"
Interval-Based Decisions for Reasoning Systems,Artificial Intelligence,"This essay looks at decision-making with interval-valued probability
measures. Existing decision methods have either supplemented expected utility
methods with additional criteria of optimality, or have attempted to supplement
the interval-valued measures. We advocate a new approach, which makes the
following questions moot: 1. which additional criteria to use, and 2. how wide
intervals should be. In order to implement the approach, we need more
epistemological information. Such information can be generated by a rule of
acceptance with a parameter that allows various attitudes toward error, or can
simply be declared. In sketch, the argument is: 1. probability intervals are
useful and natural in All. systems; 2. wide intervals avoid error, but are
useless in some risk sensitive decision-making; 3. one may obtain narrower
intervals if one is less cautious; 4. if bodies of knowledge can be ordered by
their caution, one should perform the decision analysis with the acceptable
body of knowledge that is the most cautious, of those that are useful. The
resulting behavior differs from that of a behavioral probabilist (a Bayesian)
because in the proposal, 5. intervals based on successive bodies of knowledge
are not always nested; 6. if the agent uses a probability for a particular
decision, she need not commit to that probability for credence or future
decision; and 7. there may be no acceptable body of knowledge that is useful;
hence, sometimes no decision is mandated.",['Ronald P. Loui']
"Self-Supervised Difference Detection for Weakly-Supervised Semantic
  Segmentation",Computer Vision and Pattern Recognition,"To minimize the annotation costs associated with the training of semantic
segmentation models, researchers have extensively investigated
weakly-supervised segmentation approaches. In the current weakly-supervised
segmentation methods, the most widely adopted approach is based on
visualization. However, the visualization results are not generally equal to
semantic segmentation. Therefore, to perform accurate semantic segmentation
under the weakly supervised condition, it is necessary to consider the mapping
functions that convert the visualization results into semantic segmentation.
For such mapping functions, the conditional random field and iterative
re-training using the outputs of a segmentation model are usually used.
However, these methods do not always guarantee improvements in accuracy;
therefore, if we apply these mapping functions iteratively multiple times,
eventually the accuracy will not improve or will decrease.
  In this paper, to make the most of such mapping functions, we assume that the
results of the mapping function include noise, and we improve the accuracy by
removing noise. To achieve our aim, we propose the self-supervised difference
detection module, which estimates noise from the results of the mapping
functions by predicting the difference between the segmentation masks before
and after the mapping. We verified the effectiveness of the proposed method by
performing experiments on the PASCAL Visual Object Classes 2012 dataset, and we
achieved 64.9\% in the val set and 65.5\% in the test set. Both of the results
become new state-of-the-art under the same setting of weakly supervised
semantic segmentation.","['Wataru Shimoda', 'Keiji Yanai']"
Optimizing Rank-based Metrics with Blackbox Differentiation,Machine Learning,"Rank-based metrics are some of the most widely used criteria for performance
evaluation of computer vision models. Despite years of effort, direct
optimization for these metrics remains a challenge due to their
non-differentiable and non-decomposable nature. We present an efficient,
theoretically sound, and general method for differentiating rank-based metrics
with mini-batch gradient descent. In addition, we address optimization
instability and sparsity of the supervision signal that both arise from using
rank-based metrics as optimization targets. Resulting losses based on recall
and Average Precision are applied to image retrieval and object detection
tasks. We obtain performance that is competitive with state-of-the-art on
standard image retrieval datasets and consistently improve performance of near
state-of-the-art object detectors. The code is available at
https://github.com/martius-lab/blackbox-backprop","['Michal Rolínek', 'Vít Musil', 'Anselm Paulus', 'Marin Vlastelica', 'Claudio Michaelis', 'Georg Martius']"
"STSC-SNN: Spatio-Temporal Synaptic Connection with Temporal Convolution
  and Attention for Spiking Neural Networks",Neural and Evolutionary Computing,"Spiking Neural Networks (SNNs), as one of the algorithmic models in
neuromorphic computing, have gained a great deal of research attention owing to
temporal information processing capability, low power consumption, and high
biological plausibility. The potential to efficiently extract spatio-temporal
features makes it suitable for processing the event streams. However, existing
synaptic structures in SNNs are almost full-connections or spatial 2D
convolution, neither of which can extract temporal dependencies adequately. In
this work, we take inspiration from biological synapses and propose a
spatio-temporal synaptic connection SNN (STSC-SNN) model, to enhance the
spatio-temporal receptive fields of synaptic connections, thereby establishing
temporal dependencies across layers. Concretely, we incorporate temporal
convolution and attention mechanisms to implement synaptic filtering and gating
functions. We show that endowing synaptic models with temporal dependencies can
improve the performance of SNNs on classification tasks. In addition, we
investigate the impact of performance vias varied spatial-temporal receptive
fields and reevaluate the temporal modules in SNNs. Our approach is tested on
neuromorphic datasets, including DVS128 Gesture (gesture recognition), N-MNIST,
CIFAR10-DVS (image classification), and SHD (speech digit recognition). The
results show that the proposed model outperforms the state-of-the-art accuracy
on nearly all datasets.","['Chengting Yu', 'Zheming Gu', 'Da Li', 'Gaoang Wang', 'Aili Wang', 'Erping Li']"
Data-Free Backbone Fine-Tuning for Pruned Neural Networks,Computer Vision and Pattern Recognition,"Model compression techniques reduce the computational load and memory
consumption of deep neural networks. After the compression operation, e.g.
parameter pruning, the model is normally fine-tuned on the original training
dataset to recover from the performance drop caused by compression. However,
the training data is not always available due to privacy issues or other
factors. In this work, we present a data-free fine-tuning approach for pruning
the backbone of deep neural networks. In particular, the pruned network
backbone is trained with synthetically generated images, and our proposed
intermediate supervision to mimic the unpruned backbone's output feature map.
Afterwards, the pruned backbone can be combined with the original network head
to make predictions. We generate synthetic images by back-propagating gradients
to noise images while relying on L1-pruning for the backbone pruning. In our
experiments, we show that our approach is task-independent due to pruning only
the backbone. By evaluating our approach on 2D human pose estimation, object
detection, and image classification, we demonstrate promising performance
compared to the unpruned model. Our code is available at
https://github.com/holzbock/dfbf.","['Adrian Holzbock', 'Achyut Hegde', 'Klaus Dietmayer', 'Vasileios Belagiannis']"
Bounded Situation Calculus Action Theories,Artificial Intelligence,"In this paper, we investigate bounded action theories in the situation
calculus. A bounded action theory is one which entails that, in every
situation, the number of object tuples in the extension of fluents is bounded
by a given constant, although such extensions are in general different across
the infinitely many situations. We argue that such theories are common in
applications, either because facts do not persist indefinitely or because the
agent eventually forgets some facts, as new ones are learnt. We discuss various
classes of bounded action theories. Then we show that verification of a
powerful first-order variant of the mu-calculus is decidable for such theories.
Notably, this variant supports a controlled form of quantification across
situations. We also show that through verification, we can actually check
whether an arbitrary action theory maintains boundedness.","['Giuseppe De Giacomo', 'Yves Lespérance', 'Fabio Patrizi']"
"Time Complexity Analysis of Evolutionary Algorithms for 2-Hop
  (1,2)-Minimum Spanning Tree Problem",Neural and Evolutionary Computing,"The Minimum Spanning Tree problem (abbr. MSTP) is a well-known combinatorial
optimization problem that has been extensively studied by the researchers in
the field of evolutionary computing to theoretically analyze the optimization
performance of evolutionary algorithms. Within the paper, we consider a
constrained version of the problem named 2-Hop (1,2)-Minimum Spanning Tree
problem (abbr. 2H-(1,2)-MSTP) in the context of evolutionary algorithms, which
has been shown to be NP-hard. Following how evolutionary algorithms are applied
to solve the MSTP, we first consider the evolutionary algorithms with search
points in edge-based representation adapted to the 2H-(1,2)-MSTP (including the
(1+1) EA, Global Simple Evolutionary Multi-Objective Optimizer and its two
variants). More specifically, we separately investigate the upper bounds on
their expected time (i.e., the expected number of fitness evaluations) to
obtain a $\frac{3}{2}$-approximate solution with respect to different fitness
functions. Inspired by the special structure of 2-hop spanning trees, we also
consider the (1+1) EA with search points in vertex-based representation that
seems not so natural for the problem and give an upper bound on its expected
time to obtain a $\frac{3}{2}$-approximate solution, which is better than the
above mentioned ones.","['Feng Shi', 'Frank Neumann', 'Jianxin Wang']"
CrowdPose: Efficient Crowded Scenes Pose Estimation and A New Benchmark,Computer Vision and Pattern Recognition,"Multi-person pose estimation is fundamental to many computer vision tasks and
has made significant progress in recent years. However, few previous methods
explored the problem of pose estimation in crowded scenes while it remains
challenging and inevitable in many scenarios. Moreover, current benchmarks
cannot provide an appropriate evaluation for such cases. In this paper, we
propose a novel and efficient method to tackle the problem of pose estimation
in the crowd and a new dataset to better evaluate algorithms. Our model
consists of two key components: joint-candidate single person pose estimation
(SPPE) and global maximum joints association. With multi-peak prediction for
each joint and global association using graph model, our method is robust to
inevitable interference in crowded scenes and very efficient in inference. The
proposed method surpasses the state-of-the-art methods on CrowdPose dataset by
5.2 mAP and results on MSCOCO dataset demonstrate the generalization ability of
our method. Source code and dataset will be made publicly available.","['Jiefeng Li', 'Can Wang', 'Hao Zhu', 'Yihuan Mao', 'Hao-Shu Fang', 'Cewu Lu']"
"NeuralMagicEye: Learning to See and Understand the Scene Behind an
  Autostereogram",Computer Vision and Pattern Recognition,"An autostereogram, a.k.a. magic eye image, is a single-image stereogram that
can create visual illusions of 3D scenes from 2D textures. This paper studies
an interesting question that whether a deep CNN can be trained to recover the
depth behind an autostereogram and understand its content. The key to the
autostereogram magic lies in the stereopsis - to solve such a problem, a model
has to learn to discover and estimate disparity from the quasi-periodic
textures. We show that deep CNNs embedded with disparity convolution, a novel
convolutional layer proposed in this paper that simulates stereopsis and
encodes disparity, can nicely solve such a problem after being sufficiently
trained on a large 3D object dataset in a self-supervised fashion. We refer to
our method as ``NeuralMagicEye''. Experiments show that our method can
accurately recover the depth behind autostereograms with rich details and
gradient smoothness. Experiments also show the completely different working
mechanisms for autostereogram perception between neural networks and human
eyes. We hope this research can help people with visual impairments and those
who have trouble viewing autostereograms. Our code is available at
\url{https://jiupinjia.github.io/neuralmagiceye/}.","['Zhengxia Zou', 'Tianyang Shi', 'Yi Yuan', 'Zhenwei Shi']"
"Amodal Segmentation through Out-of-Task and Out-of-Distribution
  Generalization with a Bayesian Model",Computer Vision and Pattern Recognition,"Amodal completion is a visual task that humans perform easily but which is
difficult for computer vision algorithms. The aim is to segment those object
boundaries which are occluded and hence invisible. This task is particularly
challenging for deep neural networks because data is difficult to obtain and
annotate. Therefore, we formulate amodal segmentation as an out-of-task and
out-of-distribution generalization problem. Specifically, we replace the fully
connected classifier in neural networks with a Bayesian generative model of the
neural network features. The model is trained from non-occluded images using
bounding box annotations and class labels only, but is applied to generalize
out-of-task to object segmentation and to generalize out-of-distribution to
segment occluded objects. We demonstrate how such Bayesian models can naturally
generalize beyond the training task labels when they learn a prior that models
the object's background context and shape. Moreover, by leveraging an outlier
process, Bayesian models can further generalize out-of-distribution to segment
partially occluded objects and to predict their amodal object boundaries. Our
algorithm outperforms alternative methods that use the same supervision by a
large margin, and even outperforms methods where annotated amodal segmentations
are used during training, when the amount of occlusion is large. Code is
publicly available at https://github.com/YihongSun/Bayesian-Amodal.","['Yihong Sun', 'Adam Kortylewski', 'Alan Yuille']"
Federated Learning under Importance Sampling,Machine Learning,"Federated learning encapsulates distributed learning strategies that are
managed by a central unit. Since it relies on using a selected number of agents
at each iteration, and since each agent, in turn, taps into its local data, it
is only natural to study optimal sampling policies for selecting agents and
their data in federated learning implementations. Usually, only uniform
sampling schemes are used. However, in this work, we examine the effect of
importance sampling and devise schemes for sampling agents and data
non-uniformly guided by a performance measure. We find that in schemes
involving sampling without replacement, the performance of the resulting
architecture is controlled by two factors related to data variability at each
agent, and model variability across agents. We illustrate the theoretical
findings with experiments on simulated and real data and show the improvement
in performance that results from the proposed strategies.","['Elsa Rizk', 'Stefan Vlaski', 'Ali H. Sayed']"
"Explainable Sparse Knowledge Graph Completion via High-order Graph
  Reasoning Network",Machine Learning,"Knowledge Graphs (KGs) are becoming increasingly essential infrastructures in
many applications while suffering from incompleteness issues. The KG completion
task (KGC) automatically predicts missing facts based on an incomplete KG.
However, existing methods perform unsatisfactorily in real-world scenarios. On
the one hand, their performance will dramatically degrade along with the
increasing sparsity of KGs. On the other hand, the inference procedure for
prediction is an untrustworthy black box.
  This paper proposes a novel explainable model for sparse KGC, compositing
high-order reasoning into a graph convolutional network, namely HoGRN. It can
not only improve the generalization ability to mitigate the information
insufficiency issue but also provide interpretability while maintaining the
model's effectiveness and efficiency. There are two main components that are
seamlessly integrated for joint optimization. First, the high-order reasoning
component learns high-quality relation representations by capturing endogenous
correlation among relations. This can reflect logical rules to justify a
broader of missing facts. Second, the entity updating component leverages a
weight-free Graph Convolutional Network (GCN) to efficiently model KG
structures with interpretability. Unlike conventional methods, we conduct
entity aggregation and design composition-based attention in the relational
space without additional parameters. The lightweight design makes HoGRN better
suitable for sparse settings. For evaluation, we have conducted extensive
experiments-the results of HoGRN on several sparse KGs present impressive
improvements (9% MRR gain on average). Further ablation and case studies
demonstrate the effectiveness of the main components. Our codes will be
released upon acceptance.","['Weijian Chen', 'Yixin Cao', 'Fuli Feng', 'Xiangnan He', 'Yongdong Zhang']"
Dynamic Poisson Factorization,Machine Learning,"Models for recommender systems use latent factors to explain the preferences
and behaviors of users with respect to a set of items (e.g., movies, books,
academic papers). Typically, the latent factors are assumed to be static and,
given these factors, the observed preferences and behaviors of users are
assumed to be generated without order. These assumptions limit the explorative
and predictive capabilities of such models, since users' interests and item
popularity may evolve over time. To address this, we propose dPF, a dynamic
matrix factorization model based on the recent Poisson factorization model for
recommendations. dPF models the time evolving latent factors with a Kalman
filter and the actions with Poisson distributions. We derive a scalable
variational inference algorithm to infer the latent factors. Finally, we
demonstrate dPF on 10 years of user click data from arXiv.org, one of the
largest repository of scientific papers and a formidable source of information
about the behavior of scientists. Empirically we show performance improvement
over both static and, more recently proposed, dynamic recommendation models. We
also provide a thorough exploration of the inferred posteriors over the latent
variables.","['Laurent Charlin', 'Rajesh Ranganath', 'James McInerney', 'David M. Blei']"
"The Stochastic Gradient Descent for the Primal L1-SVM Optimization
  Revisited",Machine Learning,"We reconsider the stochastic (sub)gradient approach to the unconstrained
primal L1-SVM optimization. We observe that if the learning rate is inversely
proportional to the number of steps, i.e., the number of times any training
pattern is presented to the algorithm, the update rule may be transformed into
the one of the classical perceptron with margin in which the margin threshold
increases linearly with the number of steps. Moreover, if we cycle repeatedly
through the possibly randomly permuted training set the dual variables defined
naturally via the expansion of the weight vector as a linear combination of the
patterns on which margin errors were made are shown to obey at the end of each
complete cycle automatically the box constraints arising in dual optimization.
This renders the dual Lagrangian a running lower bound on the primal objective
tending to it at the optimum and makes available an upper bound on the relative
accuracy achieved which provides a meaningful stopping criterion. In addition,
we propose a mechanism of presenting the same pattern repeatedly to the
algorithm which maintains the above properties. Finally, we give experimental
evidence that algorithms constructed along these lines exhibit a considerably
improved performance.","['Constantinos Panagiotakopoulos', 'Petroula Tsampouka']"
Contextualizing Generated Citation Texts,Computation and Language (Natural Language Processing),"Abstractive citation text generation is usually framed as an infilling task,
where a sequence-to-sequence model is trained to generate a citation given a
reference paper and the context window around the target; the generated
citation should be a brief discussion of the reference paper as it relates to
the citing context. However, examining a recent LED-based citation generation
system, we find that many of the generated citations are generic summaries of
the reference papers main contribution, ignoring the citation contexts focus on
a different topic. To address this problem, we propose a simple modification to
the citation text generation task: the generation target is not only the
citation itself, but the entire context window, including the target citation.
This approach can be easily applied to any abstractive citation generation
system, and our experimental results show that training in this way is
preferred by human readers and allows the generation model to make use of
contextual clues about what topic to discuss and what stance to take.","['Biswadip Mandal', 'Xiangci Li', 'Jessica Ouyang']"
Deontological Ethics By Monotonicity Shape Constraints,Machine Learning,"We demonstrate how easy it is for modern machine-learned systems to violate
common deontological ethical principles and social norms such as ""favor the
less fortunate,"" and ""do not penalize good attributes."" We propose that in some
cases such ethical principles can be incorporated into a machine-learned model
by adding shape constraints that constrain the model to respond only positively
to relevant inputs. We analyze the relationship between these deontological
constraints that act on individuals and the consequentialist group-based
fairness goals of one-sided statistical parity and equal opportunity. This
strategy works with sensitive attributes that are Boolean or real-valued such
as income and age, and can help produce more responsible and trustworthy AI.","['Serena Wang', 'Maya Gupta']"
"A New Approach to Automated Epileptic Diagnosis Using EEG and
  Probabilistic Neural Network",Artificial Intelligence,"Epilepsy is one of the most common neurological disorders that greatly impair
patient' daily lives. Traditional epileptic diagnosis relies on tedious visual
screening by neurologists from lengthy EEG recording that requires the presence
of seizure (ictal) activities. Nowadays, there are many systems helping the
neurologists to quickly find interesting segments of the lengthy signal by
automatic seizure detection. However, we notice that it is very difficult, if
not impossible, to obtain long-term EEG data with seizure activities for
epilepsy patients in areas lack of medical resources and trained neurologists.
Therefore, we propose to study automated epileptic diagnosis using interictal
EEG data that is much easier to collect than ictal data. The authors are not
aware of any report on automated EEG diagnostic system that can accurately
distinguish patients' interictal EEG from the EEG of normal people. The
research presented in this paper, therefore, aims to develop an automated
diagnostic system that can use interictal EEG data to diagnose whether the
person is epileptic. Such a system should also detect seizure activities for
further investigation by doctors and potential patient monitoring. To develop
such a system, we extract four classes of features from the EEG data and build
a Probabilistic Neural Network (PNN) fed with these features. Leave-one-out
cross-validation (LOO-CV) on a widely used epileptic-normal data set reflects
an impressive 99.5% accuracy of our system on distinguishing normal people's
EEG from patient's interictal EEG. We also find our system can be used in
patient monitoring (seizure detection) and seizure focus localization, with
96.7% and 77.5% accuracy respectively on the data set.","['Forrest Sheng Bao', 'Donald Yu-Chun Lie', 'Yuanlin Zhang']"
"PAC-Bayes Generalization Certificates for Learned Inductive Conformal
  Prediction",Machine Learning,"Inductive Conformal Prediction (ICP) provides a practical and effective
approach for equipping deep learning models with uncertainty estimates in the
form of set-valued predictions which are guaranteed to contain the ground truth
with high probability. Despite the appeal of this coverage guarantee, these
sets may not be efficient: the size and contents of the prediction sets are not
directly controlled, and instead depend on the underlying model and choice of
score function. To remedy this, recent work has proposed learning model and
score function parameters using data to directly optimize the efficiency of the
ICP prediction sets. While appealing, the generalization theory for such an
approach is lacking: direct optimization of empirical efficiency may yield
prediction sets that are either no longer efficient on test data, or no longer
obtain the required coverage on test data. In this work, we use PAC-Bayes
theory to obtain generalization bounds on both the coverage and the efficiency
of set-valued predictors which can be directly optimized to maximize efficiency
while satisfying a desired test coverage. In contrast to prior work, our
framework allows us to utilize the entire calibration dataset to learn the
parameters of the model and score function, instead of requiring a separate
hold-out set for obtaining test-time coverage guarantees. We leverage these
theoretical results to provide a practical algorithm for using calibration data
to simultaneously fine-tune the parameters of a model and score function while
guaranteeing test-time coverage and efficiency of the resulting prediction
sets. We evaluate the approach on regression and classification tasks, and
outperform baselines calibrated using a Hoeffding bound-based PAC guarantee on
ICP, especially in the low-data regime.","['Apoorva Sharma', 'Sushant Veer', 'Asher Hancock', 'Heng Yang', 'Marco Pavone', 'Anirudha Majumdar']"
"Interpretable Multimodal Learning for Cardiovascular Hemodynamics
  Assessment",Computer Vision and Pattern Recognition,"Pulmonary Arterial Wedge Pressure (PAWP) is an essential cardiovascular
hemodynamics marker to detect heart failure. In clinical practice, Right Heart
Catheterization is considered a gold standard for assessing cardiac
hemodynamics while non-invasive methods are often needed to screen high-risk
patients from a large population. In this paper, we propose a multimodal
learning pipeline to predict PAWP marker. We utilize complementary information
from Cardiac Magnetic Resonance Imaging (CMR) scans (short-axis and
four-chamber) and Electronic Health Records (EHRs). We extract spatio-temporal
features from CMR scans using tensor-based learning. We propose a graph
attention network to select important EHR features for prediction, where we
model subjects as graph nodes and feature relationships as graph edges using
the attention mechanism. We design four feature fusion strategies: early,
intermediate, late, and hybrid fusion. With a linear classifier and linear
fusion strategies, our pipeline is interpretable. We validate our pipeline on a
large dataset of $2,641$ subjects from our ASPIRE registry. The comparative
study against state-of-the-art methods confirms the superiority of our
pipeline. The decision curve analysis further validates that our pipeline can
be applied to screen a large population. The code is available at
https://github.com/prasunc/hemodynamics.","['Prasun C Tripathi', 'Sina Tabakhi', 'Mohammod N I Suvon', 'Lawrence Schöb', 'Samer Alabed', 'Andrew J Swift', 'Shuo Zhou', 'Haiping Lu']"
"Quasi-potential as an implicit regularizer for the loss function in the
  stochastic gradient descent",Machine Learning,"We interpret the variational inference of the Stochastic Gradient Descent
(SGD) as minimizing a new potential function named the
\textit{quasi-potential}. We analytically construct the quasi-potential
function in the case when the loss function is convex and admits only one
global minimum point. We show in this case that the quasi-potential function is
related to the noise covariance structure of SGD via a partial differential
equation of Hamilton-Jacobi type. This relation helps us to show that
anisotropic noise leads to faster escape than isotropic noise. We then consider
the dynamics of SGD in the case when the loss function is non-convex and admits
several different local minima. In this case, we demonstrate an example that
shows how the noise covariance structure plays a role in ""implicit
regularization"", a phenomenon in which SGD favors some particular local minimum
points. This is done through the relation between the noise covariance
structure and the quasi-potential function. Our analysis is based on Large
Deviations Theory (LDT), and they are validated by numerical experiments.","['Wenqing Hu', 'Zhanxing Zhu', 'Haoyi Xiong', 'Jun Huan']"
Toward domain-invariant speech recognition via large scale training,Computation and Language (Natural Language Processing),"Current state-of-the-art automatic speech recognition systems are trained to
work in specific `domains', defined based on factors like application, sampling
rate and codec. When such recognizers are used in conditions that do not match
the training domain, performance significantly drops. This work explores the
idea of building a single domain-invariant model for varied use-cases by
combining large scale training data from multiple application domains. Our
final system is trained using 162,000 hours of speech. Additionally, each
utterance is artificially distorted during training to simulate effects like
background noise, codec distortion, and sampling rates. Our results show that,
even at such a scale, a model thus trained works almost as well as those
fine-tuned to specific subsets: A single model can be robust to multiple
application domains, and variations like codecs and noise. More importantly,
such models generalize better to unseen conditions and allow for rapid
adaptation -- we show that by using as little as 10 hours of data from a new
domain, an adapted domain-invariant model can match performance of a
domain-specific model trained from scratch using 70 times as much data. We also
highlight some of the limitations of such models and areas that need addressing
in future work.","['Arun Narayanan', 'Ananya Misra', 'Khe Chai Sim', 'Golan Pundak', 'Anshuman Tripathi', 'Mohamed Elfeky', 'Parisa Haghani', 'Trevor Strohman', 'Michiel Bacchiani']"
"Poisson Image Denoising Using Best Linear Prediction: A Post-processing
  Framework",Computer Vision and Pattern Recognition,"In this paper, we address the problem of denoising images degraded by Poisson
noise. We propose a new patch-based approach based on best linear prediction to
estimate the underlying clean image. A simplified prediction formula is derived
for Poisson observations, which requires the covariance matrix of the
underlying clean patch. We use the assumption that similar patches in a
neighborhood share the same covariance matrix, and we use off-the-shelf Poisson
denoising methods in order to obtain an initial estimate of the covariance
matrices. Our method can be seen as a post-processing step for Poisson
denoising methods and the results show that it improves upon several Poisson
denoising methods by relevant margins.","['Milad Niknejad', 'Mario A. T. Figueiredo']"
"Cross-topic Argument Mining from Heterogeneous Sources Using
  Attention-based Neural Networks",Computation and Language (Natural Language Processing),"Argument mining is a core technology for automating argument search in large
document collections. Despite its usefulness for this task, most current
approaches to argument mining are designed for use only with specific text
types and fall short when applied to heterogeneous texts. In this paper, we
propose a new sentential annotation scheme that is reliably applicable by crowd
workers to arbitrary Web texts. We source annotations for over 25,000 instances
covering eight controversial topics. The results of cross-topic experiments
show that our attention-based neural network generalizes best to unseen topics
and outperforms vanilla BiLSTM models by 6% in accuracy and 11% in F-score.","['Christian Stab', 'Tristan Miller', 'Iryna Gurevych']"
"Rivalry of Two Families of Algorithms for Memory-Restricted Streaming
  PCA",Machine Learning (Statistics),"We study the problem of recovering the subspace spanned by the first $k$
principal components of $d$-dimensional data under the streaming setting, with
a memory bound of $O(kd)$. Two families of algorithms are known for this
problem. The first family is based on the framework of stochastic gradient
descent. Nevertheless, the convergence rate of the family can be seriously
affected by the learning rate of the descent steps and deserves more serious
study. The second family is based on the power method over blocks of data, but
setting the block size for its existing algorithms is not an easy task. In this
paper, we analyze the convergence rate of a representative algorithm with
decayed learning rate (Oja and Karhunen, 1985) in the first family for the
general $k>1$ case. Moreover, we propose a novel algorithm for the second
family that sets the block sizes automatically and dynamically with faster
convergence rate. We then conduct empirical studies that fairly compare the two
families on real-world data. The studies reveal the advantages and
disadvantages of these two families.","['Chun-Liang Li', 'Hsuan-Tien Lin', 'Chi-Jen Lu']"
Une expérience de sémantique inférentielle,Artificial Intelligence,"We develop a system which must be able to perform the same inferences that a
human reader of an accident report can do and more particularly to determine
the apparent causes of the accident. We describe the general framework in which
we are situated, linguistic and semantic levels of the analysis and the
inference rules used by the system.","['Farid Nouioua', 'Daniel Kayser']"
"Coarse-to-fine Surgical Instrument Detection for Cataract Surgery
  Monitoring",Computer Vision and Pattern Recognition,"The amount of surgical data, recorded during video-monitored surgeries, has
extremely increased. This paper aims at improving existing solutions for the
automated analysis of cataract surgeries in real time. Through the analysis of
a video recording the operating table, it is possible to know which instruments
exit or enter the operating table, and therefore which ones are likely being
used by the surgeon. Combining these observations with observations from the
microscope video should enhance the overall performance of the systems. To this
end, the proposed solution is divided into two main parts: one to detect the
instruments at the beginning of the surgery and one to update the list of
instruments every time a change is detected in the scene. In the first part,
the goal is to separate the instruments from the background and from irrelevant
objects. For the second, we are interested in detecting the instruments that
appear and disappear whenever the surgeon interacts with the table. Experiments
on a dataset of 36 cataract surgeries validate the good performance of the
proposed solution.","['Hassan Al Hajj', 'Gwenolé Quellec', 'Mathieu Lamard', 'Guy Cazuguel', 'Béatrice Cochener']"
"TOG: Targeted Adversarial Objectness Gradient Attacks on Real-time
  Object Detection Systems",Machine Learning,"The rapid growth of real-time huge data capturing has pushed the deep
learning and data analytic computing to the edge systems. Real-time object
recognition on the edge is one of the representative deep neural network (DNN)
powered edge systems for real-world mission-critical applications, such as
autonomous driving and augmented reality. While DNN powered object detection
edge systems celebrate many life-enriching opportunities, they also open doors
for misuse and abuse. This paper presents three Targeted adversarial Objectness
Gradient attacks, coined as TOG, which can cause the state-of-the-art deep
object detection networks to suffer from object-vanishing, object-fabrication,
and object-mislabeling attacks. We also present a universal objectness gradient
attack to use adversarial transferability for black-box attacks, which is
effective on any inputs with negligible attack time cost, low human
perceptibility, and particularly detrimental to object detection edge systems.
We report our experimental measurements using two benchmark datasets (PASCAL
VOC and MS COCO) on two state-of-the-art detection algorithms (YOLO and SSD).
The results demonstrate serious adversarial vulnerabilities and the compelling
need for developing robust object detection systems.","['Ka-Ho Chow', 'Ling Liu', 'Mehmet Emre Gursoy', 'Stacey Truex', 'Wenqi Wei', 'Yanzhao Wu']"
"Spatially-Varying Blur Detection Based on Multiscale Fused and Sorted
  Transform Coefficients of Gradient Magnitudes",Computer Vision and Pattern Recognition,"The detection of spatially-varying blur without having any information about
the blur type is a challenging task. In this paper, we propose a novel
effective approach to address the blur detection problem from a single image
without requiring any knowledge about the blur type, level, or camera settings.
Our approach computes blur detection maps based on a novel High-frequency
multiscale Fusion and Sort Transform (HiFST) of gradient magnitudes. The
evaluations of the proposed approach on a diverse set of blurry images with
different blur types, levels, and contents demonstrate that the proposed
algorithm performs favorably against the state-of-the-art methods qualitatively
and quantitatively.","['S. Alireza Golestaneh', 'Lina J. Karam']"
"WAX-ML: A Python library for machine learning and feedback loops on
  streaming data",Machine Learning,"Wax is what you put on a surfboard to avoid slipping. It is an essential tool
to go surfing... We introduce WAX-ML a research-oriented Python library
providing tools to design powerful machine learning algorithms and feedback
loops working on streaming data. It strives to complement JAX with tools
dedicated to time series. WAX-ML makes JAX-based programs easy to use for
end-users working with pandas and xarray for data manipulation. It provides a
simple mechanism for implementing feedback loops, allows the implementation of
online learning and reinforcement learning algorithms with functions, and makes
them easy to integrate by end-users working with the object-oriented
reinforcement learning framework from the Gym library. It is released with an
Apache open-source license on GitHub at https://github.com/eserie/wax-ml.",['Emmanuel Sérié']
Bayesian Adaptive Calibration and Optimal Design,Machine Learning,"The process of calibrating computer models of natural phenomena is essential
for applications in the physical sciences, where plenty of domain knowledge can
be embedded into simulations and then calibrated against real observations.
Current machine learning approaches, however, mostly rely on rerunning
simulations over a fixed set of designs available in the observed data,
potentially neglecting informative correlations across the design space and
requiring a large amount of simulations. Instead, we consider the calibration
process from the perspective of Bayesian adaptive experimental design and
propose a data-efficient algorithm to run maximally informative simulations
within a batch-sequential process. At each round, the algorithm jointly
estimates the parameters of the posterior distribution and optimal designs by
maximising a variational lower bound of the expected information gain. The
simulator is modelled as a sample from a Gaussian process, which allows us to
correlate simulations and observed data with the unknown calibration
parameters. We show the benefits of our method when compared to related
approaches across synthetic and real-data problems.","['Rafael Oliveira', 'Dino Sejdinovic', 'David Howard', 'Edwin V. Bonilla']"
"Log-linear Combinations of Monolingual and Bilingual Neural Machine
  Translation Models for Automatic Post-Editing",Computation and Language (Natural Language Processing),"This paper describes the submission of the AMU (Adam Mickiewicz University)
team to the Automatic Post-Editing (APE) task of WMT 2016. We explore the
application of neural translation models to the APE problem and achieve good
results by treating different models as components in a log-linear model,
allowing for multiple inputs (the MT-output and the source) that are decoded to
the same target language (post-edited translations). A simple string-matching
penalty integrated within the log-linear model is used to control for higher
faithfulness with regard to the raw machine translation output. To overcome the
problem of too little training data, we generate large amounts of artificial
data. Our submission improves over the uncorrected baseline on the unseen test
set by -3.2\% TER and +5.5\% BLEU and outperforms any other system submitted to
the shared-task by a large margin.","['Marcin Junczys-Dowmunt', 'Roman Grundkiewicz']"
Bit-Vector Model Counting using Statistical Estimation,Cryptography and Security,"Approximate model counting for bit-vector SMT formulas (generalizing \#SAT)
has many applications such as probabilistic inference and quantitative
information-flow security, but it is computationally difficult. Adding random
parity constraints (XOR streamlining) and then checking satisfiability is an
effective approximation technique, but it requires a prior hypothesis about the
model count to produce useful results. We propose an approach inspired by
statistical estimation to continually refine a probabilistic estimate of the
model count for a formula, so that each XOR-streamlined query yields as much
information as possible. We implement this approach, with an approximate
probability model, as a wrapper around an off-the-shelf SMT solver or SAT
solver. Experimental results show that the implementation is faster than the
most similar previous approaches which used simpler refinement strategies. The
technique also lets us model count formulas over floating-point constraints,
which we demonstrate with an application to a vulnerability in differential
privacy mechanisms.","['Seonmo Kim', 'Stephen McCamant']"
"MAP-SNN: Mapping Spike Activities with Multiplicity, Adaptability, and
  Plasticity into Bio-Plausible Spiking Neural Networks",Neural and Evolutionary Computing,"Spiking Neural Network (SNN) is considered more biologically realistic and
power-efficient as it imitates the fundamental mechanism of the human brain.
Recently, backpropagation (BP) based SNN learning algorithms that utilize deep
learning frameworks have achieved good performance. However,
bio-interpretability is partially neglected in those BP-based algorithms.
Toward bio-plausible BP-based SNNs, we consider three properties in modeling
spike activities: Multiplicity, Adaptability, and Plasticity (MAP). In terms of
multiplicity, we propose a Multiple-Spike Pattern (MSP) with multiple spike
transmission to strengthen model robustness in discrete time-iteration. To
realize adaptability, we adopt Spike Frequency Adaption (SFA) under MSP to
decrease spike activities for improved efficiency. For plasticity, we propose a
trainable convolutional synapse that models spike response current to enhance
the diversity of spiking neurons for temporal feature extraction. The proposed
SNN model achieves competitive performances on neuromorphic datasets: N-MNIST
and SHD. Furthermore, experimental results demonstrate that the proposed three
aspects are significant to iterative robustness, spike efficiency, and temporal
feature extraction capability of spike activities. In summary, this work
proposes a feasible scheme for bio-inspired spike activities with MAP, offering
a new neuromorphic perspective to embed biological characteristics into spiking
neural networks.","['Chengting Yu', 'Yangkai Du', 'Mufeng Chen', 'Aili Wang', 'Gaoang Wang', 'Erping Li']"
"Explicitizing an Implicit Bias of the Frequency Principle in Two-layer
  Neural Networks",Machine Learning,"It remains a puzzle that why deep neural networks (DNNs), with more
parameters than samples, often generalize well. An attempt of understanding
this puzzle is to discover implicit biases underlying the training process of
DNNs, such as the Frequency Principle (F-Principle), i.e., DNNs often fit
target functions from low to high frequencies. Inspired by the F-Principle, we
propose an effective model of linear F-Principle (LFP) dynamics which
accurately predicts the learning results of two-layer ReLU neural networks
(NNs) of large widths. This LFP dynamics is rationalized by a linearized mean
field residual dynamics of NNs. Importantly, the long-time limit solution of
this LFP dynamics is equivalent to the solution of a constrained optimization
problem explicitly minimizing an FP-norm, in which higher frequencies of
feasible solutions are more heavily penalized. Using this optimization
formulation, an a priori estimate of the generalization error bound is
provided, revealing that a higher FP-norm of the target function increases the
generalization error. Overall, by explicitizing the implicit bias of the
F-Principle as an explicit penalty for two-layer NNs, our work makes a step
towards a quantitative understanding of the learning and generalization of
general DNNs.","['Yaoyu Zhang', 'Zhi-Qin John Xu', 'Tao Luo', 'Zheng Ma']"
"A heuristic approach for lactate threshold estimation for training
  decision-making: An accessible and easy to use solution for recreational
  runners",Applications (Statistics),"In this work, a heuristic as operational tool to estimate the lactate
threshold and to facilitate its integration into the training process of
recreational runners is proposed. To do so, we formalize the principles for the
lactate threshold estimation from empirical data and an iterative methodology
that enables experience based learning. This strategy arises as a robust and
adaptive approach to solve data analysis problems. We compare the results of
the heuristic with the most commonly used protocol by making a first
quantitative error analysis to show its reliability. Additionally, we provide a
computational algorithm so that this quantitative analysis can be easily
performed in other lactate threshold protocols. With this work, we have shown
that a heuristic %60 of 'endurance running speed reserve', serves for the same
purpose of the most commonly used protocol in recreational runners, but
improving its operational limitations of accessibility and consistent use.","['U. Etxegarai', 'E. Portillo', 'J. Irazusta', 'L. A. Koefoed', 'N. Kasabov']"
Step length measurement in the wild using FMCW radar,Computer Vision and Pattern Recognition,"With an aging population, numerous assistive and monitoring technologies are
under development to enable older adults to age in place. To facilitate aging
in place predicting risk factors such as falls, and hospitalization and
providing early interventions are important. Much of the work on ambient
monitoring for risk prediction has centered on gait speed analysis, utilizing
privacy-preserving sensors like radar. Despite compelling evidence that
monitoring step length, in addition to gait speed, is crucial for predicting
risk, radar-based methods have not explored step length measurement in the
home. Furthermore, laboratory experiments on step length measurement using
radars are limited to proof of concept studies with few healthy subjects. To
address this gap, a radar-based step length measurement system for the home is
proposed based on detection and tracking using radar point cloud, followed by
Doppler speed profiling of the torso to obtain step lengths in the home. The
proposed method was evaluated in a clinical environment, involving 35 frail
older adults, to establish its validity. Additionally, the method was assessed
in people's homes, with 21 frail older adults who had participated in the
clinical assessment. The proposed radar-based step length measurement method
was compared to the gold standard Zeno Walkway Gait Analysis System, revealing
a 4.5cm/8.3% error in a clinical setting. Furthermore, it exhibited excellent
reliability (ICC(2,k)=0.91, 95% CI 0.82 to 0.96) in uncontrolled home settings.
The method also proved accurate in uncontrolled home settings, as indicated by
a strong agreement (ICC(3,k)=0.81 (95% CI 0.53 to 0.92)) between home
measurements and in-clinic assessments.","['Parthipan Siva', 'Alexander Wong', 'Patricia Hewston', 'George Ioannidis', 'Jonathan Adachi', 'Alexander Rabinovich', 'Andrea Lee', 'Alexandra Papaioannou']"
"Knowledge-Aided Semantic Communication Leveraging Probabilistic
  Graphical Modeling",Machine Learning,"In this paper, we propose a semantic communication approach based on
probabilistic graphical model (PGM). The proposed approach involves
constructing a PGM from a training dataset, which is then shared as common
knowledge between the transmitter and receiver. We evaluate the importance of
various semantic features and present a PGM-based compression algorithm
designed to eliminate predictable portions of semantic information.
Furthermore, we introduce a technique to reconstruct the discarded semantic
information at the receiver end, generating approximate results based on the
PGM. Simulation results indicate a significant improvement in transmission
efficiency over existing methods, while maintaining the quality of the
transmitted images.","['Haowen Wan', 'Qianqian Yang', 'Jiancheng Tang', 'Zhiguo shi']"
Learning Video Representations from Correspondence Proposals,Computer Vision and Pattern Recognition,"Correspondences between frames encode rich information about dynamic content
in videos. However, it is challenging to effectively capture and learn those
due to their irregular structure and complex dynamics. In this paper, we
propose a novel neural network that learns video representations by aggregating
information from potential correspondences. This network, named $CPNet$, can
learn evolving 2D fields with temporal consistency. In particular, it can
effectively learn representations for videos by mixing appearance and
long-range motion with an RGB-only input. We provide extensive ablation
experiments to validate our model. CPNet shows stronger performance than
existing methods on Kinetics and achieves the state-of-the-art performance on
Something-Something and Jester. We provide analysis towards the behavior of our
model and show its robustness to errors in proposals.","['Xingyu Liu', 'Joon-Young Lee', 'Hailin Jin']"
A Text Analysis of Federal Reserve meeting minutes,Information Retrieval,"Recent developments in monetary policy by the Federal Reserve has created a
need for an objective method of communication analysis.Using methods developed
for text analysis, we present a novel technique of analysis which creates a
semantic space defined by various policymakers public comments and places the
committee consensus in the appropriate location. Its then possible to determine
which member of the committee is most closely aligned with the committee
consensus over time and create a foundation for further actionable research.","['Harish Gandhi Ramachandran', 'Dan DeRose Jr']"
"Solution for Emotion Prediction Competition of Workshop on Emotionally
  and Culturally Intelligent AI",Artificial Intelligence,"This report provide a detailed description of the method that we explored and
proposed in the WECIA Emotion Prediction Competition (EPC), which predicts a
person's emotion through an artistic work with a comment. The dataset of this
competition is ArtELingo, designed to encourage work on diversity across
languages and cultures. The dataset has two main challenges, namely modal
imbalance problem and language-cultural differences problem. In order to
address this issue, we propose a simple yet effective approach called
single-multi modal with Emotion-Cultural specific prompt(ECSP), which focuses
on using the single modal message to enhance the performance of multimodal
models and a well-designed prompt to reduce cultural differences problem. To
clarify, our approach contains two main blocks:
(1)XLM-R\cite{conneau2019unsupervised} based unimodal model and
X$^2$-VLM\cite{zeng2022x} based multimodal model (2) Emotion-Cultural specific
prompt. Our approach ranked first in the final test with a score of 0.627.","['Shengdong Xu', 'Zhouyang Chi', 'Yang Yang']"
LSICC: A Large Scale Informal Chinese Corpus,Computation and Language (Natural Language Processing),"Deep learning based natural language processing model is proven powerful, but
need large-scale dataset. Due to the significant gap between the real-world
tasks and existing Chinese corpus, in this paper, we introduce a large-scale
corpus of informal Chinese. This corpus contains around 37 million book reviews
and 50 thousand netizen's comments to the news. We explore the informal words
frequencies of the corpus and show the difference between our corpus and the
existing ones. The corpus can be further used to train deep learning based
natural language processing tasks such as Chinese word segmentation, sentiment
analysis.","['Jianyu Zhao', 'Zhuoran Ji']"
"Adaptive Particle Swarm Optimization for through-foliage target
  detection with drone swarms",Systems and Control (Electrical Engineering and Systems Science),"This work contributes to efforts on autonomously detecting a
vegetation-occluded target by airborne observers. It investigates and enhances
previous work on a Particle Swarm Optimization (PSO) strategy for Airborne
Optical Sectioning (AOS) drone swarms. First, it identifies two issues with
that method and proposes to resolve them by a leader stabilization for its
scattering and projection-based line positions for its default scanning
pattern. Second, it connects this method to other PSO variants and presents a
new adaptive PSO strategy for AOS drone swarms that draws on the ideas of
Adaptive PSO (APSO).",['Julia Pöschl']
An end-to-end Neural Network Framework for Text Clustering,Computation and Language (Natural Language Processing),"The unsupervised text clustering is one of the major tasks in natural
language processing (NLP) and remains a difficult and complex problem.
Conventional \mbox{methods} generally treat this task using separated steps,
including text representation learning and clustering the representations. As
an improvement, neural methods have also been introduced for continuous
representation learning to address the sparsity problem. However, the
multi-step process still deviates from the unified optimization target.
Especially the second step of cluster is generally performed with conventional
methods such as k-Means. We propose a pure neural framework for text clustering
in an end-to-end manner. It jointly learns the text representation and the
clustering model. Our model works well when the context can be obtained, which
is nearly always the case in the field of NLP. We have our method
\mbox{evaluated} on two widely used benchmarks: IMDB movie reviews for
sentiment classification and $20$-Newsgroup for topic categorization. Despite
its simplicity, experiments show the model outperforms previous clustering
methods by a large margin. Furthermore, the model is also verified on English
wiki dataset as a large corpus.","['Jie Zhou', 'Xingyi Cheng', 'Jinchao Zhang']"
"Implementation of Rule Based Algorithm for Sandhi-Vicheda Of Compound
  Hindi Words",Computation and Language (Natural Language Processing),"Sandhi means to join two or more words to coin new word. Sandhi literally
means `putting together' or combining (of sounds), It denotes all combinatory
sound-changes effected (spontaneously) for ease of pronunciation.
Sandhi-vicheda describes [5] the process by which one letter (whether single or
cojoined) is broken to form two words. Part of the broken letter remains as the
last letter of the first word and part of the letter forms the first letter of
the next letter. Sandhi- Vicheda is an easy and interesting way that can give
entirely new dimension that add new way to traditional approach to Hindi
Teaching. In this paper using the Rule based algorithm we have reported an
accuracy of 60-80% depending upon the number of rules to be implemented.","['Priyanka Gupta', 'Vishal Goyal']"
Anomaly Detection using Capsule Networks for High-dimensional Datasets,Machine Learning,"Anomaly detection is an essential problem in machine learning. Application
areas include network security, health care, fraud detection, etc., involving
high-dimensional datasets. A typical anomaly detection system always faces the
class-imbalance problem in the form of a vast difference in the sample sizes of
different classes. They usually have class overlap problems. This study used a
capsule network for the anomaly detection task. To the best of our knowledge,
this is the first instance where a capsule network is analyzed for the anomaly
detection task in a high-dimensional complex data setting. We also handle the
related novelty and outlier detection problems. The architecture of the capsule
network was suitably modified for a binary classification task. Capsule
networks offer a good option for detecting anomalies due to the effect of
viewpoint invariance captured in its predictions and viewpoint equivariance
captured in internal capsule architecture. We used six-layered under-complete
autoencoder architecture with second and third layers containing capsules. The
capsules were trained using the dynamic routing algorithm. We created
$10$-imbalanced datasets from the original MNIST dataset and compared the
performance of the capsule network with $5$ baseline models. Our leading test
set measures are F1-score for minority class and area under the ROC curve. We
found that the capsule network outperformed every other baseline model on the
anomaly detection task by using only ten epochs for training and without using
any other data level and algorithm level approach. Thus, we conclude that
capsule networks are excellent in modeling complex high-dimensional imbalanced
datasets for the anomaly detection task.","['Inderjeet Singh', 'Nandyala Hemachandra']"
Sampling Matters in Deep Embedding Learning,Computer Vision and Pattern Recognition,"Deep embeddings answer one simple question: How similar are two images?
Learning these embeddings is the bedrock of verification, zero-shot learning,
and visual search. The most prominent approaches optimize a deep convolutional
network with a suitable loss function, such as contrastive loss or triplet
loss. While a rich line of work focuses solely on the loss functions, we show
in this paper that selecting training examples plays an equally important role.
We propose distance weighted sampling, which selects more informative and
stable examples than traditional approaches. In addition, we show that a simple
margin based loss is sufficient to outperform all other loss functions. We
evaluate our approach on the Stanford Online Products, CAR196, and the
CUB200-2011 datasets for image retrieval and clustering, and on the LFW dataset
for face verification. Our method achieves state-of-the-art performance on all
of them.","['Chao-Yuan Wu', 'R. Manmatha', 'Alexander J. Smola', 'Philipp Krähenbühl']"
Evolving Real-Time Heuristics Search Algorithms with Building Blocks,Artificial Intelligence,"The research area of real-time heuristics search has produced quite many
algorithms. In the landscape of real-time heuristics search research, it is not
rare to find that an algorithm X that appears to perform better than algorithm
Y on a group of problems, performed worse than Y for another group of problems.
If these published algorithms are combined to generate a more powerful space of
algorithms, then that novel space of algorithms may solve a distribution of
problems more efficiently. Based on this intuition, a recent work Bulitko 2016
has defined the task of finding a combination of heuristics search algorithms
as a survival task. In this evolutionary approach, a space of algorithms is
defined over a set of building blocks published algorithms and a simulated
evolution is used to recombine these building blocks to find out the best
algorithm from that space of algorithms.
  In this paper, we extend the set of building blocks by adding one published
algorithm, namely lookahead based A-star shaped local search space generation
method from LSSLRTA-star, plus an unpublished novel strategy to generate local
search space with Greedy Best First Search. Then we perform experiments in the
new space of algorithms, which show that the best algorithms selected by the
evolutionary process have the following property: the deeper is the lookahead
depth of an algorithm, the lower is its suboptimality and scrubbing complexity.","['Md Solimul Chowdhury', 'Victor Silva']"
"CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for
  Complex Problem Solving",Computation and Language (Natural Language Processing),"Large Language Models (LLMs) have shown great ability in solving traditional
natural language tasks and elementary reasoning tasks with appropriate
prompting techniques. However, their ability is still limited in solving
complicated science problems. In this work, we aim to push the upper bound of
the reasoning capability of LLMs by proposing a collaborative multi-agent,
multi-reasoning-path (CoMM) prompting framework. Specifically, we prompt LLMs
to play different roles in a problem-solving team, and encourage different
role-play agents to collaboratively solve the target task. In particular, we
discover that applying different reasoning paths for different roles is an
effective strategy to implement few-shot prompting approaches in the
multi-agent scenarios. Empirical results demonstrate the effectiveness of the
proposed methods on two college-level science problems over competitive
baselines. Our further analysis shows the necessity of prompting LLMs to play
different roles or experts independently. We release the code at:
https://github.com/amazon-science/comm-prompt","['Pei Chen', 'Boran Han', 'Shuai Zhang']"
"Robust Unsupervised Domain Adaptation for Neural Networks via Moment
  Alignment",Machine Learning (Statistics),"A novel approach for unsupervised domain adaptation for neural networks is
proposed. It relies on metric-based regularization of the learning process. The
metric-based regularization aims at domain-invariant latent feature
representations by means of maximizing the similarity between domain-specific
activation distributions. The proposed metric results from modifying an
integral probability metric such that it becomes less translation-sensitive on
a polynomial function space. The metric has an intuitive interpretation in the
dual space as the sum of differences of higher order central moments of the
corresponding activation distributions. Under appropriate assumptions on the
input distributions, error minimization is proven for the continuous case. As
demonstrated by an analysis of standard benchmark experiments for sentiment
analysis, object recognition and digit recognition, the outlined approach is
robust regarding parameter changes and achieves higher classification
accuracies than comparable approaches. The source code is available at
https://github.com/wzell/mann.","['Werner Zellinger', 'Bernhard A. Moser', 'Thomas Grubinger', 'Edwin Lughofer', 'Thomas Natschläger', 'Susanne Saminger-Platz']"
"Improving Machine Translation with Human Feedback: An Exploration of
  Quality Estimation as a Reward Model",Computation and Language (Natural Language Processing),"Insufficient modeling of human preferences within the reward model is a major
obstacle for leveraging human feedback to improve translation quality.
Fortunately, quality estimation (QE), which predicts the quality of a given
translation without reference, has achieved impressive alignment with human
evaluations in the last two years. In this work, we investigate the potential
of employing the QE model as the reward model to predict human preferences for
feedback training. We first identify the overoptimization problem during
QE-based feedback training, manifested as an increase in reward while
translation quality declines. We examine the problem and argue that the
vulnerability of the QE model might lead to high rewards for incorrect
translations, resulting in overoptimization and error propagation. To address
the problem, we adopt a simple yet effective method that uses heuristic rules
to detect the incorrect translations and assigns a penalty term to the reward
scores of them. Experimental results show that the proposed QE-based feedback
training achieves consistent and significant improvements across various
settings, further verified through human preference studies. Our subsequent
analysis demonstrates the high data efficiency of the proposed QE-based
feedback training: it outperforms systems using larger parallel corpora by a
small amount of monolingual data. Our code is available at:
https://github.com/zwhe99/FeedbackMT","['Zhiwei He', 'Xing Wang', 'Wenxiang Jiao', 'Zhuosheng Zhang', 'Rui Wang', 'Shuming Shi', 'Zhaopeng Tu']"
"A Comparison of Resampling and Recursive Partitioning Methods in Random
  Forest for Estimating the Asymptotic Variance Using the Infinitesimal
  Jackknife",Machine Learning (Statistics),"The infinitesimal jackknife (IJ) has recently been applied to the random
forest to estimate its prediction variance. These theorems were verified under
a traditional random forest framework which uses classification and regression
trees (CART) and bootstrap resampling. However, random forests using
conditional inference (CI) trees and subsampling have been found to be not
prone to variable selection bias. Here, we conduct simulation experiments using
a novel approach to explore the applicability of the IJ to random forests using
variations on the resampling method and base learner. Test data points were
simulated and each trained using random forest on one hundred simulated
training data sets using different combinations of resampling and base
learners. Using CI trees instead of traditional CART trees as well as using
subsampling instead of bootstrap sampling resulted in a much more accurate
estimation of prediction variance when using the IJ. The random forest
variations here have been incorporated into an open source software package for
the R programming language.","['Cole Brokamp', 'MB Rao', 'Patrick Ryan', 'Roman Jandarov']"
Fairness without Sensitive Attributes via Knowledge Sharing,Machine Learning,"While model fairness improvement has been explored previously, existing
methods invariably rely on adjusting explicit sensitive attribute values in
order to improve model fairness in downstream tasks. However, we observe a
trend in which sensitive demographic information becomes inaccessible as public
concerns around data privacy grow. In this paper, we propose a confidence-based
hierarchical classifier structure called ""Reckoner"" for reliable fair model
learning under the assumption of missing sensitive attributes. We first present
results showing that if the dataset contains biased labels or other hidden
biases, classifiers significantly increase the bias gap across different
demographic groups in the subset with higher prediction confidence. Inspired by
these findings, we devised a dual-model system in which a version of the model
initialised with a high-confidence data subset learns from a version of the
model initialised with a low-confidence data subset, enabling it to avoid
biased predictions. Our experimental results show that Reckoner consistently
outperforms state-of-the-art baselines in COMPAS dataset and New Adult dataset,
considering both accuracy and fairness metrics.","['Hongliang Ni', 'Lei Han', 'Tong Chen', 'Shazia Sadiq', 'Gianluca Demartini']"
Self-Balanced Dropout,Computation and Language (Natural Language Processing),"Dropout is known as an effective way to reduce overfitting via preventing
co-adaptations of units. In this paper, we theoretically prove that the
co-adaptation problem still exists after using dropout due to the correlations
among the inputs. Based on the proof, we further propose Self-Balanced Dropout,
a novel dropout method which uses a trainable variable to balance the influence
of the input correlation on parameter update. We evaluate Self-Balanced Dropout
on a range of tasks with both simple and complex models. The experimental
results show that the mechanism can effectively solve the co-adaption problem
to some extent and significantly improve the performance on all tasks.","['Shen Li', 'Chenhao Su', 'Renfen Hu', 'Zhengdong Lu']"
"Getting Started with Particle Metropolis-Hastings for Inference in
  Nonlinear Dynamical Models",Computation (Statistics),"This tutorial provides a gentle introduction to the particle
Metropolis-Hastings (PMH) algorithm for parameter inference in nonlinear
state-space models together with a software implementation in the statistical
programming language R. We employ a step-by-step approach to develop an
implementation of the PMH algorithm (and the particle filter within) together
with the reader. This final implementation is also available as the package
pmhtutorial in the CRAN repository. Throughout the tutorial, we provide some
intuition as to how the algorithm operates and discuss some solutions to
problems that might occur in practice. To illustrate the use of PMH, we
consider parameter inference in a linear Gaussian state-space model with
synthetic data and a nonlinear stochastic volatility model with real-world
data.","['Johan Dahlin', 'Thomas B. Schön']"
Radon Sobolev Variational Auto-Encoders,Machine Learning,"The quality of generative models (such as Generative adversarial networks and
Variational Auto-Encoders) depends heavily on the choice of a good probability
distance. However some popular metrics like the Wasserstein or the Sliced
Wasserstein distances, the Jensen-Shannon divergence, the Kullback-Leibler
divergence, lack convenient properties such as (geodesic) convexity, fast
evaluation and so on. To address these shortcomings, we introduce a class of
distances that have built-in convexity. We investigate the relationship with
some known paradigms (sliced distances - a synonym for Radon distances -,
reproducing kernel Hilbert spaces, energy distances). The distances are shown
to possess fast implementations and are included in an adapted Variational
Auto-Encoder termed Radon Sobolev Variational Auto-Encoder (RS-VAE) which
produces high quality results on standard generative datasets.
  Keywords: Variational Auto-Encoder; Generative model; Sobolev spaces; Radon
Sobolev Variational Auto-Encoder;",['Gabriel Turinici']
Online Stochastic Optimization with Multiple Objectives,Machine Learning,"In this paper we propose a general framework to characterize and solve the
stochastic optimization problems with multiple objectives underlying many real
world learning applications. We first propose a projection based algorithm
which attains an $O(T^{-1/3})$ convergence rate. Then, by leveraging on the
theory of Lagrangian in constrained optimization, we devise a novel primal-dual
stochastic approximation algorithm which attains the optimal convergence rate
of $O(T^{-1/2})$ for general Lipschitz continuous objectives.","['Mehrdad Mahdavi', 'Tianbao Yang', 'Rong Jin']"
"Emulating the Human Mind: A Neural-symbolic Link Prediction Model with
  Fast and Slow Reasoning and Filtered Rules",Computation and Language (Natural Language Processing),"Link prediction is an important task in addressing the incompleteness problem
of knowledge graphs (KG). Previous link prediction models suffer from issues
related to either performance or explanatory capability. Furthermore, models
that are capable of generating explanations, often struggle with erroneous
paths or reasoning leading to the correct answer. To address these challenges,
we introduce a novel Neural-Symbolic model named FaSt-FLiP (stands for Fast and
Slow Thinking with Filtered rules for Link Prediction task), inspired by two
distinct aspects of human cognition: ""commonsense reasoning"" and ""thinking,
fast and slow."" Our objective is to combine a logical and neural model for
enhanced link prediction. To tackle the challenge of dealing with incorrect
paths or rules generated by the logical model, we propose a semi-supervised
method to convert rules into sentences. These sentences are then subjected to
assessment and removal of incorrect rules using an NLI (Natural Language
Inference) model. Our approach to combining logical and neural models involves
first obtaining answers from both the logical and neural models. These answers
are subsequently unified using an Inference Engine module, which has been
realized through both algorithmic implementation and a novel neural model
architecture. To validate the efficacy of our model, we conducted a series of
experiments. The results demonstrate the superior performance of our model in
both link prediction metrics and the generation of more reliable explanations.","['Mohammad Hossein Khojasteh', 'Najmeh Torabian', 'Ali Farjami', 'Saeid Hosseini', 'Behrouz Minaei-Bidgoli']"
"Accelerating Inverse Learning via Intelligent Localization with
  Exploratory Sampling",Machine Learning,"In the scope of ""AI for Science"", solving inverse problems is a longstanding
challenge in materials and drug discovery, where the goal is to determine the
hidden structures given a set of desirable properties. Deep generative models
are recently proposed to solve inverse problems, but these currently use
expensive forward operators and struggle in precisely localizing the exact
solutions and fully exploring the parameter spaces without missing solutions.
In this work, we propose a novel approach (called iPage) to accelerate the
inverse learning process by leveraging probabilistic inference from deep
invertible models and deterministic optimization via fast gradient descent.
Given a target property, the learned invertible model provides a posterior over
the parameter space; we identify these posterior samples as an intelligent
prior initialization which enables us to narrow down the search space. We then
perform gradient descent to calibrate the inverse solutions within a local
region. Meanwhile, a space-filling sampling is imposed on the latent space to
better explore and capture all possible solutions. We evaluate our approach on
three benchmark tasks and two created datasets with real-world applications
from quantum chemistry and additive manufacturing, and find our method achieves
superior performance compared to several state-of-the-art baseline methods. The
iPage code is available at https://github.com/jxzhangjhu/MatDesINNe.","['Jiaxin Zhang', 'Sirui Bi', 'Victor Fung']"
"Adapter-based Selective Knowledge Distillation for Federated
  Multi-domain Meeting Summarization",Computation and Language (Natural Language Processing),"Meeting summarization has emerged as a promising technique for providing
users with condensed summaries. However, existing work has focused on training
models on centralized data, neglecting real-world scenarios where meeting data
are infeasible to collect centrally, due to their sensitive nature. This gap
motivates us to explore federated learning for meeting summarization. Two
critical challenges impede progress. First, state-of-the-art summarizers are
based on parameter-heavy pre-trained models. Exchanging such a model's
parameters across clients imposes large bandwidth costs. Second, as real-world
meeting data belong to various domains and are distributed across clients, they
are instances of non-identically and independently distributed (non-IID). IID
assumptions do not hold, which changes which forms of learning algorithms best
apply. To address this, we propose Adapter-based Federated Selective Knowledge
Distillation (AdaFedSelecKD) for training performant client models.
Specifically, we develop an adapter-based summarization model where two
adapters cooperatively facilitate learning using fewer parameters to reduce
communication costs. Then, we devise a selective knowledge distillation
strategy, assisting clients in robustly handling domain-focused modelling on
their own data, while leveraging global parameters based on non-IID data.
Extensive experiments on the QMSum benchmark demonstrate AdaFedSelecKD can
achieve comparable performance with powerful centralized training methods, and
shows its generalizability and robustness.","['Xiachong Feng', 'Xiaocheng Feng', 'Xiyuan Du', 'Min-Yen Kan', 'Bing Qin']"
"Video Object Segmentation with Joint Re-identification and
  Attention-Aware Mask Propagation",Computer Vision and Pattern Recognition,"The problem of video object segmentation can become extremely challenging
when multiple instances co-exist. While each instance may exhibit large scale
and pose variations, the problem is compounded when instances occlude each
other causing failures in tracking. In this study, we formulate a deep
recurrent network that is capable of segmenting and tracking objects in video
simultaneously by their temporal continuity, yet able to re-identify them when
they re-appear after a prolonged occlusion. We combine both temporal
propagation and re-identification functionalities into a single framework that
can be trained end-to-end. In particular, we present a re-identification module
with template expansion to retrieve missing objects despite their large
appearance changes. In addition, we contribute a new attention-based recurrent
mask propagation approach that is robust to distractors not belonging to the
target segment. Our approach achieves a new state-of-the-art global mean
(Region Jaccard and Boundary F measure) of 68.2 on the challenging DAVIS 2017
benchmark (test-dev set), outperforming the winning solution which achieves a
global mean of 66.1 on the same partition.","['Xiaoxiao Li', 'Chen Change Loy']"
"Fast methods for denoising matrix completion formulations, with
  applications to robust seismic data interpolation",Machine Learning (Statistics),"Recent SVD-free matrix factorization formulations have enabled rank
minimization for systems with millions of rows and columns, paving the way for
matrix completion in extremely large-scale applications, such as seismic data
interpolation.
  In this paper, we consider matrix completion formulations designed to hit a
target data-fitting error level provided by the user, and propose an algorithm
called LR-BPDN that is able to exploit factorized formulations to solve the
corresponding optimization problem. Since practitioners typically have strong
prior knowledge about target error level, this innovation makes it easy to
apply the algorithm in practice, leaving only the factor rank to be determined.
  Within the established framework, we propose two extensions that are highly
relevant to solving practical challenges of data interpolation. First, we
propose a weighted extension that allows known subspace information to improve
the results of matrix completion formulations. We show how this weighting can
be used in the context of frequency continuation, an essential aspect to
seismic data interpolation. Second, we propose matrix completion formulations
that are robust to large measurement errors in the available data.
  We illustrate the advantages of LR-BPDN on the collaborative filtering
problem using the MovieLens 1M, 10M, and Netflix 100M datasets. Then, we use
the new method, along with its robust and subspace re-weighted extensions, to
obtain high-quality reconstructions for large scale seismic interpolation
problems with real data, even in the presence of data contamination.","['Aleksandr Y. Aravkin', 'Rajiv Kumar', 'Hassan Mansour', 'Ben Recht', 'Felix J. Herrmann']"
"Computed Decision Weights and a New Learning Algorithm for Neural
  Classifiers",Machine Learning,"In this paper we consider the possibility of computing rather than training
the decision layer weights of a neural classifier. Such a possibility arises in
two way, from making an appropriate choice of loss function and by solving a
problem of constrained optimization. The latter formulation leads to a
promising new learning process for pre-decision weights with both simplicity
and efficacy.",['Eugene Wong']
"Anomaly Detection for Industrial Control Systems Using
  Sequence-to-Sequence Neural Networks",Cryptography and Security,"This study proposes an anomaly detection method for operational data of
industrial control systems (ICSs). Sequence-to-sequence neural networks were
applied to train and predict ICS operational data and interpret their
time-series characteristic. The proposed method requires only a normal dataset
to understand ICS's normal state and detect outliers. This method was evaluated
with SWaT (secure water treatment) dataset, and 29 out of 36 attacks were
detected. The reported method also detects the attack points, and 25 out of 53
points were detected. This study provides a detailed analysis of false
positives and false negatives of the experimental results.","['Jonguk Kim', 'Jeong-Han Yun', 'Hyoung Chun Kim']"
Testing for Feature Relevance: The HARVEST Algorithm,Machine Learning (Statistics),"Feature selection with high-dimensional data and a very small proportion of
relevant features poses a severe challenge to standard statistical methods. We
have developed a new approach (HARVEST) that is straightforward to apply,
albeit somewhat computer-intensive. This algorithm can be used to pre-screen a
large number of features to identify those that are potentially useful. The
basic idea is to evaluate each feature in the context of many random subsets of
other features. HARVEST is predicated on the assumption that an irrelevant
feature can add no real predictive value, regardless of which other features
are included in the subset. Motivated by this idea, we have derived a simple
statistical test for feature relevance. Empirical analyses and simulations
produced so far indicate that the HARVEST algorithm is highly effective in
predictive analytics, both in science and business.","['Herbert Weisberg', 'Victor Pontes', 'Mathis Thoma']"
Entity Type Prediction in Knowledge Graphs using Embeddings,Computation and Language (Natural Language Processing),"Open Knowledge Graphs (such as DBpedia, Wikidata, YAGO) have been recognized
as the backbone of diverse applications in the field of data mining and
information retrieval. Hence, the completeness and correctness of the Knowledge
Graphs (KGs) are vital. Most of these KGs are mostly created either via an
automated information extraction from Wikipedia snapshots or information
accumulation provided by the users or using heuristics. However, it has been
observed that the type information of these KGs is often noisy, incomplete, and
incorrect. To deal with this problem a multi-label classification approach is
proposed in this work for entity typing using KG embeddings. We compare our
approach with the current state-of-the-art type prediction method and report on
experiments with the KGs.","['Russa Biswas', 'Radina Sofronova', 'Mehwish Alam', 'Harald Sack']"
"What's Missing: A Knowledge Gap Guided Approach for Multi-hop Question
  Answering",Computation and Language (Natural Language Processing),"Multi-hop textual question answering requires combining information from
multiple sentences. We focus on a natural setting where, unlike typical reading
comprehension, only partial information is provided with each question. The
model must retrieve and use additional knowledge to correctly answer the
question. To tackle this challenge, we develop a novel approach that explicitly
identifies the knowledge gap between a key span in the provided knowledge and
the answer choices. The model, GapQA, learns to fill this gap by determining
the relationship between the span and an answer choice, based on retrieved
knowledge targeting this gap. We propose jointly training a model to
simultaneously fill this knowledge gap and compose it with the provided partial
knowledge. On the OpenBookQA dataset, given partial knowledge, explicitly
identifying what's missing substantially outperforms previous approaches.","['Tushar Khot', 'Ashish Sabharwal', 'Peter Clark']"
Safety Synthesis Sans Specification,Formal Languages and Automata Theory,"We define the problem of learning a transducer ${S}$ from a target language
$U$ containing possibly conflicting transducers, using membership queries and
conjecture queries. The requirement is that the language of ${S}$ be a subset
of $U$. We argue that this is a natural question in many situations in hardware
and software verification. We devise a learning algorithm for this problem and
show that its time and query complexity is polynomial with respect to the rank
of the target language, its incompatibility measure, and the maximal length of
a given counterexample. We report on experiments conducted with a prototype
implementation.","['Roderick Bloem', 'Hana Chockler', 'Masoud Ebrahimi', 'Dana Fisman', 'Heinz Riener']"
"Flying Bird Object Detection Algorithm in Surveillance Video Based on
  Motion Information",Computer Vision and Pattern Recognition,"A Flying Bird Object Detection algorithm Based on Motion Information
(FBOD-BMI) is proposed to solve the problem that the features of the object are
not obvious in a single frame, and the size of the object is small (low
Signal-to-Noise Ratio (SNR)) in surveillance video. Firstly, a ConvLSTM-PAN
model structure is designed to capture suspicious flying bird objects, in which
the Convolutional Long and Short Time Memory (ConvLSTM) network aggregated the
Spatio-temporal features of the flying bird object on adjacent multi-frame
before the input of the model and the Path Aggregation Network (PAN) located
the suspicious flying bird objects. Then, an object tracking algorithm is used
to track suspicious flying bird objects and calculate their Motion Range (MR).
At the same time, the size of the MR of the suspicious flying bird object is
adjusted adaptively according to its speed of movement (specifically, if the
bird moves slowly, its MR will be expanded according to the speed of the bird
to ensure the environmental information needed to detect the flying bird
object). Adaptive Spatio-temporal Cubes (ASt-Cubes) of the flying bird objects
are generated to ensure that the SNR of the flying bird objects is improved,
and the necessary environmental information is retained adaptively. Finally, a
LightWeight U-Shape Net (LW-USN) based on ASt-Cubes is designed to detect
flying bird objects, which rejects the false detections of the suspicious
flying bird objects and returns the position of the real flying bird objects.
The monitoring video including the flying birds is collected in the unattended
traction substation as the experimental dataset to verify the performance of
the algorithm. The experimental results show that the flying bird object
detection method based on motion information proposed in this paper can
effectively detect the flying bird object in surveillance video.","['Ziwei Sun', 'Zexi Hua', 'Hengcao Li', 'Haiyan Zhong']"
Generative Image Inpainting with Submanifold Alignment,Computer Vision and Pattern Recognition,"Image inpainting aims at restoring missing regions of corrupted images, which
has many applications such as image restoration and object removal. However,
current GAN-based generative inpainting models do not explicitly exploit the
structural or textural consistency between restored contents and their
surrounding contexts.To address this limitation, we propose to enforce the
alignment (or closeness) between the local data submanifolds (or subspaces)
around restored images and those around the original (uncorrupted) images
during the learning process of GAN-based inpainting models. We exploit Local
Intrinsic Dimensionality (LID) to measure, in deep feature space, the alignment
between data submanifolds learned by a GAN model and those of the original
data, from a perspective of both images (denoted as iLID) and local patches
(denoted as pLID) of images. We then apply iLID and pLID as regularizations for
GAN-based inpainting models to encourage two levels of submanifold alignment:
1) an image-level alignment for improving structural consistency, and 2) a
patch-level alignment for improving textural details. Experimental results on
four benchmark datasets show that our proposed model can generate more accurate
results than state-of-the-art models.","['Ang Li', 'Jianzhong Qi', 'Rui Zhang', 'Xingjun Ma', 'Kotagiri Ramamohanarao']"
On the visual analytic intelligence of neural networks,Neural and Evolutionary Computing,"Visual oddity task was conceived as a universal ethnic-independent analytic
intelligence test for humans. Advancements in artificial intelligence led to
important breakthroughs, yet competing with humans on such analytic
intelligence tasks remains challenging and typically resorts to
non-biologically-plausible architectures. We present a biologically realistic
system that receives inputs from synthetic eye movements - saccades, and
processes them with neurons incorporating dynamics of neocortical neurons. We
introduce a procedurally generated visual oddity dataset to train an
architecture extending conventional relational networks and our proposed
system. Both approaches surpass the human accuracy, and we uncover that both
share the same essential underlying mechanism of reasoning. Finally, we show
that the biologically inspired network achieves superior accuracy, learns
faster and requires fewer parameters than the conventional network.","['Stanisław Woźniak', 'Hlynur Jónsson', 'Giovanni Cherubini', 'Angeliki Pantazi', 'Evangelos Eleftheriou']"
"Faces à la Carte: Text-to-Face Generation via Attribute
  Disentanglement",Computer Vision and Pattern Recognition,"Text-to-Face (TTF) synthesis is a challenging task with great potential for
diverse computer vision applications. Compared to Text-to-Image (TTI) synthesis
tasks, the textual description of faces can be much more complicated and
detailed due to the variety of facial attributes and the parsing of high
dimensional abstract natural language. In this paper, we propose a Text-to-Face
model that not only produces images in high resolution (1024x1024) with
text-to-image consistency, but also outputs multiple diverse faces to cover a
wide range of unspecified facial features in a natural way. By fine-tuning the
multi-label classifier and image encoder, our model obtains the vectors and
image embeddings which are used to transform the input noise vector sampled
from the normal distribution. Afterwards, the transformed noise vector is fed
into a pre-trained high-resolution image generator to produce a set of faces
with the desired facial attributes. We refer to our model as TTF-HD.
Experimental results show that TTF-HD generates high-quality faces with
state-of-the-art performance.","['Tianren Wang', 'Teng Zhang', 'Brian Lovell']"
"STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action
  Recognition",Computer Vision and Pattern Recognition,"We study the problem of human action recognition using motion capture (MoCap)
sequences. Unlike existing techniques that take multiple manual steps to derive
standardized skeleton representations as model input, we propose a novel
Spatial-Temporal Mesh Transformer (STMT) to directly model the mesh sequences.
The model uses a hierarchical transformer with intra-frame off-set attention
and inter-frame self-attention. The attention mechanism allows the model to
freely attend between any two vertex patches to learn non-local relationships
in the spatial-temporal domain. Masked vertex modeling and future frame
prediction are used as two self-supervised tasks to fully activate the
bi-directional and auto-regressive attention in our hierarchical transformer.
The proposed method achieves state-of-the-art performance compared to
skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is
available at https://github.com/zgzxy001/STMT.","['Xiaoyu Zhu', 'Po-Yao Huang', 'Junwei Liang', 'Celso M. de Melo', 'Alexander Hauptmann']"
"Knowledge Distillation For Recurrent Neural Network Language Modeling
  With Trust Regularization",Computation and Language (Natural Language Processing),"Recurrent Neural Networks (RNNs) have dominated language modeling because of
their superior performance over traditional N-gram based models. In many
applications, a large Recurrent Neural Network language model (RNNLM) or an
ensemble of several RNNLMs is used. These models have large memory footprints
and require heavy computation. In this paper, we examine the effect of applying
knowledge distillation in reducing the model size for RNNLMs. In addition, we
propose a trust regularization method to improve the knowledge distillation
training for RNNLMs. Using knowledge distillation with trust regularization, we
reduce the parameter size to a third of that of the previously published best
model while maintaining the state-of-the-art perplexity result on Penn Treebank
data. In a speech recognition N-bestrescoring task, we reduce the RNNLM model
size to 18.5% of the baseline system, with no degradation in word error
rate(WER) performance on Wall Street Journal data set.","['Yangyang Shi', 'Mei-Yuh Hwang', 'Xin Lei', 'Haoyu Sheng']"
A resource-efficient method for repeated HPO and NAS problems,Machine Learning,"In this work we consider the problem of repeated hyperparameter and neural
architecture search (HNAS). We propose an extension of Successive Halving that
is able to leverage information gained in previous HNAS problems with the goal
of saving computational resources. We empirically demonstrate that our solution
is able to drastically decrease costs while maintaining accuracy and being
robust to negative transfer. Our method is significantly simpler than competing
transfer learning approaches, setting a new baseline for transfer learning in
HNAS.","['Giovanni Zappella', 'David Salinas', 'Cédric Archambeau']"
Stochastic Attribute-Value Grammars,Computation and Language (Legacy category),"Probabilistic analogues of regular and context-free grammars are well-known
in computational linguistics, and currently the subject of intensive research.
To date, however, no satisfactory probabilistic analogue of attribute-value
grammars has been proposed: previous attempts have failed to define a correct
parameter-estimation algorithm.
  In the present paper, I define stochastic attribute-value grammars and give a
correct algorithm for estimating their parameters. The estimation algorithm is
adapted from Della Pietra, Della Pietra, and Lafferty (1995). To estimate model
parameters, it is necessary to compute the expectations of certain functions
under random fields. In the application discussed by Della Pietra, Della
Pietra, and Lafferty (representing English orthographic constraints), Gibbs
sampling can be used to estimate the needed expectations. The fact that
attribute-value grammars generate constrained languages makes Gibbs sampling
inapplicable, but I show how a variant of Gibbs sampling, the
Metropolis-Hastings algorithm, can be used instead.",['Steven Abney']
"Learning Symbolic Representations Through Joint GEnerative and
  DIscriminative Training",Machine Learning,"We introduce GEDI, a Bayesian framework that combines existing
self-supervised learning objectives with likelihood-based generative models.
This framework leverages the benefits of both GEnerative and DIscriminative
approaches, resulting in improved symbolic representations over standalone
solutions. Additionally, GEDI can be easily integrated and trained jointly with
existing neuro-symbolic frameworks without the need for additional supervision
or costly pre-training steps. We demonstrate through experiments on real-world
data, including SVHN, CIFAR10, and CIFAR100, that GEDI outperforms existing
self-supervised learning strategies in terms of clustering performance by a
significant margin. The symbolic component further allows it to leverage
knowledge in the form of logical constraints to improve performance in the
small data regime.","['Emanuele Sansone', 'Robin Manhaeve']"
"DELFI: Deep Mixture Models for Long-term Air Quality Forecasting in the
  Delhi National Capital Region",Machine Learning,"The identification and control of human factors in climate change is a
rapidly growing concern and robust, real-time air-quality monitoring and
forecasting plays a critical role in allowing effective policy formulation and
implementation. This paper presents DELFI, a novel deep learning-based mixture
model to make effective long-term predictions of Particulate Matter (PM) 2.5
concentrations. A key novelty in DELFI is its multi-scale approach to the
forecasting problem. The observation that point predictions are more suitable
in the short-term and probabilistic predictions in the long-term allows
accurate predictions to be made as much as 24 hours in advance. DELFI
incorporates meteorological data as well as pollutant-based features to ensure
a robust model that is divided into two parts: (i) a stack of three Long
Short-Term Memory (LSTM) networks that perform differential modelling of the
same window of past data, and (ii) a fully-connected layer enabling attention
to each of the components. Experimental evaluation based on deployment of 13
stations in the Delhi National Capital Region (Delhi-NCR) in India establishes
that DELFI offers far superior predictions especially in the long-term as
compared to even non-parametric baselines. The Delhi-NCR recorded the 3rd
highest PM levels amongst 39 mega-cities across the world during 2011-2015 and
DELFI's performance establishes it as a potential tool for effective long-term
forecasting of PM levels to enable public health management and environment
protection.","['Naishadh Parmar', 'Raunak Shah', 'Tushar Goswamy', 'Vatsalya Tandon', 'Ravi Sahu', 'Ronak Sutaria', 'Purushottam Kar', 'Sachchida Nand Tripathi']"
Towards Best Experiment Design for Evaluating Dialogue System Output,Computation and Language (Natural Language Processing),"To overcome the limitations of automated metrics (e.g. BLEU, METEOR) for
evaluating dialogue systems, researchers typically use human judgments to
provide convergent evidence. While it has been demonstrated that human
judgments can suffer from the inconsistency of ratings, extant research has
also found that the design of the evaluation task affects the consistency and
quality of human judgments. We conduct a between-subjects study to understand
the impact of four experiment conditions on human ratings of dialogue system
output. In addition to discrete and continuous scale ratings, we also
experiment with a novel application of Best-Worst scaling to dialogue
evaluation. Through our systematic study with 40 crowdsourced workers in each
task, we find that using continuous scales achieves more consistent ratings
than Likert scale or ranking-based experiment design. Additionally, we find
that factors such as time taken to complete the task and no prior experience of
participating in similar studies of rating dialogue system output positively
impact consistency and agreement amongst raters","['Sashank Santhanam', 'Samira Shaikh']"
A Deep Gradient Boosting Network for Optic Disc and Cup Segmentation,Computer Vision and Pattern Recognition,"Segmentation of optic disc (OD) and optic cup (OC) is critical in automated
fundus image analysis system. Existing state-of-the-arts focus on designing
deep neural networks with one or multiple dense prediction branches. Such kind
of designs ignore connections among prediction branches and their learning
capacity is limited. To build connections among prediction branches, this paper
introduces gradient boosting framework to deep classification model and
proposes a gradient boosting network called BoostNet. Specifically, deformable
side-output unit and aggregation unit with deep supervisions are proposed to
learn base functions and expansion coefficients in gradient boosting framework.
By stacking aggregation units in a deep-to-shallow manner, models' performances
are gradually boosted along deep to shallow stages. BoostNet achieves superior
results to existing deep OD and OC segmentation networks on the public dataset
ORIGA.","['Qing Liu', 'Beiji Zou', 'Yang Zhao', 'Yixiong Liang']"
On sample complexity of neural networks,Machine Learning,"We consider functions defined by deep neural networks as definable objects in
an o-miminal expansion of the real field, and derive an almost linear (in the
number of weights) bound on sample complexity of such networks.",['Alexander Usvyatsov']
Refining the ONCE Benchmark with Hyperparameter Tuning,Computer Vision and Pattern Recognition,"In response to the growing demand for 3D object detection in applications
such as autonomous driving, robotics, and augmented reality, this work focuses
on the evaluation of semi-supervised learning approaches for point cloud data.
The point cloud representation provides reliable and consistent observations
regardless of lighting conditions, thanks to advances in LiDAR sensors. Data
annotation is of paramount importance in the context of LiDAR applications, and
automating 3D data annotation with semi-supervised methods is a pivotal
challenge that promises to reduce the associated workload and facilitate the
emergence of cost-effective LiDAR solutions. Nevertheless, the task of
semi-supervised learning in the context of unordered point cloud data remains
formidable due to the inherent sparsity and incomplete shapes that hinder the
generation of accurate pseudo-labels. In this study, we consider these
challenges by posing the question: ""To what extent does unlabelled data
contribute to the enhancement of model performance?"" We show that improvements
from previous semi-supervised methods may not be as profound as previously
thought. Our results suggest that simple grid search hyperparameter tuning
applied to a supervised model can lead to state-of-the-art performance on the
ONCE dataset, while the contribution of unlabelled data appears to be
comparatively less exceptional.","['Maksim Golyadkin', 'Alexander Gambashidze', 'Ildar Nurgaliev', 'Ilya Makarov']"
"Automatic Identification and Data Extraction from 2-Dimensional Plots in
  Digital Documents",Computer Vision and Pattern Recognition,"Most search engines index the textual content of documents in digital
libraries. However, scholarly articles frequently report important findings in
figures for visual impact and the contents of these figures are not indexed.
These contents are often invaluable to the researcher in various fields, for
the purposes of direct comparison with their own work. Therefore, searching for
figures and extracting figure data are important problems. To the best of our
knowledge, there exists no tool to automatically extract data from figures in
digital documents. If we can extract data from these images automatically and
store them in a database, an end-user can query and combine data from multiple
digital documents simultaneously and efficiently. We propose a framework based
on image analysis and machine learning to extract information from 2-D plot
images and store them in a database. The proposed algorithm identifies a 2-D
plot and extracts the axis labels, legend and the data points from the 2-D
plot. We also segregate overlapping shapes that correspond to different data
points. We demonstrate performance of individual algorithms, using a
combination of generated and real-life images.","['William Brouwer', 'Saurabh Kataria', 'Sujatha Das', 'Prasenjit Mitra', 'C. L. Giles']"
"Estimator: An Effective and Scalable Framework for Transportation Mode
  Classification over Trajectories",Machine Learning,"Transportation mode classification, the process of predicting the class
labels of moving objects transportation modes, has been widely applied to a
variety of real world applications, such as traffic management, urban
computing, and behavior study. However, existing studies of transportation mode
classification typically extract the explicit features of trajectory data but
fail to capture the implicit features that affect the classification
performance. In addition, most of the existing studies also prefer to apply
RNN-based models to embed trajectories, which is only suitable for classifying
small-scale data. To tackle the above challenges, we propose an effective and
scalable framework for transportation mode classification over GPS
trajectories, abbreviated Estimator. Estimator is established on a developed
CNN-TCN architecture, which is capable of leveraging the spatial and temporal
hidden features of trajectories to achieve high effectiveness and efficiency.
Estimator partitions the entire traffic space into disjointed spatial regions
according to traffic conditions, which enhances the scalability significantly
and thus enables parallel transportation classification. Extensive experiments
using eight public real-life datasets offer evidence that Estimator i) achieves
superior model effectiveness (i.e., 99% Accuracy and 0.98 F1-score), which
outperforms state-of-the-arts substantially; ii) exhibits prominent model
efficiency, and obtains 7-40x speedups up over state-of-the-arts learning-based
methods; and iii) shows high model scalability and robustness that enables
large-scale classification analytics.","['Danlei Hu', 'Ziquan Fang', 'Hanxi Fang', 'Tianyi Li', 'Chunhui Shen', 'Lu Chen', 'Yunjun Gao']"
Statistical Limits for Testing Correlation of Hypergraphs,Statistics Theory,"In this paper, we consider the hypothesis testing of correlation between two
$m$-uniform hypergraphs on $n$ unlabelled nodes. Under the null hypothesis, the
hypergraphs are independent, while under the alternative hypothesis, the
hyperdges have the same marginal distributions as in the null hypothesis but
are correlated after some unknown node permutation. We focus on two scenarios:
the hypergraphs are generated from the Gaussian-Wigner model and the dense
Erd\""{o}s-R\'{e}nyi model. We derive the sharp information-theoretic testing
threshold. Above the threshold, there exists a powerful test to distinguish the
alternative hypothesis from the null hypothesis. Below the threshold, the
alternative hypothesis and the null hypothesis are not distinguishable. The
threshold involves $m$ and decreases as $m$ gets larger. This indicates testing
correlation of hypergraphs ($m\geq3$) becomes easier than testing correlation
of graphs ($m=2$)","['Mingao Yuan', 'Zuofeng Shang']"
A note on the Declarative reading(s) of Logic Programming,Logic in Computer Science,"This paper analyses the declarative readings of logic programming. Logic
programming - and negation as failure - has no unique declarative reading. One
common view is that logic programming is a logic for default reasoning, a
sub-formalism of default logic or autoepistemic logic. In this view, negation
as failure is a modal operator. In an alternative view, a logic program is
interpreted as a definition. In this view, negation as failure is classical
objective negation. From a commonsense point of view, there is definitely a
difference between these views. Surprisingly though, both types of declarative
readings lead to grosso modo the same model semantics. This note investigates
the causes for this.",['Marc Denecker']
"Children's Acquisition of Tail-recursion Sequences: A Review of Locative
  Recursion and Possessive Recursion as Examples",Neural and Evolutionary Computing,"Recursion is the nature of human natural language. Since Chomsky proposed
generative grammar, many scholars have studied recursion either theoretically
or empirically. However, by observing children's acquisition of tail recursion
sequences, we can verify the nativism of language supported by universal
grammar and reveal the cognitive mechanism of human brain. To date, our
understanding of children's acquisition path of recursion and influencing
factors still remain controversial. This systematic review summarizes the
research of tail recursive sequence by taking possessive recursion and locative
recursion as examples, focusing on the experimental methods, acquisition paths,
and influencing factors of tail recursive sequence. The current behavioural
experiments reveal that, the debate about children's performance revolves
around: 1) Gradual acquisition or synchronous acquisition. 2) symmetry or
asymmetry between the acquisition of locative recursion sequences and
possessive recursion sequences. We presume that children can acquire recursion
quickly in a short period of time thanks to the language acquisition device,
though there are also scholars who believe that a third factor also plays a
role.","['Xiaoyi Wang', 'Chenxi Fu', 'Caimei Yang', 'Ziman Zhuang']"
NNrepair: Constraint-based Repair of Neural Network Classifiers,Machine Learning,"We present NNrepair, a constraint-based technique for repairing neural
network classifiers. The technique aims to fix the logic of the network at an
intermediate layer or at the last layer. NNrepair first uses fault localization
to find potentially faulty network parameters (such as the weights) and then
performs repair using constraint solving to apply small modifications to the
parameters to remedy the defects. We present novel strategies to enable precise
yet efficient repair such as inferring correctness specifications to act as
oracles for intermediate layer repair, and generation of experts for each
class. We demonstrate the technique in the context of three different
scenarios: (1) Improving the overall accuracy of a model, (2) Fixing security
vulnerabilities caused by poisoning of training data and (3) Improving the
robustness of the network against adversarial attacks. Our evaluation on MNIST
and CIFAR-10 models shows that NNrepair can improve the accuracy by 45.56
percentage points on poisoned data and 10.40 percentage points on adversarial
data. NNrepair also provides small improvement in the overall accuracy of
models, without requiring new data or re-training.","['Muhammad Usman', 'Divya Gopinath', 'Youcheng Sun', 'Yannic Noller', 'Corina Pasareanu']"
Thompson Sampling for Noncompliant Bandits,Machine Learning,"Thompson sampling, a Bayesian method for balancing exploration and
exploitation in bandit problems, has theoretical guarantees and exhibits strong
empirical performance in many domains. Traditional Thompson sampling, however,
assumes perfect compliance, where an agent's chosen action is treated as the
implemented action. This article introduces a stochastic noncompliance model
that relaxes this assumption. We prove that any noncompliance in a 2-armed
Bernoulli bandit increases existing regret bounds. With our noncompliance
model, we derive Thompson sampling variants that explicitly handle both
observed and latent noncompliance. With extensive empirical analysis, we
demonstrate that our algorithms either match or outperform traditional Thompson
sampling in both compliant and noncompliant environments.","['Andrew Stirn', 'Tony Jebara']"
Re-identification from histopathology images,Computer Vision and Pattern Recognition,"In numerous studies, deep learning algorithms have proven their potential for
the analysis of histopathology images, for example, for revealing the subtypes
of tumors or the primary origin of metastases. These models require large
datasets for training, which must be anonymized to prevent possible patient
identity leaks. This study demonstrates that even relatively simple deep
learning algorithms can re-identify patients in large histopathology datasets
with substantial accuracy. We evaluated our algorithms on two TCIA datasets
including lung squamous cell carcinoma (LSCC) and lung adenocarcinoma (LUAD).
We also demonstrate the algorithm's performance on an in-house dataset of
meningioma tissue. We predicted the source patient of a slide with F1 scores of
50.16 % and 52.30 % on the LSCC and LUAD datasets, respectively, and with 62.31
% on our meningioma dataset. Based on our findings, we formulated a risk
assessment scheme to estimate the risk to the patient's privacy prior to
publication.","['Jonathan Ganz', 'Jonas Ammeling', 'Samir Jabari', 'Katharina Breininger', 'Marc Aubreville']"
"Latent Field Discovery In Interacting Dynamical Systems With Neural
  Fields",Machine Learning,"Systems of interacting objects often evolve under the influence of field
effects that govern their dynamics, yet previous works have abstracted away
from such effects, and assume that systems evolve in a vacuum. In this work, we
focus on discovering these fields, and infer them from the observed dynamics
alone, without directly observing them. We theorize the presence of latent
force fields, and propose neural fields to learn them. Since the observed
dynamics constitute the net effect of local object interactions and global
field effects, recently popularized equivariant networks are inapplicable, as
they fail to capture global information. To address this, we propose to
disentangle local object interactions -- which are $\mathrm{SE}(n)$ equivariant
and depend on relative states -- from external global field effects -- which
depend on absolute states. We model interactions with equivariant graph
networks, and combine them with neural fields in a novel graph network that
integrates field forces. Our experiments show that we can accurately discover
the underlying fields in charged particles settings, traffic scenes, and
gravitational n-body problems, and effectively use them to learn the system and
forecast future trajectories.","['Miltiadis Kofinas', 'Erik J. Bekkers', 'Naveen Shankar Nagaraja', 'Efstratios Gavves']"
Deep Neural Machine Translation with Weakly-Recurrent Units,Computation and Language (Natural Language Processing),"Recurrent neural networks (RNNs) have represented for years the state of the
art in neural machine translation. Recently, new architectures have been
proposed, which can leverage parallel computation on GPUs better than classical
RNNs. Faster training and inference combined with different
sequence-to-sequence modeling also lead to performance improvements. While the
new models completely depart from the original recurrent architecture, we
decided to investigate how to make RNNs more efficient. In this work, we
propose a new recurrent NMT architecture, called Simple Recurrent NMT, built on
a class of fast and weakly-recurrent units that use layer normalization and
multiple attentions. Our experiments on the WMT14 English-to-German and WMT16
English-Romanian benchmarks show that our model represents a valid alternative
to LSTMs, as it can achieve better results at a significantly lower
computational cost.","['Mattia Antonino Di Gangi', 'Marcello Federico']"
Top-N: Equivariant set and graph generation without exchangeability,Machine Learning,"This work addresses one-shot set and graph generation, and, more
specifically, the parametrization of probabilistic decoders that map a
vector-shaped prior to a distribution over sets or graphs. Sets and graphs are
most commonly generated by first sampling points i.i.d. from a normal
distribution, and then processing these points along with the prior vector
using Transformer layers or Graph Neural Networks. This architecture is
designed to generate exchangeable distributions, i.e., all permutations of the
generated outputs are equally likely. We however show that it only optimizes a
proxy to the evidence lower bound, which makes it hard to train. We then study
equivariance in generative settings and show that non-exchangeable methods can
still achieve permutation equivariance. Using this result, we introduce Top-n
creation, a differentiable generation mechanism that uses the latent vector to
select the most relevant points from a trainable reference set. Top-n can
replace i.i.d. generation in any Variational Autoencoder or Generative
Adversarial Network. Experimentally, our method outperforms i.i.d. generation
by 15% at SetMNIST reconstruction, by 33% at object detection on CLEVR,
generates sets that are 74% closer to the true distribution on a synthetic
molecule-like dataset, and generates more valid molecules on QM9.","['Clement Vignac', 'Pascal Frossard']"
Non-Autoregressive Neural Machine Translation,Computation and Language (Natural Language Processing),"Existing approaches to neural machine translation condition each output word
on previously generated outputs. We introduce a model that avoids this
autoregressive property and produces its outputs in parallel, allowing an order
of magnitude lower latency during inference. Through knowledge distillation,
the use of input token fertilities as a latent variable, and policy gradient
fine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative
to the autoregressive Transformer network used as a teacher. We demonstrate
substantial cumulative improvements associated with each of the three aspects
of our training strategy, and validate our approach on IWSLT 2016
English-German and two WMT language pairs. By sampling fertilities in parallel
at inference time, our non-autoregressive model achieves near-state-of-the-art
performance of 29.8 BLEU on WMT 2016 English-Romanian.","['Jiatao Gu', 'James Bradbury', 'Caiming Xiong', 'Victor O. K. Li', 'Richard Socher']"
Escaping Saddle Points Faster with Stochastic Momentum,Machine Learning,"Stochastic gradient descent (SGD) with stochastic momentum is popular in
nonconvex stochastic optimization and particularly for the training of deep
neural networks. In standard SGD, parameters are updated by improving along the
path of the gradient at the current iterate on a batch of examples, where the
addition of a ``momentum'' term biases the update in the direction of the
previous change in parameters. In non-stochastic convex optimization one can
show that a momentum adjustment provably reduces convergence time in many
settings, yet such results have been elusive in the stochastic and non-convex
settings. At the same time, a widely-observed empirical phenomenon is that in
training deep networks stochastic momentum appears to significantly improve
convergence time, variants of it have flourished in the development of other
popular update methods, e.g. ADAM [KB15], AMSGrad [RKK18], etc. Yet theoretical
justification for the use of stochastic momentum has remained a significant
open question. In this paper we propose an answer: stochastic momentum improves
deep network training because it modifies SGD to escape saddle points faster
and, consequently, to more quickly find a second order stationary point. Our
theoretical results also shed light on the related question of how to choose
the ideal momentum parameter--our analysis suggests that $\beta \in [0,1)$
should be large (close to 1), which comports with empirical findings. We also
provide experimental findings that further validate these conclusions.","['Jun-Kun Wang', 'Chi-Heng Lin', 'Jacob Abernethy']"
"Online Coreference Resolution for Dialogue Processing: Improving
  Mention-Linking on Real-Time Conversations",Computation and Language (Natural Language Processing),"This paper suggests a direction of coreference resolution for online decoding
on actively generated input such as dialogue, where the model accepts an
utterance and its past context, then finds mentions in the current utterance as
well as their referents, upon each dialogue turn. A baseline and four
incremental-updated models adapted from the mention-linking paradigm are
proposed for this new setting, which address different aspects including the
singletons, speaker-grounded encoding and cross-turn mention contextualization.
Our approach is assessed on three datasets: Friends, OntoNotes, and BOLT.
Results show that each aspect brings out steady improvement, and our best
models outperform the baseline by over 10%, presenting an effective system for
this setting. Further analysis highlights the task characteristics, such as the
significance of addressing the mention recall.","['Liyan Xu', 'Jinho D. Choi']"
"Performance of Data Augmentation Methods for Brazilian Portuguese Text
  Classification",Computation and Language (Natural Language Processing),"Improving machine learning performance while increasing model generalization
has been a constantly pursued goal by AI researchers. Data augmentation
techniques are often used towards achieving this target, and most of its
evaluation is made using English corpora. In this work, we took advantage of
different existing data augmentation methods to analyze their performances
applied to text classification problems using Brazilian Portuguese corpora. As
a result, our analysis shows some putative improvements in using some of these
techniques; however, it also suggests further exploitation of language bias and
non-English text data scarcity.","['Marcellus Amadeus', 'Paulo Branco']"
"Using Regular Languages to Explore the Representational Capacity of
  Recurrent Neural Architectures",Machine Learning,"The presence of Long Distance Dependencies (LDDs) in sequential data poses
significant challenges for computational models. Various recurrent neural
architectures have been designed to mitigate this issue. In order to test these
state-of-the-art architectures, there is growing need for rich benchmarking
datasets. However, one of the drawbacks of existing datasets is the lack of
experimental control with regards to the presence and/or degree of LDDs. This
lack of control limits the analysis of model performance in relation to the
specific challenge posed by LDDs. One way to address this is to use synthetic
data having the properties of subregular languages. The degree of LDDs within
the generated data can be controlled through the k parameter, length of the
generated strings, and by choosing appropriate forbidden strings. In this
paper, we explore the capacity of different RNN extensions to model LDDs, by
evaluating these models on a sequence of SPk synthesized datasets, where each
subsequent dataset exhibits a longer degree of LDD. Even though SPk are simple
languages, the presence of LDDs does have significant impact on the performance
of recurrent neural architectures, thus making them prime candidate in
benchmarking tasks.","['Abhijit Mahalunkar', 'John D. Kelleher']"
Deep Learning with Gaussian Differential Privacy,Machine Learning,"Deep learning models are often trained on datasets that contain sensitive
information such as individuals' shopping transactions, personal contacts, and
medical records. An increasingly important line of work therefore has sought to
train neural networks subject to privacy constraints that are specified by
differential privacy or its divergence-based relaxations. These privacy
definitions, however, have weaknesses in handling certain important primitives
(composition and subsampling), thereby giving loose or complicated privacy
analyses of training neural networks. In this paper, we consider a recently
proposed privacy definition termed \textit{$f$-differential privacy} [18] for a
refined privacy analysis of training neural networks. Leveraging the appealing
properties of $f$-differential privacy in handling composition and subsampling,
this paper derives analytically tractable expressions for the privacy
guarantees of both stochastic gradient descent and Adam used in training deep
neural networks, without the need of developing sophisticated techniques as [3]
did. Our results demonstrate that the $f$-differential privacy framework allows
for a new privacy analysis that improves on the prior analysis~[3], which in
turn suggests tuning certain parameters of neural networks for a better
prediction accuracy without violating the privacy budget. These theoretically
derived improvements are confirmed by our experiments in a range of tasks in
image classification, text classification, and recommender systems. Python code
to calculate the privacy cost for these experiments is publicly available in
the \texttt{TensorFlow Privacy} library.","['Zhiqi Bu', 'Jinshuo Dong', 'Qi Long', 'Weijie J. Su']"
A Probabilistic approach for Learning Embeddings without Supervision,Computer Vision and Pattern Recognition,"For challenging machine learning problems such as zero-shot learning and
fine-grained categorization, embedding learning is the machinery of choice
because of its ability to learn generic notions of similarity, as opposed to
class-specific concepts in standard classification models. Embedding learning
aims at learning discriminative representations of data such that similar
examples are pulled closer, while pushing away dissimilar ones. Despite their
exemplary performances, supervised embedding learning approaches require huge
number of annotations for training. This restricts their applicability for
large datasets in new applications where obtaining labels require extensive
manual efforts and domain knowledge. In this paper, we propose to learn an
embedding in a completely unsupervised manner without using any class labels.
Using a graph-based clustering approach to obtain pseudo-labels, we form
triplet-based constraints following a metric learning paradigm. Our novel
embedding learning approach uses a probabilistic notion, that intuitively
minimizes the chances of each triplet violating a geometric constraint. Due to
nature of the search space, we learn the parameters of our approach using
Riemannian geometry. Our proposed approach performs competitive to
state-of-the-art approaches.","['Ujjal Kr Dutta', 'Mehrtash Harandi', 'Chandra Sekhar Chellu']"
"DEPTWEET: A Typology for Social Media Texts to Detect Depression
  Severities",Computation and Language (Natural Language Processing),"Mental health research through data-driven methods has been hindered by a
lack of standard typology and scarcity of adequate data. In this study, we
leverage the clinical articulation of depression to build a typology for social
media texts for detecting the severity of depression. It emulates the standard
clinical assessment procedure Diagnostic and Statistical Manual of Mental
Disorders (DSM-5) and Patient Health Questionnaire (PHQ-9) to encompass subtle
indications of depressive disorders from tweets. Along with the typology, we
present a new dataset of 40191 tweets labeled by expert annotators. Each tweet
is labeled as 'non-depressed' or 'depressed'. Moreover, three severity levels
are considered for 'depressed' tweets: (1) mild, (2) moderate, and (3) severe.
An associated confidence score is provided with each label to validate the
quality of annotation. We examine the quality of the dataset via representing
summary statistics while setting strong baseline results using attention-based
models like BERT and DistilBERT. Finally, we extensively address the
limitations of the study to provide directions for further research.","['Mohsinul Kabir', 'Tasnim Ahmed', 'Md. Bakhtiar Hasan', 'Md Tahmid Rahman Laskar', 'Tarun Kumar Joarder', 'Hasan Mahmud', 'Kamrul Hasan']"
"Self-supervised Incremental Deep Graph Learning for Ethereum Phishing
  Scam Detection",Machine Learning,"In recent years, phishing scams have become the crime type with the largest
money involved on Ethereum, the second-largest blockchain platform. Meanwhile,
graph neural network (GNN) has shown promising performance in various node
classification tasks. However, for Ethereum transaction data, which could be
naturally abstracted to a real-world complex graph, the scarcity of labels and
the huge volume of transaction data make it difficult to take advantage of GNN
methods. Here in this paper, to address the two challenges, we propose a
Self-supervised Incremental deep Graph learning model (SIEGE), for the phishing
scam detection problem on Ethereum. In our model, two pretext tasks designed
from spatial and temporal perspectives help us effectively learn useful node
embedding from the huge amount of unlabelled transaction data. And the
incremental paradigm allows us to efficiently handle large-scale transaction
data and help the model maintain good performance when the data distribution is
drastically changing. We collect transaction records about half a year from
Ethereum and our extensive experiments show that our model consistently
outperforms strong baselines in both transductive and inductive settings.","['Shucheng Li', 'Fengyuan Xu', 'Runchuan Wang', 'Sheng Zhong']"
"Finding Optimal Points for Expensive Functions Using Adaptive RBF-Based
  Surrogate Model Via Uncertainty Quantification",Machine Learning (Statistics),"Global optimization of expensive functions has important applications in
physical and computer experiments. It is a challenging problem to develop
efficient optimization scheme, because each function evaluation can be costly
and the derivative information of the function is often not available. We
propose a novel global optimization framework using adaptive Radial Basis
Functions (RBF) based surrogate model via uncertainty quantification. The
framework consists of two iteration steps. It first employs an RBF-based
Bayesian surrogate model to approximate the true function, where the parameters
of the RBFs can be adaptively estimated and updated each time a new point is
explored. Then it utilizes a model-guided selection criterion to identify a new
point from a candidate set for function evaluation. The selection criterion
adopted here is a sample version of the expected improvement (EI) criterion. We
conduct simulation studies with standard test functions, which show that the
proposed method has some advantages, especially when the true surface is not
very smooth. In addition, we also propose modified approaches to improve the
search performance for identifying global optimal points and to deal with the
higher dimension scenarios.","['Ray-Bing Chen', 'Yuan Wang', 'C. F. Jeff Wu']"
Language Identification with a Reciprocal Rank Classifier,Computation and Language (Natural Language Processing),"Language identification is a critical component of language processing
pipelines (Jauhiainen et al.,2019) and is not a solved problem in real-world
settings. We present a lightweight and effective language identifier that is
robust to changes of domain and to the absence of copious training data.
  The key idea for classification is that the reciprocal of the rank in a
frequency table makes an effective additive feature score, hence the term
Reciprocal Rank Classifier (RRC). The key finding for language classification
is that ranked lists of words and frequencies of characters form a sufficient
and robust representation of the regularities of key languages and their
orthographies.
  We test this on two 22-language data sets and demonstrate zero-effort domain
adaptation from a Wikipedia training set to a Twitter test set. When trained on
Wikipedia but applied to Twitter the macro-averaged F1-score of a
conventionally trained SVM classifier drops from 90.9% to 77.7%. By contrast,
the macro F1-score of RRC drops only from 93.1% to 90.6%. These classifiers are
compared with those from fastText and langid. The RRC performs better than
these established systems in most experiments, especially on short Wikipedia
texts and Twitter.
  The RRC classifier can be improved for particular domains and conversational
situations by adding words to the ranked lists. Using new terms learned from
such conversations, we demonstrate a further 7.9% increase in accuracy of
sample message classification, and 1.7% increase for conversation
classification. Surprisingly, this made results on Twitter data slightly worse.
  The RRC classifier is available as an open source Python package
(https://github.com/LivePersonInc/lplangid).","['Dominic Widdows', 'Chris Brew']"
"Characterizing classification datasets: a study of meta-features for
  meta-learning",Machine Learning,"Meta-learning is increasingly used to support the recommendation of machine
learning algorithms and their configurations. Such recommendations are made
based on meta-data, consisting of performance evaluations of algorithms on
prior datasets, as well as characterizations of these datasets. These
characterizations, also called meta-features, describe properties of the data
which are predictive for the performance of machine learning algorithms trained
on them. Unfortunately, despite being used in a large number of studies,
meta-features are not uniformly described, organized and computed, making many
empirical studies irreproducible and hard to compare. This paper aims to deal
with this by systematizing and standardizing data characterization measures for
classification datasets used in meta-learning. Moreover, it presents MFE, a new
tool for extracting meta-features from datasets and identifying more subtle
reproducibility issues in the literature, proposing guidelines for data
characterization that strengthen reproducible empirical research in
meta-learning.","['Adriano Rivolli', 'Luís P. F. Garcia', 'Carlos Soares', 'Joaquin Vanschoren', 'André C. P. L. F. de Carvalho']"
"Online Learning in Case of Unbounded Losses Using the Follow Perturbed
  Leader Algorithm",Machine Learning,"In this paper the sequential prediction problem with expert advice is
considered for the case where losses of experts suffered at each step cannot be
bounded in advance. We present some modification of Kalai and Vempala algorithm
of following the perturbed leader where weights depend on past losses of the
experts. New notions of a volume and a scaled fluctuation of a game are
introduced. We present a probabilistic algorithm protected from unrestrictedly
large one-step losses. This algorithm has the optimal performance in the case
when the scaled fluctuations of one-step losses of experts of the pool tend to
zero.","[""Vladimir V. V'yugin""]"
Bayesian interpretation of SGD as Ito process,Machine Learning (Statistics),"The current interpretation of stochastic gradient descent (SGD) as a
stochastic process lacks generality in that its numerical scheme restricts
continuous-time dynamics as well as the loss function and the distribution of
gradient noise. We introduce a simplified scheme with milder conditions that
flexibly interprets SGD as a discrete-time approximation of an Ito process. The
scheme also works as a common foundation of SGD and stochastic gradient
Langevin dynamics (SGLD), providing insights into their asymptotic properties.
We investigate the convergence of SGD with biased gradient in terms of the
equilibrium mode and the overestimation problem of the second moment of SGLD.","['Soma Yokoi', 'Issei Sato']"
Evolution Transformer: In-Context Evolutionary Optimization,Artificial Intelligence,"Evolutionary optimization algorithms are often derived from loose biological
analogies and struggle to leverage information obtained during the sequential
course of optimization. An alternative promising approach is to leverage data
and directly discover powerful optimization principles via meta-optimization.
In this work, we follow such a paradigm and introduce Evolution Transformer, a
causal Transformer architecture, which can flexibly characterize a family of
Evolution Strategies. Given a trajectory of evaluations and search distribution
statistics, Evolution Transformer outputs a performance-improving update to the
search distribution. The architecture imposes a set of suitable inductive
biases, i.e. the invariance of the distribution update to the order of
population members within a generation and equivariance to the order of the
search dimensions. We train the model weights using Evolutionary Algorithm
Distillation, a technique for supervised optimization of sequence models using
teacher algorithm trajectories. The resulting model exhibits strong in-context
optimization performance and shows strong generalization capabilities to
otherwise challenging neuroevolution tasks. We analyze the resulting properties
of the Evolution Transformer and propose a technique to fully
self-referentially train the Evolution Transformer, starting from a random
initialization and bootstrapping its own learning progress. We provide an open
source implementation under https://github.com/RobertTLange/evosax.","['Robert Tjarko Lange', 'Yingtao Tian', 'Yujin Tang']"
"Weakly Supervised Volumetric Segmentation via Self-taught Shape
  Denoising Model",Computer Vision and Pattern Recognition,"Weakly supervised segmentation is an important problem in medical image
analysis due to the high cost of pixelwise annotation. Prior methods, while
often focusing on weak labels of 2D images, exploit few structural cues of
volumetric medical images. To address this, we propose a novel
weakly-supervised segmentation strategy capable of better capturing 3D shape
prior in both model prediction and learning. Our main idea is to extract a
self-taught shape representation by leveraging weak labels, and then integrate
this representation into segmentation prediction for shape refinement. To this
end, we design a deep network consisting of a segmentation module and a shape
denoising module, which are trained by an iterative learning strategy.
Moreover, we introduce a weak annotation scheme with a hybrid label design for
volumetric images, which improves model learning without increasing the overall
annotation cost. The empirical experiments show that our approach outperforms
existing SOTA strategies on three organ segmentation benchmarks with
distinctive shape properties. Notably, we can achieve strong performance with
even 10\% labeled slices, which is significantly superior to other methods.","['Qian He', 'Shuailin Li', 'Xuming He']"
Swarm Intelligence in Semi-supervised Classification,Machine Learning,"This Paper represents a literature review of Swarm intelligence algorithm in
the area of semi-supervised classification. There are many research papers for
applying swarm intelligence algorithms in the area of machine learning. Some
algorithms of SI are applied in the area of ML either solely or hybrid with
other ML algorithms. SI algorithms are also used for tuning parameters of ML
algorithm, or as a backbone for ML algorithms. This paper introduces a brief
literature review for applying swarm intelligence algorithms in the field of
semi-supervised learning","['Shahira Shaaban Azab', 'Hesham Ahmed Hefny']"
"CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual
  Named Entity Recognition",Computation and Language (Natural Language Processing),"Cross-lingual named entity recognition (NER) aims to train an NER system that
generalizes well to a target language by leveraging labeled data in a given
source language. Previous work alleviates the data scarcity problem by
translating source-language labeled data or performing knowledge distillation
on target-language unlabeled data. However, these methods may suffer from label
noise due to the automatic labeling process. In this paper, we propose CoLaDa,
a Collaborative Label Denoising Framework, to address this problem.
Specifically, we first explore a model-collaboration-based denoising scheme
that enables models trained on different data sources to collaboratively
denoise pseudo labels used by each other. We then present an
instance-collaboration-based strategy that considers the label consistency of
each token's neighborhood in the representation space for denoising.
Experiments on different benchmark datasets show that the proposed CoLaDa
achieves superior results compared to previous methods, especially when
generalizing to distant languages.","['Tingting Ma', 'Qianhui Wu', 'Huiqiang Jiang', 'Börje F. Karlsson', 'Tiejun Zhao', 'Chin-Yew Lin']"
"Multilingual Chart-based Constituency Parse Extraction from Pre-trained
  Language Models",Computation and Language (Natural Language Processing),"As it has been unveiled that pre-trained language models (PLMs) are to some
extent capable of recognizing syntactic concepts in natural language, much
effort has been made to develop a method for extracting complete (binary)
parses from PLMs without training separate parsers. We improve upon this
paradigm by proposing a novel chart-based method and an effective top-K
ensemble technique. Moreover, we demonstrate that we can broaden the scope of
application of the approach into multilingual settings. Specifically, we show
that by applying our method on multilingual PLMs, it becomes possible to induce
non-trivial parses for sentences from nine languages in an integrated and
language-agnostic manner, attaining performance superior or comparable to that
of unsupervised PCFGs. We also verify that our approach is robust to
cross-lingual transfer. Finally, we provide analyses on the inner workings of
our method. For instance, we discover universal attention heads which are
consistently sensitive to syntactic information irrespective of the input
language.","['Taeuk Kim', 'Bowen Li', 'Sang-goo Lee']"
Self-Supervised Pretraining Improves Self-Supervised Pretraining,Computer Vision and Pattern Recognition,"While self-supervised pretraining has proven beneficial for many computer
vision tasks, it requires expensive and lengthy computation, large amounts of
data, and is sensitive to data augmentation. Prior work demonstrates that
models pretrained on datasets dissimilar to their target data, such as chest
X-ray models trained on ImageNet, underperform models trained from scratch.
Users that lack the resources to pretrain must use existing models with lower
performance. This paper explores Hierarchical PreTraining (HPT), which
decreases convergence time and improves accuracy by initializing the
pretraining process with an existing pretrained model. Through experimentation
on 16 diverse vision datasets, we show HPT converges up to 80x faster, improves
accuracy across tasks, and improves the robustness of the self-supervised
pretraining process to changes in the image augmentation policy or amount of
pretraining data. Taken together, HPT provides a simple framework for obtaining
better pretrained representations with less computational resources.","['Colorado J. Reed', 'Xiangyu Yue', 'Ani Nrusimha', 'Sayna Ebrahimi', 'Vivek Vijaykumar', 'Richard Mao', 'Bo Li', 'Shanghang Zhang', 'Devin Guillory', 'Sean Metzger', 'Kurt Keutzer', 'Trevor Darrell']"
"Is the Computation of Abstract Sameness Relations Human-Like in Neural
  Language Models?",Computation and Language (Natural Language Processing),"In recent years, deep neural language models have made strong progress in
various NLP tasks. This work explores one facet of the question whether
state-of-the-art NLP models exhibit elementary mechanisms known from human
cognition. The exploration is focused on a relatively primitive mechanism for
which there is a lot of evidence from various psycholinguistic experiments with
infants. The computation of ""abstract sameness relations"" is assumed to play an
important role in human language acquisition and processing, especially in
learning more complex grammar rules. In order to investigate this mechanism in
BERT and other pre-trained language models (PLMs), the experiment designs from
studies with infants were taken as the starting point. On this basis, we
designed experimental settings in which each element from the original studies
was mapped to a component of language models. Even though the task in our
experiments was relatively simple, the results suggest that the cognitive
faculty of computing abstract sameness relations is stronger in infants than in
all investigated PLMs.","['Lukas Thoma', 'Benjamin Roth']"
Deep Learning for Flight Demand Forecasting,Machine Learning,"Inspired by the success of deep learning (DL) in natural language processing
(NLP), we applied cutting-edge DL techniques to predict flight departure demand
in a strategic time horizon (4 hours or longer). This work was conducted in
support of a MITRE-developed mobile application, Pacer, which displays
predicted departure demand to general aviation (GA) flight operators so they
can have better situation awareness of the potential for departure delays
during busy periods. Field demonstrations involving Pacer's previously designed
rule-based prediction method showed that the prediction accuracy of departure
demand still has room for improvement. This research strives to improve
prediction accuracy from two key aspects: better data sources and robust
forecasting algorithms. We leveraged two data sources, Aviation System
Performance Metrics (ASPM) and System Wide Information Management (SWIM), as
our input. We then trained forecasting models with DL techniques of sequence to
sequence (seq2seq) and seq2seq with attention. The case study has shown that
our seq2seq with attention performs best among four forecasting algorithms
tested. In addition, with better data sources, seq2seq with attention can
reduce mean squared error (mse) over 60%, compared to the classical
autoregressive (AR) forecasting method.","['Liya Wang', 'Amy Mykityshyn', 'Craig Johnson', 'Benjamin D. Marple']"
"Knowledge-Routed Visual Question Reasoning: Challenges for Deep
  Representation Embedding",Computer Vision and Pattern Recognition,"Though beneficial for encouraging the Visual Question Answering (VQA) models
to discover the underlying knowledge by exploiting the input-output correlation
beyond image and text contexts, the existing knowledge VQA datasets are mostly
annotated in a crowdsource way, e.g., collecting questions and external reasons
from different users via the internet. In addition to the challenge of
knowledge reasoning, how to deal with the annotator bias also remains unsolved,
which often leads to superficial over-fitted correlations between questions and
answers. To address this issue, we propose a novel dataset named
Knowledge-Routed Visual Question Reasoning for VQA model evaluation.
Considering that a desirable VQA model should correctly perceive the image
context, understand the question, and incorporate its learned knowledge, our
proposed dataset aims to cutoff the shortcut learning exploited by the current
deep embedding models and push the research boundary of the knowledge-based
visual question reasoning. Specifically, we generate the question-answer pair
based on both the Visual Genome scene graph and an external knowledge base with
controlled programs to disentangle the knowledge from other biases. The
programs can select one or two triplets from the scene graph or knowledge base
to push multi-step reasoning, avoid answer ambiguity, and balanced the answer
distribution. In contrast to the existing VQA datasets, we further imply the
following two major constraints on the programs to incorporate knowledge
reasoning: i) multiple knowledge triplets can be related to the question, but
only one knowledge relates to the image object. This can enforce the VQA model
to correctly perceive the image instead of guessing the knowledge based on the
given question solely; ii) all questions are based on different knowledge, but
the candidate answers are the same for both the training and test sets.","['Qingxing Cao', 'Bailin Li', 'Xiaodan Liang', 'Keze Wang', 'Liang Lin']"
Parallel and Communication Avoiding Least Angle Regression,Machine Learning,"We are interested in parallelizing the Least Angle Regression (LARS)
algorithm for fitting linear regression models to high-dimensional data. We
consider two parallel and communication avoiding versions of the basic LARS
algorithm. The two algorithms have different asymptotic costs and practical
performance. One offers more speedup and the other produces more accurate
output. The first is bLARS, a block version of LARS algorithm, where we update
b columns at each iteration. Assuming that the data are row-partitioned, bLARS
reduces the number of arithmetic operations, latency, and bandwidth by a factor
of b. The second is Tournament-bLARS (T-bLARS), a tournament version of LARS
where processors compete by running several LARS computations in parallel to
choose b new columns to be added in the solution. Assuming that the data are
column-partitioned, T-bLARS reduces latency by a factor of b. Similarly to
LARS, our proposed methods generate a sequence of linear models. We present
extensive numerical experiments that illustrate speedups up to 4x compared to
LARS without any compromise in solution quality.","['S. Das', 'J. Demmel', 'K. Fountoulakis', 'L. Grigori', 'M. W. Mahoney', 'S. Yang']"
Multiple Instance Learning by Discriminative Training of Markov Networks,Machine Learning,"We introduce a graphical framework for multiple instance learning (MIL) based
on Markov networks. This framework can be used to model the traditional MIL
definition as well as more general MIL definitions. Different levels of
ambiguity -- the portion of positive instances in a bag -- can be explored in
weakly supervised data. To train these models, we propose a discriminative
max-margin learning algorithm leveraging efficient inference for
cardinality-based cliques. The efficacy of the proposed framework is evaluated
on a variety of data sets. Experimental results verify that encoding or
learning the degree of ambiguity can improve classification performance.","['Hossein Hajimirsadeghi', 'Jinling Li', 'Greg Mori', 'Mohammad Zaki', 'Tarek Sayed']"
Video Frame Interpolation Based on Deformable Kernel Region,Computer Vision and Pattern Recognition,"Video frame interpolation task has recently become more and more prevalent in
the computer vision field. At present, a number of researches based on deep
learning have achieved great success. Most of them are either based on optical
flow information, or interpolation kernel, or a combination of these two
methods. However, these methods have ignored that there are grid restrictions
on the position of kernel region during synthesizing each target pixel. These
limitations result in that they cannot well adapt to the irregularity of object
shape and uncertainty of motion, which may lead to irrelevant reference pixels
used for interpolation. In order to solve this problem, we revisit the
deformable convolution for video interpolation, which can break the fixed grid
restrictions on the kernel region, making the distribution of reference points
more suitable for the shape of the object, and thus warp a more accurate
interpolation frame. Experiments are conducted on four datasets to demonstrate
the superior performance of the proposed model in comparison to the
state-of-the-art alternatives.","['Haoyue Tian', 'Pan Gao', 'Xiaojiang Peng']"
"Library network, a possible path to explainable neural networks",Machine Learning,"Deep neural networks (DNNs) may outperform human brains in complex tasks, but
the lack of transparency in their decision-making processes makes us question
whether we could fully trust DNNs with high stakes problems. As DNNs'
operations rely on a massive number of both parallel and sequential
linear/nonlinear computations, predicting their mistakes is nearly impossible.
Also, a line of studies suggests that DNNs can be easily deceived by
adversarial attacks, indicating that their decisions can easily be corrupted by
unexpected factors. Such vulnerability must be overcome if we intend to take
advantage of DNNs' efficiency in high stakes problems. Here, we propose an
algorithm that can help us better understand DNNs' decision-making processes.
Our empirical evaluations suggest that this algorithm can effectively trace
DNNs' decision processes from one layer to another and detect adversarial
attacks.",['Jung Hoon Lee']
The current state of automated negotiation theory: a literature review,Artificial Intelligence,"Automated negotiation can be an efficient method for resolving conflict and
redistributing resources in a coalition setting. Automated negotiation has
already seen increased usage in fields such as e-commerce and power
distribution in smart girds, and recent advancements in opponent modelling have
proven to deliver better outcomes. However, significant barriers to more
widespread adoption remain, such as lack of predictable outcome over time and
user trust. Additionally, there have been many recent advancements in the field
of reasoning about uncertainty, which could help alleviate both those problems.
As there is no recent survey on these two fields, and specifically not on their
possible intersection we aim to provide such a survey here.","['Sam Vente', 'Angelika Kimmig', 'Alun Preece', 'Federico Cerutti']"
"LocalRQA: From Generating Data to Locally Training, Testing, and
  Deploying Retrieval-Augmented QA Systems",Computation and Language (Natural Language Processing),"Retrieval-augmented question-answering systems combine retrieval techniques
with large language models to provide answers that are more accurate and
informative. Many existing toolkits allow users to quickly build such systems
using off-the-shelf models, but they fall short in supporting researchers and
developers to customize the model training, testing, and deployment process. We
propose LocalRQA, an open-source toolkit that features a wide selection of
model training algorithms, evaluation methods, and deployment tools curated
from the latest research. As a showcase, we build QA systems using online
documentation obtained from Databricks and Faire's websites. We find 7B-models
trained and deployed using LocalRQA reach a similar performance compared to
using OpenAI's text-ada-002 and GPT-4-turbo.","['Xiao Yu', 'Yunan Lu', 'Zhou Yu']"
A Grothendieck-type inequality for local maxima,Optimization and Control,"A large number of problems in optimization, machine learning, signal
processing can be effectively addressed by suitable semidefinite programming
(SDP) relaxations. Unfortunately, generic SDP solvers hardly scale beyond
instances with a few hundreds variables (in the underlying combinatorial
problem). On the other hand, it has been observed empirically that an effective
strategy amounts to introducing a (non-convex) rank constraint, and solving the
resulting smooth optimization problem by ascent methods. This non-convex
problem has --generically-- a large number of local maxima, and the reason for
this success is therefore unclear.
  This paper provides rigorous support for this approach. For the problem of
maximizing a linear functional over the elliptope, we prove that all local
maxima are within a small gap from the SDP optimum. In several problems of
interest, arbitrarily small relative error can be achieved by taking the rank
constraint $k$ to be of order one, independently of the problem size.",['Andrea Montanari']
Taming Reasoning in Temporal Probabilistic Relational Models,Artificial Intelligence,"Evidence often grounds temporal probabilistic relational models over time,
which makes reasoning infeasible. To counteract groundings over time and to
keep reasoning polynomial by restoring a lifted representation, we present
temporal approximate merging (TAMe), which incorporates (i) clustering for
grouping submodels as well as (ii) statistical significance checks to test the
fitness of the clustering outcome. In exchange for faster runtimes, TAMe
introduces a bounded error that becomes negligible over time. Empirical results
show that TAMe significantly improves the runtime performance of inference,
while keeping errors small.","['Marcel Gehrke', 'Ralf Möller', 'Tanya Braun']"
Efficient algorithms for decision tree cross-validation,Machine Learning,"Cross-validation is a useful and generally applicable technique often
employed in machine learning, including decision tree induction. An important
disadvantage of straightforward implementation of the technique is its
computational overhead. In this paper we show that, for decision trees, the
computational overhead of cross-validation can be reduced significantly by
integrating the cross-validation with the normal decision tree induction
process. We discuss how existing decision tree algorithms can be adapted to
this aim, and provide an analysis of the speedups these adaptations may yield.
The analysis is supported by experimental results.","['Hendrik Blockeel', 'Jan Struyf']"
"Let the Pretrained Language Models ""Imagine"" for Short Texts Topic
  Modeling",Computation and Language (Natural Language Processing),"Topic models are one of the compelling methods for discovering latent
semantics in a document collection. However, it assumes that a document has
sufficient co-occurrence information to be effective. However, in short texts,
co-occurrence information is minimal, which results in feature sparsity in
document representation. Therefore, existing topic models (probabilistic or
neural) mostly fail to mine patterns from them to generate coherent topics. In
this paper, we take a new approach to short-text topic modeling to address the
data-sparsity issue by extending short text into longer sequences using
existing pre-trained language models (PLMs). Besides, we provide a simple
solution extending a neural topic model to reduce the effect of noisy
out-of-topics text generation from PLMs. We observe that our model can
substantially improve the performance of short-text topic modeling. Extensive
experiments on multiple real-world datasets under extreme data sparsity
scenarios show that our models can generate high-quality topics outperforming
state-of-the-art models.","['Pritom Saha Akash', 'Jie Huang', 'Kevin Chen-Chuan Chang']"
"Federated UCBVI: Communication-Efficient Federated Regret Minimization
  with Heterogeneous Agents",Machine Learning,"In this paper, we present the Federated Upper Confidence Bound Value
Iteration algorithm ($\texttt{Fed-UCBVI}$), a novel extension of the
$\texttt{UCBVI}$ algorithm (Azar et al., 2017) tailored for the federated
learning framework. We prove that the regret of $\texttt{Fed-UCBVI}$ scales as
$\tilde{\mathcal{O}}(\sqrt{H^3 |\mathcal{S}| |\mathcal{A}| T / M})$, with a
small additional term due to heterogeneity, where $|\mathcal{S}|$ is the number
of states, $|\mathcal{A}|$ is the number of actions, $H$ is the episode length,
$M$ is the number of agents, and $T$ is the number of episodes. Notably, in the
single-agent setting, this upper bound matches the minimax lower bound up to
polylogarithmic factors, while in the multi-agent scenario,
$\texttt{Fed-UCBVI}$ has linear speed-up. To conduct our analysis, we introduce
a new measure of heterogeneity, which may hold independent theoretical
interest. Furthermore, we show that, unlike existing federated reinforcement
learning approaches, $\texttt{Fed-UCBVI}$'s communication complexity only
marginally increases with the number of agents.","['Safwan Labbi', 'Daniil Tiapkin', 'Lorenzo Mancini', 'Paul Mangold', 'Eric Moulines']"
"Composing Meta-Policies for Autonomous Driving Using Hierarchical Deep
  Reinforcement Learning",Artificial Intelligence,"Rather than learning new control policies for each new task, it is possible,
when tasks share some structure, to compose a ""meta-policy"" from previously
learned policies. This paper reports results from experiments using Deep
Reinforcement Learning on a continuous-state, discrete-action autonomous
driving simulator. We explore how Deep Neural Networks can represent
meta-policies that switch among a set of previously learned policies,
specifically in settings where the dynamics of a new scenario are composed of a
mixture of previously learned dynamics and where the state observation is
possibly corrupted by sensing noise. We also report the results of experiments
varying dynamics mixes, distractor policies, magnitudes/distributions of
sensing noise, and obstacles. In a fully observed experiment, the meta-policy
learning algorithm achieves 2.6x the reward achieved by the next best policy
composition technique with 80% less exploration. In a partially observed
experiment, the meta-policy learning algorithm converges after 50 iterations
while a direct application of RL fails to converge even after 200 iterations.","['Richard Liaw', 'Sanjay Krishnan', 'Animesh Garg', 'Daniel Crankshaw', 'Joseph E. Gonzalez', 'Ken Goldberg']"
"Gradient-only line searches: An Alternative to Probabilistic Line
  Searches",Machine Learning (Statistics),"Step sizes in neural network training are largely determined using
predetermined rules such as fixed learning rates and learning rate schedules.
These require user input or expensive global optimization strategies to
determine their functional form and associated hyperparameters. Line searches
are capable of adaptively resolving learning rate schedules. However, due to
discontinuities induced by mini-batch sub-sampling, they have largely fallen
out of favour. Notwithstanding, probabilistic line searches, which use
statistical surrogates over a limited spatial domain, have recently
demonstrated viability in resolving learning rates for stochastic loss
functions.
  This paper introduces an alternative paradigm, Gradient-Only Line Searches
that are Inexact (GOLS-I), as an alternative strategy to automatically
determine learning rates in stochastic loss functions over a range of 15 orders
of magnitude without the use of surrogates. We show that GOLS-I is a
competitive strategy to reliably determine step sizes, adding high value in
terms of performance, while being easy to implement.","['Dominic Kafka', 'Daniel Wilke']"
Hybrid Dialog State Tracker with ASR Features,Computation and Language (Natural Language Processing),"This paper presents a hybrid dialog state tracker enhanced by trainable
Spoken Language Understanding (SLU) for slot-filling dialog systems. Our
architecture is inspired by previously proposed neural-network-based
belief-tracking systems. In addition, we extended some parts of our modular
architecture with differentiable rules to allow end-to-end training. We
hypothesize that these rules allow our tracker to generalize better than pure
machine-learning based systems. For evaluation, we used the Dialog State
Tracking Challenge (DSTC) 2 dataset - a popular belief tracking testbed with
dialogs from restaurant information system. To our knowledge, our hybrid
tracker sets a new state-of-the-art result in three out of four categories
within the DSTC2.","['Miroslav Vodolán', 'Rudolf Kadlec', 'Jan Kleindienst']"
"Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward
  Decomposition",Computation and Language (Natural Language Processing),"Many studies have applied reinforcement learning to train a dialog policy and
show great promise these years. One common approach is to employ a user
simulator to obtain a large number of simulated user experiences for
reinforcement learning algorithms. However, modeling a realistic user simulator
is challenging. A rule-based simulator requires heavy domain expertise for
complex tasks, and a data-driven simulator requires considerable data and it is
even unclear how to evaluate a simulator. To avoid explicitly building a user
simulator beforehand, we propose Multi-Agent Dialog Policy Learning, which
regards both the system and the user as the dialog agents. Two agents interact
with each other and are jointly learned simultaneously. The method uses the
actor-critic framework to facilitate pretraining and improve scalability. We
also propose Hybrid Value Network for the role-aware reward decomposition to
integrate role-specific domain knowledge of each agent in the task-oriented
dialog. Results show that our method can successfully build a system policy and
a user policy simultaneously, and two agents can achieve a high task success
rate through conversational interaction.","['Ryuichi Takanobu', 'Runze Liang', 'Minlie Huang']"
"Deep Learning-based Stress Determinator for Mouse Psychiatric Analysis
  using Hippocampus Activity",Machine Learning,"Decoding neurons to extract information from transmission and employ them
into other use is the goal of neuroscientists' study. Due to that the field of
neuroscience is utilizing the traditional methods presently, we hence combine
the state-of-the-art deep learning techniques with the theory of neuron
decoding to discuss its potential of accomplishment. Besides, the stress level
that is related to neuron activity in hippocampus is statistically examined as
well. The experiments suggest that our state-of-the-art deep learning-based
stress determinator provides good performance with respect to its model
prediction accuracy and additionally, there is strong evidence against
equivalence of mouse stress level under diverse environments.","['Donghan Liu', 'Benjamin C. M. Fung', 'Tak Pan Wong']"
NeuroCLIP: Neuromorphic Data Understanding by CLIP and SNN,Computer Vision and Pattern Recognition,"Recently, the neuromorphic vision sensor has received more and more interest.
However, the neuromorphic data consists of asynchronous event spikes, which
makes it difficult to construct a big benchmark to train a power general neural
network model, thus limiting the neuromorphic data understanding for ``unseen""
objects by deep learning. While for the frame image, since the training data
can be obtained easily, the zero-shot and few-shot learning for ``unseen"" task
via the large Contrastive Vision-Language Pre-training (CLIP) model, which is
pre-trained by large-scale image-text pairs in 2D, have shown inspirational
performance. We wonder whether the CLIP could be transferred to neuromorphic
data recognition to handle the ``unseen"" problem. To this end, we materialize
this idea with NeuroCLIP in the paper. The NeuroCLIP consists of 2D CLIP and
two specially designed modules for neuromorphic data understanding. First, an
event-frame module that could convert the event spikes to the sequential frame
image with a simple discrimination strategy. Second, an inter-timestep adapter,
which is a simple fine-tuned adapter based on a spiking neural network (SNN)
for the sequential features coming from the visual encoder of CLIP to improve
the few-shot performance. Various experiments on neuromorphic datasets
including N-MNIST, CIFAR10-DVS, and ES-ImageNet demonstrate the effectiveness
of NeuroCLIP. Our code is open-sourced at
https://github.com/yfguo91/NeuroCLIP.git.","['Yufei Guo', 'Yuanpei Chen', 'Zhe Ma']"
"CODE: Contrasting Self-generated Description to Combat Hallucination in
  Large Multi-modal Models",Computer Vision and Pattern Recognition,"Large Multi-modal Models (LMMs) have recently demonstrated remarkable
abilities in visual context understanding and coherent response generation.
However, alongside these advancements, the issue of hallucinations has emerged
as a significant challenge, producing erroneous responses that are unrelated to
the visual contents. In this paper, we introduce a novel contrastive-based
decoding method, COuntering DEscription Contrastive Decoding (CODE), which
leverages self-generated descriptions as contrasting references during the
decoding phase of LMMs to address hallucination issues. CODE utilizes the
comprehensive descriptions from model itself as visual counterpart to correct
and improve response alignment with actual visual content. By dynamically
adjusting the information flow and distribution of next-token predictions in
the LMM's vocabulary, CODE enhances the coherence and informativeness of
generated responses. Extensive experiments demonstrate that our method
significantly reduces hallucinations and improves cross-modal consistency
across various benchmarks and cutting-edge LMMs. Our method provides a simple
yet effective decoding strategy that can be integrated to existing LMM
frameworks without additional training.","['Junho Kim', 'Hyunjun Kim', 'Yeonju Kim', 'Yong Man Ro']"
Some New Layer Architectures for Graph CNN,Machine Learning,"While convolutional neural networks (CNNs) have recently made great strides
in supervised classification of data structured on a grid (e.g. images composed
of pixel grids), in several interesting datasets, the relations between
features can be better represented as a general graph instead of a regular
grid. Although recent algorithms that adapt CNNs to graphs have shown promising
results, they mostly neglect learning explicit operations for edge features
while focusing on vertex features alone. We propose new formulations for
convolutional, pooling, and fully connected layers for neural networks that
make more comprehensive use of the information available in multi-dimensional
graphs. Using these layers led to an improvement in classification accuracy
over the state-of-the-art methods on benchmark graph datasets.","['Shrey Gadiya', 'Deepak Anand', 'Amit Sethi']"
"Maximum Mean Discrepancy on Exponential Windows for Online Change
  Detection",Machine Learning,"Detecting changes is of fundamental importance when analyzing data streams
and has many applications, e.g., in predictive maintenance, fraud detection, or
medicine. A principled approach to detect changes is to compare the
distributions of observations within the stream to each other via hypothesis
testing. Maximum mean discrepancy (MMD), a (semi-)metric on the space of
probability distributions, provides powerful non-parametric two-sample tests on
kernel-enriched domains. In particular, MMD is able to detect any disparity
between distributions under mild conditions. However, classical MMD estimators
suffer from a quadratic runtime complexity, which renders their direct use for
change detection in data streams impractical. In this article, we propose a new
change detection algorithm, called Maximum Mean Discrepancy on Exponential
Windows (MMDEW), that combines the benefits of MMD with an efficient
computation based on exponential windows. We prove that MMDEW enjoys
polylogarithmic runtime and logarithmic memory complexity and show empirically
that it outperforms the state of the art on benchmark data streams.","['Florian Kalinke', 'Marco Heyden', 'Georg Gntuni', 'Edouard Fouché', 'Klemens Böhm']"
Non-Local Recurrent Network for Image Restoration,Computer Vision and Pattern Recognition,"Many classic methods have shown non-local self-similarity in natural images
to be an effective prior for image restoration. However, it remains unclear and
challenging to make use of this intrinsic property via deep networks. In this
paper, we propose a non-local recurrent network (NLRN) as the first attempt to
incorporate non-local operations into a recurrent neural network (RNN) for
image restoration. The main contributions of this work are: (1) Unlike existing
methods that measure self-similarity in an isolated manner, the proposed
non-local module can be flexibly integrated into existing deep networks for
end-to-end training to capture deep feature correlation between each location
and its neighborhood. (2) We fully employ the RNN structure for its parameter
efficiency and allow deep feature correlation to be propagated along adjacent
recurrent states. This new design boosts robustness against inaccurate
correlation estimation due to severely degraded images. (3) We show that it is
essential to maintain a confined neighborhood for computing deep feature
correlation given degraded images. This is in contrast to existing practice
that deploys the whole image. Extensive experiments on both image denoising and
super-resolution tasks are conducted. Thanks to the recurrent non-local
operations and correlation propagation, the proposed NLRN achieves superior
results to state-of-the-art methods with much fewer parameters.","['Ding Liu', 'Bihan Wen', 'Yuchen Fan', 'Chen Change Loy', 'Thomas S. Huang']"
Wasserstein Neural Processes,Machine Learning,"Neural Processes (NPs) are a class of models that learn a mapping from a
context set of input-output pairs to a distribution over functions. They are
traditionally trained using maximum likelihood with a KL divergence
regularization term. We show that there are desirable classes of problems where
NPs, with this loss, fail to learn any reasonable distribution. We also show
that this drawback is solved by using approximations of Wasserstein distance
which calculates optimal transport distances even for distributions of disjoint
support. We give experimental justification for our method and demonstrate
performance. These Wasserstein Neural Processes (WNPs) maintain all of the
benefits of traditional NPs while being able to approximate a new class of
function mappings.","['Andrew Carr', 'Jared Nielsen', 'David Wingate']"
"Two-way kernel matrix puncturing: towards resource-efficient PCA and
  spectral clustering",Machine Learning,"The article introduces an elementary cost and storage reduction method for
spectral clustering and principal component analysis. The method consists in
randomly ""puncturing"" both the data matrix $X\in\mathbb{C}^{p\times n}$ (or
$\mathbb{R}^{p\times n}$) and its corresponding kernel (Gram) matrix $K$
through Bernoulli masks: $S\in\{0,1\}^{p\times n}$ for $X$ and
$B\in\{0,1\}^{n\times n}$ for $K$. The resulting ""two-way punctured"" kernel is
thus given by $K=\frac{1}{p}[(X \odot S)^{\sf H} (X \odot S)] \odot B$. We
demonstrate that, for $X$ composed of independent columns drawn from a Gaussian
mixture model, as $n,p\to\infty$ with $p/n\to c_0\in(0,\infty)$, the spectral
behavior of $K$ -- its limiting eigenvalue distribution, as well as its
isolated eigenvalues and eigenvectors -- is fully tractable and exhibits a
series of counter-intuitive phenomena. We notably prove, and empirically
confirm on GAN-generated image databases, that it is possible to drastically
puncture the data, thereby providing possibly huge computational and storage
gains, for a virtually constant (clustering of PCA) performance. This
preliminary study opens as such the path towards rethinking, from a large
dimensional standpoint, computational and storage costs in elementary machine
learning models.","['Romain Couillet', 'Florent Chatelain', 'Nicolas Le Bihan']"
"Making Pre-trained Language Models Better Continual Few-Shot Relation
  Extractors",Computation and Language (Natural Language Processing),"Continual Few-shot Relation Extraction (CFRE) is a practical problem that
requires the model to continuously learn novel relations while avoiding
forgetting old ones with few labeled training data. The primary challenges are
catastrophic forgetting and overfitting. This paper harnesses prompt learning
to explore the implicit capabilities of pre-trained language models to address
the above two challenges, thereby making language models better continual
few-shot relation extractors. Specifically, we propose a Contrastive Prompt
Learning framework, which designs prompt representation to acquire more
generalized knowledge that can be easily adapted to old and new categories, and
margin-based contrastive learning to focus more on hard samples, therefore
alleviating catastrophic forgetting and overfitting issues. To further remedy
overfitting in low-resource scenarios, we introduce an effective memory
augmentation strategy that employs well-crafted prompts to guide ChatGPT in
generating diverse samples. Extensive experiments demonstrate that our method
outperforms state-of-the-art methods by a large margin and significantly
mitigates catastrophic forgetting and overfitting in low-resource scenarios.","['Shengkun Ma', 'Jiale Han', 'Yi Liang', 'Bo Cheng']"
A Non-Asymptotic Analysis for Stein Variational Gradient Descent,Machine Learning (Statistics),"We study the Stein Variational Gradient Descent (SVGD) algorithm, which
optimises a set of particles to approximate a target probability distribution
$\pi\propto e^{-V}$ on $\mathbb{R}^d$. In the population limit, SVGD performs
gradient descent in the space of probability distributions on the KL divergence
with respect to $\pi$, where the gradient is smoothed through a kernel integral
operator. In this paper, we provide a novel finite time analysis for the SVGD
algorithm. We provide a descent lemma establishing that the algorithm decreases
the objective at each iteration, and rates of convergence for the average Stein
Fisher divergence (also referred to as Kernel Stein Discrepancy). We also
provide a convergence result of the finite particle system corresponding to the
practical implementation of SVGD to its population version.","['Anna Korba', 'Adil Salim', 'Michael Arbel', 'Giulia Luise', 'Arthur Gretton']"
Distribution Free Learning with Local Queries,Machine Learning,"The model of learning with \emph{local membership queries} interpolates
between the PAC model and the membership queries model by allowing the learner
to query the label of any example that is similar to an example in the training
set. This model, recently proposed and studied by Awasthi, Feldman and Kanade,
aims to facilitate practical use of membership queries.
  We continue this line of work, proving both positive and negative results in
the {\em distribution free} setting. We restrict to the boolean cube $\{-1,
1\}^n$, and say that a query is $q$-local if it is of a hamming distance $\le
q$ from some training example. On the positive side, we show that $1$-local
queries already give an additional strength, and allow to learn a certain type
of DNF formulas. On the negative side, we show that even
$\left(n^{0.99}\right)$-local queries cannot help to learn various classes
including Automata, DNFs and more. Likewise, $q$-local queries for any constant
$q$ cannot help to learn Juntas, Decision Trees, Sparse Polynomials and more.
Moreover, for these classes, an algorithm that uses
$\left(\log^{0.99}(n)\right)$-local queries would lead to a breakthrough in the
best known running times.","['Galit Bary-Weisberg', 'Amit Daniely', 'Shai Shalev-Shwartz']"
Neural Inverse Rendering for General Reflectance Photometric Stereo,Computer Vision and Pattern Recognition,"We present a novel convolutional neural network architecture for photometric
stereo (Woodham, 1980), a problem of recovering 3D object surface normals from
multiple images observed under varying illuminations. Despite its long history
in computer vision, the problem still shows fundamental challenges for surfaces
with unknown general reflectance properties (BRDFs). Leveraging deep neural
networks to learn complicated reflectance models is promising, but studies in
this direction are very limited due to difficulties in acquiring accurate
ground truth for training and also in designing networks invariant to
permutation of input images. In order to address these challenges, we propose a
physics based unsupervised learning framework where surface normals and BRDFs
are predicted by the network and fed into the rendering equation to synthesize
observed images. The network weights are optimized during testing by minimizing
reconstruction loss between observed and synthesized images. Thus, our learning
process does not require ground truth normals or even pre-training on external
images. Our method is shown to achieve the state-of-the-art performance on a
challenging real-world scene benchmark.","['Tatsunori Taniai', 'Takanori Maehara']"
"Non-Linear Phase-Shifting of Haar Wavelets for Run-Time All-Frequency
  Lighting",Computer Vision and Pattern Recognition,"This paper focuses on real-time all-frequency image-based rendering using an
innovative solution for run-time computation of light transport. The approach
is based on new results derived for non-linear phase shifting in the Haar
wavelet domain. Although image-based methods for real-time rendering of dynamic
glossy objects have been proposed, they do not truly scale to all possible
frequencies and high sampling rates without trading storage, glossiness, or
computational time, while varying both lighting and viewpoint. This is due to
the fact that current approaches are limited to precomputed radiance transfer
(PRT), which is prohibitively expensive in terms of memory requirements and
real-time rendering when both varying light and viewpoint changes are required
together with high sampling rates for high frequency lighting of glossy
material. On the other hand, current methods cannot handle object rotation,
which is one of the paramount issues for all PRT methods using wavelets. This
latter problem arises because the precomputed data are defined in a global
coordinate system and encoded in the wavelet domain, while the object is
rotated in a local coordinate system. At the root of all the above problems is
the lack of efficient run-time solution to the nontrivial problem of rotating
wavelets (a non-linear phase-shift), which we solve in this paper.","['Mais Alnasser', 'Hassan Foroosh']"
"Local Loss Optimization in the Infinite Width: Stable Parameterization
  of Predictive Coding Networks and Target Propagation",Machine Learning,"Local learning, which trains a network through layer-wise local targets and
losses, has been studied as an alternative to backpropagation (BP) in neural
computation. However, its algorithms often become more complex or require
additional hyperparameters because of the locality, making it challenging to
identify desirable settings in which the algorithm progresses in a stable
manner. To provide theoretical and quantitative insights, we introduce the
maximal update parameterization ($\mu$P) in the infinite-width limit for two
representative designs of local targets: predictive coding (PC) and target
propagation (TP). We verified that $\mu$P enables hyperparameter transfer
across models of different widths. Furthermore, our analysis revealed unique
and intriguing properties of $\mu$P that are not present in conventional BP. By
analyzing deep linear networks, we found that PC's gradients interpolate
between first-order and Gauss-Newton-like gradients, depending on the
parameterization. We demonstrate that, in specific standard settings, PC in the
infinite-width limit behaves more similarly to the first-order gradient. For
TP, even with the standard scaling of the last layer, which differs from
classical $\mu$P, its local loss optimization favors the feature learning
regime over the kernel regime.","['Satoki Ishikawa', 'Rio Yokota', 'Ryo Karakida']"
"Explainable vision transformer enabled convolutional neural network for
  plant disease identification: PlantXViT",Computer Vision and Pattern Recognition,"Plant diseases are the primary cause of crop losses globally, with an impact
on the world economy. To deal with these issues, smart agriculture solutions
are evolving that combine the Internet of Things and machine learning for early
disease detection and control. Many such systems use vision-based machine
learning methods for real-time disease detection and diagnosis. With the
advancement in deep learning techniques, new methods have emerged that employ
convolutional neural networks for plant disease detection and identification.
Another trend in vision-based deep learning is the use of vision transformers,
which have proved to be powerful models for classification and other problems.
However, vision transformers have rarely been investigated for plant pathology
applications. In this study, a Vision Transformer enabled Convolutional Neural
Network model called ""PlantXViT"" is proposed for plant disease identification.
The proposed model combines the capabilities of traditional convolutional
neural networks with the Vision Transformers to efficiently identify a large
number of plant diseases for several crops. The proposed model has a
lightweight structure with only 0.8 million trainable parameters, which makes
it suitable for IoT-based smart agriculture services. The performance of
PlantXViT is evaluated on five publicly available datasets. The proposed
PlantXViT network performs better than five state-of-the-art methods on all
five datasets. The average accuracy for recognising plant diseases is shown to
exceed 93.55%, 92.59%, and 98.33% on Apple, Maize, and Rice datasets,
respectively, even under challenging background conditions. The efficiency in
terms of explainability of the proposed model is evaluated using
gradient-weighted class activation maps and Local Interpretable Model Agnostic
Explanation.","['Poornima Singh Thakur', 'Pritee Khanna', 'Tanuja Sheorey', 'Aparajita Ojha']"
ProtoDA: Efficient Transfer Learning for Few-Shot Intent Classification,Computation and Language (Natural Language Processing),"Practical sequence classification tasks in natural language processing often
suffer from low training data availability for target classes. Recent works
towards mitigating this problem have focused on transfer learning using
embeddings pre-trained on often unrelated tasks, for instance, language
modeling. We adopt an alternative approach by transfer learning on an ensemble
of related tasks using prototypical networks under the meta-learning paradigm.
Using intent classification as a case study, we demonstrate that increasing
variability in training tasks can significantly improve classification
performance. Further, we apply data augmentation in conjunction with
meta-learning to reduce sampling bias. We make use of a conditional generator
for data augmentation that is trained directly using the meta-learning
objective and simultaneously with prototypical networks, hence ensuring that
data augmentation is customized to the task. We explore augmentation in the
sentence embedding space as well as prototypical embedding space. Combining
meta-learning with augmentation provides upto 6.49% and 8.53% relative F1-score
improvements over the best performing systems in the 5-shot and 10-shot
learning, respectively.","['Manoj Kumar', 'Varun Kumar', 'Hadrien Glaude', 'Cyprien delichy', 'Aman Alok', 'Rahul Gupta']"
Compiling Stochastic Constraint Programs to And-Or Decision Diagrams,Artificial Intelligence,"Factored stochastic constraint programming (FSCP) is a formalism to represent
multi-stage decision making problems under uncertainty. FSCP models support
factorized probabilistic models and involve constraints over decision and
random variables. These models have many applications in real-world problems.
However, solving these problems requires evaluating the best course of action
for each possible outcome of the random variables and hence is computationally
challenging. FSCP problems often involve repeated subproblems which ideally
should be solved once. In this paper we show how identifying and exploiting
these identical subproblems can simplify solving them and leads to a compact
representation of the solution. We compile an And-Or search tree to a compact
decision diagram. Preliminary experiments show that our proposed method
significantly improves the search efficiency by reducing the size of the
problem and outperforms the existing methods.","['Behrouz Babaki', 'Golnoosh Farnadi', 'Gilles Pesant']"
"Spacecraft Pose Estimation Based on Unsupervised Domain Adaptation and
  on a 3D-Guided Loss Combination",Computer Vision and Pattern Recognition,"Spacecraft pose estimation is a key task to enable space missions in which
two spacecrafts must navigate around each other. Current state-of-the-art
algorithms for pose estimation employ data-driven techniques. However, there is
an absence of real training data for spacecraft imaged in space conditions due
to the costs and difficulties associated with the space environment. This has
motivated the introduction of 3D data simulators, solving the issue of data
availability but introducing a large gap between the training (source) and test
(target) domains. We explore a method that incorporates 3D structure into the
spacecraft pose estimation pipeline to provide robustness to intensity domain
shift and we present an algorithm for unsupervised domain adaptation with
robust pseudo-labelling. Our solution has ranked second in the two categories
of the 2021 Pose Estimation Challenge organised by the European Space Agency
and the Stanford University, achieving the lowest average error over the two
categories.","['Juan Ignacio Bravo Pérez-Villar', 'Álvaro García-Martín', 'Jesús Bescós']"
"Complex-Valued Restricted Boltzmann Machine for Direct Speech
  Parameterization from Complex Spectra",Audio and Speech Processing,"This paper describes a novel energy-based probabilistic distribution that
represents complex-valued data and explains how to apply it to direct feature
extraction from complex-valued spectra. The proposed model, the complex-valued
restricted Boltzmann machine (CRBM), is designed to deal with complex-valued
visible units as an extension of the well-known restricted Boltzmann machine
(RBM). Like the RBM, the CRBM learns the relationships between visible and
hidden units without having connections between units in the same layer, which
dramatically improves training efficiency by using Gibbs sampling or
contrastive divergence (CD). Another important characteristic is that the CRBM
also has connections between real and imaginary parts of each of the
complex-valued visible units that help represent the data distribution in the
complex domain. In speech signal processing, classification and generation
features are often based on amplitude spectra (e.g., MFCC, cepstra, and
mel-cepstra) even if they are calculated from complex spectra, and they ignore
phase information. In contrast, the proposed feature extractor using the CRBM
directly encodes the complex spectra (or another complex-valued representation
of the complex spectra) into binary-valued latent features (hidden units).
Since the visible-hidden connections are undirected, we can also recover
(decode) the complex spectra from the latent features directly. Our speech
coding experiments demonstrated that the CRBM outperformed other speech coding
methods, such as methods using the conventional RBM, the mel-log spectrum
approximate (MLSA) decoder, etc.","['Toru Nakashika', 'Shinji Takaki', 'Junichi Yamagishi']"
"Template-Based Question Generation from Retrieved Sentences for Improved
  Unsupervised Question Answering",Computation and Language (Natural Language Processing),"Question Answering (QA) is in increasing demand as the amount of information
available online and the desire for quick access to this content grows. A
common approach to QA has been to fine-tune a pretrained language model on a
task-specific labeled dataset. This paradigm, however, relies on scarce, and
costly to obtain, large-scale human-labeled data. We propose an unsupervised
approach to training QA models with generated pseudo-training data. We show
that generating questions for QA training by applying a simple template on a
related, retrieved sentence rather than the original context sentence improves
downstream QA performance by allowing the model to learn more complex
context-question relationships. Training a QA model on this data gives a
relative improvement over a previous unsupervised model in F1 score on the
SQuAD dataset by about 14%, and 20% when the answer is a named entity,
achieving state-of-the-art performance on SQuAD for unsupervised QA.","['Alexander R. Fabbri', 'Patrick Ng', 'Zhiguo Wang', 'Ramesh Nallapati', 'Bing Xiang']"
"Reinforcement Learning from Human Feedback without Reward Inference:
  Model-Free Algorithm and Instance-Dependent Analysis",Machine Learning,"In this paper, we study reinforcement learning from human feedback (RLHF)
under an episodic Markov decision process with a general trajectory-wise reward
model. We developed a model-free RLHF best policy identification algorithm,
called $\mathsf{BSAD}$, without explicit reward model inference, which is a
critical intermediate step in the contemporary RLHF paradigms for training
large language models (LLM). The algorithm identifies the optimal policy
directly from human preference information in a backward manner, employing a
dueling bandit sub-routine that constantly duels actions to identify the
superior one. $\mathsf{BSAD}$ adopts a reward-free exploration and
best-arm-identification-like adaptive stopping criteria to equalize the
visitation among all states in the same decision step while moving to the
previous step as soon as the optimal action is identifiable, leading to a
provable, instance-dependent sample complexity
$\tilde{\mathcal{O}}(c_{\mathcal{M}}SA^3H^3M\log\frac{1}{\delta})$ which
resembles the result in classic RL, where $c_{\mathcal{M}}$ is the
instance-dependent constant and $M$ is the batch size. Moreover,
$\mathsf{BSAD}$ can be transformed into an explore-then-commit algorithm with
logarithmic regret and generalized to discounted MDPs using a frame-based
approach. Our results show: (i) sample-complexity-wise, RLHF is not
significantly harder than classic RL and (ii) end-to-end RLHF may deliver
improved performance by avoiding pitfalls in reward inferring such as overfit
and distribution shift.","['Qining Zhang', 'Honghao Wei', 'Lei Ying']"
End-to-End Trainable Multi-Instance Pose Estimation with Transformers,Computer Vision and Pattern Recognition,"We propose an end-to-end trainable approach for multi-instance pose
estimation, called POET (POse Estimation Transformer). Combining a
convolutional neural network with a transformer encoder-decoder architecture,
we formulate multiinstance pose estimation from images as a direct set
prediction problem. Our model is able to directly regress the pose of all
individuals, utilizing a bipartite matching scheme. POET is trained using a
novel set-based global loss that consists of a keypoint loss, a visibility loss
and a class loss. POET reasons about the relations between multiple detected
individuals and the full image context to directly predict their poses in
parallel. We show that POET achieves high accuracy on the COCO keypoint
detection task while having less parameters and higher inference speed than
other bottom-up and top-down approaches. Moreover, we show successful transfer
learning when applying POET to animal pose estimation. To the best of our
knowledge, this model is the first end-to-end trainable multi-instance pose
estimation method and we hope it will serve as a simple and promising
alternative.","['Lucas Stoffl', 'Maxime Vidal', 'Alexander Mathis']"
"A Differential Evolution-Enhanced Latent Factor Analysis Model for
  High-dimensional and Sparse Data",Machine Learning,"High-dimensional and sparse (HiDS) matrices are frequently adopted to
describe the complex relationships in various big data-related systems and
applications. A Position-transitional Latent Factor Analysis (PLFA) model can
accurately and efficiently represent an HiDS matrix. However, its involved
latent factors are optimized by stochastic gradient descent with the specific
gradient direction step-by-step, which may cause a suboptimal solution. To
address this issue, this paper proposes a Sequential-Group-Differential-
Evolution (SGDE) algorithm to refine the latent factors optimized by a PLFA
model, thereby achieving a highly-accurate SGDE-PLFA model to HiDS matrices. As
demonstrated by the experiments on four HiDS matrices, a SGDE-PLFA model
outperforms the state-of-the-art models.","['Jia Chen', 'Di Wu', 'Xin Luo']"
"Multiobjective Vehicle Routing Optimization with Time Windows: A Hybrid
  Approach Using Deep Reinforcement Learning and NSGA-II",Artificial Intelligence,"This paper proposes a weight-aware deep reinforcement learning (WADRL)
approach designed to address the multiobjective vehicle routing problem with
time windows (MOVRPTW), aiming to use a single deep reinforcement learning
(DRL) model to solve the entire multiobjective optimization problem. The
Non-dominated sorting genetic algorithm-II (NSGA-II) method is then employed to
optimize the outcomes produced by the WADRL, thereby mitigating the limitations
of both approaches. Firstly, we design an MOVRPTW model to balance the
minimization of travel cost and the maximization of customer satisfaction.
Subsequently, we present a novel DRL framework that incorporates a
transformer-based policy network. This network is composed of an encoder
module, a weight embedding module where the weights of the objective functions
are incorporated, and a decoder module. NSGA-II is then utilized to optimize
the solutions generated by WADRL. Finally, extensive experimental results
demonstrate that our method outperforms the existing and traditional methods.
Due to the numerous constraints in VRPTW, generating initial solutions of the
NSGA-II algorithm can be time-consuming. However, using solutions generated by
the WADRL as initial solutions for NSGA-II significantly reduces the time
required for generating initial solutions. Meanwhile, the NSGA-II algorithm can
enhance the quality of solutions generated by WADRL, resulting in solutions
with better scalability. Notably, the weight-aware strategy significantly
reduces the training time of DRL while achieving better results, enabling a
single DRL model to solve the entire multiobjective optimization problem.","['Rixin Wu', 'Ran Wang', 'Jie Hao', 'Qiang Wu', 'Ping Wang', 'Dusit Niyato']"
"Faster Stochastic Variational Inference using Proximal-Gradient Methods
  with General Divergence Functions",Machine Learning (Statistics),"Several recent works have explored stochastic gradient methods for
variational inference that exploit the geometry of the variational-parameter
space. However, the theoretical properties of these methods are not
well-understood and these methods typically only apply to
conditionally-conjugate models. We present a new stochastic method for
variational inference which exploits the geometry of the variational-parameter
space and also yields simple closed-form updates even for non-conjugate models.
We also give a convergence-rate analysis of our method and many other previous
methods which exploit the geometry of the space. Our analysis generalizes
existing convergence results for stochastic mirror-descent on non-convex
objectives by using a more general class of divergence functions. Beyond giving
a theoretical justification for a variety of recent methods, our experiments
show that new algorithms derived in this framework lead to state of the art
results on a variety of problems. Further, due to its generality, we expect
that our theoretical analysis could also apply to other applications.","['Mohammad Emtiyaz Khan', 'Reza Babanezhad', 'Wu Lin', 'Mark Schmidt', 'Masashi Sugiyama']"
Decision-Aware Learning for Optimizing Health Supply Chains,Machine Learning,"We study the problem of allocating limited supply of medical resources in
developing countries, in particular, Sierra Leone. We address this problem by
combining machine learning (to predict demand) with optimization (to optimize
allocations). A key challenge is the need to align the loss function used to
train the machine learning model with the decision loss associated with the
downstream optimization problem. Traditional solutions have limited flexibility
in the model architecture and scale poorly to large datasets. We propose a
decision-aware learning algorithm that uses a novel Taylor expansion of the
optimal decision loss to derive the machine learning loss. Importantly, our
approach only requires a simple re-weighting of the training data, ensuring it
is both flexible and scalable, e.g., we incorporate it into a random forest
trained using a multitask learning framework. We apply our framework to
optimize the distribution of essential medicines in collaboration with
policymakers in Sierra Leone; highly uncertain demand and limited budgets
currently result in excessive unmet demand. Out-of-sample results demonstrate
that our end-to-end approach can significantly reduce unmet demand across 1040
health facilities throughout Sierra Leone.","['Tsai-Hsuan Chung', 'Vahid Rostami', 'Hamsa Bastani', 'Osbert Bastani']"
"Gaussian-binary Restricted Boltzmann Machines on Modeling Natural Image
  Statistics",Neural and Evolutionary Computing,"We present a theoretical analysis of Gaussian-binary restricted Boltzmann
machines (GRBMs) from the perspective of density models. The key aspect of this
analysis is to show that GRBMs can be formulated as a constrained mixture of
Gaussians, which gives a much better insight into the model's capabilities and
limitations. We show that GRBMs are capable of learning meaningful features
both in a two-dimensional blind source separation task and in modeling natural
images. Further, we show that reported difficulties in training GRBMs are due
to the failure of the training algorithm rather than the model itself. Based on
our analysis we are able to propose several training recipes, which allowed
successful and fast training in our experiments. Finally, we discuss the
relationship of GRBMs to several modifications that have been proposed to
improve the model.","['Nan Wang', 'Jan Melchior', 'Laurenz Wiskott']"
"Understanding the Power and Limitations of Teaching with Imperfect
  Knowledge",Machine Learning,"Machine teaching studies the interaction between a teacher and a
student/learner where the teacher selects training examples for the learner to
learn a specific task. The typical assumption is that the teacher has perfect
knowledge of the task---this knowledge comprises knowing the desired learning
target, having the exact task representation used by the learner, and knowing
the parameters capturing the learning dynamics of the learner. Inspired by
real-world applications of machine teaching in education, we consider the
setting where teacher's knowledge is limited and noisy, and the key research
question we study is the following: When does a teacher succeed or fail in
effectively teaching a learner using its imperfect knowledge? We answer this
question by showing connections to how imperfect knowledge affects the
teacher's solution of the corresponding machine teaching problem when
constructing optimal teaching sets. Our results have important implications for
designing robust teaching algorithms for real-world applications.","['Rati Devidze', 'Farnam Mansouri', 'Luis Haug', 'Yuxin Chen', 'Adish Singla']"
"Exploring Explainable AI in the Financial Sector: Perspectives of Banks
  and Supervisory Authorities",Artificial Intelligence,"Explainable artificial intelligence (xAI) is seen as a solution to making AI
systems less of a black box. It is essential to ensure transparency, fairness,
and accountability, which are especially paramount in the financial sector. The
aim of this study was a preliminary investigation of the perspectives of
supervisory authorities and regulated entities regarding the application of xAI
in the fi-nancial sector. Three use cases (consumer credit, credit risk, and
anti-money laundering) were examined using semi-structured interviews at three
banks and two supervisory authorities in the Netherlands. We found that for the
investigated use cases a disparity exists between supervisory authorities and
banks regarding the desired scope of explainability of AI systems. We argue
that the financial sector could benefit from clear differentiation between
technical AI (model) ex-plainability requirements and explainability
requirements of the broader AI system in relation to applicable laws and
regulations.","['Ouren Kuiper', 'Martin van den Berg', 'Joost van der Burgt', 'Stefan Leijnen']"
"Neural View Synthesis and Matching for Semi-Supervised Few-Shot Learning
  of 3D Pose",Computer Vision and Pattern Recognition,"We study the problem of learning to estimate the 3D object pose from a few
labelled examples and a collection of unlabelled data. Our main contribution is
a learning framework, neural view synthesis and matching, that can transfer the
3D pose annotation from the labelled to unlabelled images reliably, despite
unseen 3D views and nuisance variations such as the object shape, texture,
illumination or scene context. In our approach, objects are represented as 3D
cuboid meshes composed of feature vectors at each mesh vertex. The model is
initialized from a few labelled images and is subsequently used to synthesize
feature representations of unseen 3D views. The synthesized views are matched
with the feature representations of unlabelled images to generate pseudo-labels
of the 3D pose. The pseudo-labelled data is, in turn, used to train the feature
extractor such that the features at each mesh vertex are more invariant across
varying 3D views of the object. Our model is trained in an EM-type manner
alternating between increasing the 3D pose invariance of the feature extractor
and annotating unlabelled data through neural view synthesis and matching. We
demonstrate the effectiveness of the proposed semi-supervised learning
framework for 3D pose estimation on the PASCAL3D+ and KITTI datasets. We find
that our approach outperforms all baselines by a wide margin, particularly in
an extreme few-shot setting where only 7 annotated images are given.
Remarkably, we observe that our model also achieves an exceptional robustness
in out-of-distribution scenarios that involve partial occlusion.","['Angtian Wang', 'Shenxiao Mei', 'Alan Yuille', 'Adam Kortylewski']"
Formal Semantic Geometry over Transformer-based Variational AutoEncoder,Computation and Language (Natural Language Processing),"Formal/symbolic semantics can provide canonical, rigid controllability and
interpretability to sentence representations due to their \textit{localisation}
or \textit{composition} property. How can we deliver such property to the
current distributional sentence representations to control and interpret the
generation of language models (LMs)? In this work, we theoretically frame the
sentence semantics as the composition of \textit{semantic role - word content}
features and propose the formal semantic geometry. To inject such geometry into
Transformer-based LMs (i.e. GPT2), we deploy Transformer-based Variational
AutoEncoder with a supervision approach, where the sentence generation can be
manipulated and explained over low-dimensional latent Gaussian space. In
addition, we propose a new probing algorithm to guide the movement of sentence
vectors over such geometry. Experimental results reveal that the formal
semantic geometry can potentially deliver better control and interpretation to
sentence generation.","['Yingji Zhang', 'Danilo S. Carvalho', 'Ian Pratt-Hartmann', 'André Freitas']"
"Induce, Edit, Retrieve: Language Grounded Multimodal Schema for
  Instructional Video Retrieval",Computer Vision and Pattern Recognition,"Schemata are structured representations of complex tasks that can aid
artificial intelligence by allowing models to break down complex tasks into
intermediate steps. We propose a novel system that induces schemata from web
videos and generalizes them to capture unseen tasks with the goal of improving
video retrieval performance. Our system proceeds in three major phases: (1)
Given a task with related videos, we construct an initial schema for a task
using a joint video-text model to match video segments with text representing
steps from wikiHow; (2) We generalize schemata to unseen tasks by leveraging
language models to edit the text within existing schemata. Through
generalization, we can allow our schemata to cover a more extensive range of
tasks with a small amount of learning data; (3) We conduct zero-shot
instructional video retrieval with the unseen task names as the queries. Our
schema-guided approach outperforms existing methods for video retrieval, and we
demonstrate that the schemata induced by our system are better than those
generated by other models.","['Yue Yang', 'Joongwon Kim', 'Artemis Panagopoulou', 'Mark Yatskar', 'Chris Callison-Burch']"
"CM-DQN: A Value-Based Deep Reinforcement Learning Model to Simulate
  Confirmation Bias",Machine Learning,"In human decision-making tasks, individuals learn through trials and
prediction errors. When individuals learn the task, some are more influenced by
good outcomes, while others weigh bad outcomes more heavily. Such confirmation
bias can lead to different learning effects. In this study, we propose a new
algorithm in Deep Reinforcement Learning, CM-DQN, which applies the idea of
different update strategies for positive or negative prediction errors, to
simulate the human decision-making process when the task's states are
continuous while the actions are discrete. We test in Lunar Lander environment
with confirmatory, disconfirmatory bias and non-biased to observe the learning
effects. Moreover, we apply the confirmation model in a multi-armed bandit
problem (environment in discrete states and discrete actions), which utilizes
the same idea as our proposed algorithm, as a contrast experiment to
algorithmically simulate the impact of different confirmation bias in
decision-making process. In both experiments, confirmatory bias indicates a
better learning effect.","['Jiacheng Shen', 'Lihan Feng']"
Fine-tuned Pre-trained Mask R-CNN Models for Surface Object Detection,Computer Vision and Pattern Recognition,"This study evaluates road surface object detection tasks using four Mask
R-CNN models as a pre-study of surface deterioration detection of stone-made
archaeological objects. The models were pre-trained and fine-tuned by COCO
datasets and 15,188 segmented road surface annotation tags. The quality of the
models were measured using Average Precisions and Average Recalls. Result
indicates substantial number of counts of false negatives, i.e. left detection
and unclassified detections. A modified confusion matrix model to avoid
prioritizing IoU is tested and there are notable true positive increases in
bounding box detection, but almost no changes in segmentation masks.","['Haruhiro Fujita', 'Masatoshi Itagaki', 'Kenta Ichikawa', 'Yew Kwang Hooi', 'Kazutaka Kawano', 'Ryo Yamamoto']"
"Characterizing Policy Divergence for Personalized Meta-Reinforcement
  Learning",Machine Learning,"Despite ample motivation from costly exploration and limited trajectory data,
rapidly adapting to new environments with few-shot reinforcement learning (RL)
can remain a challenging task, especially with respect to personalized
settings. Here, we consider the problem of recommending optimal policies to a
set of multiple entities each with potentially different characteristics, such
that individual entities may parameterize distinct environments with unique
transition dynamics. Inspired by existing literature in meta-learning, we
extend previous work by focusing on the notion that certain environments are
more similar to each other than others in personalized settings, and propose a
model-free meta-learning algorithm that prioritizes past experiences by
relevance during gradient-based adaptation. Our algorithm involves
characterizing past policy divergence through methods in inverse reinforcement
learning, and we illustrate how such metrics are able to effectively
distinguish past policy parameters by the environment they were deployed in,
leading to more effective fast adaptation during test time. To study
personalization more effectively we introduce a navigation testbed to
specifically incorporate environment diversity across training episodes, and
demonstrate that our approach outperforms meta-learning alternatives with
respect to few-shot reinforcement learning in personalized settings.",['Michael Zhang']
Pretrained Transformers Do not Always Improve Robustness,Computation and Language (Natural Language Processing),"Pretrained Transformers (PT) have been shown to improve Out of Distribution
(OOD) robustness than traditional models such as Bag of Words (BOW), LSTMs,
Convolutional Neural Networks (CNN) powered by Word2Vec and Glove embeddings.
How does the robustness comparison hold in a real world setting where some part
of the dataset can be noisy? Do PT also provide more robust representation than
traditional models on exposure to noisy data? We perform a comparative study on
10 models and find an empirical evidence that PT provide less robust
representation than traditional models on exposure to noisy data. We
investigate further and augment PT with an adversarial filtering (AF) mechanism
that has been shown to improve OOD generalization. However, increase in
generalization does not necessarily increase robustness, as we find that noisy
data fools the AF method powered by PT.","['Swaroop Mishra', 'Bhavdeep Singh Sachdeva', 'Chitta Baral']"
An Optimal Control Approach to Sequential Machine Teaching,Machine Learning,"Given a sequential learning algorithm and a target model, sequential machine
teaching aims to find the shortest training sequence to drive the learning
algorithm to the target model. We present the first principled way to find such
shortest training sequences. Our key insight is to formulate sequential machine
teaching as a time-optimal control problem. This allows us to solve sequential
teaching by leveraging key theoretical and computational tools developed over
the past 60 years in the optimal control community. Specifically, we study the
Pontryagin Maximum Principle, which yields a necessary condition for optimality
of a training sequence. We present analytic, structural, and numerical
implications of this approach on a case study with a least-squares loss
function and gradient descent learner. We compute optimal training sequences
for this problem, and although the sequences seem circuitous, we find that they
can vastly outperform the best available heuristics for generating training
sequences.","['Laurent Lessard', 'Xuezhou Zhang', 'Xiaojin Zhu']"
"CSCF: a chaotic sine cosine firefly Algorithm for practical application
  problems",Neural and Evolutionary Computing,"Recently, numerous meta-heuristic based approaches are deliberated to reduce
the computational complexities of several existing approaches that include
tricky derivations, very large memory space requirement, initial value
sensitivity etc. However, several optimization algorithms namely firefly
algorithm, sine cosine algorithm, particle swarm optimization algorithm have
few drawbacks such as computational complexity, convergence speed etc. So to
overcome such shortcomings, this paper aims in developing a novel Chaotic Sine
Cosine Firefly (CSCF) algorithm with numerous variants to solve optimization
problems. Here, the chaotic form of two algorithms namely the sine cosine
algorithm (SCA) and the Firefly (FF) algorithms are integrated to improve the
convergence speed and efficiency thus minimizing several complexity issues.
Moreover, the proposed CSCF approach is operated under various chaotic phases
and the optimal chaotic variants containing the best chaotic mapping is
selected. Then numerous chaotic benchmark functions are utilized to examine the
system performance of the CSCF algorithm. Finally, the simulation results for
the problems based on engineering design are demonstrated to prove the
efficiency, robustness and effectiveness of the proposed algorithm.",['Bryar A. Hassan']
Image Cartoon-Texture Decomposition Using Isotropic Patch Recurrence,Computer Vision and Pattern Recognition,"Aiming at separating the cartoon and texture layers from an image,
cartoon-texture decomposition approaches resort to image priors to model
cartoon and texture respectively. In recent years, patch recurrence has emerged
as a powerful prior for image recovery. However, the existing strategies of
using patch recurrence are ineffective to cartoon-texture decomposition, as
both cartoon contours and texture patterns exhibit strong patch recurrence in
images. To address this issue, we introduce the isotropy prior of patch
recurrence, that the spatial configuration of similar patches in texture
exhibits the isotropic structure which is different from that in cartoon, to
model the texture component. Based on the isotropic patch recurrence, we
construct a nonlocal sparsification system which can effectively distinguish
well-patterned features from contour edges. Incorporating the constructed
nonlocal system into morphology component analysis, we develop an effective
method to both noiseless and noisy cartoon-texture decomposition. The
experimental results have demonstrated the superior performance of the proposed
method to the existing ones, as well as the effectiveness of the isotropic
patch recurrence prior.","['Ruotao Xu', 'Yuhui Quan', 'Yong Xu']"
Probabilistic Label Trees for Extreme Multi-label Classification,Machine Learning,"Extreme multi-label classification (XMLC) is a learning task of tagging
instances with a small subset of relevant labels chosen from an extremely large
pool of possible labels. Problems of this scale can be efficiently handled by
organizing labels as a tree, like in hierarchical softmax used for multi-class
problems. In this paper, we thoroughly investigate probabilistic label trees
(PLTs) which can be treated as a generalization of hierarchical softmax for
multi-label problems. We first introduce the PLT model and discuss training and
inference procedures and their computational costs. Next, we prove the
consistency of PLTs for a wide spectrum of performance metrics. To this end, we
upperbound their regret by a function of surrogate-loss regrets of node
classifiers. Furthermore, we consider a problem of training PLTs in a fully
online setting, without any prior knowledge of training instances, their
features, or labels. In this case, both node classifiers and the tree structure
are trained online. We prove a specific equivalence between the fully online
algorithm and an algorithm with a tree structure given in advance. Finally, we
discuss several implementations of PLTs and introduce a new one, napkinXC,
which we empirically evaluate and compare with state-of-the-art algorithms.","['Kalina Jasinska-Kobus', 'Marek Wydmuch', 'Krzysztof Dembczynski', 'Mikhail Kuznetsov', 'Robert Busa-Fekete']"
AIVC: Artificial Intelligence based Video Codec,Neural and Evolutionary Computing,"This paper introduces AIVC, an end-to-end neural video codec. It is based on
two conditional autoencoders MNet and CNet, for motion compensation and coding.
AIVC learns to compress videos using any coding configurations through a single
end-to-end rate-distortion optimization. Furthermore, it offers performance
competitive with the recent video coder HEVC under several established test
conditions. A comprehensive ablation study is performed to evaluate the
benefits of the different modules composing AIVC. The implementation is made
available at https://orange-opensource.github.io/AIVC/.","['Théo Ladune', 'Pierrick Philippe']"
"Enhancing Mortality Prediction in Heart Failure Patients: Exploring
  Preprocessing Methods for Imbalanced Clinical Datasets",Machine Learning,"Heart failure (HF) is a critical condition in which the accurate prediction
of mortality plays a vital role in guiding patient management decisions.
However, clinical datasets used for mortality prediction in HF often suffer
from an imbalanced distribution of classes, posing significant challenges. In
this paper, we explore preprocessing methods for enhancing one-month mortality
prediction in HF patients. We present a comprehensive preprocessing framework
including scaling, outliers processing and resampling as key techniques. We
also employed an aware encoding approach to effectively handle missing values
in clinical datasets. Our study utilizes a comprehensive dataset from the
Persian Registry Of cardio Vascular disease (PROVE) with a significant class
imbalance. By leveraging appropriate preprocessing techniques and Machine
Learning (ML) algorithms, we aim to improve mortality prediction performance
for HF patients. The results reveal an average enhancement of approximately
3.6% in F1 score and 2.7% in MCC for tree-based models, specifically Random
Forest (RF) and XGBoost (XGB). This demonstrates the efficiency of our
preprocessing approach in effectively handling Imbalanced Clinical Datasets
(ICD). Our findings hold promise in guiding healthcare professionals to make
informed decisions and improve patient outcomes in HF management.","['Hanif Kia', 'Mansour Vali', 'Hadi Sabahi']"
"Diffusion-geometric maximally stable component detection in deformable
  shapes",Computer Vision and Pattern Recognition,"Maximally stable component detection is a very popular method for feature
analysis in images, mainly due to its low computation cost and high
repeatability. With the recent advance of feature-based methods in geometric
shape analysis, there is significant interest in finding analogous approaches
in the 3D world. In this paper, we formulate a diffusion-geometric framework
for stable component detection in non-rigid 3D shapes, which can be used for
geometric feature detection and description. A quantitative evaluation of our
method on the SHREC'10 feature detection benchmark shows its potential as a
source of high-quality features.","['Roee Litman', 'Alex M. Bronstein', 'Michael M. Bronstein']"
"Occlusion-Robust FAU Recognition by Mining Latent Space of Masked
  Autoencoders",Computer Vision and Pattern Recognition,"Facial action units (FAUs) are critical for fine-grained facial expression
analysis. Although FAU detection has been actively studied using ideally high
quality images, it was not thoroughly studied under heavily occluded
conditions. In this paper, we propose the first occlusion-robust FAU
recognition method to maintain FAU detection performance under heavy
occlusions. Our novel approach takes advantage of rich information from the
latent space of masked autoencoder (MAE) and transforms it into FAU features.
Bypassing the occlusion reconstruction step, our model efficiently extracts FAU
features of occluded faces by mining the latent space of a pretrained masked
autoencoder. Both node and edge-level knowledge distillation are also employed
to guide our model to find a mapping between latent space vectors and FAU
features. Facial occlusion conditions, including random small patches and large
blocks, are thoroughly studied. Experimental results on BP4D and DISFA datasets
show that our method can achieve state-of-the-art performances under the
studied facial occlusion, significantly outperforming existing baseline
methods. In particular, even under heavy occlusion, the proposed method can
achieve comparable performance as state-of-the-art methods under normal
conditions.","['Minyang Jiang', 'Yongwei Wang', 'Martin J. McKeown', 'Z. Jane Wang']"
Two-Stream Neural Networks for Tampered Face Detection,Computer Vision and Pattern Recognition,"We propose a two-stream network for face tampering detection. We train
GoogLeNet to detect tampering artifacts in a face classification stream, and
train a patch based triplet network to leverage features capturing local noise
residuals and camera characteristics as a second stream. In addition, we use
two different online face swapping applications to create a new dataset that
consists of 2010 tampered images, each of which contains a tampered face. We
evaluate the proposed two-stream network on our newly collected dataset.
Experimental results demonstrate the effectiveness of our method.","['Peng Zhou', 'Xintong Han', 'Vlad I. Morariu', 'Larry S. Davis']"
Time series classification for varying length series,Machine Learning,"Research into time series classification has tended to focus on the case of
series of uniform length. However, it is common for real-world time series data
to have unequal lengths. Differing time series lengths may arise from a number
of fundamentally different mechanisms. In this work, we identify and evaluate
two classes of such mechanisms -- variations in sampling rate relative to the
relevant signal and variations between the start and end points of one time
series relative to one another. We investigate how time series generated by
each of these classes of mechanism are best addressed for time series
classification. We perform extensive experiments and provide practical
recommendations on how variations in length should be handled in time series
classification.","['Chang Wei Tan', 'Francois Petitjean', 'Eamonn Keogh', 'Geoffrey I. Webb']"
"Cross-Modality Domain Adaptation for Freespace Detection: A Simple yet
  Effective Baseline",Computer Vision and Pattern Recognition,"As one of the fundamental functions of autonomous driving system, freespace
detection aims at classifying each pixel of the image captured by the camera as
drivable or non-drivable. Current works of freespace detection heavily rely on
large amount of densely labeled training data for accuracy and robustness,
which is time-consuming and laborious to collect and annotate. To the best of
our knowledge, we are the first work to explore unsupervised domain adaptation
for freespace detection to alleviate the data limitation problem with synthetic
data. We develop a cross-modality domain adaptation framework which exploits
both RGB images and surface normal maps generated from depth images. A
Collaborative Cross Guidance (CCG) module is proposed to leverage the context
information of one modality to guide the other modality in a cross manner, thus
realizing inter-modality intra-domain complement. To better bridge the domain
gap between source domain (synthetic data) and target domain (real-world data),
we also propose a Selective Feature Alignment (SFA) module which only aligns
the features of consistent foreground area between the two domains, thus
realizing inter-domain intra-modality adaptation. Extensive experiments are
conducted by adapting three different synthetic datasets to one real-world
dataset for freespace detection respectively. Our method performs closely to
fully supervised freespace detection methods (93.08 v.s. 97.50 F1 score) and
outperforms other general unsupervised domain adaptation methods for semantic
segmentation with large margins, which shows the promising potential of domain
adaptation for freespace detection.","['Yuanbin Wang', 'Leyan Zhu', 'Shaofei Huang', 'Tianrui Hui', 'Xiaojie Li', 'Fei Wang', 'Si Liu']"
KINN: Incorporating Expert Knowledge in Neural Networks,Machine Learning,"The promise of ANNs to automatically discover and extract useful
features/patterns from data without dwelling on domain expertise although seems
highly promising but comes at the cost of high reliance on large amount of
accurately labeled data, which is often hard to acquire and formulate
especially in time-series domains like anomaly detection, natural disaster
management, predictive maintenance and healthcare. As these networks completely
rely on data and ignore a very important modality i.e. expert, they are unable
to harvest any benefit from the expert knowledge, which in many cases is very
useful. In this paper, we try to bridge the gap between these data driven and
expert knowledge based systems by introducing a novel framework for
incorporating expert knowledge into the network (KINN). Integrating expert
knowledge into the network has three key advantages: (a) Reduction in the
amount of data needed to train the model, (b) provision of a lower bound on the
performance of the resulting classifier by obtaining the best of both worlds,
and (c) improved convergence of model parameters (model converges in smaller
number of epochs). Although experts are extremely good in solving different
tasks, there are some trends and patterns, which are usually hidden only in the
data. Therefore, KINN employs a novel residual knowledge incorporation scheme,
which can automatically determine the quality of the predictions made by the
expert and rectify it accordingly by learning the trends/patterns from data.
Specifically, the method tries to use information contained in one modality to
complement information missed by the other. We evaluated KINN on a real world
traffic flow prediction problem. KINN significantly superseded performance of
both the expert and as well as the base network (LSTM in this case) when
evaluated in isolation, highlighting its superiority for the task.","['Muhammad Ali Chattha', 'Shoaib Ahmed Siddiqui', 'Muhammad Imran Malik', 'Ludger van Elst', 'Andreas Dengel', 'Sheraz Ahmed']"
High-Dimensional Screening Using Multiple Grouping of Variables,Machine Learning (Statistics),"Screening is the problem of finding a superset of the set of non-zero entries
in an unknown p-dimensional vector \beta* given n noisy observations.
Naturally, we want this superset to be as small as possible. We propose a novel
framework for screening, which we refer to as Multiple Grouping (MuG), that
groups variables, performs variable selection over the groups, and repeats this
process multiple number of times to estimate a sequence of sets that contains
the non-zero entries in \beta*. Screening is done by taking an intersection of
all these estimated sets. The MuG framework can be used in conjunction with any
group based variable selection algorithm. In the high-dimensional setting,
where p >> n, we show that when MuG is used with the group Lasso estimator,
screening can be consistently performed without using any tuning parameter. Our
numerical simulations clearly show the merits of using the MuG framework in
practice.",['Divyanshu Vats']
"Improved Deep Convolutional Neural Network For Online Handwritten
  Chinese Character Recognition using Domain-Specific Knowledge",Computer Vision and Pattern Recognition,"Deep convolutional neural networks (DCNNs) have achieved great success in
various computer vision and pattern recognition applications, including those
for handwritten Chinese character recognition (HCCR). However, most current
DCNN-based HCCR approaches treat the handwritten sample simply as an image
bitmap, ignoring some vital domain-specific information that may be useful but
that cannot be learnt by traditional networks. In this paper, we propose an
enhancement of the DCNN approach to online HCCR by incorporating a variety of
domain-specific knowledge, including deformation, non-linear normalization,
imaginary strokes, path signature, and 8-directional features. Our contribution
is twofold. First, these domain-specific technologies are investigated and
integrated with a DCNN to form a composite network to achieve improved
performance. Second, the resulting DCNNs with diversity in their domain
knowledge are combined using a hybrid serial-parallel (HSP) strategy.
Consequently, we achieve a promising accuracy of 97.20% and 96.87% on
CASIA-OLHWDB1.0 and CASIA-OLHWDB1.1, respectively, outperforming the best
results previously reported in the literature.","['Weixin Yang', 'Lianwen Jin', 'Zecheng Xie', 'Ziyong Feng']"
"Two Ridge Solutions for the Incremental Broad Learning System on Added
  Nodes",Machine Learning,"The original Broad Learning System (BLS) on new added nodes and its existing
efficient implementation both assume the ridge parameter lambda -> 0 in the
ridge inverse to approximate the generalized inverse, and compute the
generalized inverse solution for the output weights. In this paper, we propose
two ridge solutions for the output weights in the BLS on added nodes, where
lambda -> 0 is no longer assumed, and lambda can be any positive real number.
One of the proposed ridge solutions computes the output weights from the
inverse Cholesky factor, which is updated efficiently by extending the existing
inverse Cholesky factorization. The other proposed ridge solution computes the
output weights from the ridge inverse, and updates the ridge inverse by
extending the Greville's method that is a classical tool to compute the
generalized inverse of partitioned matrices. For the proposed efficient ridge
solution based on the inverse Cholesky factor, we also develop another
implementation that is numerically more stable when the ridge parameter lambda
is very small. The proposed ridge solution based on the ridge inverse and the
numerically more stable implementation of the proposed efficient ridge solution
require the same complexity as the original BLS and the existing efficient BLS,
respectively. Moreover, the speedups of the proposed efficient ridge solution
to the original BLS and the existing efficient BLS are 3 and more than 1.67
respectively, when the computational complexities for each update are compared,
and the speedups are 1.99 - 2.52 and 1.31 - 1.58, respectively, when the total
training time is compared by numerical experiments. On the other hand, our
numerical experiments show that both the proposed ridge solutions for BLS
achieve better testing accuracies than the original BLS and the existing
efficient BLS.",['Hufei Zhu']
Multivariate response and parsimony for Gaussian cluster-weighted models,Computation (Statistics),"A family of parsimonious Gaussian cluster-weighted models is presented. This
family concerns a multivariate extension to cluster-weighted modelling that can
account for correlations between multivariate responses. Parsimony is attained
by constraining parts of an eigen-decomposition imposed on the component
covariance matrices. A sufficient condition for identifiability is provided and
an expectation-maximization algorithm is presented for parameter estimation.
Model performance is investigated on both synthetic and classical real data
sets and compared with some popular approaches. Finally, accounting for linear
dependencies in the presence of a linear regression structure is shown to offer
better performance, vis-\`{a}-vis clustering, over existing methodologies.","['Utkarsh J. Dang', 'Antonio Punzo', 'Paul D. McNicholas', 'Salvatore Ingrassia', 'Ryan P. Browne']"
Pupil Learning Mechanism,Machine Learning,"Studies on artificial neural networks rarely address both vanishing gradients
and overfitting issues. In this study, we follow the pupil learning procedure,
which has the features of interpreting, picking, understanding, cramming, and
organizing, to derive the pupil learning mechanism (PLM) by which to modify the
network structure and weights of 2-layer neural networks (2LNNs). The PLM
consists of modules for sequential learning, adaptive learning, perfect
learning, and less-overfitted learning. Based upon a copper price forecasting
dataset, we conduct an experiment to validate the PLM module design modules,
and an experiment to evaluate the performance of PLM. The empirical results
indeed approve the PLM module design and show the superiority of the proposed
PLM model over the linear regression model and the conventional
backpropagation-based 2LNN model.","['Rua-Huan Tsaih', 'Yu-Hang Chien', 'Shih-Yi Chien']"
"Interpretable Fully Convolutional Classification of Intrapapillary
  Capillary Loops for Real-Time Detection of Early Squamous Neoplasia",Computer Vision and Pattern Recognition,"In this work, we have concentrated our efforts on the interpretability of
classification results coming from a fully convolutional neural network.
Motivated by the classification of oesophageal tissue for real-time detection
of early squamous neoplasia, the most frequent kind of oesophageal cancer in
Asia, we present a new dataset and a novel deep learning method that by means
of deep supervision and a newly introduced concept, the embedded Class
Activation Map (eCAM), focuses on the interpretability of results as a design
constraint of a convolutional network. We present a new approach to visualise
attention that aims to give some insights on those areas of the oesophageal
tissue that lead a network to conclude that the images belong to a particular
class and compare them with those visual features employed by clinicians to
produce a clinical diagnosis. In comparison to a baseline method which does not
feature deep supervision but provides attention by grafting Class Activation
Maps, we improve the F1-score from 87.3% to 92.7% and provide more detailed
attention maps.","['Luis C. Garcia-Peraza-Herrera', 'Martin Everson', 'Wenqi Li', 'Inmanol Luengo', 'Lorenz Berger', 'Omer Ahmad', 'Laurence Lovat', 'Hsiu-Po Wang', 'Wen-Lun Wang', 'Rehan Haidry', 'Danail Stoyanov', 'Tom Vercauteren', 'Sebastien Ourselin']"
"Scheduled Sampling Based on Decoding Steps for Neural Machine
  Translation",Computation and Language (Natural Language Processing),"Scheduled sampling is widely used to mitigate the exposure bias problem for
neural machine translation. Its core motivation is to simulate the inference
scene during training by replacing ground-truth tokens with predicted tokens,
thus bridging the gap between training and inference. However, vanilla
scheduled sampling is merely based on training steps and equally treats all
decoding steps. Namely, it simulates an inference scene with uniform error
rates, which disobeys the real inference scene, where larger decoding steps
usually have higher error rates due to error accumulations. To alleviate the
above discrepancy, we propose scheduled sampling methods based on decoding
steps, increasing the selection chance of predicted tokens with the growth of
decoding steps. Consequently, we can more realistically simulate the inference
scene during training, thus better bridging the gap between training and
inference. Moreover, we investigate scheduled sampling based on both training
steps and decoding steps for further improvements. Experimentally, our
approaches significantly outperform the Transformer baseline and vanilla
scheduled sampling on three large-scale WMT tasks. Additionally, our approaches
also generalize well to the text summarization task on two popular benchmarks.","['Yijin Liu', 'Fandong Meng', 'Yufeng Chen', 'Jinan Xu', 'Jie Zhou']"
Data Augmentation via Levy Processes,Machine Learning (Statistics),"If a document is about travel, we may expect that short snippets of the
document should also be about travel. We introduce a general framework for
incorporating these types of invariances into a discriminative classifier. The
framework imagines data as being drawn from a slice of a Levy process. If we
slice the Levy process at an earlier point in time, we obtain additional
pseudo-examples, which can be used to train the classifier. We show that this
scheme has two desirable properties: it preserves the Bayes decision boundary,
and it is equivalent to fitting a generative model in the limit where we rewind
time back to 0. Our construction captures popular schemes such as Gaussian
feature noising and dropout training, as well as admitting new generalizations.","['Stefan Wager', 'William Fithian', 'Percy Liang']"
A Counter Example to Theorems of Cox and Fine,Artificial Intelligence,"Cox's well-known theorem justifying the use of probability is shown not to
hold in finite domains. The counterexample also suggests that Cox's assumptions
are insufficient to prove the result even in infinite domains. The same
counterexample is used to disprove a result of Fine on comparative conditional
probability.",['J. Y. Halpern']
Efficient Sentence Embedding using Discrete Cosine Transform,Computation and Language (Natural Language Processing),"Vector averaging remains one of the most popular sentence embedding methods
in spite of its obvious disregard for syntactic structure. While more complex
sequential or convolutional networks potentially yield superior classification
performance, the improvements in classification accuracy are typically mediocre
compared to the simple vector averaging. As an efficient alternative, we
propose the use of discrete cosine transform (DCT) to compress word sequences
in an order-preserving manner. The lower order DCT coefficients represent the
overall feature patterns in sentences, which results in suitable embeddings for
tasks that could benefit from syntactic features. Our results in semantic
probing tasks demonstrate that DCT embeddings indeed preserve more syntactic
information compared with vector averaging. With practically equivalent
complexity, the model yields better overall performance in downstream
classification tasks that correlate with syntactic features, which illustrates
the capacity of DCT to preserve word order information.","['Nada Almarwani', 'Hanan Aldarmaki', 'Mona Diab']"
"Map2Traj: Street Map Piloted Zero-shot Trajectory Generation with
  Diffusion Model",Artificial Intelligence,"User mobility modeling serves a crucial role in analysis and optimization of
contemporary wireless networks. Typical stochastic mobility models, e.g.,
random waypoint model and Gauss Markov model, can hardly capture the
distribution characteristics of users within real-world areas. State-of-the-art
trace-based mobility models and existing learning-based trajectory generation
methods, however, are frequently constrained by the inaccessibility of
substantial real trajectories due to privacy concerns. In this paper, we
harness the intrinsic correlation between street maps and trajectories and
develop a novel zero-shot trajectory generation method, named Map2Traj, by
exploiting the diffusion model. We incorporate street maps as a condition to
consistently pilot the denoising process and train our model on diverse sets of
real trajectories from various regions in Xi'an, China, and their corresponding
street maps. With solely the street map of an unobserved area, Map2Traj
generates synthetic trajectories that not only closely resemble the real-world
mobility pattern but also offer comparable efficacy. Extensive experiments
validate the efficacy of our proposed method on zero-shot trajectory generation
tasks in terms of both trajectory and distribution similarities. In addition, a
case study of employing Map2Traj in wireless network optimization is presented
to validate its efficacy for downstream applications.","['Zhenyu Tao', 'Wei Xu', 'Xiaohu You']"
Tensor Switching Networks,Neural and Evolutionary Computing,"We present a novel neural network algorithm, the Tensor Switching (TS)
network, which generalizes the Rectified Linear Unit (ReLU) nonlinearity to
tensor-valued hidden units. The TS network copies its entire input vector to
different locations in an expanded representation, with the location determined
by its hidden unit activity. In this way, even a simple linear readout from the
TS representation can implement a highly expressive deep-network-like function.
The TS network hence avoids the vanishing gradient problem by construction, at
the cost of larger representation size. We develop several methods to train the
TS network, including equivalent kernels for infinitely wide and deep TS
networks, a one-pass linear learning algorithm, and two
backpropagation-inspired representation learning algorithms. Our experimental
results demonstrate that the TS network is indeed more expressive and
consistently learns faster than standard ReLU networks.","['Chuan-Yung Tsai', 'Andrew Saxe', 'David Cox']"
TiBERT: Tibetan Pre-trained Language Model,Computation and Language (Natural Language Processing),"The pre-trained language model is trained on large-scale unlabeled text and
can achieve state-of-the-art results in many different downstream tasks.
However, the current pre-trained language model is mainly concentrated in the
Chinese and English fields. For low resource language such as Tibetan, there is
lack of a monolingual pre-trained model. To promote the development of Tibetan
natural language processing tasks, this paper collects the large-scale training
data from Tibetan websites and constructs a vocabulary that can cover 99.95$\%$
of the words in the corpus by using Sentencepiece. Then, we train the Tibetan
monolingual pre-trained language model named TiBERT on the data and vocabulary.
Finally, we apply TiBERT to the downstream tasks of text classification and
question generation, and compare it with classic models and multilingual
pre-trained models, the experimental results show that TiBERT can achieve the
best performance. Our model is published in http://tibert.cmli-nlp.com/","['Yuan Sun', 'Sisi Liu', 'Junjie Deng', 'Xiaobing Zhao']"
Simulation-guided Beam Search for Neural Combinatorial Optimization,Machine Learning,"Neural approaches for combinatorial optimization (CO) equip a learning
mechanism to discover powerful heuristics for solving complex real-world
problems. While neural approaches capable of high-quality solutions in a single
shot are emerging, state-of-the-art approaches are often unable to take full
advantage of the solving time available to them. In contrast, hand-crafted
heuristics perform highly effective search well and exploit the computation
time given to them, but contain heuristics that are difficult to adapt to a
dataset being solved. With the goal of providing a powerful search procedure to
neural CO approaches, we propose simulation-guided beam search (SGBS), which
examines candidate solutions within a fixed-width tree search that both a
neural net-learned policy and a simulation (rollout) identify as promising. We
further hybridize SGBS with efficient active search (EAS), where SGBS enhances
the quality of solutions backpropagated in EAS, and EAS improves the quality of
the policy used in SGBS. We evaluate our methods on well-known CO benchmarks
and show that SGBS significantly improves the quality of the solutions found
under reasonable runtime assumptions.","['Jinho Choo', 'Yeong-Dae Kwon', 'Jihoon Kim', 'Jeongwoo Jae', 'André Hottung', 'Kevin Tierney', 'Youngjune Gwon']"
"Factorization Approach for Sparse Spatio-Temporal Brain-Computer
  Interface",Artificial Intelligence,"Recently, advanced technologies have unlimited potential in solving various
problems with a large amount of data. However, these technologies have yet to
show competitive performance in brain-computer interfaces (BCIs) which deal
with brain signals. Basically, brain signals are difficult to collect in large
quantities, in particular, the amount of information would be sparse in
spontaneous BCIs. In addition, we conjecture that high spatial and temporal
similarities between tasks increase the prediction difficulty. We define this
problem as sparse condition. To solve this, a factorization approach is
introduced to allow the model to obtain distinct representations from latent
space. To this end, we propose two feature extractors: A class-common module is
trained through adversarial learning acting as a generator; Class-specific
module utilizes loss function generated from classification so that features
are extracted with traditional methods. To minimize the latent space shared by
the class-common and class-specific features, the model is trained under
orthogonal constraint. As a result, EEG signals are factorized into two
separate latent spaces. Evaluations were conducted on a single-arm motor
imagery dataset. From the results, we demonstrated that factorizing the EEG
signal allows the model to extract rich and decisive features under sparse
condition.","['Byeong-Hoo Lee', 'Jeong-Hyun Cho', 'Byoung-Hee Kwon', 'Seong-Whan Lee']"
Information-Theoretic Active Learning for Content-Based Image Retrieval,Computer Vision and Pattern Recognition,"We propose Information-Theoretic Active Learning (ITAL), a novel batch-mode
active learning method for binary classification, and apply it for acquiring
meaningful user feedback in the context of content-based image retrieval.
Instead of combining different heuristics such as uncertainty, diversity, or
density, our method is based on maximizing the mutual information between the
predicted relevance of the images and the expected user feedback regarding the
selected batch. We propose suitable approximations to this computationally
demanding problem and also integrate an explicit model of user behavior that
accounts for possible incorrect labels and unnameable instances. Furthermore,
our approach does not only take the structure of the data but also the expected
model output change caused by the user feedback into account. In contrast to
other methods, ITAL turns out to be highly flexible and provides
state-of-the-art performance across various datasets, such as MIRFLICKR and
ImageNet.","['Björn Barz', 'Christoph Käding', 'Joachim Denzler']"
"Series of Hessian-Vector Products for Tractable Saddle-Free Newton
  Optimisation of Neural Networks",Machine Learning,"Despite their popularity in the field of continuous optimisation,
second-order quasi-Newton methods are challenging to apply in machine learning,
as the Hessian matrix is intractably large. This computational burden is
exacerbated by the need to address non-convexity, for instance by modifying the
Hessian's eigenvalues as in Saddle-Free Newton methods. We propose an
optimisation algorithm which addresses both of these concerns - to our
knowledge, the first efficiently-scalable optimisation algorithm to
asymptotically use the exact inverse Hessian with absolute-value eigenvalues.
Our method frames the problem as a series which principally square-roots and
inverts the squared Hessian, then uses it to precondition a gradient vector,
all without explicitly computing or eigendecomposing the Hessian. A truncation
of this infinite series provides a new optimisation algorithm which is scalable
and comparable to other first- and second-order optimisation methods in both
runtime and optimisation performance. We demonstrate this in a variety of
settings, including a ResNet-18 trained on CIFAR-10.","['Elre T. Oldewage', 'Ross M. Clarke', 'José Miguel Hernández-Lobato']"
Portability of Syntactic Structure for Language Modeling,Computation and Language (Natural Language Processing),"The paper presents a study on the portability of statistical syntactic
knowledge in the framework of the structured language model (SLM). We
investigate the impact of porting SLM statistics from the Wall Street Journal
(WSJ) to the Air Travel Information System (ATIS) domain. We compare this
approach to applying the Microsoft rule-based parser (NLPwin) for the ATIS data
and to using a small amount of data manually parsed at UPenn for gathering the
intial SLM statistics. Surprisingly, despite the fact that it performs modestly
in perplexity (PPL), the model initialized on WSJ parses outperforms the other
initialization methods based on in-domain annotated data, achieving a
significant 0.4% absolute and 7% relative reduction in word error rate (WER)
over a baseline system whose word error rate is 5.8%; the improvement measured
relative to the minimum WER achievable on the N-best lists we worked with is
12%.",['Ciprian Chelba']
"CAUSE: Counterfactual Assessment of User Satisfaction Estimation in
  Task-Oriented Dialogue Systems",Computation and Language (Natural Language Processing),"An important unexplored aspect in previous work on user satisfaction
estimation for Task-Oriented Dialogue (TOD) systems is their evaluation in
terms of robustness for the identification of user dissatisfaction: current
benchmarks for user satisfaction estimation in TOD systems are highly skewed
towards dialogues for which the user is satisfied. The effect of having a more
balanced set of satisfaction labels on performance is unknown. However,
balancing the data with more dissatisfactory dialogue samples requires further
data collection and human annotation, which is costly and time-consuming. In
this work, we leverage large language models (LLMs) and unlock their ability to
generate satisfaction-aware counterfactual dialogues to augment the set of
original dialogues of a test collection. We gather human annotations to ensure
the reliability of the generated samples. We evaluate two open-source LLMs as
user satisfaction estimators on our augmented collection against
state-of-the-art fine-tuned models. Our experiments show that when used as
few-shot user satisfaction estimators, open-source LLMs show higher robustness
to the increase in the number of dissatisfaction labels in the test collection
than the fine-tuned state-of-the-art models. Our results shed light on the need
for data augmentation approaches for user satisfaction estimation in TOD
systems. We release our aligned counterfactual dialogues, which are curated by
human annotation, to facilitate further research on this topic.","['Amin Abolghasemi', 'Zhaochun Ren', 'Arian Askari', 'Mohammad Aliannejadi', 'Maarten de Rijke', 'Suzan Verberne']"
"A novel framework for MCDM based on Z numbers and soft likelihood
  function",Artificial Intelligence,"The optimization on the structure of process of information management under
uncertain environment has attracted lots of attention from researchers around
the world. Nevertheless, how to obtain accurate and rational evaluation from
assessments produced by experts is still an open problem. Specially,
intuitionistic fuzzy set provides an effective solution in handling
indeterminate information. And Yager proposes a novel method for fusion of
probabilistic evidence to handle uncertain and conflicting information lately
which is called soft likelihood function. This paper devises a novel framework
of soft likelihood function based on information volume of fuzzy membership and
credibility measure for extracting truly useful and valuable information from
uncertainty. An application is provided to verify the validity and correctness
of the proposed framework. Besides, the comparisons with other existing methods
further demonstrate the superiority of the novel framework of soft likelihood
function.",['Yuanpeng He']
"Ultrametric Component Analysis with Application to Analysis of Text and
  of Emotion",Artificial Intelligence,"We review the theory and practice of determining what parts of a data set are
ultrametric. It is assumed that the data set, to begin with, is endowed with a
metric, and we include discussion of how this can be brought about if a
dissimilarity, only, holds. The basis for part of the metric-endowed data set
being ultrametric is to consider triplets of the observables (vectors). We
develop a novel consensus of hierarchical clusterings. We do this in order to
have a framework (including visualization and supporting interpretation) for
the parts of the data that are determined to be ultrametric. Furthermore a
major objective is to determine locally ultrametric relationships as opposed to
non-local ultrametric relationships. As part of this work, we also study a
particular property of our ultrametricity coefficient, namely, it being a
function of the difference of angles of the base angles of the isosceles
triangle. This work is completed by a review of related work, on consensus
hierarchies, and of a major new application, namely quantifying and
interpreting the emotional content of narrative.",['Fionn Murtagh']
"The Quenching-Activation Behavior of the Gradient Descent Dynamics for
  Two-layer Neural Network Models",Machine Learning,"A numerical and phenomenological study of the gradient descent (GD) algorithm
for training two-layer neural network models is carried out for different
parameter regimes when the target function can be accurately approximated by a
relatively small number of neurons. It is found that for Xavier-like
initialization, there are two distinctive phases in the dynamic behavior of GD
in the under-parametrized regime: An early phase in which the GD dynamics
follows closely that of the corresponding random feature model and the neurons
are effectively quenched, followed by a late phase in which the neurons are
divided into two groups: a group of a few ""activated"" neurons that dominate the
dynamics and a group of background (or ""quenched"") neurons that support the
continued activation and deactivation process. This neural network-like
behavior is continued into the mildly over-parametrized regime, where it
undergoes a transition to a random feature-like behavior. The
quenching-activation process seems to provide a clear mechanism for ""implicit
regularization"". This is qualitatively different from the dynamics associated
with the ""mean-field"" scaling where all neurons participate equally and there
does not appear to be qualitative changes when the network parameters are
changed.","['Chao Ma', 'Lei Wu', 'Weinan E']"
Federated Few-Shot Learning with Adversarial Learning,Machine Learning,"We are interested in developing a unified machine learning model over many
mobile devices for practical learning tasks, where each device only has very
few training data. This is a commonly encountered situation in mobile computing
scenarios, where data is scarce and distributed while the tasks are distinct.
In this paper, we propose a federated few-shot learning (FedFSL) framework to
learn a few-shot classification model that can classify unseen data classes
with only a few labeled samples. With the federated learning strategy, FedFSL
can utilize many data sources while keeping data privacy and communication
efficiency. There are two technical challenges: 1) directly using the existing
federated learning approach may lead to misaligned decision boundaries produced
by client models, and 2) constraining the decision boundaries to be similar
over clients would overfit to training tasks but not adapt well to unseen
tasks. To address these issues, we propose to regularize local updates by
minimizing the divergence of client models. We also formulate the training in
an adversarial fashion and optimize the client models to produce a
discriminative feature space that can better represent unseen data samples. We
demonstrate the intuitions and conduct experiments to show our approaches
outperform baselines by more than 10% in learning vision tasks and 5% in
language tasks.","['Chenyou Fan', 'Jianwei Huang']"
Networked Intelligence: Towards Autonomous Cyber Physical Systems,Artificial Intelligence,"Developing intelligent systems requires combining results from both industry
and academia. In this report you find an overview of relevant research fields
and industrially applicable technologies for building very large scale cyber
physical systems. A concept architecture is used to illustrate how existing
pieces may fit together, and the maturity of the subsystems is estimated.
  The goal is to structure the developments and the challenge of machine
intelligence for Consumer and Industrial Internet technologists, cyber physical
systems researchers and people interested in the convergence of data & Internet
of Things. It can be used for planning developments of intelligent systems.",['Andre Karpistsenko']
"Automatic identification of segmentation errors for radiotherapy using
  geometric learning",Computer Vision and Pattern Recognition,"Automatic segmentation of organs-at-risk (OARs) in CT scans using
convolutional neural networks (CNNs) is being introduced into the radiotherapy
workflow. However, these segmentations still require manual editing and
approval by clinicians prior to clinical use, which can be time consuming. The
aim of this work was to develop a tool to automatically identify errors in 3D
OAR segmentations without a ground truth. Our tool uses a novel architecture
combining a CNN and graph neural network (GNN) to leverage the segmentation's
appearance and shape. The proposed model is trained using self-supervised
learning using a synthetically-generated dataset of segmentations of the
parotid and with realistic contouring errors. The effectiveness of our model is
assessed with ablation tests, evaluating the efficacy of different portions of
the architecture as well as the use of transfer learning from an unsupervised
pretext task. Our best performing model predicted errors on the parotid gland
with a precision of 85.0% & 89.7% for internal and external errors
respectively, and recall of 66.5% & 68.6%. This offline QA tool could be used
in the clinical pathway, potentially decreasing the time clinicians spend
correcting contours by detecting regions which require their attention. All our
code is publicly available at
https://github.com/rrr-uom-projects/contour_auto_QATool.","['Edward G. A. Henderson', 'Andrew F. Green', 'Marcel van Herk', 'Eliana M. Vasquez Osorio']"
"CNN-MERP: An FPGA-Based Memory-Efficient Reconfigurable Processor for
  Forward and Backward Propagation of Convolutional Neural Networks",Machine Learning,"Large-scale deep convolutional neural networks (CNNs) are widely used in
machine learning applications. While CNNs involve huge complexity, VLSI (ASIC
and FPGA) chips that deliver high-density integration of computational
resources are regarded as a promising platform for CNN's implementation. At
massive parallelism of computational units, however, the external memory
bandwidth, which is constrained by the pin count of the VLSI chip, becomes the
system bottleneck. Moreover, VLSI solutions are usually regarded as a lack of
the flexibility to be reconfigured for the various parameters of CNNs. This
paper presents CNN-MERP to address these issues. CNN-MERP incorporates an
efficient memory hierarchy that significantly reduces the bandwidth
requirements from multiple optimizations including on/off-chip data allocation,
data flow optimization and data reuse. The proposed 2-level reconfigurability
is utilized to enable fast and efficient reconfiguration, which is based on the
control logic and the multiboot feature of FPGA. As a result, an external
memory bandwidth requirement of 1.94MB/GFlop is achieved, which is 55% lower
than prior arts. Under limited DRAM bandwidth, a system throughput of
1244GFlop/s is achieved at the Vertex UltraScale platform, which is 5.48 times
higher than the state-of-the-art FPGA implementations.","['Xushen Han', 'Dajiang Zhou', 'Shihao Wang', 'Shinji Kimura']"
OPEB: Open Physical Environment Benchmark for Artificial Intelligence,Artificial Intelligence,"Artificial Intelligence methods to solve continuous- control tasks have made
significant progress in recent years. However, these algorithms have important
limitations and still need significant improvement to be used in industry and
real- world applications. This means that this area is still in an active
research phase. To involve a large number of research groups, standard
benchmarks are needed to evaluate and compare proposed algorithms. In this
paper, we propose a physical environment benchmark framework to facilitate
collaborative research in this area by enabling different research groups to
integrate their designed benchmarks in a unified cloud-based repository and
also share their actual implemented benchmarks via the cloud. We demonstrate
the proposed framework using an actual implementation of the classical
mountain-car example and present the results obtained using a Reinforcement
Learning algorithm.","['Hamid Mirzaei', 'Mona Fathollahi', 'Tony Givargis']"
"Emulator-based global sensitivity analysis for flow-like landslide
  run-out models",Fluid Dynamics,"Landslide run-out modeling involves various uncertainties originating from
model input data. It is therefore desirable to assess the model's sensitivity.
A global sensitivity analysis that is capable of exploring the entire input
space and accounts for all interactions, often remains limited due to
computational challenges resulting from a large number of necessary model runs.
We address this research gap by integrating Gaussian process emulation into
landslide run-out modeling and apply it to the open-source simulation tool
r.avaflow. The feasibility and efficiency of our approach is illustrated based
on the 2017 Bondo landslide event. The sensitivity of aggregated model outputs,
such as the apparent friction angle, impact area, as well as spatially resolved
maximum flow height and velocity, to the dry-Coulomb friction coefficient,
turbulent friction coefficient and the release volume are studied. The results
of first-order effects are consistent with previous results of common
one-at-a-time sensitivity analyses. In addition to that, our approach allows to
rigorously investigate interactions. Strong interactions are detected on the
margins of the flow path where the expectation and variation of maximum flow
height and velocity are small. The interactions generally become weak with
increasing variation of maximum flow height and velocity. Besides, there are
stronger interactions between the two friction coefficients than between the
release volume and each friction coefficient. In the future, it is promising to
extend the approach for other computationally expensive tasks like uncertainty
quantification, model calibration, and smart early warning.","['Hu Zhao', 'Florian Amann', 'Julia Kowalski']"
"Early Recall, Late Precision: Multi-Robot Semantic Object Mapping under
  Operational Constraints in Perceptually-Degraded Environments",Robotics,"Semantic object mapping in uncertain, perceptually degraded environments
during long-range multi-robot autonomous exploration tasks such as
search-and-rescue is important and challenging. During such missions, high
recall is desirable to avoid missing true target objects and high precision is
also critical to avoid wasting valuable operational time on false positives.
Given recent advancements in visual perception algorithms, the former is
largely solvable autonomously, but the latter is difficult to address without
the supervision of a human operator. However, operational constraints such as
mission time, computational requirements, mesh network bandwidth and so on, can
make the operator's task infeasible unless properly managed. We propose the
Early Recall, Late Precision (EaRLaP) semantic object mapping pipeline to solve
this problem. EaRLaP was used by Team CoSTAR in DARPA Subterranean Challenge,
where it successfully detected all the artifacts encountered by the team of
robots. We will discuss these results and performance of the EaRLaP on various
datasets.","['Xianmei Lei', 'Taeyeon Kim', 'Nicolas Marchal', 'Daniel Pastor', 'Barry Ridge', 'Frederik Schöller', 'Edward Terry', 'Fernando Chavez', 'Thomas Touma', 'Kyohei Otsu', 'Ali Agha']"
Video Instance Shadow Detection Under the Sun and Sky,Computer Vision and Pattern Recognition,"Instance shadow detection, crucial for applications such as photo editing and
light direction estimation, has undergone significant advancements in
predicting shadow instances, object instances, and their associations. The
extension of this task to videos presents challenges in annotating diverse
video data and addressing complexities arising from occlusion and temporary
disappearances within associations. In response to these challenges, we
introduce ViShadow, a semi-supervised video instance shadow detection framework
that leverages both labeled image data and unlabeled video data for training.
ViShadow features a two-stage training pipeline: the first stage, utilizing
labeled image data, identifies shadow and object instances through contrastive
learning for cross-frame pairing. The second stage employs unlabeled videos,
incorporating an associated cycle consistency loss to enhance tracking ability.
A retrieval mechanism is introduced to manage temporary disappearances,
ensuring tracking continuity. The SOBA-VID dataset, comprising unlabeled
training videos and labeled testing videos, along with the SOAP-VID metric, is
introduced for the quantitative evaluation of VISD solutions. The effectiveness
of ViShadow is further demonstrated through various video-level applications
such as video inpainting, instance cloning, shadow editing, and text-instructed
shadow-object manipulation.","['Zhenghao Xing', 'Tianyu Wang', 'Xiaowei Hu', 'Haoran Wu', 'Chi-Wing Fu', 'Pheng-Ann Heng']"
Adaptive Deep Kernel Learning,Machine Learning,"Deep kernel learning provides an elegant and principled framework for
combining the structural properties of deep learning algorithms with the
flexibility of kernel methods. By means of a deep neural network, we learn a
parametrized kernel operator that can be combined with a differentiable kernel
algorithm during inference. While previous work within this framework has
focused on learning a single kernel for large datasets, we learn a kernel
family for a variety of few-shot regression tasks. Compared to single deep
kernel learning, our algorithm enables the identification of the appropriate
kernel for each task during inference. As such, it is well adapted for complex
task distributions in a few-shot learning setting, which we demonstrate by
comparing against existing state-of-the-art algorithms using real-world,
few-shot regression tasks related to the field of drug discovery.","['Prudencio Tossou', 'Basile Dura', 'Francois Laviolette', 'Mario Marchand', 'Alexandre Lacoste']"
On the Performance of Empirical Risk Minimization with Smoothed Data,Machine Learning (Statistics),"In order to circumvent statistical and computational hardness results in
sequential decision-making, recent work has considered smoothed online
learning, where the distribution of data at each time is assumed to have
bounded likeliehood ratio with respect to a base measure when conditioned on
the history. While previous works have demonstrated the benefits of smoothness,
they have either assumed that the base measure is known to the learner or have
presented computationally inefficient algorithms applying only in special
cases. This work investigates the more general setting where the base measure
is \emph{unknown} to the learner, focusing in particular on the performance of
Empirical Risk Minimization (ERM) with square loss when the data are
well-specified and smooth. We show that in this setting, ERM is able to achieve
sublinear error whenever a class is learnable with iid data; in particular, ERM
achieves error scaling as $\tilde O( \sqrt{\mathrm{comp}(\mathcal F)\cdot T}
)$, where $\mathrm{comp}(\mathcal F)$ is the statistical complexity of learning
$\mathcal F$ with iid data. In so doing, we prove a novel norm comparison bound
for smoothed data that comprises the first sharp norm comparison for dependent
data applying to arbitrary, nonlinear function classes. We complement these
results with a lower bound indicating that our analysis of ERM is essentially
tight, establishing a separation in the performance of ERM between smoothed and
iid data.","['Adam Block', 'Alexander Rakhlin', 'Abhishek Shetty']"
"""Pale as death"" or ""pâle comme la mort"" : Frozen similes used as
  literary clichés",Computation and Language (Natural Language Processing),"The present study is focused on the automatic identification and description
of frozen similes in British and French novels written between the 19 th
century and the beginning of the 20 th century. Two main patterns of frozen
similes were considered: adjectival ground + simile marker + nominal vehicle
(e.g. happy as a lark) and eventuality + simile marker + nominal vehicle (e.g.
sleep like a top). All potential similes and their components were first
extracted using a rule-based algorithm. Then, frozen similes were identified
based on reference lists of existing similes and semantic distance between the
tenor and the vehicle. The results obtained tend to confirm the fact that
frozen similes are not used haphazardly in literary texts. In addition,
contrary to how they are often presented, frozen similes often go beyond the
ground or the eventuality and the vehicle to also include the tenor.","['Suzanne Mpouli', 'Jean-Gabriel Ganascia']"
GNOME: Generating Negotiations through Open-Domain Mapping of Exchanges,Computation and Language (Natural Language Processing),"Language Models have previously shown strong negotiation capabilities in
closed domains where the negotiation strategy prediction scope is constrained
to a specific setup. In this paper, we first show that these models are not
generalizable beyond their original training domain despite their wide-scale
pretraining. Following this, we propose an automated framework called GNOME,
which processes existing human-annotated, closed-domain datasets using Large
Language Models and produces synthetic open-domain dialogues for negotiation.
GNOME improves the generalizability of negotiation systems while reducing the
expensive and subjective task of manual data curation. Through our experimental
setup, we create a benchmark comparing encoder and decoder models trained on
existing datasets against datasets created through GNOME. Our results show that
models trained on our dataset not only perform better than previous state of
the art models on domain specific strategy prediction, but also generalize
better to previously unseen domains.","['Darshan Deshpande', 'Shambhavi Sinha', 'Anirudh Ravi Kumar', 'Debaditya Pal', 'Jonathan May']"
"Learnable Activation Functions in Physics-Informed Neural Networks for
  Solving Partial Differential Equations",Neural and Evolutionary Computing,"We investigate the use of learnable activation functions in Physics-Informed
Neural Networks (PINNs) for solving Partial Differential Equations (PDEs).
Specifically, we compare the efficacy of traditional Multilayer Perceptrons
(MLPs) with fixed and learnable activations against Kolmogorov-Arnold Networks
(KANs), which employ learnable basis functions. Physics-informed neural
networks (PINNs) have emerged as an effective method for directly incorporating
physical laws into the learning process, offering a data-efficient solution for
both the forward and inverse problems associated with PDEs. However, challenges
such as effective training and spectral bias, where low-frequency components
are learned more effectively, often limit their applicability to problems
characterized by rapid oscillations or sharp transitions. By employing
different activation or basis functions on MLP and KAN, we assess their impact
on convergence behavior and spectral bias mitigation, and the accurate
approximation of PDEs. The findings offer insights into the design of neural
network architectures that balance training efficiency, convergence speed, and
test accuracy for PDE solvers. By evaluating the influence of activation or
basis function choices, this work provides guidelines for developing more
robust and accurate PINN models. The source code and pre-trained models used in
this study are made publicly available to facilitate reproducibility and future
exploration.","['Afrah Fareaa', 'Mustafa Serdar Celebi']"
"On the Generation of Alternative Explanations with Implications for
  Belief Revision",Artificial Intelligence,"In general, the best explanation for a given observation makes no promises on
how good it is with respect to other alternative explanations. A major
deficiency of message-passing schemes for belief revision in Bayesian networks
is their inability to generate alternatives beyond the second best. In this
paper, we present a general approach based on linear constraint systems that
naturally generates alternative explanations in an orderly and highly efficient
manner. This approach is then applied to cost-based abduction problems as well
as belief revision in Bayesian net works.",['Eugene Santos Jr']
Multiscale Fields of Patterns,Computer Vision and Pattern Recognition,"We describe a framework for defining high-order image models that can be used
in a variety of applications. The approach involves modeling local patterns in
a multiscale representation of an image. Local properties of a coarsened image
reflect non-local properties of the original image. In the case of binary
images local properties are defined by the binary patterns observed over small
neighborhoods around each pixel. With the multiscale representation we capture
the frequency of patterns observed at different scales of resolution. This
framework leads to expressive priors that depend on a relatively small number
of parameters. For inference and learning we use an MCMC method for block
sampling with very large blocks. We evaluate the approach with two example
applications. One involves contour detection. The other involves binary
segmentation.","['Pedro F. Felzenszwalb', 'John G. Oberlin']"
Language Modelling as a Multi-Task Problem,Computation and Language (Natural Language Processing),"In this paper, we propose to study language modelling as a multi-task
problem, bringing together three strands of research: multi-task learning,
linguistics, and interpretability. Based on hypotheses derived from linguistic
theory, we investigate whether language models adhere to learning principles of
multi-task learning during training. To showcase the idea, we analyse the
generalisation behaviour of language models as they learn the linguistic
concept of Negative Polarity Items (NPIs). Our experiments demonstrate that a
multi-task setting naturally emerges within the objective of the more general
task of language modelling.We argue that this insight is valuable for
multi-task learning, linguistics and interpretability research and can lead to
exciting new findings in all three domains.","['Lucas Weber', 'Jaap Jumelet', 'Elia Bruni', 'Dieuwke Hupkes']"
"Make Thunderbolts Less Frightening -- Predicting Extreme Weather Using
  Deep Learning",Machine Learning,"Forecasting severe weather conditions is still a very challenging and
computationally expensive task due to the enormous amount of data and the
complexity of the underlying physics. Machine learning approaches and
especially deep learning have however shown huge improvements in many research
areas dealing with large datasets in recent years. In this work, we tackle one
specific sub-problem of weather forecasting, namely the prediction of
thunderstorms and lightning. We propose the use of a convolutional neural
network architecture inspired by UNet++ and ResNet to predict thunderstorms as
a binary classification problem based on satellite images and lightnings
recorded in the past. We achieve a probability of detection of more than 94%
for lightnings within the next 15 minutes while at the same time minimizing the
false alarm ratio compared to previous approaches.","['Christian Schön', 'Jens Dittrich']"
Drone Object Detection Using RGB/IR Fusion,Computer Vision and Pattern Recognition,"Object detection using aerial drone imagery has received a great deal of
attention in recent years. While visible light images are adequate for
detecting objects in most scenarios, thermal cameras can extend the
capabilities of object detection to night-time or occluded objects. As such,
RGB and Infrared (IR) fusion methods for object detection are useful and
important. One of the biggest challenges in applying deep learning methods to
RGB/IR object detection is the lack of available training data for drone IR
imagery, especially at night. In this paper, we develop several strategies for
creating synthetic IR images using the AIRSim simulation engine and CycleGAN.
Furthermore, we utilize an illumination-aware fusion framework to fuse RGB and
IR images for object detection on the ground. We characterize and test our
methods for both simulated and actual data. Our solution is implemented on an
NVIDIA Jetson Xavier running on an actual drone, requiring about 28
milliseconds of processing per RGB/IR image pair.","['Lizhi Yang', 'Ruhang Ma', 'Avideh Zakhor']"
Aligning Large Language Models for Controllable Recommendations,Information Retrieval,"Inspired by the exceptional general intelligence of Large Language Models
(LLMs), researchers have begun to explore their application in pioneering the
next generation of recommender systems - systems that are conversational,
explainable, and controllable. However, existing literature primarily
concentrates on integrating domain-specific knowledge into LLMs to enhance
accuracy, often neglecting the ability to follow instructions. To address this
gap, we initially introduce a collection of supervised learning tasks,
augmented with labels derived from a conventional recommender model, aimed at
explicitly improving LLMs' proficiency in adhering to recommendation-specific
instructions. Subsequently, we develop a reinforcement learning-based alignment
procedure to further strengthen LLMs' aptitude in responding to users'
intentions and mitigating formatting errors. Through extensive experiments on
two real-world datasets, our method markedly advances the capability of LLMs to
comply with instructions within recommender systems, while sustaining a high
level of accuracy performance.","['Wensheng Lu', 'Jianxun Lian', 'Wei Zhang', 'Guanghua Li', 'Mingyang Zhou', 'Hao Liao', 'Xing Xie']"
On Convergence Property of Implicit Self-paced Objective,Artificial Intelligence,"Self-paced learning (SPL) is a new methodology that simulates the learning
principle of humans/animals to start learning easier aspects of a learning
task, and then gradually take more complex examples into training. This
new-coming learning regime has been empirically substantiated to be effective
in various computer vision and pattern recognition tasks. Recently, it has been
proved that the SPL regime has a close relationship to a implicit self-paced
objective function. While this implicit objective could provide helpful
interpretations to the effectiveness, especially the robustness, insights under
the SPL paradigms, there are still no theoretical results strictly proved to
verify such relationship. To this issue, in this paper, we provide some
convergence results on this implicit objective of SPL. Specifically, we prove
that the learning process of SPL always converges to critical points of this
implicit objective under some mild conditions. This result verifies the
intrinsic relationship between SPL and this implicit objective, and makes the
previous robustness analysis on SPL complete and theoretically rational.","['Zilu Ma', 'Shiqi Liu', 'Deyu Meng']"
"GEC-DePenD: Non-Autoregressive Grammatical Error Correction with
  Decoupled Permutation and Decoding",Computation and Language (Natural Language Processing),"Grammatical error correction (GEC) is an important NLP task that is currently
usually solved with autoregressive sequence-to-sequence models. However,
approaches of this class are inherently slow due to one-by-one token
generation, so non-autoregressive alternatives are needed. In this work, we
propose a novel non-autoregressive approach to GEC that decouples the
architecture into a permutation network that outputs a self-attention weight
matrix that can be used in beam search to find the best permutation of input
tokens (with auxiliary {ins} tokens) and a decoder network based on a
step-unrolled denoising autoencoder that fills in specific tokens. This allows
us to find the token permutation after only one forward pass of the permutation
network, avoiding autoregressive constructions. We show that the resulting
network improves over previously known non-autoregressive methods for GEC and
reaches the level of autoregressive methods that do not use language-specific
synthetic data generation methods. Our results are supported by a comprehensive
experimental validation on the ConLL-2014 and Write&Improve+LOCNESS datasets
and an extensive ablation study that supports our architectural and algorithmic
choices.","['Konstantin Yakovlev', 'Alexander Podolskiy', 'Andrey Bout', 'Sergey Nikolenko', 'Irina Piontkovskaya']"
"From ""What"" to ""When"" -- a Spiking Neural Network Predicting Rare Events
  and Time to their Occurrence",Neural and Evolutionary Computing,"In the reinforcement learning (RL) tasks, the ability to predict receiving
reward in the near or more distant future means the ability to evaluate the
current state as more or less close to the target state (labelled by the reward
signal). In the present work, we utilize a spiking neural network (SNN) to
predict time to the next target event (reward - in case of RL). In the context
of SNNs, events are represented as spikes emitted by network neurons or input
nodes. It is assumed that target events are indicated by spikes emitted by a
special network input node. Using description of the current state encoded in
the form of spikes from the other input nodes, the network should predict
approximate time of the next target event. This research paper presents a novel
approach to learning the corresponding predictive model by an SNN consisting of
leaky integrate-and-fire (LIF) neurons. The proposed method leverages specially
designed local synaptic plasticity rules and a novel columnar-layered SNN
architecture. Similar to our previous works, this study places a strong
emphasis on the hardware-friendliness of the proposed models, ensuring their
efficient implementation on modern and future neuroprocessors. The approach
proposed was tested on a simple reward prediction task in the context of one of
the RL benchmark ATARI games, ping-pong. It was demonstrated that the SNN
described in this paper gives superior prediction accuracy in comparison with
precise machine learning techniques, such as decision tree algorithms and
convolutional neural networks.",['Mikhail Kiselev']
Retrieval is Accurate Generation,Computation and Language (Natural Language Processing),"Standard language models generate text by selecting tokens from a fixed,
finite, and standalone vocabulary. We introduce a novel method that selects
context-aware phrases from a collection of supporting documents. One of the
most significant challenges for this paradigm shift is determining the training
oracles, because a string of text can be segmented in various ways and each
segment can be retrieved from numerous possible documents. To address this, we
propose to initialize the training oracles using linguistic heuristics and,
more importantly, bootstrap the oracles through iterative self-reinforcement.
Extensive experiments show that our model not only outperforms standard
language models on a variety of knowledge-intensive tasks but also demonstrates
improved generation quality in open-ended text generation. For instance,
compared to the standard language model counterpart, our model raises the
accuracy from 23.47% to 36.27% on OpenbookQA, and improves the MAUVE score from
42.61% to 81.58% in open-ended text generation. Remarkably, our model also
achieves the best performance and the lowest latency among several
retrieval-augmented baselines. In conclusion, we assert that retrieval is more
accurate generation and hope that our work will encourage further research on
this new paradigm shift.","['Bowen Cao', 'Deng Cai', 'Leyang Cui', 'Xuxin Cheng', 'Wei Bi', 'Yuexian Zou', 'Shuming Shi']"
"On Estimating Multi-Attribute Choice Preferences using Private Signals
  and Matrix Factorization",Machine Learning (Statistics),"Revealed preference theory studies the possibility of modeling an agent's
revealed preferences and the construction of a consistent utility function.
However, modeling agent's choices over preference orderings is not always
practical and demands strong assumptions on human rationality and
data-acquisition abilities. Therefore, we propose a simple generative choice
model where agents are assumed to generate the choice probabilities based on
latent factor matrices that capture their choice evaluation across multiple
attributes. Since the multi-attribute evaluation is typically hidden within the
agent's psyche, we consider a signaling mechanism where agents are provided
with choice information through private signals, so that the agent's choices
provide more insight about his/her latent evaluation across multiple
attributes. We estimate the choice model via a novel multi-stage matrix
factorization algorithm that minimizes the average deviation of the factor
estimates from choice data. Simulation results are presented to validate the
estimation performance of our proposed algorithm.","['Venkata Sriram Siddhardh Nadendla', 'Cedric Langbort']"
"DPMPC-Planner: A real-time UAV trajectory planning framework for complex
  static environments with dynamic obstacles",Robotics,"Safe UAV navigation is challenging due to the complex environment structures,
dynamic obstacles, and uncertainties from measurement noises and unpredictable
moving obstacle behaviors. Although plenty of recent works achieve safe
navigation in complex static environments with sophisticated mapping
algorithms, such as occupancy map and ESDF map, these methods cannot reliably
handle dynamic environments due to the mapping limitation from moving
obstacles. To address the limitation, this paper proposes a trajectory planning
framework to achieve safe navigation considering complex static environments
with dynamic obstacles. To reliably handle dynamic obstacles, we divide the
environment representation into static mapping and dynamic object
representation, which can be obtained from computer vision methods. Our
framework first generates a static trajectory based on the proposed iterative
corridor shrinking algorithm. Then, reactive chance-constrained model
predictive control with temporal goal tracking is applied to avoid dynamic
obstacles with uncertainties. The simulation results in various environments
demonstrate the ability of our algorithm to navigate safely in complex static
environments with dynamic obstacles.","['Zhefan Xu', 'Di Deng', 'Yiping Dong', 'Kenji Shimada']"
"OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal
  Regression",Computer Vision and Pattern Recognition,"This paper presents a language-powered paradigm for ordinal regression.
Existing methods usually treat each rank as a category and employ a set of
weights to learn these concepts. These methods are easy to overfit and usually
attain unsatisfactory performance as the learned concepts are mainly derived
from the training set. Recent large pre-trained vision-language models like
CLIP have shown impressive performance on various visual tasks. In this paper,
we propose to learn the rank concepts from the rich semantic CLIP latent space.
Specifically, we reformulate this task as an image-language matching problem
with a contrastive objective, which regards labels as text and obtains a
language prototype from a text encoder for each rank. While prompt engineering
for CLIP is extremely time-consuming, we propose OrdinalCLIP, a differentiable
prompting method for adapting CLIP for ordinal regression. OrdinalCLIP consists
of learnable context tokens and learnable rank embeddings; The learnable rank
embeddings are constructed by explicitly modeling numerical continuity,
resulting in well-ordered, compact language prototypes in the CLIP space. Once
learned, we can only save the language prototypes and discard the huge language
model, resulting in zero additional computational overhead compared with the
linear head counterpart. Experimental results show that our paradigm achieves
competitive performance in general ordinal regression tasks, and gains
improvements in few-shot and distribution shift settings for age estimation.
The code is available at https://github.com/xk-huang/OrdinalCLIP.","['Wanhua Li', 'Xiaoke Huang', 'Zheng Zhu', 'Yansong Tang', 'Xiu Li', 'Jie Zhou', 'Jiwen Lu']"
"Stability-penalty-adaptive follow-the-regularized-leader: Sparsity,
  game-dependency, and best-of-both-worlds",Machine Learning,"Adaptivity to the difficulties of a problem is a key property in sequential
decision-making problems to broaden the applicability of algorithms.
Follow-the-regularized-leader (FTRL) has recently emerged as one of the most
promising approaches for obtaining various types of adaptivity in bandit
problems. Aiming to further generalize this adaptivity, we develop a generic
adaptive learning rate, called stability-penalty-adaptive (SPA) learning rate
for FTRL. This learning rate yields a regret bound jointly depending on
stability and penalty of the algorithm, into which the regret of FTRL is
typically decomposed. With this result, we establish several algorithms with
three types of adaptivity: sparsity, game-dependency, and best-of-both-worlds
(BOBW). Despite the fact that sparsity appears frequently in real problems,
existing sparse multi-armed bandit algorithms with $k$-arms assume that the
sparsity level $s \leq k$ is known in advance, which is often not the case in
real-world scenarios. To address this issue, we first establish $s$-agnostic
algorithms with regret bounds of $\tilde{O}(\sqrt{sT})$ in the adversarial
regime for $T$ rounds, which matches the existing lower bound up to a
logarithmic factor. Meanwhile, BOBW algorithms aim to achieve a near-optimal
regret in both the stochastic and adversarial regimes. Leveraging the SPA
learning rate and the technique for $s$-agnostic algorithms combined with a new
analysis to bound the variation in FTRL output in response to changes in a
regularizer, we establish the first BOBW algorithm with a sparsity-dependent
bound. Additionally, we explore partial monitoring and demonstrate that the
proposed SPA learning rate framework allows us to achieve a game-dependent
bound and the BOBW simultaneously.","['Taira Tsuchiya', 'Shinji Ito', 'Junya Honda']"
Bandits with Abstention under Expert Advice,Machine Learning,"We study the classic problem of prediction with expert advice under bandit
feedback. Our model assumes that one action, corresponding to the learner's
abstention from play, has no reward or loss on every trial. We propose the CBA
algorithm, which exploits this assumption to obtain reward bounds that can
significantly improve those of the classical Exp4 algorithm. We can view our
problem as the aggregation of confidence-rated predictors when the learner has
the option of abstention from play. Importantly, we are the first to achieve
bounds on the expected cumulative reward for general confidence-rated
predictors. In the special case of specialists we achieve a novel reward bound,
significantly improving previous bounds of SpecialistExp (treating abstention
as another action). As an example application, we discuss learning unions of
balls in a finite metric space. In this contextual setting, we devise an
efficient implementation of CBA, reducing the runtime from quadratic to almost
linear in the number of contexts. Preliminary experiments show that CBA
improves over existing bandit algorithms.","['Stephen Pasteris', 'Alberto Rumi', 'Maximilian Thiessen', 'Shota Saito', 'Atsushi Miyauchi', 'Fabio Vitale', 'Mark Herbster']"
"SE-ECGNet: A Multi-scale Deep Residual Network with
  Squeeze-and-Excitation Module for ECG Signal Classification",Machine Learning,"The classification of electrocardiogram (ECG) signals, which takes much time
and suffers from a high rate of misjudgment, is recognized as an extremely
challenging task for cardiologists. The major difficulty of the ECG signals
classification is caused by the long-term sequence dependencies. Most existing
approaches for ECG signal classification use Recurrent Neural Network models,
e.g., LSTM and GRU, which are unable to extract accurate features for such long
sequences. Other approaches utilize 1-Dimensional Convolutional Neural Network
(CNN), such as ResNet or its variant, and they can not make good use of the
multi-lead information from ECG signals.Based on the above observations, we
develop a multi-scale deep residual network for the ECG signal classification
task. We are the first to propose to treat the multi-lead signal as a
2-dimensional matrix and combines multi-scale 2-D convolution blocks with 1-D
convolution blocks for feature extraction. Our proposed model achieves 99.2%
F1-score in the MIT-BIH dataset and 89.4% F1-score in Alibaba dataset and
outperforms the state-of-the-art performance by 2% and 3%, respectively, view
related code and data at https://github.com/Amadeuszhao/SE-ECGNet","['Haozhen Zhang', 'Wei Zhao', 'Shuang Liu']"
"Fusing Deep Learned and Hand-Crafted Features of Appearance, Shape, and
  Dynamics for Automatic Pain Estimation",Computer Vision and Pattern Recognition,"Automatic continuous time, continuous value assessment of a patient's pain
from face video is highly sought after by the medical profession. Despite the
recent advances in deep learning that attain impressive results in many
domains, pain estimation risks not being able to benefit from this due to the
difficulty in obtaining data sets of considerable size. In this work we propose
a combination of hand-crafted and deep-learned features that makes the most of
deep learning techniques in small sample settings. Encoding shape, appearance,
and dynamics, our method significantly outperforms the current state of the
art, attaining a RMSE error of less than 1 point on a 16-level pain scale,
whilst simultaneously scoring a 67.3% Pearson correlation coefficient between
our predicted pain level time series and the ground truth.","['Joy Egede', 'Michel Valstar', 'Brais Martinez']"
"FortuneTeller: Predicting Microarchitectural Attacks via Unsupervised
  Deep Learning",Cryptography and Security,"The growing security threat of microarchitectural attacks underlines the
importance of robust security sensors and detection mechanisms at the hardware
level. While there are studies on runtime detection of cache attacks, a generic
model to consider the broad range of existing and future attacks is missing.
Unfortunately, previous approaches only consider either a single attack
variant, e.g. Prime+Probe, or specific victim applications such as
cryptographic implementations. Furthermore, the state-of-the art anomaly
detection methods are based on coarse-grained statistical models, which are not
successful to detect anomalies in a large-scale real world systems. Thanks to
the memory capability of advanced Recurrent Neural Networks (RNNs) algorithms,
both short and long term dependencies can be learned more accurately.
Therefore, we propose FortuneTeller, which for the first time leverages the
superiority of RNNs to learn complex execution patterns and detects unseen
microarchitectural attacks in real world systems. FortuneTeller models benign
workload pattern from a microarchitectural standpoint in an unsupervised
fashion, and then, it predicts how upcoming benign executions are supposed to
behave. Potential attacks and malicious behaviors will be detected
automatically, when there is a discrepancy between the predicted execution
pattern and the runtime observation. We implement FortuneTeller based on the
available hardware performance counters on Intel processors and it is trained
with 10 million samples obtained from benign applications. For the first time,
the latest attacks such as Meltdown, Spectre, Rowhammer and Zombieload are
detected with one trained model and without observing these attacks during the
training. We show that FortuneTeller achieves F-score of 0.9970.","['Berk Gulmezoglu', 'Ahmad Moghimi', 'Thomas Eisenbarth', 'Berk Sunar']"
Input Aggregated Network for Face Video Representation,Computer Vision and Pattern Recognition,"Recently, deep neural network has shown promising performance in face image
recognition. The inputs of most networks are face images, and there is hardly
any work reported in literature on network with face videos as input. To
sufficiently discover the useful information contained in face videos, we
present a novel network architecture called input aggregated network which is
able to learn fixed-length representations for variable-length face videos. To
accomplish this goal, an aggregation unit is designed to model a face video
with various frames as a point on a Riemannian manifold, and the mapping unit
aims at mapping the point into high-dimensional space where face videos
belonging to the same subject are close-by and others are distant. These two
units together with the frame representation unit build an end-to-end learning
system which can learn representations of face videos for the specific tasks.
Experiments on two public face video datasets demonstrate the effectiveness of
the proposed network.","['Zhen Dong', 'Su Jia', 'Chi Zhang', 'Mingtao Pei']"
"Applying Recent Innovations from NLP to MOOC Student Course Trajectory
  Modeling",Machine Learning,"This paper presents several strategies that can improve neural network-based
predictive methods for MOOC student course trajectory modeling, applying
multiple ideas previously applied to tackle NLP (Natural Language Processing)
tasks. In particular, this paper investigates LSTM networks enhanced with two
forms of regularization, along with the more recently introduced Transformer
architecture.","['Clarence Chen', 'Zachary Pardos']"
Convolutional 2D Knowledge Graph Embeddings,Machine Learning,"Link prediction for knowledge graphs is the task of predicting missing
relationships between entities. Previous work on link prediction has focused on
shallow, fast models which can scale to large knowledge graphs. However, these
models learn less expressive features than deep, multi-layer models -- which
potentially limits performance. In this work, we introduce ConvE, a multi-layer
convolutional network model for link prediction, and report state-of-the-art
results for several established datasets. We also show that the model is highly
parameter efficient, yielding the same performance as DistMult and R-GCN with
8x and 17x fewer parameters. Analysis of our model suggests that it is
particularly effective at modelling nodes with high indegree -- which are
common in highly-connected, complex knowledge graphs such as Freebase and
YAGO3. In addition, it has been noted that the WN18 and FB15k datasets suffer
from test set leakage, due to inverse relations from the training set being
present in the test set -- however, the extent of this issue has so far not
been quantified. We find this problem to be severe: a simple rule-based model
can achieve state-of-the-art results on both WN18 and FB15k. To ensure that
models are evaluated on datasets where simply exploiting inverse relations
cannot yield competitive results, we investigate and validate several commonly
used datasets -- deriving robust variants where necessary. We then perform
experiments on these robust datasets for our own and several previously
proposed models and find that ConvE achieves state-of-the-art Mean Reciprocal
Rank across most datasets.","['Tim Dettmers', 'Pasquale Minervini', 'Pontus Stenetorp', 'Sebastian Riedel']"
Processing of Test Matrices with Guessing Correction,Machine Learning,"It is suggested to insert into test matrix 1s for correct responses, 0s for
response refusals, and negative corrective elements for incorrect responses.
With the classical test theory approach test scores of examinees and items are
calculated traditionally as sums of matrix elements, organized in rows and
columns. Correlation coefficients are estimated using correction coefficients.
In item response theory approach examinee and item logits are estimated using
maximum likelihood method and probabilities of all matrix elements.",['Kromer Victor']
Analyzing Encoded Concepts in Transformer Language Models,Computation and Language (Natural Language Processing),"We propose a novel framework ConceptX, to analyze how latent concepts are
encoded in representations learned within pre-trained language models. It uses
clustering to discover the encoded concepts and explains them by aligning with
a large set of human-defined concepts. Our analysis on seven transformer
language models reveal interesting insights: i) the latent space within the
learned representations overlap with different linguistic concepts to a varying
degree, ii) the lower layers in the model are dominated by lexical concepts
(e.g., affixation), whereas the core-linguistic concepts (e.g., morphological
or syntactic relations) are better represented in the middle and higher layers,
iii) some encoded concepts are multi-faceted and cannot be adequately explained
using the existing human-defined concepts.","['Hassan Sajjad', 'Nadir Durrani', 'Fahim Dalvi', 'Firoj Alam', 'Abdul Rafae Khan', 'Jia Xu']"
"Propagation with Adaptive Mask then Training for Node Classification on
  Attributed Networks",Machine Learning,"Node classification on attributed networks is a semi-supervised task that is
crucial for network analysis. By decoupling two critical operations in Graph
Convolutional Networks (GCNs), namely feature transformation and neighborhood
aggregation, some recent works of decoupled GCNs could support the information
to propagate deeper and achieve advanced performance. However, they follow the
traditional structure-aware propagation strategy of GCNs, making it hard to
capture the attribute correlation of nodes and sensitive to the structure noise
described by edges whose two endpoints belong to different categories. To
address these issues, we propose a new method called the itshape Propagation
with Adaptive Mask then Training (PAMT). The key idea is to integrate the
attribute similarity mask into the structure-aware propagation process. In this
way, PAMT could preserve the attribute correlation of adjacent nodes during the
propagation and effectively reduce the influence of structure noise. Moreover,
we develop an iterative refinement mechanism to update the similarity mask
during the training process for improving the training performance. Extensive
experiments on four real-world datasets demonstrate the superior performance
and robustness of PAMT.","['Jinsong Chen', 'Boyu Li', 'Qiuting He', 'Kun He']"
A Unified Generative Approach to Product Attribute-Value Identification,Computation and Language (Natural Language Processing),"Product attribute-value identification (PAVI) has been studied to link
products on e-commerce sites with their attribute values (e.g., <Material,
Cotton>) using product text as clues. Technical demands from real-world
e-commerce platforms require PAVI methods to handle unseen values,
multi-attribute values, and canonicalized values, which are only partly
addressed in existing extraction- and classification-based approaches.
Motivated by this, we explore a generative approach to the PAVI task. We
finetune a pre-trained generative model, T5, to decode a set of attribute-value
pairs as a target sequence from the given product text. Since the attribute
value pairs are unordered set elements, how to linearize them will matter; we,
thus, explore methods of composing an attribute-value pair and ordering the
pairs for the task. Experimental results confirm that our generation-based
approach outperforms the existing extraction and classification-based methods
on large-scale real-world datasets meant for those methods.","['Keiji Shinzato', 'Naoki Yoshinaga', 'Yandi Xia', 'Wei-Te Chen']"
Query-Reward Tradeoffs in Multi-Armed Bandits,Machine Learning,"We consider a stochastic multi-armed bandit setting where reward must be
actively queried for it to be observed. We provide tight lower and upper
problem-dependent guarantees on both the regret and the number of queries.
Interestingly, we prove that there is a fundamental difference between problems
with a unique and multiple optimal arms, unlike in the standard multi-armed
bandit problem. We also present a new, simple, UCB-style sampling concept, and
show that it naturally adapts to the number of optimal arms and achieves tight
regret and querying bounds.","['Nadav Merlis', 'Yonathan Efroni', 'Shie Mannor']"
OPERA:Operation-Pivoted Discrete Reasoning over Text,Computation and Language (Natural Language Processing),"Machine reading comprehension (MRC) that requires discrete reasoning
involving symbolic operations, e.g., addition, sorting, and counting, is a
challenging task. According to this nature, semantic parsing-based methods
predict interpretable but complex logical forms. However, logical form
generation is nontrivial and even a little perturbation in a logical form will
lead to wrong answers. To alleviate this issue, multi-predictor -based methods
are proposed to directly predict different types of answers and achieve
improvements. However, they ignore the utilization of symbolic operations and
encounter a lack of reasoning ability and interpretability. To inherit the
advantages of these two types of methods, we propose OPERA, an
operation-pivoted discrete reasoning framework, where lightweight symbolic
operations (compared with logical forms) as neural modules are utilized to
facilitate the reasoning ability and interpretability. Specifically, operations
are first selected and then softly executed to simulate the answer reasoning
procedure. Extensive experiments on both DROP and RACENum datasets show the
reasoning ability of OPERA. Moreover, further analysis verifies its
interpretability.","['Yongwei Zhou', 'Junwei Bao', 'Chaoqun Duan', 'Haipeng Sun', 'Jiahui Liang', 'Yifan Wang', 'Jing Zhao', 'Youzheng Wu', 'Xiaodong He', 'Tiejun Zhao']"
"Generating Probabilistic Safety Guarantees for Neural Network
  Controllers",Artificial Intelligence,"Neural networks serve as effective controllers in a variety of complex
settings due to their ability to represent expressive policies. The complex
nature of neural networks, however, makes their output difficult to verify and
predict, which limits their use in safety-critical applications. While
simulations provide insight into the performance of neural network controllers,
they are not enough to guarantee that the controller will perform safely in all
scenarios. To address this problem, recent work has focused on formal methods
to verify properties of neural network outputs. For neural network controllers,
we can use a dynamics model to determine the output properties that must hold
for the controller to operate safely. In this work, we develop a method to use
the results from neural network verification tools to provide probabilistic
safety guarantees on a neural network controller. We develop an adaptive
verification approach to efficiently generate an overapproximation of the
neural network policy. Next, we modify the traditional formulation of Markov
decision process (MDP) model checking to provide guarantees on the
overapproximated policy given a stochastic dynamics model. Finally, we
incorporate techniques in state abstraction to reduce overapproximation error
during the model checking process. We show that our method is able to generate
meaningful probabilistic safety guarantees for aircraft collision avoidance
neural networks that are loosely inspired by Airborne Collision Avoidance
System X (ACAS X), a family of collision avoidance systems that formulates the
problem as a partially observable Markov decision process (POMDP).","['Sydney M. Katz', 'Kyle D. Julian', 'Christopher A. Strong', 'Mykel J. Kochenderfer']"
"Linear Iterative Feature Embedding: An Ensemble Framework for
  Interpretable Model",Machine Learning (Statistics),"A new ensemble framework for interpretable model called Linear Iterative
Feature Embedding (LIFE) has been developed to achieve high prediction
accuracy, easy interpretation and efficient computation simultaneously. The
LIFE algorithm is able to fit a wide single-hidden-layer neural network (NN)
accurately with three steps: defining the subsets of a dataset by the linear
projections of neural nodes, creating the features from multiple narrow
single-hidden-layer NNs trained on the different subsets of the data, combining
the features with a linear model. The theoretical rationale behind LIFE is also
provided by the connection to the loss ambiguity decomposition of stack
ensemble methods. Both simulation and empirical experiments confirm that LIFE
consistently outperforms directly trained single-hidden-layer NNs and also
outperforms many other benchmark models, including multi-layers Feed Forward
Neural Network (FFNN), Xgboost, and Random Forest (RF) in many experiments. As
a wide single-hidden-layer NN, LIFE is intrinsically interpretable. Meanwhile,
both variable importance and global main and interaction effects can be easily
created and visualized. In addition, the parallel nature of the base learner
building makes LIFE computationally efficient by leveraging parallel computing.","['Agus Sudjianto', 'Jinwen Qiu', 'Miaoqi Li', 'Jie Chen']"
Robust Super-Level Set Estimation using Gaussian Processes,Machine Learning (Statistics),"This paper focuses on the problem of determining as large a region as
possible where a function exceeds a given threshold with high probability. We
assume that we only have access to a noise-corrupted version of the function
and that function evaluations are costly. To select the next query point, we
propose maximizing the expected volume of the domain identified as above the
threshold as predicted by a Gaussian process, robustified by a variance term.
We also give asymptotic guarantees on the exploration effect of the algorithm,
regardless of the prior misspecification. We show by various numerical examples
that our approach also outperforms existing techniques in the literature in
practice.","['Andrea Zanette', 'Junzi Zhang', 'Mykel J. Kochenderfer']"
Systematic Evaluation of Predictive Fairness,Machine Learning,"Mitigating bias in training on biased datasets is an important open problem.
Several techniques have been proposed, however the typical evaluation regime is
very limited, considering very narrow data conditions. For instance, the effect
of target class imbalance and stereotyping is under-studied. To address this
gap, we examine the performance of various debiasing methods across multiple
tasks, spanning binary classification (Twitter sentiment), multi-class
classification (profession prediction), and regression (valence prediction).
Through extensive experimentation, we find that data conditions have a strong
influence on relative model performance, and that general conclusions cannot be
drawn about method efficacy when evaluating only on standard datasets, as is
current practice in fairness research.","['Xudong Han', 'Aili Shen', 'Trevor Cohn', 'Timothy Baldwin', 'Lea Frermann']"
Learning Neural Templates for Recommender Dialogue System,Computation and Language (Natural Language Processing),"Though recent end-to-end neural models have shown promising progress on
Conversational Recommender System (CRS), two key challenges still remain.
First, the recommended items cannot be always incorporated into the generated
replies precisely and appropriately. Second, only the items mentioned in the
training corpus have a chance to be recommended in the conversation. To tackle
these challenges, we introduce a novel framework called NTRD for recommender
dialogue system that decouples the dialogue generation from the item
recommendation. NTRD has two key components, i.e., response template generator
and item selector. The former adopts an encoder-decoder model to generate a
response template with slot locations tied to target items, while the latter
fills in slot locations with the proper items using a sufficient attention
mechanism. Our approach combines the strengths of both classical slot filling
approaches (that are generally controllable) and modern neural NLG approaches
(that are generally more natural and accurate). Extensive experiments on the
benchmark ReDial show our NTRD significantly outperforms the previous
state-of-the-art methods. Besides, our approach has the unique advantage to
produce novel items that do not appear in the training set of dialogue corpus.
The code is available at \url{https://github.com/jokieleung/NTRD}.","['Zujie Liang', 'Huang Hu', 'Can Xu', 'Jian Miao', 'Yingying He', 'Yining Chen', 'Xiubo Geng', 'Fan Liang', 'Daxin Jiang']"
"DS-Net: Dynamic Spatiotemporal Network for Video Salient Object
  Detection",Computer Vision and Pattern Recognition,"As moving objects always draw more attention of human eyes, the temporal
motive information is always exploited complementarily with spatial information
to detect salient objects in videos. Although efficient tools such as optical
flow have been proposed to extract temporal motive information, it often
encounters difficulties when used for saliency detection due to the movement of
camera or the partial movement of salient objects. In this paper, we
investigate the complimentary roles of spatial and temporal information and
propose a novel dynamic spatiotemporal network (DS-Net) for more effective
fusion of spatiotemporal information. We construct a symmetric two-bypass
network to explicitly extract spatial and temporal features. A dynamic weight
generator (DWG) is designed to automatically learn the reliability of
corresponding saliency branch. And a top-down cross attentive aggregation (CAA)
procedure is designed so as to facilitate dynamic complementary aggregation of
spatiotemporal features. Finally, the features are modified by spatial
attention with the guidance of coarse saliency map and then go through decoder
part for final saliency map. Experimental results on five benchmarks VOS,
DAVIS, FBMS, SegTrack-v2, and ViSal demonstrate that the proposed method
achieves superior performance than state-of-the-art algorithms. The source code
is available at https://github.com/TJUMMG/DS-Net.","['Jing Liu', 'Jiaxiang Wang', 'Weikang Wang', 'Yuting Su']"
"Efficient single input-output layer spiking neural classifier with
  time-varying weight model",Neural and Evolutionary Computing,"This paper presents a supervised learning algorithm, namely, the Synaptic
Efficacy Function with Meta-neuron based learning algorithm (SEF-M) for a
spiking neural network with a time-varying weight model. For a given pattern,
SEF-M uses the learning algorithm derived from meta-neuron based learning
algorithm to determine the change in weights corresponding to each presynaptic
spike times. The changes in weights modulate the amplitude of a Gaussian
function centred at the same presynaptic spike times. The sum of amplitude
modulated Gaussian functions represents the synaptic efficacy functions (or
time-varying weight models). The performance of SEF-M is evaluated against
state-of-the-art spiking neural network learning algorithms on 10 benchmark
datasets from UCI machine learning repository. Performance studies show
superior generalization ability of SEF-M. An ablation study on time-varying
weight model is conducted using JAFFE dataset. The results of the ablation
study indicate that using a time-varying weight model instead of single weight
model improves the classification accuracy by 14%. Thus, it can be inferred
that a single input-output layer spiking neural network with time-varying
weight model is computationally more efficient than a multi-layer spiking
neural network with long-term or short-term weight model.","['Abeegithan Jeyasothy', 'Savitha Ramasamy', 'Suresh Sundaram']"
"Defogging Kinect: Simultaneous Estimation of Object Region and Depth in
  Foggy Scenes",Computer Vision and Pattern Recognition,"Three-dimensional (3D) reconstruction and scene depth estimation from
2-dimensional (2D) images are major tasks in computer vision. However, using
conventional 3D reconstruction techniques gets challenging in participating
media such as murky water, fog, or smoke. We have developed a method that uses
a time-of-flight (ToF) camera to estimate an object region and depth in
participating media simultaneously. The scattering component is saturated, so
it does not depend on the scene depth, and received signals bouncing off
distant points are negligible due to light attenuation in the participating
media, so the observation of such a point contains only a scattering component.
These phenomena enable us to estimate the scattering component in an object
region from a background that only contains the scattering component. The
problem is formulated as robust estimation where the object region is regarded
as outliers, and it enables the simultaneous estimation of an object region and
depth on the basis of an iteratively reweighted least squares (IRLS)
optimization scheme. We demonstrate the effectiveness of the proposed method
using captured images from a Kinect v2 in real foggy scenes and evaluate the
applicability with synthesized data.","['Yuki Fujimura', 'Motoharu Sonogashira', 'Masaaki Iiyama']"
"v-SVR Polynomial Kernel for Predicting the Defect Density in New
  Software Projects",Software Engineering,"An important product measure to determine the effectiveness of software
processes is the defect density (DD). In this study, we propose the application
of support vector regression (SVR) to predict the DD of new software projects
obtained from the International Software Benchmarking Standards Group (ISBSG)
Release 2018 data set. Two types of SVR (e-SVR and v-SVR) were applied to train
and test these projects. Each SVR used four types of kernels. The prediction
accuracy of each SVR was compared to that of a statistical regression (i.e., a
simple linear regression, SLR). Statistical significance test showed that v-SVR
with polynomial kernel was better than that of SLR when new software projects
were developed on mainframes and coded in programming languages of third
generation","['Cuauhtemoc Lopez-Martin', 'Mohammad Azzeh', 'Ali Bou Nassif', 'Shadi Banitaan']"
Building the Signature of Set Theory Using the MathSem Program,Logic in Computer Science,"Knowledge representation is a popular research field in IT. As mathematical
knowledge is most formalized, its representation is important and interesting.
Mathematical knowledge consists of various mathematical theories. In this paper
we consider a deductive system that derives mathematical notions, axioms and
theorems. All these notions, axioms and theorems can be considered as the part
of elementary set theory. This theory will be represented as a semantic net.",['Andrey Luxemburg']
Knowledge Squeezed Adversarial Network Compression,Machine Learning,"Deep network compression has been achieved notable progress via knowledge
distillation, where a teacher-student learning manner is adopted by using
predetermined loss. Recently, more focuses have been transferred to employ the
adversarial training to minimize the discrepancy between distributions of
output from two networks. However, they always emphasize on result-oriented
learning while neglecting the scheme of process-oriented learning, leading to
the loss of rich information contained in the whole network pipeline. Inspired
by the assumption that, the small network can not perfectly mimic a large one
due to the huge gap of network scale, we propose a knowledge transfer method,
involving effective intermediate supervision, under the adversarial training
framework to learn the student network. To achieve powerful but highly compact
intermediate information representation, the squeezed knowledge is realized by
task-driven attention mechanism. Then, the transferred knowledge from teacher
network could accommodate the size of student network. As a result, the
proposed method integrates merits from both process-oriented and
result-oriented learning. Extensive experimental results on three typical
benchmark datasets, i.e., CIFAR-10, CIFAR-100, and ImageNet, demonstrate that
our method achieves highly superior performances against other state-of-the-art
methods.","['Shu Changyong', 'Li Peng', 'Xie Yuan', 'Qu Yanyun', 'Dai Longquan', 'Ma Lizhuang']"
"Prior-based Hierarchical Segmentation Highlighting Structures of
  Interest",Computer Vision and Pattern Recognition,"Image segmentation is the process of partitioning an image into a set of
meaningful regions according to some criteria. Hierarchical segmentation has
emerged as a major trend in this regard as it favors the emergence of important
regions at different scales. On the other hand, many methods allow us to have
prior information on the position of structures of interest in the images. In
this paper, we present a versatile hierarchical segmentation method that takes
into account any prior spatial information and outputs a hierarchical
segmentation that emphasizes the contours or regions of interest while
preserving the important structures in the image. Several applications are
presented that illustrate the method versatility and efficiency.","['Amin Fehri', 'Santiago Velasco-Forero', 'Fernand Meyer']"
"An Automated Engineering Assistant: Learning Parsers for Technical
  Drawings",Artificial Intelligence,"From a set of technical drawings and expert knowledge, we automatically learn
a parser to interpret such a drawing. This enables automatic reasoning and
learning on top of a large database of technical drawings. In this work, we
develop a similarity based search algorithm to help engineers and designers
find or complete designs more easily and flexibly. This is part of an ongoing
effort to build an automated engineering assistant. The proposed methods make
use of both neural methods to learn to interpret images, and symbolic methods
to learn to interpret the structure in the technical drawing and incorporate
expert knowledge.","['Dries Van Daele', 'Nicholas Decleyre', 'Herman Dubois', 'Wannes Meert']"
Towards a new Social Choice Theory,Artificial Intelligence,"Social choice is the theory about collective decision towards social welfare
starting from individual opinions, preferences, interests or welfare. The field
of Computational Social Welfare is somewhat recent and it is gaining impact in
the Artificial Intelligence Community. Classical literature makes the
assumption of single-peaked preferences, i.e. there exist a order in the
preferences and there is a global maximum in this order. This year some
theoretical results were published about Two-stage Approval Voting Systems
(TAVs), Multi-winner Selection Rules (MWSR) and Incomplete (IPs) and Circular
Preferences (CPs). The purpose of this paper is three-fold: Firstly, I want to
introduced Social Choice Optimisation as a generalisation of TAVs where there
is a max stage and a min stage implementing thus a Minimax, well-known
Artificial Intelligence decision-making rule to minimize hindering towards a
(Social) Goal. Secondly, I want to introduce, following my Open Standardization
and Open Integration Theory (in refinement process) put in practice in my
dissertation, the Open Standardization of Social Inclusion, as a global social
goal of Social Choice Optimization.",['Andrés García-Camino']
"Policy-Gradient Algorithms Have No Guarantees of Convergence in Linear
  Quadratic Games",Machine Learning,"We show by counterexample that policy-gradient algorithms have no guarantees
of even local convergence to Nash equilibria in continuous action and state
space multi-agent settings. To do so, we analyze gradient-play in N-player
general-sum linear quadratic games, a classic game setting which is recently
emerging as a benchmark in the field of multi-agent learning. In such games the
state and action spaces are continuous and global Nash equilibria can be found
be solving coupled Ricatti equations. Further, gradient-play in LQ games is
equivalent to multi agent policy-gradient. We first show that these games are
surprisingly not convex games. Despite this, we are still able to show that the
only critical points of the gradient dynamics are global Nash equilibria. We
then give sufficient conditions under which policy-gradient will avoid the Nash
equilibria, and generate a large number of general-sum linear quadratic games
that satisfy these conditions. In such games we empirically observe the players
converging to limit cycles for which the time average does not coincide with a
Nash equilibrium. The existence of such games indicates that one of the most
popular approaches to solving reinforcement learning problems in the classic
reinforcement learning setting has no local guarantee of convergence in
multi-agent settings. Further, the ease with which we can generate these
counterexamples suggests that such situations are not mere edge cases and are
in fact quite common.","['Eric Mazumdar', 'Lillian J. Ratliff', 'Michael I. Jordan', 'S. Shankar Sastry']"
"Routing Networks and the Challenges of Modular and Compositional
  Computation",Machine Learning,"Compositionality is a key strategy for addressing combinatorial complexity
and the curse of dimensionality. Recent work has shown that compositional
solutions can be learned and offer substantial gains across a variety of
domains, including multi-task learning, language modeling, visual question
answering, machine comprehension, and others. However, such models present
unique challenges during training when both the module parameters and their
composition must be learned jointly. In this paper, we identify several of
these issues and analyze their underlying causes. Our discussion focuses on
routing networks, a general approach to this problem, and examines empirically
the interplay of these challenges and a variety of design decisions. In
particular, we consider the effect of how the algorithm decides on module
composition, how the algorithm updates the modules, and if the algorithm uses
regularization.","['Clemens Rosenbaum', 'Ignacio Cases', 'Matthew Riemer', 'Tim Klinger']"
"AdvKnn: Adversarial Attacks On K-Nearest Neighbor Classifiers With
  Approximate Gradients",Computer Vision and Pattern Recognition,"Deep neural networks have been shown to be vulnerable to adversarial
examples---maliciously crafted examples that can trigger the target model to
misbehave by adding imperceptible perturbations. Existing attack methods for
k-nearest neighbor~(kNN) based algorithms either require large perturbations or
are not applicable for large k. To handle this problem, this paper proposes a
new method called AdvKNN for evaluating the adversarial robustness of kNN-based
models. Firstly, we propose a deep kNN block to approximate the output of kNN
methods, which is differentiable thus can provide gradients for attacks to
cross the decision boundary with small distortions. Second, a new consistency
learning for distribution instead of classification is proposed for the
effectiveness in distribution based methods. Extensive experimental results
indicate that the proposed method significantly outperforms state of the art in
terms of attack success rate and the added perturbations.","['Xiaodan Li', 'Yuefeng Chen', 'Yuan He', 'Hui Xue']"
Learning Formation of Physically-Based Face Attributes,Computer Vision and Pattern Recognition,"Based on a combined data set of 4000 high resolution facial scans, we
introduce a non-linear morphable face model, capable of producing multifarious
face geometry of pore-level resolution, coupled with material attributes for
use in physically-based rendering. We aim to maximize the variety of face
identities, while increasing the robustness of correspondence between unique
components, including middle-frequency geometry, albedo maps, specular
intensity maps and high-frequency displacement details. Our deep learning based
generative model learns to correlate albedo and geometry, which ensures the
anatomical correctness of the generated assets. We demonstrate potential use of
our generative model for novel identity generation, model fitting,
interpolation, animation, high fidelity data visualization, and low-to-high
resolution data domain transferring. We hope the release of this generative
model will encourage further cooperation between all graphics, vision, and data
focused professionals while demonstrating the cumulative value of every
individual's complete biometric profile.","['Ruilong Li', 'Karl Bladin', 'Yajie Zhao', 'Chinmay Chinara', 'Owen Ingraham', 'Pengda Xiang', 'Xinglei Ren', 'Pratusha Prasad', 'Bipin Kishore', 'Jun Xing', 'Hao Li']"
Uncertainty and Structure in Neural Ordinary Differential Equations,Machine Learning,"Neural ordinary differential equations (ODEs) are an emerging class of deep
learning models for dynamical systems. They are particularly useful for
learning an ODE vector field from observed trajectories (i.e., inverse
problems). We here consider aspects of these models relevant for their
application in science and engineering. Scientific predictions generally
require structured uncertainty estimates. As a first contribution, we show that
basic and lightweight Bayesian deep learning techniques like the Laplace
approximation can be applied to neural ODEs to yield structured and meaningful
uncertainty quantification. But, in the scientific domain, available
information often goes beyond raw trajectories, and also includes mechanistic
knowledge, e.g., in the form of conservation laws. We explore how mechanistic
knowledge and uncertainty quantification interact on two recently proposed
neural ODE frameworks - symplectic neural ODEs and physical models augmented
with neural ODEs. In particular, uncertainty reflects the effect of mechanistic
information more directly than the predictive power of the trained model could.
And vice versa, structure can improve the extrapolation abilities of neural
ODEs, a fact that can be best assessed in practice through uncertainty
estimates. Our experimental analysis demonstrates the effectiveness of the
Laplace approach on both low dimensional ODE problems and a high dimensional
partial differential equation.","['Katharina Ott', 'Michael Tiemann', 'Philipp Hennig']"
Explicit-Duration Markov Switching Models,Machine Learning (Statistics),"Markov switching models (MSMs) are probabilistic models that employ multiple
sets of parameters to describe different dynamic regimes that a time series may
exhibit at different periods of time. The switching mechanism between regimes
is controlled by unobserved random variables that form a first-order Markov
chain. Explicit-duration MSMs contain additional variables that explicitly
model the distribution of time spent in each regime. This allows to define
duration distributions of any form, but also to impose complex dependence
between the observations and to reset the dynamics to initial conditions.
Models that focus on the first two properties are most commonly known as hidden
semi-Markov models or segment models, whilst models that focus on the third
property are most commonly known as changepoint models or reset models. In this
monograph, we provide a description of explicit-duration modelling by
categorizing the different approaches into three groups, which differ in
encoding in the explicit-duration variables different information about regime
change/reset boundaries. The approaches are described using the formalism of
graphical models, which allows to graphically represent and assess statistical
dependence and therefore to easily describe the structure of complex models and
derive inference routines. The presentation is intended to be pedagogical,
focusing on providing a characterization of the three groups in terms of model
structure constraints and inference properties. The monograph is supplemented
with a software package that contains most of the models and examples
described. The material presented should be useful to both researchers wishing
to learn about these models and researchers wishing to develop them further.",['Silvia Chiappa']
ToxTrac: a fast and robust software for tracking organisms,Computer Vision and Pattern Recognition,"1. Behavioral analysis based on video recording is becoming increasingly
popular within research fields such as; ecology, medicine, ecotoxicology, and
toxicology. However, the programs available to analyze the data, which are;
free of cost, user-friendly, versatile, robust, fast and provide reliable
statistics for different organisms (invertebrates, vertebrates and mammals) are
significantly limited.
  2. We present an automated open-source executable software (ToxTrac) for
image-based tracking that can simultaneously handle several organisms monitored
in a laboratory environment. We compare the performance of ToxTrac with current
accessible programs on the web.
  3. The main advantages of ToxTrac are: i) no specific knowledge of the
geometry of the tracked bodies is needed; ii) processing speed, ToxTrac can
operate at a rate >25 frames per second in HD videos using modern desktop
computers; iii) simultaneous tracking of multiple organisms in multiple arenas;
iv) integrated distortion correction and camera calibration; v) robust against
false positives; vi) preservation of individual identification if crossing
occurs; vii) useful statistics and heat maps in real scale are exported in:
image, text and excel formats.
  4. ToxTrac can be used for high speed tracking of insects, fish, rodents or
other species, and provides useful locomotor information. We suggest using
ToxTrac for future studies of animal behavior independent of research area.
Download ToxTrac here: https://toxtrac.sourceforge.io","['Alvaro Rodriquez', 'Hanqing Zhang', 'Jonatan Klaminder', 'Tomas Brodin', 'Patrik L. Andersson', 'Magnus Andersson']"
"Extracting Predictive Information from Heterogeneous Data Streams using
  Gaussian Processes",Statistical Finance,"Financial markets are notoriously complex environments, presenting vast
amounts of noisy, yet potentially informative data. We consider the problem of
forecasting financial time series from a wide range of information sources
using online Gaussian Processes with Automatic Relevance Determination (ARD)
kernels. We measure the performance gain, quantified in terms of Normalised
Root Mean Square Error (NRMSE), Median Absolute Deviation (MAD) and Pearson
correlation, from fusing each of four separate data domains: time series
technicals, sentiment analysis, options market data and broker recommendations.
We show evidence that ARD kernels produce meaningful feature rankings that help
retain salient inputs and reduce input dimensionality, providing a framework
for sifting through financial complexity. We measure the performance gain from
fusing each domain's heterogeneous data streams into a single probabilistic
model. In particular our findings highlight the critical value of options data
in mapping out the curvature of price space and inspire an intuitive, novel
direction for research in financial prediction.","['Sid Ghoshal', 'Stephen Roberts']"
"Genetic Constrained Graph Variational Autoencoder for COVID-19 Drug
  Discovery",Machine Learning,"In the past several months, COVID-19 has spread over the globe and caused
severe damage to the people and the society. In the context of this severe
situation, an effective drug discovery method to generate potential drugs is
extremely meaningful. In this paper, we provide a methodology of discovering
potential drugs for the treatment of Severe Acute Respiratory Syndrome
Corona-Virus 2 (commonly known as SARS-CoV-2). We proposed a new model called
Genetic Constrained Graph Variational Autoencoder (GCGVAE) to solve this
problem. We trained our model based on the data of various viruses' protein
structure, including that of the SARS, HIV, Hep3, and MERS, and used it to
generate possible drugs for SARS-CoV-2. Several optimization algorithms,
including valency masking and genetic algorithm, are deployed to fine tune our
model. According to the simulation, our generated molecules have great
effectiveness in inhibiting SARS-CoV-2. We quantitatively calculated the scores
of our generated molecules and compared it with the scores of existing drugs,
and the result shows our generated molecules scores much better than those
existing drugs. Moreover, our model can be also applied to generate effective
drugs for treating other viruses given their protein structure, which could be
used to generate drugs for future viruses.","['Tianyue Cheng', 'Tianchi Fan', 'Landi Wang']"
"Hybrid Learning for Orchestrating Deep Learning Inference in Multi-user
  Edge-cloud Networks",Machine Learning,"Deep-learning-based intelligent services have become prevalent in
cyber-physical applications including smart cities and health-care.
Collaborative end-edge-cloud computing for deep learning provides a range of
performance and efficiency that can address application requirements through
computation offloading. The decision to offload computation is a
communication-computation co-optimization problem that varies with both system
parameters (e.g., network condition) and workload characteristics (e.g.,
inputs). Identifying optimal orchestration considering the cross-layer
opportunities and requirements in the face of varying system dynamics is a
challenging multi-dimensional problem. While Reinforcement Learning (RL)
approaches have been proposed earlier, they suffer from a large number of
trial-and-errors during the learning process resulting in excessive time and
resource consumption. We present a Hybrid Learning orchestration framework that
reduces the number of interactions with the system environment by combining
model-based and model-free reinforcement learning. Our Deep Learning inference
orchestration strategy employs reinforcement learning to find the optimal
orchestration policy. Furthermore, we deploy Hybrid Learning (HL) to accelerate
the RL learning process and reduce the number of direct samplings. We
demonstrate efficacy of our HL strategy through experimental comparison with
state-of-the-art RL-based inference orchestration, demonstrating that our HL
strategy accelerates the learning process by up to 166.6x.","['Sina Shahhosseini', 'Tianyi Hu', 'Dongjoo Seo', 'Anil Kanduri', 'Bryan Donyanavard', 'Amir M. Rahmani', 'Nikil Dutt']"
CraftAssist: A Framework for Dialogue-enabled Interactive Agents,Artificial Intelligence,"This paper describes an implementation of a bot assistant in Minecraft, and
the tools and platform allowing players to interact with the bot and to record
those interactions. The purpose of building such an assistant is to facilitate
the study of agents that can complete tasks specified by dialogue, and
eventually, to learn from dialogue interactions.","['Jonathan Gray', 'Kavya Srinet', 'Yacine Jernite', 'Haonan Yu', 'Zhuoyuan Chen', 'Demi Guo', 'Siddharth Goyal', 'C. Lawrence Zitnick', 'Arthur Szlam']"
"Trajectory Prediction using Generative Adversarial Network in
  Multi-Class Scenarios",Machine Learning,"Predicting traffic agents' trajectories is an important task for
auto-piloting. Most previous work on trajectory prediction only considers a
single class of road agents. We use a sequence-to-sequence model to predict
future paths from observed paths and we incorporate class information into the
model by concatenating extracted label representations with traditional
location inputs. We experiment with both LSTM and transformer encoders and we
use generative adversarial network as introduced in Social GAN to learn the
multi-modal behavior of traffic agents. We train our model on Stanford Drone
dataset which includes 6 classes of road agents and evaluate the impact of
different model components on the prediction performance in multi-class scenes.","['Shilun Li', 'Tracy Cai', 'Jiayi Li']"
TransQuest at WMT2020: Sentence-Level Direct Assessment,Computation and Language (Natural Language Processing),"This paper presents the team TransQuest's participation in Sentence-Level
Direct Assessment shared task in WMT 2020. We introduce a simple QE framework
based on cross-lingual transformers, and we use it to implement and evaluate
two different neural architectures. The proposed methods achieve
state-of-the-art results surpassing the results obtained by OpenKiwi, the
baseline used in the shared task. We further fine tune the QE framework by
performing ensemble and data augmentation. Our approach is the winning solution
in all of the language pairs according to the WMT 2020 official results.","['Tharindu Ranasinghe', 'Constantin Orasan', 'Ruslan Mitkov']"
Toward Idealized Decision Theory,Artificial Intelligence,"This paper motivates the study of decision theory as necessary for aligning
smarter-than-human artificial systems with human interests. We discuss the
shortcomings of two standard formulations of decision theory, and demonstrate
that they cannot be used to describe an idealized decision procedure suitable
for approximation by artificial systems. We then explore the notions of policy
selection and logical counterfactuals, two recent insights into decision theory
that point the way toward promising paths for future research.","['Nate Soares', 'Benja Fallenstein']"
Relational Deep Reinforcement Learning,Machine Learning,"We introduce an approach for deep reinforcement learning (RL) that improves
upon the efficiency, generalization capacity, and interpretability of
conventional approaches through structured perception and relational reasoning.
It uses self-attention to iteratively reason about the relations between
entities in a scene and to guide a model-free policy. Our results show that in
a novel navigation and planning task called Box-World, our agent finds
interpretable solutions that improve upon baselines in terms of sample
complexity, ability to generalize to more complex scenes than experienced
during training, and overall performance. In the StarCraft II Learning
Environment, our agent achieves state-of-the-art performance on six mini-games
-- surpassing human grandmaster performance on four. By considering
architectural inductive biases, our work opens new directions for overcoming
important, but stubborn, challenges in deep RL.","['Vinicius Zambaldi', 'David Raposo', 'Adam Santoro', 'Victor Bapst', 'Yujia Li', 'Igor Babuschkin', 'Karl Tuyls', 'David Reichert', 'Timothy Lillicrap', 'Edward Lockhart', 'Murray Shanahan', 'Victoria Langston', 'Razvan Pascanu', 'Matthew Botvinick', 'Oriol Vinyals', 'Peter Battaglia']"
"Dimensionality Reduction has Quantifiable Imperfections: Two Geometric
  Bounds",Machine Learning (Statistics),"In this paper, we investigate Dimensionality reduction (DR) maps in an
information retrieval setting from a quantitative topology point of view. In
particular, we show that no DR maps can achieve perfect precision and perfect
recall simultaneously. Thus a continuous DR map must have imperfect precision.
We further prove an upper bound on the precision of Lipschitz continuous DR
maps. While precision is a natural measure in an information retrieval setting,
it does not measure `how' wrong the retrieved data is. We therefore propose a
new measure based on Wasserstein distance that comes with similar theoretical
guarantee. A key technical step in our proofs is a particular optimization
problem of the $L_2$-Wasserstein distance over a constrained set of
distributions. We provide a complete solution to this optimization problem,
which can be of independent interest on the technical side.","['Kry Yik Chau Lui', 'Gavin Weiguang Ding', 'Ruitong Huang', 'Robert J. McCann']"
"Alleviating the Inequality of Attention Heads for Neural Machine
  Translation",Computation and Language (Natural Language Processing),"Recent studies show that the attention heads in Transformer are not equal. We
relate this phenomenon to the imbalance training of multi-head attention and
the model dependence on specific heads. To tackle this problem, we propose a
simple masking method: HeadMask, in two specific ways. Experiments show that
translation improvements are achieved on multiple language pairs. Subsequent
empirical analyses also support our assumption and confirm the effectiveness of
the method.","['Zewei Sun', 'Shujian Huang', 'Xin-Yu Dai', 'Jiajun Chen']"
Differentiation of Blackbox Combinatorial Solvers,Machine Learning,"Achieving fusion of deep learning with combinatorial algorithms promises
transformative changes to artificial intelligence. One possible approach is to
introduce combinatorial building blocks into neural networks. Such end-to-end
architectures have the potential to tackle combinatorial problems on raw input
data such as ensuring global consistency in multi-object tracking or route
planning on maps in robotics. In this work, we present a method that implements
an efficient backward pass through blackbox implementations of combinatorial
solvers with linear objective functions. We provide both theoretical and
experimental backing. In particular, we incorporate the Gurobi MIP solver,
Blossom V algorithm, and Dijkstra's algorithm into architectures that extract
suitable features from raw inputs for the traveling salesman problem, the
min-cost perfect matching problem and the shortest path problem. The code is
available at https://github.com/martius-lab/blackbox-backprop.","['Marin Vlastelica', 'Anselm Paulus', 'Vít Musil', 'Georg Martius', 'Michal Rolínek']"
Predictive Collective Variable Discovery with Deep Bayesian Models,Machine Learning (Statistics),"Extending spatio-temporal scale limitations of models for complex atomistic
systems considered in biochemistry and materials science necessitates the
development of enhanced sampling methods. The potential acceleration in
exploring the configurational space by enhanced sampling methods depends on the
choice of collective variables (CVs). In this work, we formulate the discovery
of CVs as a Bayesian inference problem and consider the CVs as hidden
generators of the full-atomistic trajectory. The ability to generate samples of
the fine-scale atomistic configurations using limited training data allows us
to compute estimates of observables as well as our probabilistic confidence on
them. The methodology is based on emerging methodological advances in machine
learning and variational inference. The discovered CVs are related to
physicochemical properties which are essential for understanding mechanisms
especially in unexplored complex systems. We provide a quantitative assessment
of the CVs in terms of their predictive ability for alanine dipeptide (ALA-2)
and ALA-15 peptide.","['Markus Schöberl', 'Nicholas Zabaras', 'Phaedon-Stelios Koutsourelakis']"
Material Editing Using a Physically Based Rendering Network,Computer Vision and Pattern Recognition,"The ability to edit materials of objects in images is desirable by many
content creators. However, this is an extremely challenging task as it requires
to disentangle intrinsic physical properties of an image. We propose an
end-to-end network architecture that replicates the forward image formation
process to accomplish this task. Specifically, given a single image, the
network first predicts intrinsic properties, i.e. shape, illumination, and
material, which are then provided to a rendering layer. This layer performs
in-network image synthesis, thereby enabling the network to understand the
physics behind the image formation process. The proposed rendering layer is
fully differentiable, supports both diffuse and specular materials, and thus
can be applicable in a variety of problem settings. We demonstrate a rich set
of visually plausible material editing examples and provide an extensive
comparative study.","['Guilin Liu', 'Duygu Ceylan', 'Ersin Yumer', 'Jimei Yang', 'Jyh-Ming Lien']"
Neural Mixed Effects for Nonlinear Personalized Predictions,Machine Learning,"Personalized prediction is a machine learning approach that predicts a
person's future observations based on their past labeled observations and is
typically used for sequential tasks, e.g., to predict daily mood ratings. When
making personalized predictions, a model can combine two types of trends: (a)
trends shared across people, i.e., person-generic trends, such as being happier
on weekends, and (b) unique trends for each person, i.e., person-specific
trends, such as a stressful weekly meeting. Mixed effect models are popular
statistical models to study both trends by combining person-generic and
person-specific parameters. Though linear mixed effect models are gaining
popularity in machine learning by integrating them with neural networks, these
integrations are currently limited to linear person-specific parameters: ruling
out nonlinear person-specific trends. In this paper, we propose Neural Mixed
Effect (NME) models to optimize nonlinear person-specific parameters anywhere
in a neural network in a scalable manner. NME combines the efficiency of neural
network optimization with nonlinear mixed effects modeling. Empirically, we
observe that NME improves performance across six unimodal and multimodal
datasets, including a smartphone dataset to predict daily mood and a
mother-adolescent dataset to predict affective state sequences where half the
mothers experience at least moderate symptoms of depression. Furthermore, we
evaluate NME for two model architectures, including for neural conditional
random fields (CRF) to predict affective state sequences where the CRF learns
nonlinear person-specific temporal transitions between affective states.
Analysis of these person-specific transitions on the mother-adolescent dataset
shows interpretable trends related to the mother's depression symptoms.","['Torsten Wörtwein', 'Nicholas Allen', 'Lisa B. Sheeber', 'Randy P. Auerbach', 'Jeffrey F. Cohn', 'Louis-Philippe Morency']"
Mildly Conservative Q-Learning for Offline Reinforcement Learning,Machine Learning,"Offline reinforcement learning (RL) defines the task of learning from a
static logged dataset without continually interacting with the environment. The
distribution shift between the learned policy and the behavior policy makes it
necessary for the value function to stay conservative such that
out-of-distribution (OOD) actions will not be severely overestimated. However,
existing approaches, penalizing the unseen actions or regularizing with the
behavior policy, are too pessimistic, which suppresses the generalization of
the value function and hinders the performance improvement. This paper explores
mild but enough conservatism for offline learning while not harming
generalization. We propose Mildly Conservative Q-learning (MCQ), where OOD
actions are actively trained by assigning them proper pseudo Q values. We
theoretically show that MCQ induces a policy that behaves at least as well as
the behavior policy and no erroneous overestimation will occur for OOD actions.
Experimental results on the D4RL benchmarks demonstrate that MCQ achieves
remarkable performance compared with prior work. Furthermore, MCQ shows
superior generalization ability when transferring from offline to online, and
significantly outperforms baselines. Our code is publicly available at
https://github.com/dmksjfl/MCQ.","['Jiafei Lyu', 'Xiaoteng Ma', 'Xiu Li', 'Zongqing Lu']"
"Improvements to Inference Compilation for Probabilistic Programming in
  Large-Scale Scientific Simulators",Artificial Intelligence,"We consider the problem of Bayesian inference in the family of probabilistic
models implicitly defined by stochastic generative models of data. In
scientific fields ranging from population biology to cosmology, low-level
mechanistic components are composed to create complex generative models. These
models lead to intractable likelihoods and are typically non-differentiable,
which poses challenges for traditional approaches to inference. We extend
previous work in ""inference compilation"", which combines universal
probabilistic programming and deep learning methods, to large-scale scientific
simulators, and introduce a C++ based probabilistic programming library called
CPProb. We successfully use CPProb to interface with SHERPA, a large code-base
used in particle physics. Here we describe the technical innovations realized
and planned for this library.","['Mario Lezcano Casado', 'Atilim Gunes Baydin', 'David Martinez Rubio', 'Tuan Anh Le', 'Frank Wood', 'Lukas Heinrich', 'Gilles Louppe', 'Kyle Cranmer', 'Karen Ng', 'Wahid Bhimji', ' Prabhat']"
"EHRs Connect Research and Practice: Where Predictive Modeling,
  Artificial Intelligence, and Clinical Decision Support Intersect",Artificial Intelligence,"Objectives: Electronic health records (EHRs) are only a first step in
capturing and utilizing health-related data - the challenge is turning that
data into useful information. Furthermore, EHRs are increasingly likely to
include data relating to patient outcomes, functionality such as clinical
decision support, and genetic information as well, and, as such, can be seen as
repositories of increasingly valuable information about patients' health
conditions and responses to treatment over time. Methods: We describe a case
study of 423 patients treated by Centerstone within Tennessee and Indiana in
which we utilized electronic health record data to generate predictive
algorithms of individual patient treatment response. Multiple models were
constructed using predictor variables derived from clinical, financial and
geographic data. Results: For the 423 patients, 101 deteriorated, 223 improved
and in 99 there was no change in clinical condition. Based on modeling of
various clinical indicators at baseline, the highest accuracy in predicting
individual patient response ranged from 70-72% within the models tested. In
terms of individual predictors, the Centerstone Assessment of Recovery Level -
Adult (CARLA) baseline score was most significant in predicting outcome over
time (odds ratio 4.1 + 2.27). Other variables with consistently significant
impact on outcome included payer, diagnostic category, location and provision
of case management services. Conclusions: This approach represents a promising
avenue toward reducing the current gap between research and practice across
healthcare, developing data-driven clinical decision support based on
real-world populations, and serving as a component of embedded clinical
artificial intelligences that ""learn"" over time.","['Casey Bennett', 'Tom Doub', 'Rebecca Selove']"
MarlRank: Multi-agent Reinforced Learning to Rank,Machine Learning,"When estimating the relevancy between a query and a document, ranking models
largely neglect the mutual information among documents. A common wisdom is that
if two documents are similar in terms of the same query, they are more likely
to have similar relevance score. To mitigate this problem, in this paper, we
propose a multi-agent reinforced ranking model, named MarlRank. In particular,
by considering each document as an agent, we formulate the ranking process as a
multi-agent Markov Decision Process (MDP), where the mutual interactions among
documents are incorporated in the ranking process. To compute the ranking list,
each document predicts its relevance to a query considering not only its own
query-document features but also its similar documents features and actions. By
defining reward as a function of NDCG, we can optimize our model directly on
the ranking performance measure. Our experimental results on two LETOR
benchmark datasets show that our model has significant performance gains over
the state-of-art baselines. We also find that the NDCG shows an overall
increasing trend along with the step of interactions, which demonstrates that
the mutual information among documents helps improve the ranking performance.","['Shihao Zou', 'Zhonghua Li', 'Mohammad Akbari', 'Jun Wang', 'Peng Zhang']"
In Search for a Generalizable Method for Source Free Domain Adaptation,Machine Learning,"Source-free domain adaptation (SFDA) is compelling because it allows adapting
an off-the-shelf model to a new domain using only unlabelled data. In this
work, we apply existing SFDA techniques to a challenging set of
naturally-occurring distribution shifts in bioacoustics, which are very
different from the ones commonly studied in computer vision. We find existing
methods perform differently relative to each other than observed in vision
benchmarks, and sometimes perform worse than no adaptation at all. We propose a
new simple method which outperforms the existing methods on our new shifts
while exhibiting strong performance on a range of vision datasets. Our findings
suggest that existing SFDA methods are not as generalizable as previously
thought and that considering diverse modalities can be a useful avenue for
designing more robust models.","['Malik Boudiaf', 'Tom Denton', 'Bart van Merriënboer', 'Vincent Dumoulin', 'Eleni Triantafillou']"
"O(logT) Projections for Stochastic Optimization of Smooth and Strongly
  Convex Functions",Machine Learning,"Traditional algorithms for stochastic optimization require projecting the
solution at each iteration into a given domain to ensure its feasibility. When
facing complex domains, such as positive semi-definite cones, the projection
operation can be expensive, leading to a high computational cost per iteration.
In this paper, we present a novel algorithm that aims to reduce the number of
projections for stochastic optimization. The proposed algorithm combines the
strength of several recent developments in stochastic optimization, including
mini-batch, extra-gradient, and epoch gradient descent, in order to effectively
explore the smoothness and strong convexity. We show, both in expectation and
with a high probability, that when the objective function is both smooth and
strongly convex, the proposed algorithm achieves the optimal $O(1/T)$ rate of
convergence with only $O(\log T)$ projections. Our empirical study verifies the
theoretical result.","['Lijun Zhang', 'Tianbao Yang', 'Rong Jin', 'Xiaofei He']"
"Generating Contrastive Explanations for Inductive Logic Programming
  Based on a Near Miss Approach",Machine Learning,"In recent research, human-understandable explanations of machine learning
models have received a lot of attention. Often explanations are given in form
of model simplifications or visualizations. However, as shown in cognitive
science as well as in early AI research, concept understanding can also be
improved by the alignment of a given instance for a concept with a similar
counterexample. Contrasting a given instance with a structurally similar
example which does not belong to the concept highlights what characteristics
are necessary for concept membership. Such near misses have been proposed by
Winston (1970) as efficient guidance for learning in relational domains. We
introduce an explanation generation algorithm for relational concepts learned
with Inductive Logic Programming (\textsc{GeNME}). The algorithm identifies
near miss examples from a given set of instances and ranks these examples by
their degree of closeness to a specific positive instance. A modified rule
which covers the near miss but not the original instance is given as an
explanation. We illustrate \textsc{GeNME} with the well known family domain
consisting of kinship relations, the visual relational Winston arches domain
and a real-world domain dealing with file management. We also present a
psychological experiment comparing human preferences of rule-based,
example-based, and near miss explanations in the family and the arches domains.","['Johannes Rabold', 'Michael Siebers', 'Ute Schmid']"
"Label Enhanced Event Detection with Heterogeneous Graph Attention
  Networks",Computation and Language (Natural Language Processing),"Event Detection (ED) aims to recognize instances of specified types of event
triggers in text. Different from English ED, Chinese ED suffers from the
problem of word-trigger mismatch due to the uncertain word boundaries. Existing
approaches injecting word information into character-level models have achieved
promising progress to alleviate this problem, but they are limited by two
issues. First, the interaction between characters and lexicon words is not
fully exploited. Second, they ignore the semantic information provided by event
labels. We thus propose a novel architecture named Label enhanced Heterogeneous
Graph Attention Networks (L-HGAT). Specifically, we transform each sentence
into a graph, where character nodes and word nodes are connected with different
types of edges, so that the interaction between words and characters is fully
reserved. A heterogeneous graph attention networks is then introduced to
propagate relational message and enrich information interaction. Furthermore,
we convert each label into a trigger-prototype-based embedding, and design a
margin loss to guide the model distinguish confusing event labels. Experiments
on two benchmark datasets show that our model achieves significant improvement
over a range of competitive baseline methods.","['Shiyao Cui', 'Bowen Yu', 'Xin Cong', 'Tingwen Liu', 'Quangang Li', 'Jinqiao Shi']"
"Reducing the Computational Complexity of Pseudoinverse for the
  Incremental Broad Learning System on Added Inputs",Machine Learning,"In this brief, we improve the Broad Learning System (BLS) [7] by reducing the
computational complexity of the incremental learning for added inputs. We
utilize the inverse of a sum of matrices in [8] to improve a step in the
pseudoinverse of a row-partitioned matrix. Accordingly we propose two fast
algorithms for the cases of q > k and q < k, respectively, where q and k denote
the number of additional training samples and the total number of nodes,
respectively. Specifically, when q > k, the proposed algorithm computes only a
k * k matrix inverse, instead of a q * q matrix inverse in the existing
algorithm. Accordingly it can reduce the complexity dramatically. Our
simulations, which follow those for Table V in [7], show that the proposed
algorithm and the existing algorithm achieve the same testing accuracy, while
the speedups in BLS training time of the proposed algorithm over the existing
algorithm are 1.24 - 1.30.","['Hufei Zhu', 'Zhulin Liu', 'C. L. Philip Chen', 'Yanyang Liang']"
Labeling Chaos to Learning Harmony: Federated Learning with Noisy Labels,Machine Learning,"Federated Learning (FL) is a distributed machine learning paradigm that
enables learning models from decentralized private datasets, where the labeling
effort is entrusted to the clients. While most existing FL approaches assume
high-quality labels are readily available on users' devices; in reality, label
noise can naturally occur in FL and is closely related to clients'
characteristics. Due to scarcity of available data and significant label noise
variations among clients in FL, existing state-of-the-art centralized
approaches exhibit unsatisfactory performance, while prior FL studies rely on
excessive on-device computational schemes or additional clean data available on
server. Here, we propose FedLN, a framework to deal with label noise across
different FL training stages; namely, FL initialization, on-device model
training, and server model aggregation, able to accommodate the diverse
computational capabilities of devices in a FL system. Specifically, FedLN
computes per-client noise-level estimation in a single federated round and
improves the models' performance by either correcting or mitigating the effect
of noisy samples. Our evaluation on various publicly available vision and audio
datasets demonstrate a 22% improvement on average compared to other existing
methods for a label noise level of 60%. We further validate the efficiency of
FedLN in human-annotated real-world noisy datasets and report a 4.8% increase
on average in models' recognition performance, highlighting that~\method~can be
useful for improving FL services provided to everyday users.","['Vasileios Tsouvalas', 'Aaqib Saeed', 'Tanir Ozcelebi', 'Nirvana Meratnia']"
Optimally Teaching a Linear Behavior Cloning Agent,Machine Learning,"We study optimal teaching of Linear Behavior Cloning (LBC) learners. In this
setup, the teacher can select which states to demonstrate to an LBC learner.
The learner maintains a version space of infinite linear hypotheses consistent
with the demonstration. The goal of the teacher is to teach a realizable target
policy to the learner using minimum number of state demonstrations. This number
is known as the Teaching Dimension(TD). We present a teaching algorithm called
``Teach using Iterative Elimination(TIE)"" that achieves instance optimal TD.
However, we also show that finding optimal teaching set computationally is
NP-hard. We further provide an approximation algorithm that guarantees an
approximation ratio of $\log(|A|-1)$ on the teaching dimension. Finally, we
provide experimental results to validate the efficiency and effectiveness of
our algorithm.","['Shubham Kumar Bharti', 'Stephen Wright', 'Adish Singla', 'Xiaojin Zhu']"
"The Case for Developing a Foundation Model for Planning-like Tasks from
  Scratch",Artificial Intelligence,"Foundation Models (FMs) have revolutionized many areas of computing,
including Automated Planning and Scheduling (APS). For example, a recent study
found them useful for planning problems: plan generation, language translation,
model construction, multi-agent planning, interactive planning, heuristics
optimization, tool integration, and brain-inspired planning. Besides APS, there
are many seemingly related tasks involving the generation of a series of
actions with varying guarantees of their executability to achieve intended
goals, which we collectively call planning-like (PL) tasks like business
processes, programs, workflows, and guidelines, where researchers have
considered using FMs. However, previous works have primarily focused on
pre-trained, off-the-shelf FMs and optionally fine-tuned them. This paper
discusses the need for a comprehensive FM for PL tasks from scratch and
explores its design considerations. We argue that such an FM will open new and
efficient avenues for PL problem-solving, just like LLMs are creating for APS.","['Biplav Srivastava', 'Vishal Pallagani']"
"Evaluation of Large Language Models: STEM education and Gender
  Stereotypes",Computation and Language (Natural Language Processing),"Large Language Models (LLMs) have an increasing impact on our lives with use
cases such as chatbots, study support, coding support, ideation, writing
assistance, and more. Previous studies have revealed linguistic biases in
pronouns used to describe professions or adjectives used to describe men vs
women. These issues have to some degree been addressed in updated LLM versions,
at least to pass existing tests. However, biases may still be present in the
models, and repeated use of gender stereotypical language may reinforce the
underlying assumptions and are therefore important to examine further. This
paper investigates gender biases in LLMs in relation to educational choices
through an open-ended, true to user-case experimental design and a quantitative
analysis. We investigate the biases in the context of four different cultures,
languages, and educational systems (English/US/UK, Danish/DK, Catalan/ES, and
Hindi/IN) for ages ranging from 10 to 16 years, corresponding to important
educational transition points in the different countries. We find that there
are significant and large differences in the ratio of STEM to non-STEM
suggested education paths provided by chatGPT when using typical girl vs boy
names to prompt lists of suggested things to become. There are generally fewer
STEM suggestions in the Danish, Spanish, and Indian context compared to the
English. We also find subtle differences in the suggested professions, which we
categorise and report.","['Smilla Due', 'Sneha Das', 'Marianne Andersen', 'Berta Plandolit López', 'Sniff Andersen Nexø', 'Line Clemmensen']"
Chain Graphs for Learning,Artificial Intelligence,"Chain graphs combine directed and undirected graphs and their underlying
mathematics combines properties of the two. This paper gives a simplified
definition of chain graphs based on a hierarchical combination of Bayesian
(directed) and Markov (undirected) networks. Examples of a chain graph are
multivariate feed-forward networks, clustering with conditional interaction
between variables, and forms of Bayes classifiers. Chain graphs are then
extended using the notation of plates so that samples and data analysis
problems can be represented in a graphical model as well. Implications for
learning are discussed in the conclusion.",['Wray L. Buntine']
A Structural Graph-Based Method for MRI Analysis,Computer Vision and Pattern Recognition,"The importance of imaging exams, such as Magnetic Resonance Imaging (MRI),
for the diagnostic and follow-up of pediatric pathologies and the assessment of
anatomical structures' development has been increasingly highlighted in recent
times. Manual analysis of MRIs is time-consuming, subjective, and requires
significant expertise. To mitigate this, automatic techniques are necessary.
Most techniques focus on adult subjects, while pediatric MRI has specific
challenges such as the ongoing anatomical and histological changes related to
normal development of the organs, reduced signal-to-noise ratio due to the
smaller bodies, motion artifacts and cooperation issues, especially in long
exams, which can in many cases preclude common analysis methods developed for
use in adults. Therefore, the development of a robust technique to aid in
pediatric MRI analysis is necessary. This paper presents the current
development of a new method based on the learning and matching of structural
relational graphs (SRGs). The experiments were performed on liver MRI sequences
of one patient from ICr-HC-FMUSP, and preliminary results showcased the
viability of the project. Future experiments are expected to culminate with an
application for pediatric liver substructure and brain tumor segmentation.","['Larissa de O. Penteado', 'Mateus Riva', 'Roberto M. Cesar Jr']"
A Deep Reinforcement Learning Approach for Composing Moving IoT Services,Machine Learning,"We develop a novel framework for efficiently and effectively discovering
crowdsourced services that move in close proximity to a user over a period of
time. We introduce a moving crowdsourced service model which is modelled as a
moving region. We propose a deep reinforcement learning-based composition
approach to select and compose moving IoT services considering quality
parameters. Additionally, we develop a parallel flock-based service discovery
algorithm as a ground-truth to measure the accuracy of the proposed approach.
The experiments on two real-world datasets verify the effectiveness and
efficiency of the deep reinforcement learning-based approach.","['Azadeh Ghari Neiat', 'Athman Bouguettaya', 'Mohammed Bahutair']"
"Robust Kernel Density Estimation by Scaling and Projection in Hilbert
  Space",Machine Learning (Statistics),"While robust parameter estimation has been well studied in parametric density
estimation, there has been little investigation into robust density estimation
in the nonparametric setting. We present a robust version of the popular kernel
density estimator (KDE). As with other estimators, a robust version of the KDE
is useful since sample contamination is a common issue with datasets. What
""robustness"" means for a nonparametric density estimate is not straightforward
and is a topic we explore in this paper. To construct a robust KDE we scale the
traditional KDE and project it to its nearest weighted KDE in the $L^2$ norm.
This yields a scaled and projected KDE (SPKDE). Because the squared $L^2$ norm
penalizes point-wise errors superlinearly this causes the weighted KDE to
allocate more weight to high density regions. We demonstrate the robustness of
the SPKDE with numerical experiments and a consistency result which shows that
asymptotically the SPKDE recovers the uncontaminated density under sufficient
conditions on the contamination.","['Robert A. Vandermeulen', 'Clayton D. Scott']"
Modality Dropout for Improved Performance-driven Talking Faces,Audio and Speech Processing,"We describe our novel deep learning approach for driving animated faces using
both acoustic and visual information. In particular, speech-related facial
movements are generated using audiovisual information, and non-speech facial
movements are generated using only visual information. To ensure that our model
exploits both modalities during training, batches are generated that contain
audio-only, video-only, and audiovisual input features. The probability of
dropping a modality allows control over the degree to which the model exploits
audio and visual information during training. Our trained model runs in
real-time on resource limited hardware (e.g.\ a smart phone), it is user
agnostic, and it is not dependent on a potentially error-prone transcription of
the speech. We use subjective testing to demonstrate: 1) the improvement of
audiovisual-driven animation over the equivalent video-only approach, and 2)
the improvement in the animation of speech-related facial movements after
introducing modality dropout. Before introducing dropout, viewers prefer
audiovisual-driven animation in 51% of the test sequences compared with only
18% for video-driven. After introducing dropout viewer preference for
audiovisual-driven animation increases to 74%, but decreases to 8% for
video-only.","['Ahmed Hussen Abdelaziz', 'Barry-John Theobald', 'Paul Dixon', 'Reinhard Knothe', 'Nicholas Apostoloff', 'Sachin Kajareker']"
A General Purpose Supervisory Signal for Embodied Agents,Computer Vision and Pattern Recognition,"Training effective embodied AI agents often involves manual reward
engineering, expert imitation, specialized components such as maps, or
leveraging additional sensors for depth and localization. Another approach is
to use neural architectures alongside self-supervised objectives which
encourage better representation learning. In practice, there are few guarantees
that these self-supervised objectives encode task-relevant information. We
propose the Scene Graph Contrastive (SGC) loss, which uses scene graphs as
general-purpose, training-only, supervisory signals. The SGC loss does away
with explicit graph decoding and instead uses contrastive learning to align an
agent's representation with a rich graphical encoding of its environment. The
SGC loss is generally applicable, simple to implement, and encourages
representations that encode objects' semantics, relationships, and history.
Using the SGC loss, we attain significant gains on three embodied tasks: Object
Navigation, Multi-Object Navigation, and Arm Point Navigation. Finally, we
present studies and analyses which demonstrate the ability of our trained
representation to encode semantic cues about the environment.","['Kunal Pratap Singh', 'Jordi Salvador', 'Luca Weihs', 'Aniruddha Kembhavi']"
"Comparing Inferential Strategies of Humans and Large Language Models in
  Deductive Reasoning",Computation and Language (Natural Language Processing),"Deductive reasoning plays a pivotal role in the formulation of sound and
cohesive arguments. It allows individuals to draw conclusions that logically
follow, given the truth value of the information provided. Recent progress in
the domain of large language models (LLMs) has showcased their capability in
executing deductive reasoning tasks. Nonetheless, a significant portion of
research primarily assesses the accuracy of LLMs in solving such tasks, often
overlooking a deeper analysis of their reasoning behavior. In this study, we
draw upon principles from cognitive psychology to examine inferential
strategies employed by LLMs, through a detailed evaluation of their responses
to propositional logic problems. Our findings indicate that LLMs display
reasoning patterns akin to those observed in humans, including strategies like
$\textit{supposition following}$ or $\textit{chain construction}$. Moreover,
our research demonstrates that the architecture and scale of the model
significantly affect its preferred method of reasoning, with more advanced
models tending to adopt strategies more frequently than less sophisticated
ones. Importantly, we assert that a model's accuracy, that is the correctness
of its final conclusion, does not necessarily reflect the validity of its
reasoning process. This distinction underscores the necessity for more nuanced
evaluation procedures in the field.","['Philipp Mondorf', 'Barbara Plank']"
Geometry Enhancements from Visual Content: Going Beyond Ground Truth,Computer Vision and Pattern Recognition,"This work presents a new cyclic architecture that extracts high-frequency
patterns from images and re-insert them as geometric features. This procedure
allows us to enhance the resolution of low-cost depth sensors capturing fine
details on the one hand and being loyal to the scanned ground truth on the
other. We present state-of-the-art results for depth super-resolution tasks and
as well as visually attractive, enhanced generated 3D models.","['Liran Azaria', 'Dan Raviv']"
Feature Selection for Huge Data via Minipatch Learning,Machine Learning (Statistics),"Feature selection often leads to increased model interpretability, faster
computation, and improved model performance by discarding irrelevant or
redundant features. While feature selection is a well-studied problem with many
widely-used techniques, there are typically two key challenges: i) many
existing approaches become computationally intractable in huge-data settings
with millions of observations and features; and ii) the statistical accuracy of
selected features degrades in high-noise, high-correlation settings, thus
hindering reliable model interpretation. We tackle these problems by proposing
Stable Minipatch Selection (STAMPS) and Adaptive STAMPS (AdaSTAMPS). These are
meta-algorithms that build ensembles of selection events of base feature
selectors trained on many tiny, (adaptively-chosen) random subsets of both the
observations and features of the data, which we call minipatches. Our
approaches are general and can be employed with a variety of existing feature
selection strategies and machine learning techniques. In addition, we provide
theoretical insights on STAMPS and empirically demonstrate that our approaches,
especially AdaSTAMPS, dominate competing methods in terms of feature selection
accuracy and computational time.","['Tianyi Yao', 'Genevera I. Allen']"
Neural versus Phrase-Based Machine Translation Quality: a Case Study,Computation and Language (Natural Language Processing),"Within the field of Statistical Machine Translation (SMT), the neural
approach (NMT) has recently emerged as the first technology able to challenge
the long-standing dominance of phrase-based approaches (PBMT). In particular,
at the IWSLT 2015 evaluation campaign, NMT outperformed well established
state-of-the-art PBMT systems on English-German, a language pair known to be
particularly hard because of morphology and syntactic differences. To
understand in what respects NMT provides better translation quality than PBMT,
we perform a detailed analysis of neural versus phrase-based SMT outputs,
leveraging high quality post-edits performed by professional translators on the
IWSLT data. For the first time, our analysis provides useful insights on what
linguistic phenomena are best modeled by neural models -- such as the
reordering of verbs -- while pointing out other aspects that remain to be
improved.","['Luisa Bentivogli', 'Arianna Bisazza', 'Mauro Cettolo', 'Marcello Federico']"
"Signal Instructed Coordination in Cooperative Multi-agent Reinforcement
  Learning",Multiagent Systems,"In many real-world problems, a team of agents need to collaborate to maximize
the common reward. Although existing works formulate this problem into a
centralized learning with decentralized execution framework, which avoids the
non-stationary problem in training, their decentralized execution paradigm
limits the agents' capability to coordinate. Inspired by the concept of
correlated equilibrium, we propose to introduce a coordination signal to
address this limitation, and theoretically show that following mild conditions,
decentralized agents with the coordination signal can coordinate their
individual policies as manipulated by a centralized controller. The idea of
introducing coordination signal is to encapsulate coordinated strategies into
the signals, and use the signals to instruct the collaboration in decentralized
execution. To encourage agents to learn to exploit the coordination signal, we
propose Signal Instructed Coordination (SIC), a novel coordination module that
can be integrated with most existing MARL frameworks. SIC casts a common signal
sampled from a pre-defined distribution to all agents, and introduces an
information-theoretic regularization to facilitate the consistency between the
observed signal and agents' policies. Our experiments show that SIC
consistently improves performance over well-recognized MARL models in both
matrix games and a predator-prey game with high-dimensional strategy space.","['Liheng Chen', 'Hongyi Guo', 'Yali Du', 'Fei Fang', 'Haifeng Zhang', 'Yaoming Zhu', 'Ming Zhou', 'Weinan Zhang', 'Qing Wang', 'Yong Yu']"
"Inferring Restaurant Styles by Mining Crowd Sourced Photos from
  User-Review Websites",Computer Vision and Pattern Recognition,"When looking for a restaurant online, user uploaded photos often give people
an immediate and tangible impression about a restaurant. Due to their
informativeness, such user contributed photos are leveraged by restaurant
review websites to provide their users an intuitive and effective search
experience. In this paper, we present a novel approach to inferring restaurant
types or styles (ambiance, dish styles, suitability for different occasions)
from user uploaded photos on user-review websites. To that end, we first
collect a novel restaurant photo dataset associating the user contributed
photos with the restaurant styles from TripAdvior. We then propose a deep
multi-instance multi-label learning (MIML) framework to deal with the unique
problem setting of the restaurant style classification task. We employ a
two-step bootstrap strategy to train a multi-label convolutional neural network
(CNN). The multi-label CNN is then used to compute the confidence scores of
restaurant styles for all the images associated with a restaurant. The computed
confidence scores are further used to train a final binary classifier for each
restaurant style tag. Upon training, the styles of a restaurant can be profiled
by analyzing restaurant photos with the trained multi-label CNN and SVM models.
Experimental evaluation has demonstrated that our crowd sourcing-based approach
can effectively infer the restaurant style when there are a sufficient number
of user uploaded photos for a given restaurant.","['Haofu Liao', 'Yuncheng Li', 'Tianran Hu', 'Jiebo Luo']"
"EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level
  Latencies",Computer Vision and Pattern Recognition,"Detecting anomalies in images is an important task, especially in real-time
computer vision applications. In this work, we focus on computational
efficiency and propose a lightweight feature extractor that processes an image
in less than a millisecond on a modern GPU. We then use a student-teacher
approach to detect anomalous features. We train a student network to predict
the extracted features of normal, i.e., anomaly-free training images. The
detection of anomalies at test time is enabled by the student failing to
predict their features. We propose a training loss that hinders the student
from imitating the teacher feature extractor beyond the normal images. It
allows us to drastically reduce the computational cost of the student-teacher
model, while improving the detection of anomalous features. We furthermore
address the detection of challenging logical anomalies that involve invalid
combinations of normal local features, for example, a wrong ordering of
objects. We detect these anomalies by efficiently incorporating an autoencoder
that analyzes images globally. We evaluate our method, called EfficientAD, on
32 datasets from three industrial anomaly detection dataset collections.
EfficientAD sets new standards for both the detection and the localization of
anomalies. At a latency of two milliseconds and a throughput of six hundred
images per second, it enables a fast handling of anomalies. Together with its
low error rate, this makes it an economical solution for real-world
applications and a fruitful basis for future research.","['Kilian Batzner', 'Lars Heckler', 'Rebecca König']"
Bayesian structure learning using dynamic programming and MCMC,Machine Learning,"MCMC methods for sampling from the space of DAGs can mix poorly due to the
local nature of the proposals that are commonly used. It has been shown that
sampling from the space of node orders yields better results [FK03, EW06].
Recently, Koivisto and Sood showed how one can analytically marginalize over
orders using dynamic programming (DP) [KS04, Koi06]. Their method computes the
exact marginal posterior edge probabilities, thus avoiding the need for MCMC.
Unfortunately, there are four drawbacks to the DP technique: it can only use
modular priors, it can only compute posteriors over modular features, it is
difficult to compute a predictive density, and it takes exponential time and
space. We show how to overcome the first three of these problems by using the
DP algorithm as a proposal distribution for MCMC in DAG space. We show that
this hybrid technique converges to the posterior faster than other methods,
resulting in more accurate structure learning and higher predictive likelihoods
on test data.","['Daniel Eaton', 'Kevin Murphy']"
Manifold Mixup: Better Representations by Interpolating Hidden States,Machine Learning (Statistics),"Deep neural networks excel at learning the training data, but often provide
incorrect and confident predictions when evaluated on slightly different test
examples. This includes distribution shifts, outliers, and adversarial
examples. To address these issues, we propose Manifold Mixup, a simple
regularizer that encourages neural networks to predict less confidently on
interpolations of hidden representations. Manifold Mixup leverages semantic
interpolations as additional training signal, obtaining neural networks with
smoother decision boundaries at multiple levels of representation. As a result,
neural networks trained with Manifold Mixup learn class-representations with
fewer directions of variance. We prove theory on why this flattening happens
under ideal conditions, validate it on practical situations, and connect it to
previous works on information theory and generalization. In spite of incurring
no significant computation and being implemented in a few lines of code,
Manifold Mixup improves strong baselines in supervised learning, robustness to
single-step adversarial attacks, and test log-likelihood.","['Vikas Verma', 'Alex Lamb', 'Christopher Beckham', 'Amir Najafi', 'Ioannis Mitliagkas', 'Aaron Courville', 'David Lopez-Paz', 'Yoshua Bengio']"
"Hierarchical Deep Recurrent Neural Network based Method for Fault
  Detection and Diagnosis",Machine Learning,"A Deep Neural Network (DNN) based algorithm is proposed for the detection and
classification of faults in industrial plants. The proposed algorithm has the
ability to classify faults, especially incipient faults that are difficult to
detect and diagnose with traditional threshold based statistical methods or by
conventional Artificial Neural Networks (ANNs). The algorithm is based on a
Supervised Deep Recurrent Autoencoder Neural Network (Supervised DRAE-NN) that
uses dynamic information of the process along the time horizon. Based on this
network a hierarchical structure is formulated by grouping faults based on
their similarity into subsets of faults for detection and diagnosis. Further,
an external pseudo-random binary signal (PRBS) is designed and injected into
the system to identify incipient faults. The hierarchical structure based
strategy improves the detection and classification accuracy significantly for
both incipient and non-incipient faults. The proposed approach is tested on the
benchmark Tennessee Eastman Process resulting in significant improvements in
classification as compared to both multivariate linear model-based strategies
and non-hierarchical nonlinear model-based strategies.","['Piyush Agarwal', 'Jorge Ivan Mireles Gonzalez', 'Ali Elkamel', 'Hector Budman']"
"BTS-Net: Bi-directional Transfer-and-Selection Network For RGB-D Salient
  Object Detection",Computer Vision and Pattern Recognition,"Depth information has been proved beneficial in RGB-D salient object
detection (SOD). However, depth maps obtained often suffer from low quality and
inaccuracy. Most existing RGB-D SOD models have no cross-modal interactions or
only have unidirectional interactions from depth to RGB in their encoder
stages, which may lead to inaccurate encoder features when facing low quality
depth. To address this limitation, we propose to conduct progressive
bi-directional interactions as early in the encoder stage, yielding a novel
bi-directional transfer-and-selection network named BTS-Net, which adopts a set
of bi-directional transfer-and-selection (BTS) modules to purify features
during encoding. Based on the resulting robust encoder features, we also design
an effective light-weight group decoder to achieve accurate final saliency
prediction. Comprehensive experiments on six widely used datasets demonstrate
that BTS-Net surpasses 16 latest state-of-the-art approaches in terms of four
key metrics.","['Wenbo Zhang', 'Yao Jiang', 'Keren Fu', 'Qijun Zhao']"
Linguistic features for sentence difficulty prediction in ABSA,Computation and Language (Natural Language Processing),"One of the challenges of natural language understanding is to deal with the
subjectivity of sentences, which may express opinions and emotions that add
layers of complexity and nuance. Sentiment analysis is a field that aims to
extract and analyze these subjective elements from text, and it can be applied
at different levels of granularity, such as document, paragraph, sentence, or
aspect. Aspect-based sentiment analysis is a well-studied topic with many
available data sets and models. However, there is no clear definition of what
makes a sentence difficult for aspect-based sentiment analysis. In this paper,
we explore this question by conducting an experiment with three data sets:
""Laptops"", ""Restaurants"", and ""MTSC"" (Multi-Target-dependent Sentiment
Classification), and a merged version of these three datasets. We study the
impact of domain diversity and syntactic diversity on difficulty. We use a
combination of classifiers to identify the most difficult sentences and analyze
their characteristics. We employ two ways of defining sentence difficulty. The
first one is binary and labels a sentence as difficult if the classifiers fail
to correctly predict the sentiment polarity. The second one is a six-level
scale based on how many of the top five best-performing classifiers can
correctly predict the sentiment polarity. We also define 9 linguistic features
that, combined, aim at estimating the difficulty at sentence level.","['Adrian-Gabriel Chifu', 'Sébastien Fournier']"
Neural Tangent Kernel Analysis of Deep Narrow Neural Networks,Machine Learning,"The tremendous recent progress in analyzing the training dynamics of
overparameterized neural networks has primarily focused on wide networks and
therefore does not sufficiently address the role of depth in deep learning. In
this work, we present the first trainability guarantee of infinitely deep but
narrow neural networks. We study the infinite-depth limit of a multilayer
perceptron (MLP) with a specific initialization and establish a trainability
guarantee using the NTK theory. We then extend the analysis to an infinitely
deep convolutional neural network (CNN) and perform brief experiments.","['Jongmin Lee', 'Joo Young Choi', 'Ernest K. Ryu', 'Albert No']"
"Parameter-Efficient Language Model Tuning with Active Learning in
  Low-Resource Settings",Computation and Language (Natural Language Processing),"Pre-trained language models (PLMs) have ignited a surge in demand for
effective fine-tuning techniques, particularly in low-resource domains and
languages. Active learning (AL), a set of algorithms designed to decrease
labeling costs by minimizing label complexity, has shown promise in confronting
the labeling bottleneck. In parallel, adapter modules designed for
parameter-efficient fine-tuning (PEFT) have demonstrated notable potential in
low-resource settings. However, the interplay between AL and adapter-based PEFT
remains unexplored. We present an empirical study of PEFT behavior with AL in
low-resource settings for text classification tasks. Our findings affirm the
superiority of PEFT over full-fine tuning (FFT) in low-resource settings and
demonstrate that this advantage persists in AL setups. We further examine the
properties of PEFT and FFT through the lens of forgetting dynamics and
instance-level representations, where we find that PEFT yields more stable
representations of early and middle layers compared to FFT. Our research
underscores the synergistic potential of AL and PEFT in low-resource settings,
paving the way for advancements in efficient and effective fine-tuning.","['Josip Jukić', 'Jan Šnajder']"
"From text to multimodal: a survey of adversarial example generation in
  question answering systems",Computation and Language (Natural Language Processing),"Integrating adversarial machine learning with Question Answering (QA) systems
has emerged as a critical area for understanding the vulnerabilities and
robustness of these systems. This article aims to comprehensively review
adversarial example-generation techniques in the QA field, including textual
and multimodal contexts. We examine the techniques employed through systematic
categorization, providing a comprehensive, structured review. Beginning with an
overview of traditional QA models, we traverse the adversarial example
generation by exploring rule-based perturbations and advanced generative
models. We then extend our research to include multimodal QA systems, analyze
them across various methods, and examine generative models, seq2seq
architectures, and hybrid methodologies. Our research grows to different
defense strategies, adversarial datasets, and evaluation metrics and
illustrates the comprehensive literature on adversarial QA. Finally, the paper
considers the future landscape of adversarial question generation, highlighting
potential research directions that can advance textual and multimodal QA
systems in the context of adversarial challenges.","['Gulsum Yigit', 'Mehmet Fatih Amasyali']"
"Offspring Population Size Matters when Comparing Evolutionary Algorithms
  with Self-Adjusting Mutation Rates",Neural and Evolutionary Computing,"We analyze the performance of the 2-rate $(1+\lambda)$ Evolutionary Algorithm
(EA) with self-adjusting mutation rate control, its 3-rate counterpart, and a
$(1+\lambda)$~EA variant using multiplicative update rules on the OneMax
problem. We compare their efficiency for offspring population sizes ranging up
to $\lambda=3,200$ and problem sizes up to $n=100,000$.
  Our empirical results show that the ranking of the algorithms is very
consistent across all tested dimensions, but strongly depends on the population
size. While for small values of $\lambda$ the 2-rate EA performs best, the
multiplicative updates become superior for starting for some threshold value of
$\lambda$ between 50 and 100. Interestingly, for population sizes around 50,
the $(1+\lambda)$~EA with static mutation rates performs on par with the best
of the self-adjusting algorithms.
  We also consider how the lower bound $p_{\min}$ for the mutation rate
influences the efficiency of the algorithms. We observe that for the 2-rate EA
and the EA with multiplicative update rules the more generous bound
$p_{\min}=1/n^2$ gives better results than $p_{\min}=1/n$ when $\lambda$ is
small. For both algorithms the situation reverses for large~$\lambda$.","['Anna Rodionova', 'Kirill Antonov', 'Arina Buzdalova', 'Carola Doerr']"
"AI Knowledge and Reasoning: Emulating Expert Creativity in Scientific
  Research",Artificial Intelligence,"We investigate whether modern AI can emulate expert creativity in complex
scientific endeavors. We introduce novel methodology that utilizes original
research articles published after the AI's training cutoff, ensuring no prior
exposure, mitigating concerns of rote memorization and prior training. The AI
are tasked with redacting findings, predicting outcomes from redacted research,
and assessing prediction accuracy against reported results. Analysis on 589
published studies in four leading psychology journals over a 28-month period,
showcase the AI's proficiency in understanding specialized research, deductive
reasoning, and evaluating evidentiary alignment--cognitive hallmarks of human
subject matter expertise and creativity. These findings suggest the potential
of general-purpose AI to transform academia, with roles requiring
knowledge-based creativity become increasingly susceptible to technological
substitution.","['Anirban Mukherjee', 'Hannah Hanwen Chang']"
"Japanese Tort-case Dataset for Rationale-supported Legal Judgment
  Prediction",Computation and Language (Natural Language Processing),"This paper presents the first dataset for Japanese Legal Judgment Prediction
(LJP), the Japanese Tort-case Dataset (JTD), which features two tasks: tort
prediction and its rationale extraction. The rationale extraction task
identifies the court's accepting arguments from alleged arguments by plaintiffs
and defendants, which is a novel task in the field. JTD is constructed based on
annotated 3,477 Japanese Civil Code judgments by 41 legal experts, resulting in
7,978 instances with 59,697 of their alleged arguments from the involved
parties. Our baseline experiments show the feasibility of the proposed two
tasks, and our error analysis by legal experts identifies sources of errors and
suggests future directions of the LJP research.","['Hiroaki Yamada', 'Takenobu Tokunaga', 'Ryutaro Ohara', 'Akira Tokutsu', 'Keisuke Takeshita', 'Mihoko Sumida']"
"ICL-TSVD: Bridging Theory and Practice in Continual Learning with
  Pre-trained Models",Machine Learning,"The goal of continual learning (CL) is to train a model that can solve
multiple tasks presented sequentially. Recent CL approaches have achieved
strong performance by leveraging large pre-trained models that generalize well
to downstream tasks. However, such methods lack theoretical guarantees, making
them prone to unexpected failures. Conversely, principled CL approaches often
fail to achieve competitive performance. In this work, we bridge this gap
between theory and practice by integrating an empirically strong approach
(RanPAC) into a principled framework, Ideal Continual Learner (ICL), designed
to prevent forgetting. Specifically, we lift pre-trained features into a higher
dimensional space and formulate an over-parametrized minimum-norm least-squares
problem. We find that the lifted features are highly ill-conditioned,
potentially leading to large training errors (numerical instability) and
increased generalization errors (double descent). We address these challenges
by continually truncating the singular value decomposition (SVD) of the lifted
features. Our approach, termed ICL-TSVD, is stable with respect to the choice
of hyperparameters, can handle hundreds of tasks, and outperforms
state-of-the-art CL methods on multiple datasets. Importantly, our method
satisfies a recurrence relation throughout its continual learning process,
which allows us to prove it maintains small training and generalization errors
by appropriately truncating a fraction of SVD factors. This results in a stable
continual learning method with strong empirical performance and theoretical
guarantees.","['Liangzu Peng', 'Juan Elenter', 'Joshua Agterberg', 'Alejandro Ribeiro', 'René Vidal']"
Dynamic Word Embeddings for Evolving Semantic Discovery,Computation and Language (Natural Language Processing),"Word evolution refers to the changing meanings and associations of words
throughout time, as a byproduct of human language evolution. By studying word
evolution, we can infer social trends and language constructs over different
periods of human history. However, traditional techniques such as word
representation learning do not adequately capture the evolving language
structure and vocabulary. In this paper, we develop a dynamic statistical model
to learn time-aware word vector representation. We propose a model that
simultaneously learns time-aware embeddings and solves the resulting ""alignment
problem"". This model is trained on a crawled NYTimes dataset. Additionally, we
develop multiple intuitive evaluation strategies of temporal word embeddings.
Our qualitative and quantitative tests indicate that our method not only
reliably captures this evolution over time, but also consistently outperforms
state-of-the-art temporal embedding approaches on both semantic accuracy and
alignment quality.","['Zijun Yao', 'Yifan Sun', 'Weicong Ding', 'Nikhil Rao', 'Hui Xiong']"
Offline Model-Based Optimization by Learning to Rank,Machine Learning,"Offline model-based optimization (MBO) aims to identify a design that
maximizes a black-box function using only a fixed, pre-collected dataset of
designs and their corresponding scores. A common approach in offline MBO is to
train a regression-based surrogate model by minimizing mean squared error (MSE)
and then find the best design within this surrogate model by different
optimizers (e.g., gradient ascent). However, a critical challenge is the risk
of out-of-distribution errors, i.e., the surrogate model may typically
overestimate the scores and mislead the optimizers into suboptimal regions.
Prior works have attempted to address this issue in various ways, such as using
regularization techniques and ensemble learning to enhance the robustness of
the model, but it still remains. In this paper, we argue that regression models
trained with MSE are not well-aligned with the primary goal of offline MBO,
which is to select promising designs rather than to predict their scores
precisely. Notably, if a surrogate model can maintain the order of candidate
designs based on their relative score relationships, it can produce the best
designs even without precise predictions. To validate it, we conduct
experiments to compare the relationship between the quality of the final
designs and MSE, finding that the correlation is really very weak. In contrast,
a metric that measures order-maintaining quality shows a significantly stronger
correlation. Based on this observation, we propose learning a ranking-based
model that leverages learning to rank techniques to prioritize promising
designs based on their relative scores. We show that the generalization error
on ranking loss can be well bounded. Empirical results across diverse tasks
demonstrate the superior performance of our proposed ranking-based models than
twenty existing methods.","['Rong-Xi Tan', 'Ke Xue', 'Shen-Huan Lyu', 'Haopu Shang', 'Yao Wang', 'Yaoyuan Wang', 'Sheng Fu', 'Chao Qian']"
"Text Grafting: Near-Distribution Weak Supervision for Minority Classes
  in Text Classification",Computation and Language (Natural Language Processing),"For extremely weak-supervised text classification, pioneer research generates
pseudo labels by mining texts similar to the class names from the raw corpus,
which may end up with very limited or even no samples for the minority classes.
Recent works have started to generate the relevant texts by prompting LLMs
using the class names or definitions; however, there is a high risk that LLMs
cannot generate in-distribution (i.e., similar to the corpus where the text
classifier will be applied) data, leading to ungeneralizable classifiers. In
this paper, we combine the advantages of these two approaches and propose to
bridge the gap via a novel framework, \emph{text grafting}, which aims to
obtain clean and near-distribution weak supervision for minority classes.
Specifically, we first use LLM-based logits to mine masked templates from the
raw corpus, which have a high potential for data synthesis into the target
minority class. Then, the templates are filled by state-of-the-art LLMs to
synthesize near-distribution texts falling into minority classes. Text grafting
shows significant improvement over direct mining or synthesis on minority
classes. We also use analysis and case studies to comprehend the property of
text grafting.","['Letian Peng', 'Yi Gu', 'Chengyu Dong', 'Zihan Wang', 'Jingbo Shang']"
"Infinite Tucker Decomposition: Nonparametric Bayesian Models for
  Multiway Data Analysis",Machine Learning,"Tensor decomposition is a powerful computational tool for multiway data
analysis. Many popular tensor decomposition approaches---such as the Tucker
decomposition and CANDECOMP/PARAFAC (CP)---amount to multi-linear
factorization. They are insufficient to model (i) complex interactions between
data entities, (ii) various data types (e.g. missing data and binary data), and
(iii) noisy observations and outliers. To address these issues, we propose
tensor-variate latent nonparametric Bayesian models, coupled with efficient
inference methods, for multiway data analysis. We name these models InfTucker.
Using these InfTucker, we conduct Tucker decomposition in an infinite feature
space. Unlike classical tensor decomposition models, our new approaches handle
both continuous and binary data in a probabilistic framework. Unlike previous
Bayesian models on matrices and tensors, our models are based on latent
Gaussian or $t$ processes with nonlinear covariance functions. To efficiently
learn the InfTucker from data, we develop a variational inference technique on
tensors. Compared with classical implementation, the new technique reduces both
time and space complexities by several orders of magnitude. Our experimental
results on chemometrics and social network datasets demonstrate that our new
models achieved significantly higher prediction accuracy than the most
state-of-art tensor decomposition","['Zenglin Xu', 'Feng Yan', ' Yuan', ' Qi']"
"Closed-form Inference and Prediction in Gaussian Process State-Space
  Models",Machine Learning (Statistics),"We examine an analytic variational inference scheme for the Gaussian Process
State Space Model (GPSSM) - a probabilistic model for system identification and
time-series modelling. Our approach performs variational inference over both
the system states and the transition function. We exploit Markov structure in
the true posterior, as well as an inducing point approximation to achieve
linear time complexity in the length of the time series. Contrary to previous
approaches, no Monte Carlo sampling is required: inference is cast as a
deterministic optimisation problem. In a number of experiments, we demonstrate
the ability to model non-linear dynamics in the presence of both process and
observation noise as well as to impute missing information (e.g. velocities
from raw positions through time), to de-noise, and to estimate the underlying
dimensionality of the system. Finally, we also introduce a closed-form method
for multi-step prediction, and a novel criterion for assessing the quality of
our approximate posterior.","['Alessandro Davide Ialongo', 'Mark van der Wilk', 'Carl Edward Rasmussen']"
"All-optical neuromorphic binary convolution with a spiking VCSEL neuron
  for image gradient magnitudes",Optics,"All-optical binary convolution with a photonic spiking vertical-cavity
surface-emitting laser (VCSEL) neuron is proposed and demonstrated
experimentally for the first time. Optical inputs, extracted from digital
images and temporally encoded using rectangular pulses, are injected in the
VCSEL neuron which delivers the convolution result in the number of fast (<100
ps long) spikes fired. Experimental and numerical results show that binary
convolution is achieved successfully with a single spiking VCSEL neuron and
that all-optical binary convolution can be used to calculate image gradient
magnitudes to detect edge features and separate vertical and horizontal
components in source images. We also show that this all-optical spiking binary
convolution system is robust to noise and can operate with high-resolution
images. Additionally, the proposed system offers important advantages such as
ultrafast speed, high energy efficiency and simple hardware implementation,
highlighting the potentials of spiking photonic VCSEL neurons for high-speed
neuromorphic image processing systems and future photonic spiking convolutional
neural networks.","['Yahui Zhang', 'Joshua Robertson', 'Shuiying Xiang', 'MatĚJ Hejda', 'JuliÁn Bueno', 'Antonio Hurtado']"
Cross-Domain Transfer in Reinforcement Learning using Target Apprentice,Artificial Intelligence,"In this paper, we present a new approach to Transfer Learning (TL) in
Reinforcement Learning (RL) for cross-domain tasks. Many of the available
techniques approach the transfer architecture as a method of speeding up the
target task learning. We propose to adapt and reuse the mapped source task
optimal-policy directly in related domains. We show the optimal policy from a
related source task can be near optimal in target domain provided an adaptive
policy accounts for the model error between target and source. The main benefit
of this policy augmentation is generalizing policies across multiple related
domains without having to re-learn the new tasks. Our results show that this
architecture leads to better sample efficiency in the transfer, reducing sample
complexity of target task learning to target apprentice learning.","['Girish Joshi', 'Girish Chowdhary']"
A Bandit-Based Algorithm for Fairness-Aware Hyperparameter Optimization,Machine Learning,"Considerable research effort has been guided towards algorithmic fairness but
there is still no major breakthrough. In practice, an exhaustive search over
all possible techniques and hyperparameters is needed to find optimal
fairness-accuracy trade-offs. Hence, coupled with the lack of tools for ML
practitioners, real-world adoption of bias reduction methods is still scarce.
To address this, we present Fairband, a bandit-based fairness-aware
hyperparameter optimization (HO) algorithm. Fairband is conceptually simple,
resource-efficient, easy to implement, and agnostic to both the objective
metrics, model types and the hyperparameter space being explored. Moreover, by
introducing fairness notions into HO, we enable seamless and efficient
integration of fairness objectives into real-world ML pipelines. We compare
Fairband with popular HO methods on four real-world decision-making datasets.
We show that Fairband can efficiently navigate the fairness-accuracy trade-off
through hyperparameter optimization. Furthermore, without extra training cost,
it consistently finds configurations attaining substantially improved fairness
at a comparatively small decrease in predictive accuracy.","['André F. Cruz', 'Pedro Saleiro', 'Catarina Belém', 'Carlos Soares', 'Pedro Bizarro']"
"Efficient Variational Graph Autoencoders for Unsupervised Cross-domain
  Prerequisite Chains",Machine Learning,"Prerequisite chain learning helps people acquire new knowledge efficiently.
While people may quickly determine learning paths over concepts in a domain,
finding such paths in other domains can be challenging. We introduce
Domain-Adversarial Variational Graph Autoencoders (DAVGAE) to solve this
cross-domain prerequisite chain learning task efficiently. Our novel model
consists of a variational graph autoencoder (VGAE) and a domain discriminator.
The VGAE is trained to predict concept relations through link prediction, while
the domain discriminator takes both source and target domain data as input and
is trained to predict domain labels. Most importantly, this method only needs
simple homogeneous graphs as input, compared with the current state-of-the-art
model. We evaluate our model on the LectureBankCD dataset, and results show
that our model outperforms recent graph-based benchmarks while using only 1/10
of graph scale and 1/3 computation time.","['Irene Li', 'Vanessa Yan', 'Dragomir Radev']"
"Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving
  Objects",Computer Vision and Pattern Recognition,"We address the novel task of jointly reconstructing the 3D shape, texture,
and motion of an object from a single motion-blurred image. While previous
approaches address the deblurring problem only in the 2D image domain, our
proposed rigorous modeling of all object properties in the 3D domain enables
the correct description of arbitrary object motion. This leads to significantly
better image decomposition and sharper deblurring results. We model the
observed appearance of a motion-blurred object as a combination of the
background and a 3D object with constant translation and rotation. Our method
minimizes a loss on reconstructing the input image via differentiable rendering
with suitable regularizers. This enables estimating the textured 3D mesh of the
blurred object with high fidelity. Our method substantially outperforms
competing approaches on several benchmarks for fast moving objects deblurring.
Qualitative results show that the reconstructed 3D mesh generates high-quality
temporal super-resolution and novel views of the deblurred object.","['Denys Rozumnyi', 'Martin R. Oswald', 'Vittorio Ferrari', 'Marc Pollefeys']"
Novelty-Prepared Few-Shot Classification,Machine Learning,"Few-shot classification algorithms can alleviate the data scarceness issue,
which is vital in many real-world problems, by adopting models pre-trained from
abundant data in other domains. However, the pre-training process was commonly
unaware of the future adaptation to other concept classes. We disclose that a
classically fully trained feature extractor can leave little embedding space
for unseen classes, which keeps the model from well-fitting the new classes. In
this work, we propose to use a novelty-prepared loss function, called
self-compacting softmax loss (SSL), for few-shot classification. The SSL can
prevent the full occupancy of the embedding space. Thus the model is more
prepared to learn new classes. In experiments on CUB-200-2011 and mini-ImageNet
datasets, we show that SSL leads to significant improvement of the
state-of-the-art performance. This work may shed some light on considering the
model capacity for few-shot classification tasks.","['Chao Wang', 'Ruo-Ze Liu', 'Han-Jia Ye', 'Yang Yu']"
"Reason Against the Machine: Future Directions for Mass Online
  Deliberation",Artificial Intelligence,"Designers of online deliberative platforms aim to counter the degrading
quality of online debates. Support technologies such as machine learning and
natural language processing open avenues for widening the circle of people
involved in deliberation, moving from small groups to ""crowd"" scale. Numerous
design features of large-scale online discussion systems allow larger numbers
of people to discuss shared problems, enhance critical thinking, and formulate
solutions. We review the transdisciplinary literature on the design of digital
mass deliberation platforms and examine the commonly featured design aspects
(e.g., argumentation support, automated facilitation, and gamification) that
attempt to facilitate scaling up. We find that the literature is largely
focused on developing technical fixes for scaling up deliberation, but may
neglect the more nuanced requirements of high quality deliberation. Current
design research is carried out with a small, atypical segment of the world's
population, and much research is still needed on how to facilitate and
accommodate different genders or cultures in deliberation, how to deal with the
implications of pre-existing social inequalities, how to build motivation and
self-efficacy in certain groups, and how to deal with differences in cognitive
abilities and cultural or linguistic differences. Few studies bridge
disciplines between deliberative theory, design and engineering. As a result,
scaling up deliberation will likely advance in separate systemic siloes. We
make design and process recommendations to correct this course and suggest
avenues for future research","['Ruth Shortall', 'Anatol Itten', 'Michiel van der Meer', 'Pradeep K. Murukannaiah', 'Catholijn M. Jonker']"
Aesthetic Visual Question Answering of Photographs,Computer Vision and Pattern Recognition,"Aesthetic assessment of images can be categorized into two main forms:
numerical assessment and language assessment. Aesthetics caption of photographs
is the only task of aesthetic language assessment that has been addressed. In
this paper, we propose a new task of aesthetic language assessment: aesthetic
visual question and answering (AVQA) of images. If we give a question of images
aesthetics, model can predict the answer. We use images from
\textit{www.flickr.com}. The objective QA pairs are generated by the proposed
aesthetic attributes analysis algorithms. Moreover, we introduce subjective QA
pairs that are converted from aesthetic numerical labels and sentiment analysis
from large-scale pre-train models. We build the first aesthetic visual question
answering dataset, AesVQA, that contains 72,168 high-quality images and 324,756
pairs of aesthetic questions. Two methods for adjusting the data distribution
have been proposed and proved to improve the accuracy of existing models. This
is the first work that both addresses the task of aesthetic VQA and introduces
subjectiveness into VQA tasks. The experimental results reveal that our methods
outperform other VQA models on this new task.","['Xin Jin', 'Wu Zhou', 'Xinghui Zhou', 'Shuai Cui', 'Le Zhang', 'Jianwen Lv', 'Shu Zhao']"
"Improving the Certified Robustness of Neural Networks via Consistency
  Regularization",Machine Learning,"A range of defense methods have been proposed to improve the robustness of
neural networks on adversarial examples, among which provable defense methods
have been demonstrated to be effective to train neural networks that are
certifiably robust to the attacker. However, most of these provable defense
methods treat all examples equally during training process, which ignore the
inconsistent constraint of certified robustness between correctly classified
(natural) and misclassified examples. In this paper, we explore this
inconsistency caused by misclassified examples and add a novel consistency
regularization term to make better use of the misclassified examples.
Specifically, we identified that the certified robustness of network can be
significantly improved if the constraint of certified robustness on
misclassified examples and correctly classified examples is consistent.
Motivated by this discovery, we design a new defense regularization term called
Misclassification Aware Adversarial Regularization (MAAR), which constrains the
output probability distributions of all examples in the certified region of the
misclassified example. Experimental results show that our proposed MAAR
achieves the best certified robustness and comparable accuracy on CIFAR-10 and
MNIST datasets in comparison with several state-of-the-art methods.","['Mengting Xu', 'Tao Zhang', 'Zhongnian Li', 'Daoqiang Zhang']"
Chatbots Are Not Reliable Text Annotators,Computation and Language (Natural Language Processing),"Recent research highlights the significant potential of ChatGPT for text
annotation in social science research. However, ChatGPT is a closed-source
product which has major drawbacks with regards to transparency,
reproducibility, cost, and data protection. Recent advances in open-source (OS)
large language models (LLMs) offer alternatives which remedy these challenges.
This means that it is important to evaluate the performance of OS LLMs relative
to ChatGPT and standard approaches to supervised machine learning
classification. We conduct a systematic comparative evaluation of the
performance of a range of OS LLM models alongside ChatGPT, using both zero- and
few-shot learning as well as generic and custom prompts, with results compared
to more traditional supervised classification models. Using a new dataset of
Tweets from US news media, and focusing on simple binary text annotation tasks
for standard social science concepts, we find significant variation in the
performance of ChatGPT and OS models across the tasks, and that supervised
classifiers consistently outperform both. Given the unreliable performance of
ChatGPT and the significant challenges it poses to Open Science we advise
against using ChatGPT for substantive text annotation tasks in social science
research.","['Ross Deans Kristensen-McLachlan', 'Miceal Canavan', 'Márton Kardos', 'Mia Jacobsen', 'Lene Aarøe']"
A Review on Algorithms for Constraint-based Causal Discovery,Artificial Intelligence,"Causal discovery studies the problem of mining causal relationships between
variables from data, which is of primary interest in science. During the past
decades, significant amount of progresses have been made toward this
fundamental data mining paradigm. Recent years, as the availability of abundant
large-sized and complex observational data, the constrain-based approaches have
gradually attracted a lot of interest and have been widely applied to many
diverse real-world problems due to the fast running speed and easy generalizing
to the problem of causal insufficiency. In this paper, we aim to review the
constraint-based causal discovery algorithms. Firstly, we discuss the learning
paradigm of the constraint-based approaches. Secondly and primarily, the
state-of-the-art constraint-based casual inference algorithms are surveyed with
the detailed analysis. Thirdly, several related open-source software packages
and benchmark data repositories are briefly summarized. As a conclusion, some
open problems in constraint-based causal discovery are outlined for future
research.","['Kui Yu', 'Jiuyong Li', 'Lin Liu']"
Universality of the stochastic block model,Physics and Society,"Mesoscopic pattern extraction (MPE) is the problem of finding a partition of
the nodes of a complex network that maximizes some objective function. Many
well-known network inference problems fall in this category, including, for
instance, community detection, core-periphery identification, and imperfect
graph coloring. In this paper, we show that the most popular algorithms
designed to solve MPE problems can in fact be understood as special cases of
the maximum likelihood formulation of the stochastic block model (SBM), or one
of its direct generalizations. These equivalence relations show that the SBM is
nearly universal with respect to MPE problems.","['Jean-Gabriel Young', 'Guillaume St-Onge', 'Patrick Desrosiers', 'Louis J. Dubé']"
"A Mapping Study of Machine Learning Methods for Remaining Useful Life
  Estimation of Lead-Acid Batteries",Machine Learning,"Energy storage solutions play an increasingly important role in modern
infrastructure and lead-acid batteries are among the most commonly used in the
rechargeable category. Due to normal degradation over time, correctly
determining the battery's State of Health (SoH) and Remaining Useful Life (RUL)
contributes to enhancing predictive maintenance, reliability, and longevity of
battery systems. Besides improving the cost savings, correct estimation of the
SoH can lead to reduced pollution though reuse of retired batteries. This paper
presents a mapping study of the state-of-the-art in machine learning methods
for estimating the SoH and RUL of lead-acid batteries. These two indicators are
critical in the battery management systems of electric vehicles, renewable
energy systems, and other applications that rely heavily on this battery
technology. In this study, we analyzed the types of machine learning algorithms
employed for estimating SoH and RUL, and evaluated their performance in terms
of accuracy and inference time. Additionally, this mapping identifies and
analyzes the most commonly used combinations of sensors in specific
applications, such as vehicular batteries. The mapping concludes by
highlighting potential gaps and opportunities for future research, which lays
the foundation for further advancements in the field.","['Sérgio F Chevtchenko', 'Elisson da Silva Rocha', 'Bruna Cruz', 'Ermeson Carneiro de Andrade', 'Danilo Ricardo Barbosa de Araújo']"
"Measuring Similarity of Interactive Driving Behaviors Using Matrix
  Profile",Machine Learning,"Understanding multi-vehicle interactive behaviors with temporal sequential
observations is crucial for autonomous vehicles to make appropriate decisions
in an uncertain traffic environment. On-demand similarity measures are
significant for autonomous vehicles to deal with massive interactive driving
behaviors by clustering and classifying diverse scenarios. This paper proposes
a general approach for measuring spatiotemporal similarity of interactive
behaviors using a multivariate matrix profile technique. The key attractive
features of the approach are its superior space and time complexity, real-time
online computing for streaming traffic data, and possible capability of
leveraging hardware for parallel computation. The proposed approach is
validated through automatically discovering similar interactive driving
behaviors at intersections from sequential data.","['Qin Lin', 'Wenshuo Wang', 'Yihuan Zhang', 'John Dolan']"
Scalable Learning Paradigms for Data-Driven Wireless Communication,Machine Learning,"The marriage of wireless big data and machine learning techniques
revolutionizes the wireless system by the data-driven philosophy. However, the
ever exploding data volume and model complexity will limit centralized
solutions to learn and respond within a reasonable time. Therefore, scalability
becomes a critical issue to be solved. In this article, we aim to provide a
systematic discussion on the building blocks of scalable data-driven wireless
networks. On one hand, we discuss the forward-looking architecture and
computing framework of scalable data-driven systems from a global perspective.
On the other hand, we discuss the learning algorithms and model training
strategies performed at each individual node from a local perspective. We also
highlight several promising research directions in the context of scalable
data-driven wireless communications to inspire future research.","['Yue Xu', 'Feng Yin', 'Wenjun Xu', 'Chia-Han Lee', 'Jiaru Lin', 'Shuguang Cui']"
"DecAug: Out-of-Distribution Generalization via Decomposed Feature
  Representation and Semantic Augmentation",Machine Learning,"While deep learning demonstrates its strong ability to handle independent and
identically distributed (IID) data, it often suffers from out-of-distribution
(OoD) generalization, where the test data come from another distribution
(w.r.t. the training one). Designing a general OoD generalization framework to
a wide range of applications is challenging, mainly due to possible correlation
shift and diversity shift in the real world. Most of the previous approaches
can only solve one specific distribution shift, such as shift across domains or
the extrapolation of correlation. To address that, we propose DecAug, a novel
decomposed feature representation and semantic augmentation approach for OoD
generalization. DecAug disentangles the category-related and context-related
features. Category-related features contain causal information of the target
object, while context-related features describe the attributes, styles,
backgrounds, or scenes, causing distribution shifts between training and test
data. The decomposition is achieved by orthogonalizing the two gradients
(w.r.t. intermediate features) of losses for predicting category and context
labels. Furthermore, we perform gradient-based augmentation on context-related
features to improve the robustness of the learned representations. Experimental
results show that DecAug outperforms other state-of-the-art methods on various
OoD datasets, which is among the very few methods that can deal with different
types of OoD generalization challenges.","['Haoyue Bai', 'Rui Sun', 'Lanqing Hong', 'Fengwei Zhou', 'Nanyang Ye', 'Han-Jia Ye', 'S. -H. Gary Chan', 'Zhenguo Li']"
"Fully Convolutional Networks with Sequential Information for Robust Crop
  and Weed Detection in Precision Farming",Computer Vision and Pattern Recognition,"Reducing the use of agrochemicals is an important component towards
sustainable agriculture. Robots that can perform targeted weed control offer
the potential to contribute to this goal, for example, through specialized
weeding actions such as selective spraying or mechanical weed removal. A
prerequisite of such systems is a reliable and robust plant classification
system that is able to distinguish crop and weed in the field. A major
challenge in this context is the fact that different fields show a large
variability. Thus, classification systems have to robustly cope with
substantial environmental changes with respect to weed pressure and weed types,
growth stages of the crop, visual appearance, and soil conditions. In this
paper, we propose a novel crop-weed classification system that relies on a
fully convolutional network with an encoder-decoder structure and incorporates
spatial information by considering image sequences. Exploiting the crop
arrangement information that is observable from the image sequences enables our
system to robustly estimate a pixel-wise labeling of the images into crop and
weed, i.e., a semantic segmentation. We provide a thorough experimental
evaluation, which shows that our system generalizes well to previously unseen
fields under varying environmental conditions --- a key capability to actually
use such systems in precision framing. We provide comparisons to other
state-of-the-art approaches and show that our system substantially improves the
accuracy of crop-weed classification without requiring a retraining of the
model.","['Philipp Lottes', 'Jens Behley', 'Andres Milioto', 'Cyrill Stachniss']"
Better Schedules for Low Precision Training of Deep Neural Networks,Machine Learning,"Low precision training can significantly reduce the computational overhead of
training deep neural networks (DNNs). Though many such techniques exist, cyclic
precision training (CPT), which dynamically adjusts precision throughout
training according to a cyclic schedule, achieves particularly impressive
improvements in training efficiency, while actually improving DNN performance.
Existing CPT implementations take common learning rate schedules (e.g.,
cyclical cosine schedules) and use them for low precision training without
adequate comparisons to alternative scheduling options. We define a diverse
suite of CPT schedules and analyze their performance across a variety of DNN
training regimes, some of which are unexplored in the low precision training
literature (e.g., node classification with graph neural networks). From these
experiments, we discover alternative CPT schedules that offer further
improvements in training efficiency and model performance, as well as derive a
set of best practices for choosing CPT schedules. Going further, we find that a
correlation exists between model performance and training cost, and that
changing the underlying CPT schedule can control the tradeoff between these two
variables. To explain the direct correlation between model performance and
training cost, we draw a connection between quantized training and critical
learning periods, suggesting that aggressive quantization is a form of learning
impairment that can permanently damage model performance.","['Cameron R. Wolfe', 'Anastasios Kyrillidis']"
German FinBERT: A German Pre-trained Language Model,Computation and Language (Natural Language Processing),"This study presents German FinBERT, a novel pre-trained German language model
tailored for financial textual data. The model is trained through a
comprehensive pre-training process, leveraging a substantial corpus comprising
financial reports, ad-hoc announcements and news related to German companies.
The corpus size is comparable to the data sets commonly used for training
standard BERT models. I evaluate the performance of German FinBERT on
downstream tasks, specifically sentiment prediction, topic recognition and
question answering against generic German language models. My results
demonstrate improved performance on finance-specific data, indicating the
efficacy of German FinBERT in capturing domain-specific nuances. The presented
findings suggest that German FinBERT holds promise as a valuable tool for
financial text analysis, potentially benefiting various applications in the
financial domain.",['Moritz Scherrmann']
Convolutional Dictionary Learning through Tensor Factorization,Machine Learning,"Tensor methods have emerged as a powerful paradigm for consistent learning of
many latent variable models such as topic models, independent component
analysis and dictionary learning. Model parameters are estimated via CP
decomposition of the observed higher order input moments. However, in many
domains, additional invariances such as shift invariances exist, enforced via
models such as convolutional dictionary learning. In this paper, we develop
novel tensor decomposition algorithms for parameter estimation of convolutional
models. Our algorithm is based on the popular alternating least squares method,
but with efficient projections onto the space of stacked circulant matrices.
Our method is embarrassingly parallel and consists of simple operations such as
fast Fourier transforms and matrix multiplications. Our algorithm converges to
the dictionary much faster and more accurately compared to the alternating
minimization over filters and activation maps.","['Furong Huang', 'Animashree Anandkumar']"
"Emotional Intelligence Through Artificial Intelligence : NLP and Deep
  Learning in the Analysis of Healthcare Texts",Computation and Language (Natural Language Processing),"This manuscript presents a methodical examination of the utilization of
Artificial Intelligence in the assessment of emotions in texts related to
healthcare, with a particular focus on the incorporation of Natural Language
Processing and deep learning technologies. We scrutinize numerous research
studies that employ AI to augment sentiment analysis, categorize emotions, and
forecast patient outcomes based on textual information derived from clinical
narratives, patient feedback on medications, and online health discussions. The
review demonstrates noteworthy progress in the precision of algorithms used for
sentiment classification, the prognostic capabilities of AI models for
neurodegenerative diseases, and the creation of AI-powered systems that offer
support in clinical decision-making. Remarkably, the utilization of AI
applications has exhibited an enhancement in personalized therapy plans by
integrating patient sentiment and contributing to the early identification of
mental health disorders. There persist challenges, which encompass ensuring the
ethical application of AI, safeguarding patient confidentiality, and addressing
potential biases in algorithmic procedures. Nevertheless, the potential of AI
to revolutionize healthcare practices is unmistakable, offering a future where
healthcare is not only more knowledgeable and efficient but also more
empathetic and centered around the needs of patients. This investigation
underscores the transformative influence of AI on healthcare, delivering a
comprehensive comprehension of its role in examining emotional content in
healthcare texts and highlighting the trajectory towards a more compassionate
approach to patient care. The findings advocate for a harmonious synergy
between AI's analytical capabilities and the human aspects of healthcare.","['Prashant Kumar Nag', 'Amit Bhagat', 'R. Vishnu Priya', 'Deepak kumar Khare']"
"Perfectly Balanced: Improving Transfer and Robustness of Supervised
  Contrastive Learning",Machine Learning (Statistics),"An ideal learned representation should display transferability and
robustness. Supervised contrastive learning (SupCon) is a promising method for
training accurate models, but produces representations that do not capture
these properties due to class collapse -- when all points in a class map to the
same representation. Recent work suggests that ""spreading out"" these
representations improves them, but the precise mechanism is poorly understood.
We argue that creating spread alone is insufficient for better representations,
since spread is invariant to permutations within classes. Instead, both the
correct degree of spread and a mechanism for breaking this invariance are
necessary. We first prove that adding a weighted class-conditional InfoNCE loss
to SupCon controls the degree of spread. Next, we study three mechanisms to
break permutation invariance: using a constrained encoder, adding a
class-conditional autoencoder, and using data augmentation. We show that the
latter two encourage clustering of latent subclasses under more realistic
conditions than the former. Using these insights, we show that adding a
properly-weighted class-conditional InfoNCE loss and a class-conditional
autoencoder to SupCon achieves 11.1 points of lift on coarse-to-fine transfer
across 5 standard datasets and 4.7 points on worst-group robustness on 3
datasets, setting state-of-the-art on CelebA by 11.5 points.","['Mayee F. Chen', 'Daniel Y. Fu', 'Avanika Narayan', 'Michael Zhang', 'Zhao Song', 'Kayvon Fatahalian', 'Christopher Ré']"
Classifying Clustering Schemes,Machine Learning (Statistics),"Many clustering schemes are defined by optimizing an objective function
defined on the partitions of the underlying set of a finite metric space. In
this paper, we construct a framework for studying what happens when we instead
impose various structural conditions on the clustering schemes, under the
general heading of functoriality. Functoriality refers to the idea that one
should be able to compare the results of clustering algorithms as one varies
the data set, for example by adding points or by applying functions to it. We
show that within this framework, one can prove a theorems analogous to one of
J. Kleinberg, in which for example one obtains an existence and uniqueness
theorem instead of a non-existence result.
  We obtain a full classification of all clustering schemes satisfying a
condition we refer to as excisiveness. The classification can be changed by
varying the notion of maps of finite metric spaces. The conditions occur
naturally when one considers clustering as the statistical version of the
geometric notion of connected components. By varying the degree of
functoriality that one requires from the schemes it is possible to construct
richer families of clustering schemes that exhibit sensitivity to density.","['Gunnar Carlsson', 'Facundo Memoli']"
"Does syntax matter? A strong baseline for Aspect-based Sentiment
  Analysis with RoBERTa",Computation and Language (Natural Language Processing),"Aspect-based Sentiment Analysis (ABSA), aiming at predicting the polarities
for aspects, is a fine-grained task in the field of sentiment analysis.
Previous work showed syntactic information, e.g. dependency trees, can
effectively improve the ABSA performance. Recently, pre-trained models (PTMs)
also have shown their effectiveness on ABSA. Therefore, the question naturally
arises whether PTMs contain sufficient syntactic information for ABSA so that
we can obtain a good ABSA model only based on PTMs. In this paper, we firstly
compare the induced trees from PTMs and the dependency parsing trees on several
popular models for the ABSA task, showing that the induced tree from fine-tuned
RoBERTa (FT-RoBERTa) outperforms the parser-provided tree. The further analysis
experiments reveal that the FT-RoBERTa Induced Tree is more
sentiment-word-oriented and could benefit the ABSA task. The experiments also
show that the pure RoBERTa-based model can outperform or approximate to the
previous SOTA performances on six datasets across four languages since it
implicitly incorporates the task-oriented syntactic information.","['Junqi Dai', 'Hang Yan', 'Tianxiang Sun', 'Pengfei Liu', 'Xipeng Qiu']"
On the Expressive Power of Overlapping Architectures of Deep Learning,Machine Learning,"Expressive efficiency refers to the relation between two architectures A and
B, whereby any function realized by B could be replicated by A, but there
exists functions realized by A, which cannot be replicated by B unless its size
grows significantly larger. For example, it is known that deep networks are
exponentially efficient with respect to shallow networks, in the sense that a
shallow network must grow exponentially large in order to approximate the
functions represented by a deep network of polynomial size. In this work, we
extend the study of expressive efficiency to the attribute of network
connectivity and in particular to the effect of ""overlaps"" in the convolutional
process, i.e., when the stride of the convolution is smaller than its filter
size (receptive field). To theoretically analyze this aspect of network's
design, we focus on a well-established surrogate for ConvNets called
Convolutional Arithmetic Circuits (ConvACs), and then demonstrate empirically
that our results hold for standard ConvNets as well. Specifically, our analysis
shows that having overlapping local receptive fields, and more broadly denser
connectivity, results in an exponential increase in the expressive capacity of
neural networks. Moreover, while denser connectivity can increase the
expressive capacity, we show that the most common types of modern architectures
already exhibit exponential increase in expressivity, without relying on
fully-connected layers.","['Or Sharir', 'Amnon Shashua']"
Fire Threat Detection From Videos with Q-Rough Sets,Computer Vision and Pattern Recognition,"This article defines new methods for unsupervised fire region segmentation
and fire threat detection from video stream. Fire in control serves a number of
purposes to human civilization, but it could simultaneously be a threat once
its spread becomes uncontrolled. There exists many methods on fire region
segmentation and fire non-fire classification. But the approaches to determine
the threat associated with fire is relatively scare, and no such unsupervised
method has been formulated yet. Here we focus on developing an unsupervised
method with which the threat of fire can be quantified and accordingly generate
an alarm in automated surveillance systems in indoor as well as in outdoors.
Fire region segmentation without any manual intervention/ labelled data set is
a major challenge while formulating such a method. Here we have used rough
approximations to approximate the fire region, and to manage the incompleteness
of the knowledge base, due to absence of any prior information. Utility
maximization of Q-learning has been used to minimize ambiguities in the rough
approximations. The new set approximation method, thus developed here, is named
as Q-rough set. It is used for fire region segmentation from video frames. The
threat index of fire flame over the input video stream has been defined in sync
with the relative growth in the fire segments on the recent frames. All
theories and indices defined here have been experimentally validated with
different types of fire videos, through demonstrations and comparisons, as
superior to the state of the art.","['Debarati B. Chakrabortya', 'Vinay Detania', 'Shah Parshv Jigneshkumar']"
What makes multilingual BERT multilingual?,Computation and Language (Natural Language Processing),"Recently, multilingual BERT works remarkably well on cross-lingual transfer
tasks, superior to static non-contextualized word embeddings. In this work, we
provide an in-depth experimental study to supplement the existing literature of
cross-lingual ability. We compare the cross-lingual ability of
non-contextualized and contextualized representation model with the same data.
We found that datasize and context window size are crucial factors to the
transferability.","['Chi-Liang Liu', 'Tsung-Yuan Hsu', 'Yung-Sung Chuang', 'Hung-yi Lee']"
A Machine Learning Approach to Shipping Box Design,Machine Learning (Statistics),"Having the right assortment of shipping boxes in the fulfillment warehouse to
pack and ship customer's online orders is an indispensable and integral part of
nowadays eCommerce business, as it will not only help maintain a profitable
business but also create great experiences for customers. However, it is an
extremely challenging operations task to strategically select the best
combination of tens of box sizes from thousands of feasible ones to be
responsible for hundreds of thousands of orders daily placed on millions of
inventory products. In this paper, we present a machine learning approach to
tackle the task by formulating the box design problem prescriptively as a
generalized version of weighted $k$-medoids clustering problem, where the
parameters are estimated through a variety of descriptive analytics. We test
this machine learning approach on fulfillment data collected from Walmart U.S.
eCommerce, and our approach is shown to be capable of improving the box
utilization rate by more than $10\%$.","['Guang Yang', 'Cun Mu']"
Edge SLAM: Edge Points Based Monocular Visual SLAM,Computer Vision and Pattern Recognition,"Visual SLAM shows significant progress in recent years due to high attention
from vision community but still, challenges remain for low-textured
environments. Feature based visual SLAMs do not produce reliable camera and
structure estimates due to insufficient features in a low-textured environment.
Moreover, existing visual SLAMs produce partial reconstruction when the number
of 3D-2D correspondences is insufficient for incremental camera estimation
using bundle adjustment. This paper presents Edge SLAM, a feature based
monocular visual SLAM which mitigates the above mentioned problems. Our
proposed Edge SLAM pipeline detects edge points from images and tracks those
using optical flow for point correspondence. We further refine these point
correspondences using geometrical relationship among three views. Owing to our
edge-point tracking, we use a robust method for two-view initialization for
bundle adjustment. Our proposed SLAM also identifies the potential situations
where estimating a new camera into the existing reconstruction is becoming
unreliable and we adopt a novel method to estimate the new camera reliably
using a local optimization technique. We present an extensive evaluation of our
proposed SLAM pipeline with most popular open datasets and compare with the
state-of-the art. Experimental result indicates that our Edge SLAM is robust
and works reliably well for both textured and less-textured environment in
comparison to existing state-of-the-art SLAMs.","['Soumyadip Maity', 'Arindam Saha', 'Brojeshwar Bhowmick']"
"Exploiting Problem Structure in Deep Declarative Networks: Two Case
  Studies",Machine Learning,"Deep declarative networks and other recent related works have shown how to
differentiate the solution map of a (continuous) parametrized optimization
problem, opening up the possibility of embedding mathematical optimization
problems into end-to-end learnable models. These differentiability results can
lead to significant memory savings by providing an expression for computing the
derivative without needing to unroll the steps of the forward-pass optimization
procedure during the backward pass. However, the results typically require
inverting a large Hessian matrix, which is computationally expensive when
implemented naively. In this work we study two applications of deep declarative
networks -- robust vector pooling and optimal transport -- and show how problem
structure can be exploited to obtain very efficient backward pass computations
in terms of both time and memory. Our ideas can be used as a guide for
improving the computational performance of other novel deep declarative nodes.","['Stephen Gould', 'Dylan Campbell', 'Itzik Ben-Shabat', 'Chamin Hewa Koneputugodage', 'Zhiwei Xu']"
"Ad Hoc Microphone Array Calibration: Euclidean Distance Matrix
  Completion Algorithm and Theoretical Guarantees",Sound,"This paper addresses the problem of ad hoc microphone array calibration where
only partial information about the distances between microphones is available.
We construct a matrix consisting of the pairwise distances and propose to
estimate the missing entries based on a novel Euclidean distance matrix
completion algorithm by alternative low-rank matrix completion and projection
onto the Euclidean distance space. This approach confines the recovered matrix
to the EDM cone at each iteration of the matrix completion algorithm. The
theoretical guarantees of the calibration performance are obtained considering
the random and locally structured missing entries as well as the measurement
noise on the known distances. This study elucidates the links between the
calibration error and the number of microphones along with the noise level and
the ratio of missing distances. Thorough experiments on real data recordings
and simulated setups are conducted to demonstrate these theoretical insights. A
significant improvement is achieved by the proposed Euclidean distance matrix
completion algorithm over the state-of-the-art techniques for ad hoc microphone
array calibration.","['Mohammad J. Taghizadeh', 'Reza Parhizkar', 'Philip N. Garner', 'Herve Bourlard', 'Afsaneh Asaei']"
NOLA: Compressing LoRA using Linear Combination of Random Basis,Computation and Language (Natural Language Processing),"Fine-tuning Large Language Models (LLMs) and storing them for each downstream
task or domain is impractical because of the massive model size (e.g., 350GB in
GPT-3). Current literature, such as LoRA, showcases the potential of low-rank
modifications to the original weights of an LLM, enabling efficient adaptation
and storage for task-specific models. These methods can reduce the number of
parameters needed to fine-tune an LLM by several orders of magnitude. Yet,
these methods face two primary limitations: (1) the parameter count is
lower-bounded by the rank one decomposition, and (2) the extent of reduction is
heavily influenced by both the model architecture and the chosen rank. We
introduce NOLA, which overcomes the rank one lower bound present in LoRA. It
achieves this by re-parameterizing the low-rank matrices in LoRA using linear
combinations of randomly generated matrices (basis) and optimizing the linear
mixture coefficients only. This approach allows us to decouple the number of
trainable parameters from both the choice of rank and the network architecture.
We present adaptation results using GPT-2, LLaMA-2, and ViT in natural language
and computer vision tasks. NOLA performs as well as LoRA models with much fewer
number of parameters compared to LoRA with rank one, the best compression LoRA
can archive. Particularly, on LLaMA-2 70B, our method is almost 20 times more
compact than the most compressed LoRA without degradation in accuracy. Our code
is available here: https://github.com/UCDvision/NOLA","['Soroush Abbasi Koohpayegani', 'KL Navaneet', 'Parsa Nooralinejad', 'Soheil Kolouri', 'Hamed Pirsiavash']"
Descriptive Knowledge Graph in Biomedical Domain,Computation and Language (Natural Language Processing),"We present a novel system that automatically extracts and generates
informative and descriptive sentences from the biomedical corpus and
facilitates the efficient search for relational knowledge. Unlike previous
search engines or exploration systems that retrieve unconnected passages, our
system organizes descriptive sentences as a relational graph, enabling
researchers to explore closely related biomedical entities (e.g., diseases
treated by a chemical) or indirectly connected entities (e.g., potential drugs
for treating a disease). Our system also uses ChatGPT and a fine-tuned relation
synthesis model to generate concise and reliable descriptive sentences from
retrieved information, reducing the need for extensive human reading effort.
With our system, researchers can easily obtain both high-level knowledge and
detailed references and interactively steer to the information of interest. We
spotlight the application of our system in COVID-19 research, illustrating its
utility in areas such as drug repurposing and literature curation.","['Kerui Zhu', 'Jie Huang', 'Kevin Chen-Chuan Chang']"
"Dynamic Systems Simulation and Control Using Consecutive Recurrent
  Neural Networks",Machine Learning,"In this paper, we introduce a novel architecture to connecting adaptive
learning and neural networks into an arbitrary machine's control system
paradigm. Two consecutive Recurrent Neural Networks (RNNs) are used together to
accurately model the dynamic characteristics of electromechanical systems that
include controllers, actuators and motors. The age-old method of achieving
control with the use of the- Proportional, Integral and Derivative constants is
well understood as a simplified method that does not capture the complexities
of the inherent nonlinearities of complex control systems. In the context of
controlling and simulating electromechanical systems, we propose an alternative
to PID controllers, employing a sequence of two Recurrent Neural Networks. The
first RNN emulates the behavior of the controller, and the second the
actuator/motor. The second RNN when used in isolation, potentially serves as an
advantageous alternative to extant testing methods of electromechanical
systems.","['Srikanth Chandar', 'Harsha Sunder']"
PAPM: A Physics-aware Proxy Model for Process Systems,Machine Learning,"In the context of proxy modeling for process systems, traditional data-driven
deep learning approaches frequently encounter significant challenges, such as
substantial training costs induced by large amounts of data, and limited
generalization capabilities. As a promising alternative, physics-aware models
incorporate partial physics knowledge to ameliorate these challenges. Although
demonstrating efficacy, they fall short in terms of exploration depth and
universality. To address these shortcomings, we introduce a physics-aware proxy
model (PAPM) that fully incorporates partial prior physics of process systems,
which includes multiple input conditions and the general form of conservation
relations, resulting in better out-of-sample generalization. Additionally, PAPM
contains a holistic temporal-spatial stepping module for flexible adaptation
across various process systems. Through systematic comparisons with
state-of-the-art pure data-driven and physics-aware models across five
two-dimensional benchmarks in nine generalization tasks, PAPM notably achieves
an average performance improvement of 6.7%, while requiring fewer FLOPs, and
just 1% of the parameters compared to the prior leading method. The code is
available at https://github.com/pengwei07/PAPM.","['Pengwei Liu', 'Zhongkai Hao', 'Xingyu Ren', 'Hangjie Yuan', 'Jiayang Ren', 'Dong Ni']"
Strong Optimal Classification Trees,Machine Learning,"Decision trees are among the most popular machine learning models and are
used routinely in applications ranging from revenue management and medicine to
bioinformatics. In this paper, we consider the problem of learning optimal
binary classification trees with univariate splits. Literature on the topic has
burgeoned in recent years, motivated both by the empirical suboptimality of
heuristic approaches and the tremendous improvements in mixed-integer
optimization (MIO) technology. Yet, existing MIO-based approaches from the
literature do not leverage the power of MIO to its full extent: they rely on
weak formulations, resulting in slow convergence and large optimality gaps. To
fill this gap in the literature, we propose an intuitive flow-based MIO
formulation for learning optimal binary classification trees. Our formulation
can accommodate side constraints to enable the design of interpretable and fair
decision trees. Moreover, we show that our formulation has a stronger linear
optimization relaxation than existing methods in the case of binary data. We
exploit the decomposable structure of our formulation and max-flow/min-cut
duality to derive a Benders' decomposition method to speed-up computation. We
propose a tailored procedure for solving each decomposed subproblem that
provably generates facets of the feasible set of the MIO as constraints to add
to the main problem. We conduct extensive computational experiments on standard
benchmark datasets on which we show that our proposed approaches are 29 times
faster than state-of-the-art MIO-based techniques and improve out-of-sample
performance by up to 8%.","['Sina Aghaei', 'Andrés Gómez', 'Phebe Vayanos']"
Semantic Frame Forecast,Computation and Language (Natural Language Processing),"This paper introduces semantic frame forecast, a task that predicts the
semantic frames that will occur in the next 10, 100, or even 1,000 sentences in
a running story. Prior work focused on predicting the immediate future of a
story, such as one to a few sentences ahead. However, when novelists write long
stories, generating a few sentences is not enough to help them gain high-level
insight to develop the follow-up story. In this paper, we formulate a long
story as a sequence of ""story blocks,"" where each block contains a fixed number
of sentences (e.g., 10, 100, or 200). This formulation allows us to predict the
follow-up story arc beyond the scope of a few sentences. We represent a story
block using the term frequencies (TF) of semantic frames in it, normalized by
each frame's inverse document frequency (IDF). We conduct semantic frame
forecast experiments on 4,794 books from the Bookcorpus and 7,962 scientific
abstracts from CODA-19, with block sizes ranging from 5 to 1,000 sentences. The
results show that automated models can forecast the follow-up story blocks
better than the random, prior, and replay baselines, indicating the task's
feasibility. We also learn that the models using the frame representation as
features outperform all the existing approaches when the block size is over 150
sentences. The human evaluation also shows that the proposed frame
representation, when visualized as word clouds, is comprehensible,
representative, and specific to humans. Our code is available at
https://github.com/appleternity/FrameForecasting.","['Chieh-Yang Huang', ""Ting-Hao 'Kenneth' Huang""]"
"Potential Idiomatic Expression (PIE)-English: Corpus for Classes of
  Idioms",Computation and Language (Natural Language Processing),"We present a fairly large, Potential Idiomatic Expression (PIE) dataset for
Natural Language Processing (NLP) in English. The challenges with NLP systems
with regards to tasks such as Machine Translation (MT), word sense
disambiguation (WSD) and information retrieval make it imperative to have a
labelled idioms dataset with classes such as it is in this work. To the best of
the authors' knowledge, this is the first idioms corpus with classes of idioms
beyond the literal and the general idioms classification. In particular, the
following classes are labelled in the dataset: metaphor, simile, euphemism,
parallelism, personification, oxymoron, paradox, hyperbole, irony and literal.
We obtain an overall inter-annotator agreement (IAA) score, between two
independent annotators, of 88.89%. Many past efforts have been limited in the
corpus size and classes of samples but this dataset contains over 20,100
samples with almost 1,200 cases of idioms (with their meanings) from 10 classes
(or senses). The corpus may also be extended by researchers to meet specific
needs. The corpus has part of speech (PoS) tagging from the NLTK library.
Classification experiments performed on the corpus to obtain a baseline and
comparison among three common models, including the BERT model, give good
results. We also make publicly available the corpus and the relevant codes for
working with it for NLP tasks.","['Tosin P. Adewumi', 'Roshanak Vadoodi', 'Aparajita Tripathy', 'Konstantina Nikolaidou', 'Foteini Liwicki', 'Marcus Liwicki']"
Asynchronous Evolution of Deep Neural Network Architectures,Neural and Evolutionary Computing,"Many evolutionary algorithms (EAs) take advantage of parallel evaluation of
candidates. However, if evaluation times vary significantly, many worker nodes
(i.e.,\ compute clients) are idle much of the time, waiting for the next
generation to be created. Evolutionary neural architecture search (ENAS), a
class of EAs that optimizes the architecture and hyperparameters of deep neural
networks, is particularly vulnerable to this issue. This paper proposes a
generic asynchronous evaluation strategy (AES) that is then adapted to work
with ENAS. AES increases throughput by maintaining a queue of up to $K$
individuals ready to be sent to the workers for evaluation and proceeding to
the next generation as soon as $M<<K$ individuals have been evaluated. A
suitable value for $M$ is determined experimentally, balancing diversity and
efficiency. To showcase the generality and power of AES, it was first evaluated
in eight-line sorting network design (a single-population optimization task
with limited evaluation-time variability), achieving an over two-fold speedup.
Next, it was evaluated in 11-bit multiplexer design (a single-population
discovery task with extended variability), where a 14-fold speedup was
observed. It was then scaled up to ENAS for image captioning (a
multi-population open-ended-optimization task), resulting in an over two-fold
speedup. In all problems, a multifold performance improvement was observed,
suggesting that AES is a promising method for parallelizing the evolution of
complex systems with long and variable evaluation times, such as those in ENAS.","['Jason Liang', 'Hormoz Shahrzad', 'Risto Miikkulainen']"
Modeling Uncertain Temporal Evolutions in Model-Based Diagnosis,Artificial Intelligence,"Although the notion of diagnostic problem has been extensively investigated
in the context of static systems, in most practical applications the behavior
of the modeled system is significantly variable during time. The goal of the
paper is to propose a novel approach to the modeling of uncertainty about
temporal evolutions of time-varying systems and a characterization of
model-based temporal diagnosis. Since in most real world cases knowledge about
the temporal evolution of the system to be diagnosed is uncertain, we consider
the case when probabilistic temporal knowledge is available for each component
of the system and we choose to model it by means of Markov chains. In fact, we
aim at exploiting the statistical assumptions underlying reliability theory in
the context of the diagnosis of timevarying systems. We finally show how to
exploit Markov chain theory in order to discard, in the diagnostic process,
very unlikely diagnoses.",['Luigi Portinale']
Zero-shot Cross-lingual Conversational Semantic Role Labeling,Computation and Language (Natural Language Processing),"While conversational semantic role labeling (CSRL) has shown its usefulness
on Chinese conversational tasks, it is still under-explored in non-Chinese
languages due to the lack of multilingual CSRL annotations for the parser
training. To avoid expensive data collection and error-propagation of
translation-based methods, we present a simple but effective approach to
perform zero-shot cross-lingual CSRL. Our model implicitly learns
language-agnostic, conversational structure-aware and semantically rich
representations with the hierarchical encoders and elaborately designed
pre-training objectives. Experimental results show that our model outperforms
all baselines by large margins on two newly collected English CSRL test sets.
More importantly, we confirm the usefulness of CSRL to non-Chinese
conversational tasks such as the question-in-context rewriting task in English
and the multi-turn dialogue response generation tasks in English, German and
Japanese by incorporating the CSRL information into the downstream
conversation-based models. We believe this finding is significant and will
facilitate the research of non-Chinese dialogue tasks which suffer the problems
of ellipsis and anaphora.","['Han Wu', 'Haochen Tan', 'Kun Xu', 'Shuqi Liu', 'Lianwei Wu', 'Linqi Song']"
Generating Literal and Implied Subquestions to Fact-check Complex Claims,Computation and Language (Natural Language Processing),"Verifying complex political claims is a challenging task, especially when
politicians use various tactics to subtly misrepresent the facts. Automatic
fact-checking systems fall short here, and their predictions like ""half-true""
are not very useful in isolation, since we have no idea which parts of the
claim are true and which are not. In this work, we focus on decomposing a
complex claim into a comprehensive set of yes-no subquestions whose answers
influence the veracity of the claim. We present ClaimDecomp, a dataset of
decompositions for over 1000 claims. Given a claim and its verification
paragraph written by fact-checkers, our trained annotators write subquestions
covering both explicit propositions of the original claim and its implicit
facets, such as asking about additional political context that changes our view
of the claim's veracity. We study whether state-of-the-art models can generate
such subquestions, showing that these models generate reasonable questions to
ask, but predicting the comprehensive set of subquestions from the original
claim without evidence remains challenging. We further show that these
subquestions can help identify relevant evidence to fact-check the full claim
and derive the veracity through their answers, suggesting that they can be
useful pieces of a fact-checking pipeline.","['Jifan Chen', 'Aniruddh Sriram', 'Eunsol Choi', 'Greg Durrett']"
Approximate Cross-Validation for Structured Models,Machine Learning (Statistics),"Many modern data analyses benefit from explicitly modeling dependence
structure in data -- such as measurements across time or space, ordered words
in a sentence, or genes in a genome. A gold standard evaluation technique is
structured cross-validation (CV), which leaves out some data subset (such as
data within a time interval or data in a geographic region) in each fold. But
CV here can be prohibitively slow due to the need to re-run already-expensive
learning algorithms many times. Previous work has shown approximate
cross-validation (ACV) methods provide a fast and provably accurate alternative
in the setting of empirical risk minimization. But this existing ACV work is
restricted to simpler models by the assumptions that (i) data across CV folds
are independent and (ii) an exact initial model fit is available. In structured
data analyses, both these assumptions are often untrue. In the present work, we
address (i) by extending ACV to CV schemes with dependence structure between
the folds. To address (ii), we verify -- both theoretically and empirically --
that ACV quality deteriorates smoothly with noise in the initial fit. We
demonstrate the accuracy and computational benefits of our proposed methods on
a diverse set of real-world applications.","['Soumya Ghosh', 'William T. Stephenson', 'Tin D. Nguyen', 'Sameer K. Deshpande', 'Tamara Broderick']"
"Measuring an Artificial Intelligence System's Performance on a Verbal IQ
  Test For Young Children",Artificial Intelligence,"We administered the Verbal IQ (VIQ) part of the Wechsler Preschool and
Primary Scale of Intelligence (WPPSI-III) to the ConceptNet 4 AI system. The
test questions (e.g., ""Why do we shake hands?"") were translated into ConceptNet
4 inputs using a combination of the simple natural language processing tools
that come with ConceptNet together with short Python programs that we wrote.
The question answering used a version of ConceptNet based on spectral methods.
The ConceptNet system scored a WPPSI-III VIQ that is average for a
four-year-old child, but below average for 5 to 7 year-olds. Large variations
among subtests indicate potential areas of improvement. In particular, results
were strongest for the Vocabulary and Similarities subtests, intermediate for
the Information subtest, and lowest for the Comprehension and Word Reasoning
subtests. Comprehension is the subtest most strongly associated with common
sense. The large variations among subtests and ordinary common sense strongly
suggest that the WPPSI-III VIQ results do not show that ""ConceptNet has the
verbal abilities a four-year-old."" Rather, children's IQ tests offer one
objective metric for the evaluation and comparison of AI systems. Also, this
work continues previous research on Psychometric AI.","['Stellan Ohlsson', 'Robert H. Sloan', 'György Turán', 'Aaron Urasky']"
"Fuzzy Forests For Feature Selection in High-Dimensional Survey Data: An
  Application to the 2020 U.S. Presidential Election",Machine Learning,"An increasingly common methodological issue in the field of social science is
high-dimensional and highly correlated datasets that are unamenable to the
traditional deductive framework of study. Analysis of candidate choice in the
2020 Presidential Election is one area in which this issue presents itself: in
order to test the many theories explaining the outcome of the election, it is
necessary to use data such as the 2020 Cooperative Election Study Common
Content, with hundreds of highly correlated features. We present the Fuzzy
Forests algorithm, a variant of the popular Random Forests ensemble method, as
an efficient way to reduce the feature space in such cases with minimal bias,
while also maintaining predictive performance on par with common algorithms
like Random Forests and logit. Using Fuzzy Forests, we isolate the top
correlates of candidate choice and find that partisan polarization was the
strongest factor driving the 2020 presidential election.","['Sreemanti Dey', 'R. Michael Alvarez']"
EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment,Computer Vision and Pattern Recognition,"Vision-language models such as CLIP have boosted the performance of
open-vocabulary object detection, where the detector is trained on base
categories but required to detect novel categories. Existing methods leverage
CLIP's strong zero-shot recognition ability to align object-level embeddings
with textual embeddings of categories. However, we observe that using CLIP for
object-level alignment results in overfitting to base categories, i.e., novel
categories most similar to base categories have particularly poor performance
as they are recognized as similar base categories. In this paper, we first
identify that the loss of critical fine-grained local image semantics hinders
existing methods from attaining strong base-to-novel generalization. Then, we
propose Early Dense Alignment (EDA) to bridge the gap between generalizable
local semantics and object-level prediction. In EDA, we use object-level
supervision to learn the dense-level rather than object-level alignment to
maintain the local fine-grained semantics. Extensive experiments demonstrate
our superior performance to competing approaches under the same strict setting
and without using external training resources, i.e., improving the +8.4% novel
box AP50 on COCO and +3.9% rare mask AP on LVIS.","['Cheng Shi', 'Sibei Yang']"
"Self-Control of LLM Behaviors by Compressing Suffix Gradient into Prefix
  Controller",Computation and Language (Natural Language Processing),"We propose SelfControl, an inference-time model control method utilizing
gradients to control the behavior of large language models (LLMs) without
explicit human annotations. Given a desired behavior expressed in a natural
language suffix string concatenated to the input prompt, SelfControl computes
gradients of the LLM's self-evaluation of the suffix with respect to its latent
representations. The gradients are used to directly control the auto-regressive
generation process towards desired behaviors, which eliminates human
supervision, achieves precise and transparent control, and offers on-the-fly
adaptability. To further enhance efficiency, we introduce SelfControl_{Prefix},
a compact module that encapsulates the learned representations from gradients
into a SelfControl_{Prefix}, facilitating efficient inference-time control with
no latency compared to the original model and allowing control for multiple
behaviors simultaneously. Our experiments demonstrate SelfControl's efficacy
across multiple domains, where it improves over SOTA for 8.3% in
detoxification, 3.1% in truthfulness enhancement, 4%~10% in controlling on
emotion tones, and 48.2% in privacy protection, i.e., completely remove privacy
leakage issue. Additionally, we demonstrate that SelfControl can be used for
data synthesis and to improve reasoning abilities.","['Min Cai', 'Yuchen Zhang', 'Shichang Zhang', 'Fan Yin', 'Dan Zhang', 'Difan Zou', 'Yisong Yue', 'Ziniu Hu']"
"Bias no more: high-probability data-dependent regret bounds for
  adversarial bandits and MDPs",Machine Learning,"We develop a new approach to obtaining high probability regret bounds for
online learning with bandit feedback against an adaptive adversary. While
existing approaches all require carefully constructing optimistic and biased
loss estimators, our approach uses standard unbiased estimators and relies on a
simple increasing learning rate schedule, together with the help of
logarithmically homogeneous self-concordant barriers and a strengthened
Freedman's inequality.
  Besides its simplicity, our approach enjoys several advantages. First, the
obtained high-probability regret bounds are data-dependent and could be much
smaller than the worst-case bounds, which resolves an open problem asked by Neu
(2015). Second, resolving another open problem of Bartlett et al. (2008) and
Abernethy and Rakhlin (2009), our approach leads to the first general and
efficient algorithm with a high-probability regret bound for adversarial linear
bandits, while previous methods are either inefficient or only applicable to
specific action sets. Finally, our approach can also be applied to learning
adversarial Markov Decision Processes and provides the first algorithm with a
high-probability small-loss bound for this problem.","['Chung-Wei Lee', 'Haipeng Luo', 'Chen-Yu Wei', 'Mengxiao Zhang']"
Characterizing the dynamics of learning in repeated reference games,Computation and Language (Natural Language Processing),"The language we use over the course of conversation changes as we establish
common ground and learn what our partner finds meaningful. Here we draw upon
recent advances in natural language processing to provide a finer-grained
characterization of the dynamics of this learning process. We release an open
corpus (>15,000 utterances) of extended dyadic interactions in a classic
repeated reference game task where pairs of participants had to coordinate on
how to refer to initially difficult-to-describe tangram stimuli. We find that
different pairs discover a wide variety of idiosyncratic but efficient and
stable solutions to the problem of reference. Furthermore, these conventions
are shaped by the communicative context: words that are more discriminative in
the initial context (i.e. that are used for one target more than others) are
more likely to persist through the final repetition. Finally, we find
systematic structure in how a speaker's referring expressions become more
efficient over time: syntactic units drop out in clusters following positive
feedback from the listener, eventually leaving short labels containing
open-class parts of speech. These findings provide a higher resolution look at
the quantitative dynamics of ad hoc convention formation and support further
development of computational models of learning in communication.","['Robert D. Hawkins', 'Michael C. Frank', 'Noah D. Goodman']"
Are LLMs All You Need for Task-Oriented Dialogue?,Computation and Language (Natural Language Processing),"Instructions-tuned Large Language Models (LLMs) gained recently huge
popularity thanks to their ability to interact with users through conversation.
In this work we aim to evaluate their ability to complete multi-turn tasks and
interact with external databases in the context of established task-oriented
dialogue benchmarks. We show that for explicit belief state tracking, LLMs
underperform compared to specialized task-specific models. Nevertheless, they
show ability to guide the dialogue to successful ending if given correct slot
values. Furthermore this ability improves with access to true belief state
distribution or in-domain examples.","['Vojtěch Hudeček', 'Ondřej Dušek']"
"Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for
  Mid-term Human Mobility Prediction",Artificial Intelligence,"Predicting individual mobility patterns is crucial across various
applications. While current methods mainly focus on predicting the next
location for personalized services like recommendations, they often fall short
in supporting broader applications such as traffic management and epidemic
control, which require longer period forecasts of human mobility. This study
addresses mid-term mobility prediction, aiming to capture daily travel patterns
and forecast trajectories for the upcoming day or week. We propose a novel
Multi-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to
efficiently extract spatial and temporal information by decoupling daily
trajectories into distinct location-duration chains. Our approach employs a
hierarchical encoder to model multi-scale temporal patterns, including daily
recurrence and weekly periodicity, and utilizes a transformer-based decoder to
globally attend to predicted information in the location or duration chain.
Additionally, we introduce a spatial heterogeneous graph learner to capture
multi-scale spatial relationships, enhancing semantic-rich representations.
Extensive experiments, including statistical physics analysis, are conducted on
large-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay
Area, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to
epidemic modeling in Boston, MSTDP significantly outperforms the
best-performing baseline, achieving a remarkable 62.8% reduction in MAE for
cumulative new cases.","['Zongyuan Huang', 'Weipeng Wang', 'Shaoyu Huang', 'Marta C. Gonzalez', 'Yaohui Jin', 'Yanyan Xu']"
"Deep Transformer Networks for Time Series Classification: The NPP Safety
  Case",Machine Learning,"A challenging part of dynamic probabilistic risk assessment for nuclear power
plants is the need for large amounts of temporal simulations given various
initiating events and branching conditions from which representative feature
extraction becomes complicated for subsequent applications. Artificial
Intelligence techniques have been shown to be powerful tools in time-dependent
sequential data processing to automatically extract and yield complex features
from large data. An advanced temporal neural network referred to as the
Transformer is used within a supervised learning fashion to model the
time-dependent NPP simulation data and to infer whether a given sequence of
events leads to core damage or not. The training and testing datasets for the
Transformer are obtained by running 10,000 RELAP5-3D NPP blackout simulations
with the list of variables obtained from the RAVEN software. Each simulation is
classified as ""OK"" or ""CORE DAMAGE"" based on the consequence. The results show
that the Transformer can learn the characteristics of the sequential data and
yield promising performance with approximately 99% classification accuracy on
the testing dataset.","['Bing Zha', 'Alessandro Vanni', 'Yassin Hassan', 'Tunc Aldemir', 'Alper Yilmaz']"
"Post-Abstention: Towards Reliably Re-Attempting the Abstained Instances
  in QA",Computation and Language (Natural Language Processing),"Despite remarkable progress made in natural language processing, even the
state-of-the-art models often make incorrect predictions. Such predictions
hamper the reliability of systems and limit their widespread adoption in
real-world applications. 'Selective prediction' partly addresses the above
concern by enabling models to abstain from answering when their predictions are
likely to be incorrect. While selective prediction is advantageous, it leaves
us with a pertinent question 'what to do after abstention'. To this end, we
present an explorative study on 'Post-Abstention', a task that allows
re-attempting the abstained instances with the aim of increasing 'coverage' of
the system without significantly sacrificing its 'accuracy'. We first provide
mathematical formulation of this task and then explore several methods to solve
it. Comprehensive experiments on 11 QA datasets show that these methods lead to
considerable risk improvements -- performance metric of the Post-Abstention
task -- both in the in-domain and the out-of-domain settings. We also conduct a
thorough analysis of these results which further leads to several interesting
findings. Finally, we believe that our work will encourage and facilitate
further research in this important area of addressing the reliability of NLP
systems.","['Neeraj Varshney', 'Chitta Baral']"
Learning Class Regularized Features for Action Recognition,Computer Vision and Pattern Recognition,"Training Deep Convolutional Neural Networks (CNNs) is based on the notion of
using multiple kernels and non-linearities in their subsequent activations to
extract useful features. The kernels are used as general feature extractors
without specific correspondence to the target class. As a result, the extracted
features do not correspond to specific classes. Subtle differences between
similar classes are modeled in the same way as large differences between
dissimilar classes. To overcome the class-agnostic use of kernels in CNNs, we
introduce a novel method named Class Regularization that performs class-based
regularization of layer activations. We demonstrate that this not only improves
feature search during training, but also allows an explicit assignment of
features per class during each stage of the feature extraction process. We show
that using Class Regularization blocks in state-of-the-art CNN architectures
for action recognition leads to systematic improvement gains of 1.8%, 1.2% and
1.4% on the Kinetics, UCF-101 and HMDB-51 datasets, respectively.","['Alexandros Stergiou', 'Ronald Poppe', 'Remco C. Veltkamp']"
"Selective Greedy Equivalence Search: Finding Optimal Bayesian Networks
  Using a Polynomial Number of Score Evaluations",Machine Learning,"We introduce Selective Greedy Equivalence Search (SGES), a restricted version
of Greedy Equivalence Search (GES). SGES retains the asymptotic correctness of
GES but, unlike GES, has polynomial performance guarantees. In particular, we
show that when data are sampled independently from a distribution that is
perfect with respect to a DAG ${\cal G}$ defined over the observable variables
then, in the limit of large data, SGES will identify ${\cal G}$'s equivalence
class after a number of score evaluations that is (1) polynomial in the number
of nodes and (2) exponential in various complexity measures including
maximum-number-of-parents, maximum-clique-size, and a new measure called {\em
v-width} that is at least as small as---and potentially much smaller than---the
other two. More generally, we show that for any hereditary and
equivalence-invariant property $\Pi$ known to hold in ${\cal G}$, we retain the
large-sample optimality guarantees of GES even if we ignore any GES deletion
operator during the backward phase that results in a state for which $\Pi$ does
not hold in the common-descendants subgraph.","['David Maxwell Chickering', 'Christopher Meek']"
"A Disease Diagnosis and Treatment Recommendation System Based on Big
  Data Mining and Cloud Computing",Machine Learning,"It is crucial to provide compatible treatment schemes for a disease according
to various symptoms at different stages. However, most classification methods
might be ineffective in accurately classifying a disease that holds the
characteristics of multiple treatment stages, various symptoms, and
multi-pathogenesis. Moreover, there are limited exchanges and cooperative
actions in disease diagnoses and treatments between different departments and
hospitals. Thus, when new diseases occur with atypical symptoms, inexperienced
doctors might have difficulty in identifying them promptly and accurately.
Therefore, to maximize the utilization of the advanced medical technology of
developed hospitals and the rich medical knowledge of experienced doctors, a
Disease Diagnosis and Treatment Recommendation System (DDTRS) is proposed in
this paper. First, to effectively identify disease symptoms more accurately, a
Density-Peaked Clustering Analysis (DPCA) algorithm is introduced for
disease-symptom clustering. In addition, association analyses on
Disease-Diagnosis (D-D) rules and Disease-Treatment (D-T) rules are conducted
by the Apriori algorithm separately. The appropriate diagnosis and treatment
schemes are recommended for patients and inexperienced doctors, even if they
are in a limited therapeutic environment. Moreover, to reach the goals of high
performance and low latency response, we implement a parallel solution for
DDTRS using the Apache Spark cloud platform. Extensive experimental results
demonstrate that the proposed DDTRS realizes disease-symptom clustering
effectively and derives disease treatment recommendations intelligently and
accurately.","['Jianguo Chen', 'Kenli Li', 'Huigui Rong', 'Kashif Bilal', 'Nan Yang', 'Keqin Li']"
Meerkat Behaviour Recognition Dataset,Computer Vision and Pattern Recognition,"Recording animal behaviour is an important step in evaluating the well-being
of animals and further understanding the natural world. Current methods for
documenting animal behaviour within a zoo setting, such as scan sampling,
require excessive human effort, are unfit for around-the-clock monitoring, and
may produce human-biased results. Several animal datasets already exist that
focus predominantly on wildlife interactions, with some extending to action or
behaviour recognition. However, there is limited data in a zoo setting or data
focusing on the group behaviours of social animals. We introduce a large
meerkat (Suricata Suricatta) behaviour recognition video dataset with diverse
annotated behaviours, including group social interactions, tracking of
individuals within the camera view, skewed class distribution, and varying
illumination conditions. This dataset includes videos from two positions within
the meerkat enclosure at the Wellington Zoo (Wellington, New Zealand), with
848,400 annotated frames across 20 videos and 15 unannotated videos.","['Mitchell Rogers', 'Gaël Gendron', 'David Arturo Soriano Valdez', 'Mihailo Azhar', 'Yang Chen', 'Shahrokh Heidari', 'Caleb Perelini', ""Padriac O'Leary"", 'Kobe Knowles', 'Izak Tait', 'Simon Eyre', 'Michael Witbrock', 'Patrice Delmas']"
"Adversarial Concept Drift Detection under Poisoning Attacks for Robust
  Data Stream Mining",Machine Learning,"Continuous learning from streaming data is among the most challenging topics
in the contemporary machine learning. In this domain, learning algorithms must
not only be able to handle massive volumes of rapidly arriving data, but also
adapt themselves to potential emerging changes. The phenomenon of the evolving
nature of data streams is known as concept drift. While there is a plethora of
methods designed for detecting its occurrence, all of them assume that the
drift is connected with underlying changes in the source of data. However, one
must consider the possibility of a malicious injection of false data that
simulates a concept drift. This adversarial setting assumes a poisoning attack
that may be conducted in order to damage the underlying classification system
by forcing adaptation to false data. Existing drift detectors are not capable
of differentiating between real and adversarial concept drift. In this paper,
we propose a framework for robust concept drift detection in the presence of
adversarial and poisoning attacks. We introduce the taxonomy for two types of
adversarial concept drifts, as well as a robust trainable drift detector. It is
based on the augmented Restricted Boltzmann Machine with improved gradient
computation and energy function. We also introduce Relative Loss of Robustness
- a novel measure for evaluating the performance of concept drift detectors
under poisoning attacks. Extensive computational experiments, conducted on both
fully and sparsely labeled data streams, prove the high robustness and efficacy
of the proposed drift detection framework in adversarial scenarios.","['Łukasz Korycki', 'Bartosz Krawczyk']"
"A Dual-Perspective Metaphor Detection Framework Using Large Language
  Models",Computation and Language (Natural Language Processing),"Metaphor detection, a critical task in natural language processing, involves
identifying whether a particular word in a sentence is used metaphorically.
Traditional approaches often rely on supervised learning models that implicitly
encode semantic relationships based on metaphor theories. However, these
methods often suffer from a lack of transparency in their decision-making
processes, which undermines the reliability of their predictions. Recent
research indicates that LLMs (large language models) exhibit significant
potential in metaphor detection. Nevertheless, their reasoning capabilities are
constrained by predefined knowledge graphs. To overcome these limitations, we
propose DMD, a novel dual-perspective framework that harnesses both implicit
and explicit applications of metaphor theories to guide LLMs in metaphor
detection and adopts a self-judgment mechanism to validate the responses from
the aforementioned forms of guidance. In comparison to previous methods, our
framework offers more transparent reasoning processes and delivers more
reliable predictions. Experimental results prove the effectiveness of DMD,
demonstrating state-of-the-art performance across widely-used datasets.","['Yujie Lin', 'Jingyao Liu', 'Yan Gao', 'Ante Wang', 'Jinsong Su']"
"Unsupervised Learning with Imbalanced Data via Structure Consolidation
  Latent Variable Model",Machine Learning,"Unsupervised learning on imbalanced data is challenging because, when given
imbalanced data, current model is often dominated by the major category and
ignores the categories with small amount of data. We develop a latent variable
model that can cope with imbalanced data by dividing the latent space into a
shared space and a private space. Based on Gaussian Process Latent Variable
Models, we propose a new kernel formulation that enables the separation of
latent space and derives an efficient variational inference method. The
performance of our model is demonstrated with an imbalanced medical image
dataset.","['Fariba Yousefi', 'Zhenwen Dai', 'Carl Henrik Ek', 'Neil Lawrence']"
Trajectory growth lower bounds for random sparse deep ReLU networks,Machine Learning (Statistics),"This paper considers the growth in the length of one-dimensional trajectories
as they are passed through deep ReLU neural networks, which, among other
things, is one measure of the expressivity of deep networks. We generalise
existing results, providing an alternative, simpler method for lower bounding
expected trajectory growth through random networks, for a more general class of
weights distributions, including sparsely connected networks. We illustrate
this approach by deriving bounds for sparse-Gaussian, sparse-uniform, and
sparse-discrete-valued random nets. We prove that trajectory growth can remain
exponential in depth with these new distributions, including their sparse
variants, with the sparsity parameter appearing in the base of the exponent.","['Ilan Price', 'Jared Tanner']"
Learning Optimal Decision Trees from Large Datasets,Machine Learning,"Inferring a decision tree from a given dataset is one of the classic problems
in machine learning. This problem consists of buildings, from a labelled
dataset, a tree such that each node corresponds to a class and a path between
the tree root and a leaf corresponds to a conjunction of features to be
satisfied in this class. Following the principle of parsimony, we want to infer
a minimal tree consistent with the dataset. Unfortunately, inferring an optimal
decision tree is known to be NP-complete for several definitions of optimality.
Hence, the majority of existing approaches relies on heuristics, and as for the
few exact inference approaches, they do not work on large data sets. In this
paper, we propose a novel approach for inferring a decision tree of a minimum
depth based on the incremental generation of Boolean formula. The experimental
results indicate that it scales sufficiently well and the time it takes to run
grows slowly with the size of dataset.",['Florent Avellaneda']
Space-Time Diffusion Bridge,Machine Learning (Statistics),"In this study, we introduce a novel method for generating new synthetic
samples that are independent and identically distributed (i.i.d.) from
high-dimensional real-valued probability distributions, as defined implicitly
by a set of Ground Truth (GT) samples. Central to our method is the integration
of space-time mixing strategies that extend across temporal and spatial
dimensions. Our methodology is underpinned by three interrelated stochastic
processes designed to enable optimal transport from an easily tractable initial
probability distribution to the target distribution represented by the GT
samples: (a) linear processes incorporating space-time mixing that yield
Gaussian conditional probability densities, (b) their diffusion bridge analogs
that are conditioned to the initial and final state vectors, and (c) nonlinear
stochastic processes refined through score-matching techniques. The crux of our
training regime involves fine-tuning the nonlinear model, and potentially the
linear models -- to align closely with the GT data. We validate the efficacy of
our space-time diffusion approach with numerical experiments, laying the
groundwork for more extensive future theory and experiments to fully
authenticate the method, particularly providing a more efficient (possibly
simulation-free) inference.","['Hamidreza Behjoo', 'Michael Chertkov']"
"Self-Learning for Received Signal Strength Map Reconstruction with
  Neural Architecture Search",Machine Learning,"In this paper, we present a Neural Network (NN) model based on Neural
Architecture Search (NAS) and self-learning for received signal strength (RSS)
map reconstruction out of sparse single-snapshot input measurements, in the
case where data-augmentation by side deterministic simulations cannot be
performed. The approach first finds an optimal NN architecture and
simultaneously train the deduced model over some ground-truth measurements of a
given (RSS) map. These ground-truth measurements along with the predictions of
the model over a set of randomly chosen points are then used to train a second
NN model having the same architecture. Experimental results show that signal
predictions of this second model outperforms non-learning based interpolation
state-of-the-art techniques and NN models with no architecture search on five
large-scale maps of RSS measurements.","['Aleksandra Malkova', 'Loic Pauletto', 'Christophe Villien', 'Benoit Denis', 'Massih-Reza Amini']"
"How Suitable Are Subword Segmentation Strategies for Translating
  Non-Concatenative Morphology?",Computation and Language (Natural Language Processing),"Data-driven subword segmentation has become the default strategy for
open-vocabulary machine translation and other NLP tasks, but may not be
sufficiently generic for optimal learning of non-concatenative morphology. We
design a test suite to evaluate segmentation strategies on different types of
morphological phenomena in a controlled, semi-synthetic setting. In our
experiments, we compare how well machine translation models trained on subword-
and character-level can translate these morphological phenomena. We find that
learning to analyse and generate morphologically complex surface
representations is still challenging, especially for non-concatenative
morphological phenomena like reduplication or vowel harmony and for rare word
stems. Based on our results, we recommend that novel text representation
strategies be tested on a range of typologically diverse languages to minimise
the risk of adopting a strategy that inadvertently disadvantages certain
languages.","['Chantal Amrhein', 'Rico Sennrich']"
Joint Optimization of Piecewise Linear Ensembles,Machine Learning,"Tree ensembles achieve state-of-the-art performance on numerous prediction
tasks. We propose $\textbf{J}$oint $\textbf{O}$ptimization of
$\textbf{P}$iecewise $\textbf{L}$inear $\textbf{En}$sembles (JOPLEn), which
jointly fits piecewise linear models at all leaf nodes of an existing tree
ensemble. In addition to enhancing the ensemble expressiveness, JOPLEn allows
several common penalties, including sparsity-promoting and subspace-norms, to
be applied to nonlinear prediction. For example, JOPLEn with a nuclear norm
penalty learns subspace-aligned functions. Additionally, JOPLEn (combined with
a Dirty LASSO penalty) is an effective feature selection method for nonlinear
prediction in multitask learning. Finally, we demonstrate the performance of
JOPLEn on 153 regression and classification datasets and with a variety of
penalties. JOPLEn leads to improved prediction performance relative to not only
standard random forest and boosted tree ensembles, but also other methods for
enhancing tree ensembles.","['Matt Raymond', 'Angela Violi', 'Clayton Scott']"
"Hyperspectral pan-sharpening: a variational convex constrained
  formulation to impose parallel level lines, solved with ADMM",Computer Vision and Pattern Recognition,"In this paper, we address the issue of hyperspectral pan-sharpening, which
consists in fusing a (low spatial resolution) hyperspectral image HX and a
(high spatial resolution) panchromatic image P to obtain a high spatial
resolution hyperspectral image. The problem is addressed under a variational
convex constrained formulation. The objective favors high resolution spectral
bands with level lines parallel to those of the panchromatic image. This term
is balanced with a total variation term as regularizer. Fit-to-P data and
fit-to-HX data constraints are effectively considered as mathematical
constraints, which depend on the statistics of the data noise measurements. The
developed Alternating Direction Method of Multipliers (ADMM) optimization
scheme enables us to solve this problem efficiently despite the non
differentiabilities and the huge number of unknowns.","['Alexis Huck', 'François de Vieilleville', 'Pierre Weiss', 'Manuel Grizonnet']"
VMF-SNE: Embedding for Spherical Data,Machine Learning,"T-SNE is a well-known approach to embedding high-dimensional data and has
been widely used in data visualization. The basic assumption of t-SNE is that
the data are non-constrained in the Euclidean space and the local proximity can
be modelled by Gaussian distributions. This assumption does not hold for a wide
range of data types in practical applications, for instance spherical data for
which the local proximity is better modelled by the von Mises-Fisher (vMF)
distribution instead of the Gaussian. This paper presents a vMF-SNE embedding
algorithm to embed spherical data. An iterative process is derived to produce
an efficient embedding. The results on a simulation data set demonstrated that
vMF-SNE produces better embeddings than t-SNE for spherical data.","['Mian Wang', 'Dong Wang']"
Learning Longer-term Dependencies via Grouped Distributor Unit,Neural and Evolutionary Computing,"Learning long-term dependencies still remains difficult for recurrent neural
networks (RNNs) despite their success in sequence modeling recently. In this
paper, we propose a novel gated RNN structure, which contains only one gate.
Hidden states in the proposed grouped distributor unit (GDU) are partitioned
into groups. For each group, the proportion of memory to be overwritten in each
state transition is limited to a constant and is adaptively distributed to each
group member. In other word, every separate group has a fixed overall update
rate, yet all units are allowed to have different paces. Information is
therefore forced to be latched in a flexible way, which helps the model to
capture long-term dependencies in data. Besides having a simpler structure, GDU
is demonstrated experimentally to outperform LSTM and GRU on tasks including
both pathological problems and natural data set.","['Wei Luo', 'Feng Yu']"
Selective Sampling for Online Best-arm Identification,Machine Learning,"This work considers the problem of selective-sampling for best-arm
identification. Given a set of potential options
$\mathcal{Z}\subset\mathbb{R}^d$, a learner aims to compute with probability
greater than $1-\delta$, $\arg\max_{z\in \mathcal{Z}} z^{\top}\theta_{\ast}$
where $\theta_{\ast}$ is unknown. At each time step, a potential measurement
$x_t\in \mathcal{X}\subset\mathbb{R}^d$ is drawn IID and the learner can either
choose to take the measurement, in which case they observe a noisy measurement
of $x^{\top}\theta_{\ast}$, or to abstain from taking the measurement and wait
for a potentially more informative point to arrive in the stream. Hence the
learner faces a fundamental trade-off between the number of labeled samples
they take and when they have collected enough evidence to declare the best arm
and stop sampling. The main results of this work precisely characterize this
trade-off between labeled samples and stopping time and provide an algorithm
that nearly-optimally achieves the minimal label complexity given a desired
stopping time. In addition, we show that the optimal decision rule has a simple
geometric form based on deciding whether a point is in an ellipse or not.
Finally, our framework is general enough to capture binary classification
improving upon previous works.","['Romain Camilleri', 'Zhihan Xiong', 'Maryam Fazel', 'Lalit Jain', 'Kevin Jamieson']"
Soft Computing approaches on the Bandwidth Problem,Artificial Intelligence,"The Matrix Bandwidth Minimization Problem (MBMP) seeks for a simultaneous
reordering of the rows and the columns of a square matrix such that the nonzero
entries are collected within a band of small width close to the main diagonal.
The MBMP is a NP-complete problem, with applications in many scientific
domains, linear systems, artificial intelligence, and real-life situations in
industry, logistics, information recovery. The complex problems are hard to
solve, that is why any attempt to improve their solutions is beneficent.
Genetic algorithms and ant-based systems are Soft Computing methods used in
this paper in order to solve some MBMP instances. Our approach is based on a
learning agent-based model involving a local search procedure. The algorithm is
compared with the classical Cuthill-McKee algorithm, and with a hybrid genetic
algorithm, using several instances from Matrix Market collection. Computational
experiments confirm a good performance of the proposed algorithms for the
considered set of MBMP instances. On Soft Computing basis, we also propose a
new theoretical Reinforcement Learning model for solving the MBMP problem.","['Gabriela Czibula', 'Gloria Cerasela Crisan', 'Camelia-M. Pintea', 'Istvan-Gergely Czibula']"
"Hybrid Oracle: Making Use of Ambiguity in Transition-based Chinese
  Dependency Parsing",Computation and Language (Natural Language Processing),"In the training of transition-based dependency parsers, an oracle is used to
predict a transition sequence for a sentence and its gold tree. However, the
transition system may exhibit ambiguity, that is, there can be multiple correct
transition sequences that form the gold tree. We propose to make use of the
property in the training of neural dependency parsers, and present the Hybrid
Oracle. The new oracle gives all the correct transitions for a parsing state,
which are used in the cross entropy loss function to provide better supervisory
signal. It is also used to generate different transition sequences for a
sentence to better explore the training data and improve the generalization
ability of the parser. Evaluations show that the parsers trained using the
hybrid oracle outperform the parsers using the traditional oracle in Chinese
dependency parsing. We provide analysis from a linguistic view. The code is
available at https://github.com/lancopku/nndep .","['Xuancheng Ren', 'Xu Sun']"
Evaluate Geometry of Radiance Fields with Low-frequency Color Prior,Computer Vision and Pattern Recognition,"A radiance field is an effective representation of 3D scenes, which has been
widely adopted in novel-view synthesis and 3D reconstruction. It is still an
open and challenging problem to evaluate the geometry, i.e., the density field,
as the ground-truth is almost impossible to obtain. One alternative indirect
solution is to transform the density field into a point-cloud and compute its
Chamfer Distance with the scanned ground-truth. However, many widely-used
datasets have no point-cloud ground-truth since the scanning process along with
the equipment is expensive and complicated. To this end, we propose a novel
metric, named Inverse Mean Residual Color (IMRC), which can evaluate the
geometry only with the observation images. Our key insight is that the better
the geometry, the lower-frequency the computed color field. From this insight,
given a reconstructed density field and observation images, we design a
closed-form method to approximate the color field with low-frequency spherical
harmonics, and compute the inverse mean residual color. Then the higher the
IMRC, the better the geometry. Qualitative and quantitative experimental
results verify the effectiveness of our proposed IMRC metric. We also benchmark
several state-of-the-art methods using IMRC to promote future related research.
Our code is available at https://github.com/qihangGH/IMRC.","['Qihang Fang', 'Yafei Song', 'Keqiang Li', 'Li Shen', 'Huaiyu Wu', 'Gang Xiong', 'Liefeng Bo']"
Robust Regression via Hard Thresholding,Machine Learning,"We study the problem of Robust Least Squares Regression (RLSR) where several
response variables can be adversarially corrupted. More specifically, for a
data matrix X \in R^{p x n} and an underlying model w*, the response vector is
generated as y = X'w* + b where b \in R^n is the corruption vector supported
over at most C.n coordinates. Existing exact recovery results for RLSR focus
solely on L1-penalty based convex formulations and impose relatively strict
model assumptions such as requiring the corruptions b to be selected
independently of X.
  In this work, we study a simple hard-thresholding algorithm called TORRENT
which, under mild conditions on X, can recover w* exactly even if b corrupts
the response variables in an adversarial manner, i.e. both the support and
entries of b are selected adversarially after observing X and w*. Our results
hold under deterministic assumptions which are satisfied if X is sampled from
any sub-Gaussian distribution. Finally unlike existing results that apply only
to a fixed w*, generated independently of X, our results are universal and hold
for any w* \in R^p.
  Next, we propose gradient descent-based extensions of TORRENT that can scale
efficiently to large scale problems, such as high dimensional sparse recovery
and prove similar recovery guarantees for these extensions. Empirically we find
TORRENT, and more so its extensions, offering significantly faster recovery
than the state-of-the-art L1 solvers. For instance, even on moderate-sized
datasets (with p = 50K) with around 40% corrupted responses, a variant of our
proposed method called TORRENT-HYB is more than 20x faster than the best L1
solver.","['Kush Bhatia', 'Prateek Jain', 'Purushottam Kar']"
Opinion mining of text documents written in Macedonian language,Computation and Language (Natural Language Processing),"The ability to extract public opinion from web portals such as review sites,
social networks and blogs will enable companies and individuals to form a view,
an attitude and make decisions without having to do lengthy and costly
researches and surveys. In this paper machine learning techniques are used for
determining the polarity of forum posts on kajgana which are written in
Macedonian language. The posts are classified as being positive, negative or
neutral. We test different feature metrics and classifiers and provide detailed
evaluation of their participation in improving the overall performance on a
manually generated dataset. By achieving 92% accuracy, we show that the
performance of systems for automated opinion mining is comparable to a human
evaluator, thus making it a viable option for text data analysis. Finally, we
present a few statistics derived from the forum posts using the developed
system.","['Andrej Gajduk', 'Ljupco Kocarev']"
"Scalability vs. Utility: Do We Have to Sacrifice One for the Other in
  Data Importance Quantification?",Machine Learning,"Quantifying the importance of each training point to a learning task is a
fundamental problem in machine learning and the estimated importance scores
have been leveraged to guide a range of data workflows such as data
summarization and domain adaption. One simple idea is to use the leave-one-out
error of each training point to indicate its importance. Recent work has also
proposed to use the Shapley value, as it defines a unique value distribution
scheme that satisfies a set of appealing properties. However, calculating
Shapley values is often expensive, which limits its applicability in real-world
applications at scale. Multiple heuristics to improve the scalability of
calculating Shapley values have been proposed recently, with the potential risk
of compromising their utility in real-world applications.
  \textit{How well do existing data quantification methods perform on existing
workflows? How do these methods compare with each other, empirically and
theoretically? Must we sacrifice scalability for the utility in these workflows
when using these methods?} In this paper, we conduct a novel theoretical
analysis comparing the utility of different importance quantification methods,
and report extensive experimental studies on existing and proposed workflows
such as noisy label detection, watermark removal, data summarization, data
acquisition, and domain adaptation. We show that Shapley value approximation
based on a $K$NN surrogate over pre-trained feature embeddings obtains
comparable utility with existing algorithms while achieving significant
scalability improvement, often by orders of magnitude. Our theoretical analysis
also justifies its advantage over the leave-one-out error.
  The code is available at \url{https://github.com/AI-secure/Shapley-Study}.","['Ruoxi Jia', 'Fan Wu', 'Xuehui Sun', 'Jiacen Xu', 'David Dao', 'Bhavya Kailkhura', 'Ce Zhang', 'Bo Li', 'Dawn Song']"
Cormorant: Covariant Molecular Neural Networks,Computational Physics,"We propose Cormorant, a rotationally covariant neural network architecture
for learning the behavior and properties of complex many-body physical systems.
We apply these networks to molecular systems with two goals: learning atomic
potential energy surfaces for use in Molecular Dynamics simulations, and
learning ground state properties of molecules calculated by Density Functional
Theory. Some of the key features of our network are that (a) each neuron
explicitly corresponds to a subset of atoms; (b) the activation of each neuron
is covariant to rotations, ensuring that overall the network is fully
rotationally invariant. Furthermore, the non-linearity in our network is based
upon tensor products and the Clebsch-Gordan decomposition, allowing the network
to operate entirely in Fourier space. Cormorant significantly outperforms
competing algorithms in learning molecular Potential Energy Surfaces from
conformational geometries in the MD-17 dataset, and is competitive with other
methods at learning geometric, energetic, electronic, and thermodynamic
properties of molecules on the GDB-9 dataset.","['Brandon Anderson', 'Truong-Son Hy', 'Risi Kondor']"
